
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 114 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-zhiya-IT外企--一直都在注意Oracle的招聘信息/">一直都在注意Oracle的招聘信息</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-zhiya-IT外企--一直都在注意Oracle的招聘信息/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-oracle-">一直都在注意Oracle的招聘信息</h1>
<p>一直都在注意Oracle的招聘信息，毕竟是世界第二大软件公司呀。可是，奇怪的是观察了很长的时间都没有发现任何招聘广告。并且，从我对它的初步了解来看，与微软，Google中国研发中心比起来，它显得那样的无声无息。终于有一天的早上，打开zhaopin.com，第一次发现了Oracle的招聘信息。高兴的是，里边包括若干个测试的职位。马上把简历投了过去。下午接到了电话，一听果然就是Oracle的，要跟我安排面试。Oracle的招聘比较奇怪，没有recruiter,都是hiring manager跟你联系。
面试当天，早了几分钟来到公司，被前台领到一间会议室里面，给了一套试题来做。同屋已经有好几个人在做题了，心理顿感不爽。本来以为是要单独给我面试的，没想到竟然会跟大家一起做题。更没想到的是，当我打开试题的时候，我好像基本都不会做。实话实说，我并没有什么Oracle的技术背景，可是我觉得做测试也不需要懂这么多试题上的知识吧？硬着头皮做了两道，实在做不下去了，起身就走。到了前台，告诉他们我感觉这个面试不对劲。他们才反应过来给搞错了。忙着给我的hiring manager打电话，让我去了她那里。
Hiring manager是个中年女士，看起来人就很nice。面试也是在一间会议室进行的，做了一屋子的人。看来对一个测试人员的面试也搞得挺隆重。Hiring manager并没有提问，第一个提问的是个技术大拿。他面试的场面我还从来没经历过。简单的说就是，他看着你简历问你问题，问得肯定是你做过的东西，但是，问得深度是特别的深，一般你还回答不上来。这种知识面，深度的人，到任何地方都是大拿。我是挺佩服的。第二个面试的可能是一个香港人，他主要是考察我的英文水平，用英文跟我聊了很长时间。第三个人主要是考察我的Linux的技术，很抱歉好久没有用Linux了，问我的很多简单的命令，本来我以前是会的，可是忘记了。不过，这个时候那个manager讲话了，说我的背景学Linux应该是很快的事情。然后我主要跟他们聊了自动化测试的东西，他们竟然还没有什么自动化的测试，基本还是靠手工测试。他们也希望我能够在自动化测试方面能够给公司带来些新鲜的东西。
第二天，manager给我打电话，说美国的老板想跟我聊聊。与此同时，我也接受到美国的一封email,要跟我电话面试，搞得我有点迷惑。最后才知道，是两个不同的老板要跟我面试。定了周末两天的上午，因为对方是在加州，我们合适的时间只有每天的上午。第一天面试是一个中国人，不过我们全是用英文交谈的。看得出他对我很满意，多次给我说这个职位不是在他的team，如果对方的不要我，我可以来他的team。他是做日本方面的项目，另一个team是做 open source的项目。一直谈的都很愉快，直到谈到待遇的问题。说实话，我当时的目标是每月2万，不过由于微软，Google的情况还不明朗，不想再错过这次机会，因此就要了每月1.5万。没想到他却明确回答不能满足，并跟我说他们有很多福利等等。最后问我要多少钱，我就回答算上福利全年20万。实际上当时有点傻，因为月薪1.5万和加上福利年薪20万应该是差不多的。对方就没有再说什么，我们结束了谈话。第二天是个老外，主要谈一些技术的问题吧，我也没感觉是好是坏，因为昨天的人已经说过不行就去他的team了。
不过，后来他们就再也没跟我联系过。我估计是我的要价太高了，而且我最近知道我一个朋友有多年的Oracle经验，刚刚进入他们那里，也不过是20万年薪。这样解释了我的一个疑惑。我当时就奇怪，堂堂一个Oracle怎么把研发中心放到上地。看来他们本身就不想投入太多。后来又听人说，这个中心的老板不地道，总之有一些rumor,不知道是真是假。
我想当时如果我真想进的话，开口小点应该是没什么问题的。这里给大家介绍一个面试的经验，对方的技术你不熟悉可能不是一个大问题。面试的时候，一定要有自信，让对方知道你有能力，有激情，有头脑。并且，一定要大胆跟他们讨论一些你擅长的技术问题。让他们更细致的了解你的能力，留下与其他人不一样的印象，就更容易打动他们。还有一个经验就是，谈待遇的时候，如果你真的想进这个公司，你就不要说具体数目了，就说我很珍惜这个工作进会，我一直都期望能进入你们的公司，你们可以按照标准给我工资就可以了，我没什么特殊的要求。我后来的面试在待遇上都是如此回答的，并且都得到了offer。
下次有时间，讲讲我去微软，北电面试的经验教训。</p>
<p>来源： <a href="[http://www.linuxdiyf.com/viewarticle.php?id=97760](http://www.linuxdiyf.com/viewarticle.php?id=97760)">[http://www.linuxdiyf.com/viewarticle.php?id=97760](http://www.linuxdiyf.com/viewarticle.php?id=97760)</a></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/zhiya/">zhiya</a></li></span><span class="breadcrumb"><li><a href="/categories/职涯/">职涯</a></li><li><a href="/categories/职涯/IT外企/">IT外企</a></li></span></span> | <span class="tags">Tagged <a href="/tags/IT外企/" class="label label-primary">IT外企</a><a href="/tags/zhiya/" class="label label-success">zhiya</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-zhiya-IT外企--一直都在注意Oracle的招聘信息/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-zhiya-IT外企--一直都在注意Oracle的招聘信息" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事6：管理路线和技术路线/">IT外企那点儿事(6)：管理路线和技术路线</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事6：管理路线和技术路线/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="it-6-">IT外企那点儿事(6)：管理路线和技术路线</h1>
<p><a href=""></a></p>
<h1 id="-http-www-cnblogs-com-forfuture1978-"><a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a></h1>
<p>  <a href="http://www.cnblogs.com/" target="_blank">博客园</a> :: <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">首页</a> :: <a href="http://q.cnblogs.com/" target="_blank">博问</a> :: <a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?opt=1" target="_blank">新随笔</a> :: <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">联系</a> :: <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank">订阅</a> <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank"><img src="" alt="订阅"></a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx" target="_blank">管理</a> :: <img src="" alt="">   130 随笔 :: 0 文章 :: 544 评论 :: 0 引用
<a href="">&lt;</a>2010年5月<a href="">&gt;</a>日一二三四五六252627282930<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/01.html" target="_blank">1</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/02.html" target="_blank">2</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03.html" target="_blank">3</a>4<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05.html" target="_blank">5</a>67<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/08.html" target="_blank">8</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/09.html" target="_blank">9</a>101112<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13.html" target="_blank">13</a>1415<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/16.html" target="_blank">16</a>1718<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/19.html" target="_blank">19</a>2021<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/22.html" target="_blank">22</a>23<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/24.html" target="_blank">24</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/25.html" target="_blank">25</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/26.html" target="_blank">26</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/27.html" target="_blank">27</a>2829303112345</p>
<h3 id="-">公告</h3>
<p>昵称：<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
园龄：<a href="http://home.cnblogs.com/u/forfuture1978/" title="入园时间：2009-12-10" target="_blank">3年7个月</a>
荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
粉丝：<a href="http://home.cnblogs.com/u/forfuture1978/followers/" target="_blank">560</a>
关注：<a href="http://home.cnblogs.com/u/forfuture1978/followees/" target="_blank">3</a></p>
<p><a href="">+加关注</a></p>
<h3 id="-">搜索</h3>
<h3 id="-">常用链接</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/MyPosts.html" target="_blank">我的随笔</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/MyComments.html" target="_blank">我的评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/OtherPosts.html" title="我发表过评论的随笔" target="_blank">我的参与</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/RecentComments.html" target="_blank">最新评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/tag/" target="_blank">我的标签</a></li>
</ul>
<h3 id="-">随笔分类</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300670.html" target="_blank">Hadoop原理与代码分析(7)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事(12)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345798.html" target="_blank">Java(2)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345797.html" target="_blank">Linux(14)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300665.html" target="_blank">Lucene原理与代码分析(38)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300666.html" target="_blank">长尾理论(16)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345794.html" target="_blank">管理学(10)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345800.html" target="_blank">经济学(4)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345796.html" target="_blank">算法(1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345795.html" target="_blank">闲话IT业(3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300667.html" target="_blank">心理学与管理学效应(9)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300668.html" target="_blank">组织行为学(15)</a></li>
</ul>
<h3 id="-">随笔档案</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11.html" target="_blank">2012年11月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/01.html" target="_blank">2012年1月 (5)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/12.html" target="_blank">2011年12月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/10.html" target="_blank">2011年10月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/09.html" target="_blank">2011年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11.html" target="_blank">2010年11月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/10.html" target="_blank">2010年10月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/09.html" target="_blank">2010年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08.html" target="_blank">2010年8月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/07.html" target="_blank">2010年7月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06.html" target="_blank">2010年6月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05.html" target="_blank">2010年5月 (22)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04.html" target="_blank">2010年4月 (18)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/03.html" target="_blank">2010年3月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02.html" target="_blank">2010年2月 (39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/01.html" target="_blank">2010年1月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12.html" target="_blank">2009年12月 (6)</a></li>
</ul>
<h3 id="-">相册</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/gallery/247104.html" target="_blank">IT外企那点儿事</a></li>
</ul>
<h3 id="-">最新评论</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2727561" target="_blank">1. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li>楼主怎么之后没有更新hadoop的相关信息了呢？是没有再研究了吗？</li>
<li>--lyeoswu</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html#2713121" target="_blank">2. Re:Lucene 原理与代码分析完整版</a></li>
<li>提个建议，你生成的pdf中没有目录，影响阅读，用office转制的过程中其实设置一下即可，方便大众嘛~，还望能发我一份，谢谢！
sendreams@hotmail.com</li>
<li>--sendreams</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2712415" target="_blank">3. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>mojunbin
现在这公司，本来做的Siverlight，我进去后没多久就转JAVA了，最近在公司折腾JAVA的一些东西，业余时间玩玩游戏，看看CLR、并折腾linux。现在观点有所转变，觉得学技术更多的是为了扩宽思维、提高眼界</li>
<li>--峰顶飞龙</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2711923" target="_blank">4. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>峰顶飞龙
您的经历和我差不多，呵呵。不晓得现在兄弟在搞C/C++呢？</li>
<li>--mojunbin</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/23/1884967.html#2708814" target="_blank">5. Re:Hadoop学习总结之五：Hadoop的运行痕迹</a></li>
<li>楼主你好，在远程调试MapReduce时，本地代码进入不了自定义的job类，而是进入到Credentials class中，此类在hadoop-core-1.0.4.jar中，请问楼主在调试过程可否遇到此问题？</li>
<li>--彭莉珊</li>
</ul>
<h3 id="-">阅读排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">1. IT外企那点儿事(8)：又是一年加薪时(26799)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">2. Lucene 原理与代码分析完整版(25616)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02/23/1671909.html" target="_blank">3. 从技术生命周期看IT历史(20878)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12/21/1628546.html" target="_blank">4. 101个著名的管理学及心理学效应(20828)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/14/1877086.html" target="_blank">5. Hadoop学习总结之三：Map-Reduce入门(18681)</a></li>
</ul>
<h3 id="-">评论排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(68)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05/1727644.html" target="_blank">2. IT外企那点儿事(4)：激动人心的入职演讲(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">3. IT外企那点儿事(6)：管理路线和技术路线(37)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">4. IT外企那点儿事(8)：又是一年加薪时(35)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">5. IT外企那点儿事(12)：也说跳槽(33)</a></li>
</ul>
<h3 id="-">推荐排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(55)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03/1726200.html" target="_blank">2. IT外企那点儿事(3)：奇怪的面试(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">3. IT外企那点儿事(8)：又是一年加薪时(36)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">4. IT外企那点儿事(12)：也说跳槽(34)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">5. IT外企那点儿事(6)：管理路线和技术路线(27)</a></li>
</ul>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">IT外企那点儿事(6)：管理路线和技术路线</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/30/1725341.html" target="_blank">IT外企那点儿事(1)：外企也就那么回事</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/02/1725948.html" target="_blank">IT外企那点儿事(2)：多种多样的外企</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03/1726200.html" target="_blank">IT外企那点儿事(3)：奇怪的面试</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05/1727644.html" target="_blank">IT外企那点儿事(4)：激动人心的入职演讲</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/09/1730857.html" target="_blank">IT外企那点儿事(5)：像系统一样升级</a></p>
<p>技术路线和管理路线始终是每个程序员纠结的问题，也是各大论坛经常被辩论的问题。</p>
<p>然而一个有趣的现象是，在现实生活中，人们多愿意承认自己不精通某项技术，却很少有人愿意承认自己不能做管理。技术方面有问题多能够校正自我，而管理方面有了问题却总认为是对方的错，总之领导怨员工，员工怨领导，闹得不可开交。</p>
<p>在中国传统的官本位的思想中，不能不说管理路线占了绝对性的优势，尤其是在稳定的外企，管好管坏极难衡量的情况下。</p>
<p>做技术苦啊，相比于管理路线，有如下的弱势：</p>
<p>首先，IT业的技术变化太快，弄的技术人员疲于奔命。年轻人可以每天晚上几个小时的看新技术的书籍，而年纪偏大的你上有老下有小，做饭，洗衣，陪老婆，照顾老人小孩，逛超市，每天能有一个小时的学习时间十分不易了。如果是你已经很熟悉的领域，你自然可以用较少的时间就能达到年轻人较长时间看完的东西(理想状态下)，然而公司的项目所用的技术方向可不是随你心愿的。如果你是一个Java高手，碰巧公司买的一个第三方的库是用C++写的，需要对其进行封装，如此艰巨的任务，工程师中你的薪水最高，你不入地狱谁入地狱啊。你总不能说：我只负责Java的部分，C++的别来找我吧。</p>
<p>也许你经常听领导说：“编程主要靠思想，语言和平台无所谓”。然而如果你跳槽的时候，却经常听到面试官这样说：“好像你没有太多这方面的经验嘛”，你却不能以我很有编程的思想来回答。此矛盾之处着实使人困惑许久。技术路线还是分很多的方向的，正如武林有很多的门派。语言，操作系统等属于内功，然而只有内功却不足以行走江湖，必须还要有一定的套路，如Debug tool，profile tool，出现问题后的分析办法，编程时候的各种习惯，一些非常管用的技巧等，都是因语言和平台不同而不同。虽然对于初级的工程师来说，这些不是很重要，然而工作三年五年之后，是否能够熟练运用这些套路来准确的定位问题和解决问题，却是区别你是初级工程师，还是高级工程师的一个标志。当然当你在上升到项目经理的时候，又可以只谈编程思想的时候了。一句实话，一个要饭的不要因为听富人说吃青菜养生就见肉也不吃。周易中，同样在乾卦，同样元亨利贞，初九则应潜龙勿用，九五则可飞龙在天了，不同的位，同样的话，意义不同。</p>
<p>其次，没有优先知情权。当任务到来的时候，美国那面的老大一般是先发邮件给项目经理的。项目经理会进行一系列统筹考虑后再选择发给那些人。作为同项目经理同一级别的技术人员，是否提前或同时，甚至晚于与其他技术人员收到邮件，取决于你技术外的能力(你的reputation, 你和项目经理的关系等)。上面的文章也说过了，在外企，邮件是一门很大的学问，也决定了从属关系。把本来你擅长的任务先发邮件给他人，从而变成了他人的任务，也不是不可能的事情。当然当美国老板过来的时候，陪同和展示成果的，也多是管理人员的事情，虽然里面全是你的心血。</p>
<p>其三，没有资源支配权。项目经理一般可以支配多种资源的，如买硬件，Team building的经费，培训的机会等。但是相同级别的技术人员却没有。</p>
<p>其四，没有绩效评定权。任何员工的绩效都是基本由其report得顶头上司起决定作用的。相同级别的技术人员可能会有一些评价做参考，但是你不会知道和你平级甚至下级的薪水和绩效。</p>
<p>最后，没有人事任免权。一个员工是否能够进某个项目组，也基本是项目经理起决定作用的。一般的外企都会有推荐的制度，而通常会发现一般状况下(被推荐人不是明显的差)，管理路线的人推荐到其他组的人比较容易录取(同组推荐没有推荐费啊)。大家总要多少照顾个面子嘛，万一哪天要向对方的组推荐自己的人呢？</p>
<p>基于上述几点，经济基础决定上层建筑，你也就怪不得基层员工对你仅仅是因为技术而产生的尊敬，而对manager则是因为既威且信而产生的敬畏了。也许其实是你的建议是正确的，大家却都同意按照manager的来做；也许你一把年纪还要和年轻人因一个小小的设计争得面红耳赤，而他在manager面前总是yes, ok, i am 100% agree；也许你因一项新技术不很精通而被新人鄙视；也许就没有也许。</p>
<p>当前的中国是浮躁的，以上的原因造成大批大批的人涌入管理路线的独木桥，也造成了一些不合格的管理者走上了管理岗位。也许有这样的现象，明明在国外仅够做高级工程师的在中国做了Team lead，却在和普通工程师争功劳；在国外仅够做Team lead的，在中国做了manager，却不能很好的领导多层化的组织结构。</p>
<p>这种情况是悲剧的，却不仅仅在软件业，包括高校(系主任更容易拿项目)，包括医院(院长更容易申请经费)，包括研究所。</p>
<p>这也是为什么总有转管理，转售前，转销售，甚至转其他行业的论调的原因了。</p>
<p>其实技术路线也有它的好处，你可以埋头认认真真研究自己感兴趣的技术，两耳不闻窗外事。而由于一直没有放下技术，跳槽也相对容易的多，毕竟在中国，号称会管理一个团队的一抓一大把，而真的很有经验的技术人员却不是很多。</p>
<p>作为软件工程师，我们应该找到一条属于我们自己的路。</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/IT6_147DC/%C3%A6%C2%BC%C2%94%C3%A7%C2%A4%C2%BA%C3%A6%C2%96%C2%87%C3%A7%C2%A8%C2%BF1_2.jpg" target="_blank"><img src="&quot;演示文稿1&quot;" alt="演示文稿1"></a></p>
<p>让我们来看上述三条曲线，是随着时间的推移，收入的变化。</p>
<p>很不幸，技术人员的收入曲线基本成C曲线状，也即刚开始收人较高，也能较快增加，后面随着时间的推移，收人增长略显平缓。</p>
<p>这主要是技术更新迅速的结果，设想从工作开始，就接触某项技术和某项框架，逐渐的掌握直到精通，到了十年的时候，正是规模效应开始体现的时候，可惜，此框架已经不流行了，已经淘汰了，行业中已经使用另一种语言或者框架了。也许你会说，以我十年的经验，对于新的框架也会更好的掌握。是的，我承认，然而由于框架的更新，你所谓的更好的程度，相对于刚接触新框架两三年的人来讲，公司不足以付给你另外7年经验所应给的薪水，毕竟，你也不是很熟。所以C曲线的形态显示出来了，由于技术的更新，你所得到的薪水增长远远低于你的经验所应该带来的薪水增长。</p>
<p>原因就在于：不易积累。</p>
<p>积累，尤其是对我们普通人来讲，是非常重要的，是最后成功的重要途径。当我们看《大家》栏目的时候，其实我们可以看出，这些成功人士基本上分两种，一种是天才，很年轻就能够取得很伟大的成就，当然我们不可能是这种人。另一种是泰斗，即靠多年的积累而取得的最后的成就，比如2008年获中国国家最高科学技术奖的吴征镒院士，被称为中国植物的“活词典”。虽然我们不期望能够成为大家，但是他们的精神和经验却能给我们启迪。像植物，或者是医生，是相对比较容易积累的行业，吴老可以在90高龄，如数家珍的说着自己年轻的时候积累下来的各种植物的知识。而工作十年的软件工程师，却难以启齿十年前的语言和框架，那已经out了。</p>
<p>这也是为什么很多销售的同学最后薪水会越做增长越快的原因。比如他们培养一个客户能得来收入1000元，随着客户的不断积累，手中有20个客户就有20000元。而软件工程师，看了10本fortran的书，得到一份1000元的工作，后来又读了10本Java的书，再加上经验，可能得到1500元的工作。</p>
<p>所以，我们也要学会积累，争取从C曲线变成B曲线，使得我们积累的经验能够带来相应的薪水。所以本人窃以为(仅供参考，自己的路还是要自己走)，有至于从事技术的软件工程师，尽量选择一些可以积累，相对稳定的方向，如Linxu内核，windows driver等，相信一个做了10年的Linux kernel工程师，绝不是一个可以读几本书就能够赶上的人。而很多流行的上层框架，如SSH等，如果你熟悉了它们的每一行代码，当Web开发开始使用其他框架的时候，岂不悲剧。(没别的以上，也希望SSH青春常在)</p>
<p>然而如果在事业的后期，想成就A曲线，就不是容易的事了。</p>
<p>当你想以较少的经验积累获得较高的收入，则必须要有放大器的作用，这种放大器我们经常能够接触的到，即营销。</p>
<p>很多研发人员十分鄙视管理和销售，营销。然而我认为，我们可以不从事管理和销售工作，然而我们最好了解一些人与人之间的交流规则，而非天天埋头于人与机器的交流规则。</p>
<p>可以举几个例子，比如我们卖烤鸭，当我们做的不好吃的时候(技术不好)，一只烤鸭卖5块钱，慢慢的我们有经验了，能烤出好吃的烤鸭了，也就能够卖10块钱，再加上好吃的调料，良好的环境，最多也就一只20元，到头了。而全聚德的烤鸭198元一只。</p>
<p>再比如，普通包子铺的包子5毛一个，你如果能够做的好吃1块一个，也就差不多了，而天津狗不理包子一个10多块，20多块。</p>
<p>这就是营销的作用，这就是品牌的力量。</p>
<p>也就可以理解为什么李开复要给大学生写信了，从而创新工厂即便比原来薪水少，即便每周工作60小时，也有大批程序员欣然而往。也就可以理解各个公司的老总总是不定时的出现在电视上，不断重复着自己成功的故事。</p>
<p>程序员不应该老待在自己的圈子里面，埋头做着自己的事情，而是要想办法扩大自己的影响力，多交朋友，多参加技术会议，多参加各种聚会。</p>
<p>有很多人抱怨，刚毕业就要工作经验，诸葛亮没有工作经验，不也成功就业了吗？《三国演义》中是这样描述诸葛亮的&quot;或驾小舟游于江湖之中，或访僧道于山岭之上，或寻朋友于村落之间，或乐琴棋于洞府之内，往来莫测，不知去所&quot;。这那是隐居啊，不出茅庐而名声在外，工作也是至交徐庶鼎力推荐的，卧龙先生可不仅仅是束发读史书啊。</p>
<p>总而言之，窃以为，做一个程序员，一要钻下去，积累技术，二要跳出来，影响世界(虽然只是一点点)。</p>
<p>分类: <a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事</a></p>
<p>绿色通道： <a href="">好文要顶</a> <a href="">关注我</a> <a href="">收藏该文</a><a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">与我联系</a> <a href="&quot;分享至新浪微博&quot;"><img src="" alt=""></a>
<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank"><img src="" alt=""></a></p>
<p><a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followees" target="_blank">关注 - 3</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followers" target="_blank">粉丝 - 560</a></p>
<p>荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
<a href="">+加关注</a></p>
<p>27</p>
<p>0
(请您对文章做出评价)</p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/09/1730857.html" target="_blank">«</a> 上一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/09/1730857.html" title="发布于2010-05-09 01:10" target="_blank">IT外企那点儿事(5)：像系统一样升级</a>
<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/16/1736482.html" target="_blank">»</a> 下一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/16/1736482.html" title="发布于2010-05-16 00:18" target="_blank">linux Kill多个进程</a>
posted on 2010-05-13 01:51 <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a> 阅读(8195) 评论(37) <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?postid=1734162" target="_blank">编辑</a> <a href="">收藏</a></p>
<p><a href=""></a></p>
<h3 id="-">评论</h3>
<p><a href="">/#1楼</a><a href=""></a>  2010-05-13 06:22  <a href="http://www.cnblogs.com/thinkriver/">我写的不是代码 是寂寞</a> <a href="http://space.cnblogs.com/msg/send/%e6%88%91%e5%86%99%e7%9a%84%e4%b8%8d%e6%98%af%e4%bb%a3%e7%a0%81+%e6%98%af%e5%af%82%e5%af%9e" title="发送站内短消息" target="_blank"> </a></p>
<p>&quot;做一个程序员，一要钻下去，积累技术，二要跳出来，影响世界&quot; 说的好。
窃以为，做一个程序员，就应该追求这样的境界，哈哈～</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u82735.jpg" target="_blank">http://pic.cnitblog.com/face/u82735.jpg</a></p>
<p><a href="">/#2楼</a><a href=""></a>  2010-05-13 08:31  <a href="http://www.cnblogs.com/gaotianle/">高天乐</a> <a href="http://space.cnblogs.com/msg/send/%e9%ab%98%e5%a4%a9%e4%b9%90" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主文采真好，说了很多实际有用的话。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#3楼</a><a href=""></a>  2010-05-13 08:44  <a href="http://www.cnblogs.com/schoolers/">兔兔子</a> <a href="http://space.cnblogs.com/msg/send/%e5%85%94%e5%85%94%e5%ad%90" title="发送站内短消息" target="_blank"> </a></p>
<p>在我国，只做技术的是没有什么前途！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u121822.jpg?id=08205343" target="_blank">http://pic.cnitblog.com/face/u121822.jpg?id=08205343</a></p>
<p><a href="">/#4楼</a><a href=""></a>  2010-05-13 09:08  <a href="http://www.cnblogs.com/mvpajun/">Showdren</a> <a href="http://space.cnblogs.com/msg/send/Showdren" title="发送站内短消息" target="_blank"> </a></p>
<p>就技术与管理说下自己的想法，有个发现，以前有很多迷茫的时候，而走出迷茫的方法就是重新寻找目标，而定制的目标都是与技术或学习有关，然后就充电，在这个过程中，慢慢的就会发现学习可以使自己有信心。但是这个目标的定位自己也不知道是不是正确，可能就是没有经过所以处于无知状态。您的文章给我的新的启示，想要以后做什么，给自己的定位应该越早越好。可是又回到原点了，怎么合理的确定自己以后的发展...，这个问题一直在我脑中循环。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u25855.jpg" target="_blank">http://pic.cnitblog.com/face/u25855.jpg</a></p>
<p><a href="">/#5楼</a><a href=""></a>  2010-05-13 09:18  <a href="http://www.cnblogs.com/coki/">Coki</a> <a href="http://space.cnblogs.com/msg/send/Coki" title="发送站内短消息" target="_blank"> </a></p>
<p>写的太对了！一直跟着看果然是正确的！
顺便问一个小问题，我感觉是有道理的，请高人解析：
技术，特别是软件开发技术，整体的发展好像是一个不断的堆积木的过程，某个时期的上层技术经过一段时间的发展就极有可能慢慢沉淀下去变成下层技术了。
从纵向来看，比如C之于汇编，刚开始C是上层技术，当有比C更上层的技术出现之后，比如C++之类，C语言就渐渐成为了下层技术，而出现JAVA、.Net这类技术之后，C++又渐渐的下沉了。
从横向来看，原本的算法累积起来变成模块，模块组织起来变成组件，组件合并之后变成框架，基于框架之上开发出应用程序，而之后这些程序加入更庞大的项目又会变成基础结构。随着软件业的发展，更大更复杂的软件系统越来越多，这个趋势就越明显。
那么，会不会有一天，会产生基于.NET之上的更智能更简洁的技术？比如第四代语言？更加智能的语言？这些技术会用来解决更复杂的问题？其实随着.NET体系的不断发展，这个也越来越明显了，WPF\SilverLight\linq\AEF等等这些随着.NET发展逐渐添加进来的东西越来越趋向于把.NET原先浮在表面上的技术压下去。
究竟符合什么特征的技术会被时代挑选出来，进而保留成下一个时代的底层技术呢？其实人类的整体发展也是在不断地积累，被验证正确的可用的东西会慢慢沉降下去，前一代人研究一生的发现，在当今的教科书上可能也就一笔带过了，扯得更远一点，会不会有哪一天，人类发现自己已经无力控制庞大的知识了，以至于只能在前人的基础上继续创造，而如果哪一天前人留下的东西损坏了，人类的文明就会失去根基，彻底崩塌呢？
呵呵……年轻人的胡思乱想，还望智者不要见笑啦！~</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#6楼</a><a href=""></a>  2010-05-13 09:25  <a href="http://www.cnblogs.com/beyondjay/">Tony Zhou</a> <a href="http://space.cnblogs.com/msg/send/Tony+Zhou" title="发送站内短消息" target="_blank"> </a></p>
<p>那一开始不做程序员做销售不就好了么。。。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u24912.png" target="_blank">http://pic.cnitblog.com/face/u24912.png</a></p>
<p><a href="">/#7楼</a><a href=""></a>  2010-05-13 09:37  <a href="http://www.cnblogs.com/pinpkm/">个人知识管理</a> <a href="http://space.cnblogs.com/msg/send/%e4%b8%aa%e4%ba%ba%e7%9f%a5%e8%af%86%e7%ae%a1%e7%90%86" title="发送站内短消息" target="_blank"> </a></p>
<p>一只烤鸭卖5块钱，慢慢的我们有经验了，能烤出好吃的烤鸭了，也就能够卖10块钱，再加上好吃的调料，良好的环境，最多也就一只20元，到头了。而全聚德的烤鸭198元一只
==和技术无关，和资本有关；
资本会改变你的客户定位</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#8楼</a><a href=""></a>[楼主]  2010-05-13 10:05  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>Tony Zhou
谢谢您的关注。
本文章是对从事软件工程师的困惑的思考而已，我还是爱软件业的，而不是爱销售业啊。
而且千万不要非此即彼的二元思维啊，我觉得程序员思想要开阔，要包容一些，而不要自我清高啊。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#9楼</a><a href=""></a>[楼主]  2010-05-13 10:07  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>Coki
很有见地啊。
这方面还真的没有仔细考虑过。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#10楼</a><a href=""></a>  2010-05-13 10:19  <a href="http://www.cnblogs.com/jciwolf/">Jerry Qian</a> <a href="http://space.cnblogs.com/msg/send/Jerry+Qian" title="发送站内短消息" target="_blank"> </a></p>
<p>哈哈顶顶。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#11楼</a><a href=""></a>  2010-05-13 10:36  <a href="http://www.cnblogs.com/nuaalfm/">你听海是不是在笑</a> <a href="http://space.cnblogs.com/msg/send/%e4%bd%a0%e5%90%ac%e6%b5%b7%e6%98%af%e4%b8%8d%e6%98%af%e5%9c%a8%e7%ac%91" title="发送站内短消息" target="_blank"> </a></p>
<p>行，相当有道理啊，而且可以看出作者的知识相当的渊博啊</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u6998.png?id=09133001" target="_blank">http://pic.cnitblog.com/face/u6998.png?id=09133001</a></p>
<p><a href="">/#12楼</a><a href=""></a>  2010-05-13 10:54  <a href="http://www.cnblogs.com/touch/">oyster.oy</a> <a href="http://space.cnblogs.com/msg/send/oyster.oy" title="发送站内短消息" target="_blank"> </a></p>
<p>不错~</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u115643.png" target="_blank">http://pic.cnitblog.com/face/u115643.png</a></p>
<p><a href="">/#13楼</a><a href=""></a>  2010-05-13 10:56  <a href="http://www.cnblogs.com/jiahello/">禅酷</a> <a href="http://space.cnblogs.com/msg/send/%e7%a6%85%e9%85%b7" title="发送站内短消息" target="_blank"> </a></p>
<p>我说技术就要做底层的，管理要做高层的，永远不过时。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u36146.jpg" target="_blank">http://pic.cnitblog.com/face/u36146.jpg</a></p>
<p><a href="">/#14楼</a><a href=""></a>  2010-05-13 11:01  <a href="http://www.cnblogs.com/millen/">赵文星</a> <a href="http://space.cnblogs.com/msg/send/%e8%b5%b5%e6%96%87%e6%98%9f" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主这个系列真的很不错，给人的启示很深啊。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#15楼</a><a href=""></a>  2010-05-13 11:54  <a href="http://www.cnblogs.com/tcom/">T.M</a> <a href="http://space.cnblogs.com/msg/send/T.M" title="发送站内短消息" target="_blank"> </a></p>
<p>受教了，顶</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#16楼</a><a href=""></a>  2010-05-13 12:13  <a href="http://www.cnblogs.com/bmate/">悟道2010</a> <a href="http://space.cnblogs.com/msg/send/%e6%82%9f%e9%81%932010" title="发送站内短消息" target="_blank"> </a></p>
<p>推荐，收藏．话说．没见过198一只的鸭子．也没见过10几20几块一个的包子．想像不出来是啥样子．持续关注此系列．
另外邀请.net大牛加入本人qq群868500</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#17楼</a><a href=""></a>  2010-05-13 12:17  <a href="http://www.cnblogs.com/Damon/">Damon.Tian</a> <a href="http://space.cnblogs.com/msg/send/Damon.Tian" title="发送站内短消息" target="_blank"> </a></p>
<p>国内程序员都在求生存，国外程序员都在求发展。人力成本的差别注定我们大部分都会是一个杯具。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u82873.png?id=10094316" target="_blank">http://pic.cnitblog.com/face/u82873.png?id=10094316</a></p>
<p><a href="">/#18楼</a><a href=""></a>  2010-05-13 12:34  <a href="http://www.cnblogs.com/wing011203/">李胜攀</a> <a href="http://space.cnblogs.com/msg/send/%e6%9d%8e%e8%83%9c%e6%94%80" title="发送站内短消息" target="_blank"> </a></p>
<p>说的真好！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/26980/20130411124002.png" target="_blank">http://pic.cnitblog.com/face/26980/20130411124002.png</a></p>
<p><a href="">/#19楼</a><a href=""></a>  2010-05-13 15:19  <a href="http://www.cnblogs.com/shiyangxt/">施杨</a> <a href="http://space.cnblogs.com/msg/send/%e6%96%bd%e6%9d%a8" title="发送站内短消息" target="_blank"> </a></p>
<p>好文章，喜欢最后一句</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u34037.jpg" target="_blank">http://pic.cnitblog.com/face/u34037.jpg</a></p>
<p><a href="">/#20楼</a><a href=""></a>  2010-05-13 15:39  <a href="http://www.cnblogs.com/pmallen/">AllenLee</a> <a href="http://space.cnblogs.com/msg/send/AllenLee" title="发送站内短消息" target="_blank"> </a></p>
<p>我一直埋头研究技术，看来需要重新规划下了</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#21楼</a><a href=""></a>  2010-05-13 15:47  <a href="http://www.cnblogs.com/Aaron_Anubis/">Aaron_Aanubis</a> <a href="http://space.cnblogs.com/msg/send/Aaron_Aanubis" title="发送站内短消息" target="_blank"> </a></p>
<p>师者，所以传道受业解惑也。真该尊称您声：“老师”！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#22楼</a><a href=""></a>[楼主]  2010-05-13 16:01  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>Aaron_Aanubis
不敢不敢，一些感悟而已，与大家分享，可能有不对的地方，关键还是自己把握自己的人生啊。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#23楼</a><a href=""></a>  2010-05-13 16:03  <a href="http://www.cnblogs.com/duncannjm/">duncannjm</a> <a href="http://space.cnblogs.com/msg/send/duncannjm" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主好文笔，不仅仅是个技术的，看来博客园还是人才济济啊。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u38570.jpg?id=12171922" target="_blank">http://pic.cnitblog.com/face/u38570.jpg?id=12171922</a></p>
<p><a href="">/#24楼</a><a href=""></a>  2010-05-13 16:35  <a href="http://www.cnblogs.com/shijianmin/">史建敏</a> <a href="http://space.cnblogs.com/msg/send/%e5%8f%b2%e5%bb%ba%e6%95%8f" title="发送站内短消息" target="_blank"> </a></p>
<p>//<em>/</em>
@ 史建敏
/*/
每天一回，最热帖子</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#25楼</a><a href=""></a>  2010-05-13 18:19  <a href="http://www.cnblogs.com/wudiwushen/">波哥2010</a> <a href="http://space.cnblogs.com/msg/send/%e6%b3%a2%e5%93%a52010" title="发送站内短消息" target="_blank"> </a></p>
<p>每天专研一点点，只要你坚持就必定成功，但是人呀！惰性!所以你要仔细看好自己的方向！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#26楼</a><a href=""></a>  2010-05-13 20:19  <a href="http://www.cnblogs.com/aiaitiantian/">aiaitiantian</a> <a href="http://space.cnblogs.com/msg/send/aiaitiantian" title="发送站内短消息" target="_blank"> </a></p>
<p>情商和智商都要发展，齐头并进。每天坐在电脑前确实会散发出一种呆气，不愿意跟人交流了。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#27楼</a><a href=""></a>  2010-05-13 21:44  <a href="http://www.cnblogs.com/yuphone/">.COM 缺氧</a> <a href="http://space.cnblogs.com/msg/send/.COM+%e7%bc%ba%e6%b0%a7" title="发送站内短消息" target="_blank"> </a></p>
<p>长见识了。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u97502.jpg" target="_blank">http://pic.cnitblog.com/face/u97502.jpg</a></p>
<p><a href="">/#28楼</a><a href=""></a>  2010-05-13 22:52  <a href="http://www.cnblogs.com/gracestoney/">gracestoney</a> <a href="http://space.cnblogs.com/msg/send/gracestoney" title="发送站内短消息" target="_blank"> </a></p>
<p>写的很不错，支持下<del>~</del>~
技术和管理完全是不同的方向啊，如果转管理，其实也要学很多很多东西，管理是一门艺术，要想得道也要持之以恒啦。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#29楼</a><a href=""></a>  2010-05-14 09:23  <a href="http://www.cnblogs.com/liu_xf/">liu_xf</a> <a href="http://space.cnblogs.com/msg/send/liu_xf" title="发送站内短消息" target="_blank"> </a></p>
<p>写到我心坎上去了
楼主我转载了，时不时的看一下，鞭策自已</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u46640.jpg" target="_blank">http://pic.cnitblog.com/face/u46640.jpg</a></p>
<p><a href="">/#30楼</a><a href=""></a>  2010-05-14 09:48  <a href="http://www.cnblogs.com/kerrycode/">潇湘隐者</a> <a href="http://space.cnblogs.com/msg/send/%e6%bd%87%e6%b9%98%e9%9a%90%e8%80%85" title="发送站内短消息" target="_blank"> </a></p>
<p>深受启发</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u73542.jpg" target="_blank">http://pic.cnitblog.com/face/u73542.jpg</a></p>
<p><a href="">/#31楼</a><a href=""></a>  2010-05-14 09:52  <a href="http://home.cnblogs.com/u/128713/">柳东</a> <a href="http://space.cnblogs.com/msg/send/%e6%9f%b3%e4%b8%9c" title="发送站内短消息" target="_blank"> </a></p>
<p>我徘徊在技术与销售之间.......还没找工作</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#32楼</a><a href=""></a>  2010-05-14 10:59  <a href="http://www.cnblogs.com/cjc1021/">开心每一天ㄨ</a> <a href="http://space.cnblogs.com/msg/send/%e5%bc%80%e5%bf%83%e6%af%8f%e4%b8%80%e5%a4%a9%e3%84%a8" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>柳东
静待兄弟去向</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u25669.jpg" target="_blank">http://pic.cnitblog.com/face/u25669.jpg</a></p>
<p><a href="">/#33楼</a><a href=""></a>  2010-05-14 16:58  <a href="http://home.cnblogs.com/u/66400/">sunnyysb</a> <a href="http://space.cnblogs.com/msg/send/sunnyysb" title="发送站内短消息" target="_blank"> </a></p>
<p>哈哈，顶顶</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#34楼</a><a href=""></a>  2010-05-22 21:40  <a href="http://home.cnblogs.com/u/134973/">fyljf</a> <a href="http://space.cnblogs.com/msg/send/fyljf" title="发送站内短消息" target="_blank"> </a></p>
<p>博主的例子总是举得很到位</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#35楼</a><a href=""></a>  2010-09-20 13:21  <a href="http://www.cnblogs.com/huyh/">hans.hu</a> <a href="http://space.cnblogs.com/msg/send/hans.hu" title="发送站内短消息" target="_blank"> </a></p>
<p>关于积累的例子,说得太到位了.
我认为技术上的积累无非就是这两类比较有前景:1,底层核心的部分（如Linux Kernel）;2,高门槛、更新慢（如SAP）。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#36楼</a><a href=""></a>  2011-07-25 23:28  <a href="http://home.cnblogs.com/u/318507/">YYCY</a> <a href="http://space.cnblogs.com/msg/send/YYCY" title="发送站内短消息" target="_blank"> </a></p>
<p>谢谢楼主，说的太好了</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#37楼</a><a href=""></a>25368142012/11/16 12:39:49  2012-11-16 12:39  <a href="http://www.cnblogs.com/bear412/">冲锋撞大树</a> <a href="http://space.cnblogs.com/msg/send/%e5%86%b2%e9%94%8b%e6%92%9e%e5%a4%a7%e6%a0%91" title="发送站内短消息" target="_blank"> </a></p>
<p>真心受教了。。。先钻下去，就是为了跳出来的那天，厚聚薄发！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/377438/20130316092316.png" target="_blank">http://pic.cnitblog.com/face/377438/20130316092316.png</a></p>
<p><a href="">刷新评论</a><a href="">刷新页面</a><a href="">返回顶部</a></p>
<p>注册用户登录后才能发表评论，请 <a href="">登录</a> 或 <a href="">注册</a>，<a href="http://www.cnblogs.com/" target="_blank">访问</a>网站首页。
<a href="http://www.cnblogs.com/" title="程序员的网上家园" target="_blank">博客园首页</a><a href="http://q.cnblogs.com/" title="程序员问答社区" target="_blank">博问</a><a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">新闻</a><a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a><a href="http://job.cnblogs.com/" target="_blank">程序员招聘</a><a href="http://kb.cnblogs.com/" target="_blank">知识库</a></p>
<p><strong>最新IT新闻</strong>:
· <a href="http://news.cnblogs.com/n/182486/" target="_blank">新硬硬整合时代</a>
· <a href="http://news.cnblogs.com/n/182485/" target="_blank">狗血的百度91并购案啊 阿里和周鸿祎都曾掺和</a>
· <a href="http://news.cnblogs.com/n/182483/" target="_blank">如何让搜索引擎抓取AJAX内容？</a>
· <a href="http://news.cnblogs.com/n/182482/" target="_blank">避免代码注释的五大理由</a>
· <a href="http://news.cnblogs.com/n/182481/" target="_blank">OpenWrt——适用于路由器的Linux系统</a>
» <a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">更多新闻...</a></p>
<p><strong>最新知识库文章</strong>:
· <a href="http://kb.cnblogs.com/page/141892/" target="_blank">阿里巴巴集团去IOE运动的思考与总结</a>
· <a href="http://kb.cnblogs.com/page/182265/" target="_blank">硅谷归来7点分享：创业者，做你自己</a>
· <a href="http://kb.cnblogs.com/page/182200/" target="_blank">我为什么不能坚持？</a>
· <a href="http://kb.cnblogs.com/page/168725/" target="_blank">成为高效程序员的7个重要习惯</a>
· <a href="http://kb.cnblogs.com/page/182047/" target="_blank">谈谈对BPM的理解</a>
» <a href="http://kb.cnblogs.com/" target="_blank">更多知识库文章...</a>
Powered by:
<a href="http://www.cnblogs.com/" target="_blank">博客园</a>
Copyright © 觉先</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/zhiya/">zhiya</a></li></span><span class="breadcrumb"><li><a href="/categories/职涯/">职涯</a></li><li><a href="/categories/职涯/IT外企/">IT外企</a></li></span></span> | <span class="tags">Tagged <a href="/tags/IT外企/" class="label label-primary">IT外企</a><a href="/tags/zhiya/" class="label label-success">zhiya</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:37"datetime="2014-03-07 09:54:37"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事6：管理路线和技术路线/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-zhiya-IT外企--IT外企那点儿事6：管理路线和技术路线" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事5：像系统一样升级/">IT外企那点儿事(5)：像系统一样升级</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事5：像系统一样升级/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="it-5-">IT外企那点儿事(5)：像系统一样升级</h1>
<p><a href=""></a></p>
<h1 id="-http-www-cnblogs-com-forfuture1978-"><a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a></h1>
<p>  <a href="http://www.cnblogs.com/" target="_blank">博客园</a> :: <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">首页</a> :: <a href="http://q.cnblogs.com/" target="_blank">博问</a> :: <a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?opt=1" target="_blank">新随笔</a> :: <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">联系</a> :: <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank">订阅</a> <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank"><img src="" alt="订阅"></a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx" target="_blank">管理</a> :: <img src="" alt="">   130 随笔 :: 0 文章 :: 544 评论 :: 0 引用
<a href="">&lt;</a>2010年5月<a href="">&gt;</a>日一二三四五六252627282930<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/01.html" target="_blank">1</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/02.html" target="_blank">2</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03.html" target="_blank">3</a>4<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05.html" target="_blank">5</a>67<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/08.html" target="_blank">8</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/09.html" target="_blank">9</a>101112<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13.html" target="_blank">13</a>1415<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/16.html" target="_blank">16</a>1718<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/19.html" target="_blank">19</a>2021<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/22.html" target="_blank">22</a>23<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/24.html" target="_blank">24</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/25.html" target="_blank">25</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/26.html" target="_blank">26</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/27.html" target="_blank">27</a>2829303112345</p>
<h3 id="-">公告</h3>
<p>昵称：<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
园龄：<a href="http://home.cnblogs.com/u/forfuture1978/" title="入园时间：2009-12-10" target="_blank">3年7个月</a>
荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
粉丝：<a href="http://home.cnblogs.com/u/forfuture1978/followers/" target="_blank">560</a>
关注：<a href="http://home.cnblogs.com/u/forfuture1978/followees/" target="_blank">3</a></p>
<p><a href="">+加关注</a></p>
<h3 id="-">搜索</h3>
<h3 id="-">常用链接</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/MyPosts.html" target="_blank">我的随笔</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/MyComments.html" target="_blank">我的评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/OtherPosts.html" title="我发表过评论的随笔" target="_blank">我的参与</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/RecentComments.html" target="_blank">最新评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/tag/" target="_blank">我的标签</a></li>
</ul>
<h3 id="-">随笔分类</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300670.html" target="_blank">Hadoop原理与代码分析(7)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事(12)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345798.html" target="_blank">Java(2)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345797.html" target="_blank">Linux(14)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300665.html" target="_blank">Lucene原理与代码分析(38)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300666.html" target="_blank">长尾理论(16)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345794.html" target="_blank">管理学(10)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345800.html" target="_blank">经济学(4)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345796.html" target="_blank">算法(1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345795.html" target="_blank">闲话IT业(3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300667.html" target="_blank">心理学与管理学效应(9)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300668.html" target="_blank">组织行为学(15)</a></li>
</ul>
<h3 id="-">随笔档案</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11.html" target="_blank">2012年11月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/01.html" target="_blank">2012年1月 (5)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/12.html" target="_blank">2011年12月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/10.html" target="_blank">2011年10月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/09.html" target="_blank">2011年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11.html" target="_blank">2010年11月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/10.html" target="_blank">2010年10月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/09.html" target="_blank">2010年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08.html" target="_blank">2010年8月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/07.html" target="_blank">2010年7月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06.html" target="_blank">2010年6月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05.html" target="_blank">2010年5月 (22)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04.html" target="_blank">2010年4月 (18)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/03.html" target="_blank">2010年3月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02.html" target="_blank">2010年2月 (39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/01.html" target="_blank">2010年1月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12.html" target="_blank">2009年12月 (6)</a></li>
</ul>
<h3 id="-">相册</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/gallery/247104.html" target="_blank">IT外企那点儿事</a></li>
</ul>
<h3 id="-">最新评论</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2727561" target="_blank">1. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li>楼主怎么之后没有更新hadoop的相关信息了呢？是没有再研究了吗？</li>
<li>--lyeoswu</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html#2713121" target="_blank">2. Re:Lucene 原理与代码分析完整版</a></li>
<li>提个建议，你生成的pdf中没有目录，影响阅读，用office转制的过程中其实设置一下即可，方便大众嘛~，还望能发我一份，谢谢！
sendreams@hotmail.com</li>
<li>--sendreams</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2712415" target="_blank">3. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>mojunbin
现在这公司，本来做的Siverlight，我进去后没多久就转JAVA了，最近在公司折腾JAVA的一些东西，业余时间玩玩游戏，看看CLR、并折腾linux。现在观点有所转变，觉得学技术更多的是为了扩宽思维、提高眼界</li>
<li>--峰顶飞龙</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2711923" target="_blank">4. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>峰顶飞龙
您的经历和我差不多，呵呵。不晓得现在兄弟在搞C/C++呢？</li>
<li>--mojunbin</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/23/1884967.html#2708814" target="_blank">5. Re:Hadoop学习总结之五：Hadoop的运行痕迹</a></li>
<li>楼主你好，在远程调试MapReduce时，本地代码进入不了自定义的job类，而是进入到Credentials class中，此类在hadoop-core-1.0.4.jar中，请问楼主在调试过程可否遇到此问题？</li>
<li>--彭莉珊</li>
</ul>
<h3 id="-">阅读排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">1. IT外企那点儿事(8)：又是一年加薪时(26799)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">2. Lucene 原理与代码分析完整版(25616)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02/23/1671909.html" target="_blank">3. 从技术生命周期看IT历史(20878)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12/21/1628546.html" target="_blank">4. 101个著名的管理学及心理学效应(20828)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/14/1877086.html" target="_blank">5. Hadoop学习总结之三：Map-Reduce入门(18681)</a></li>
</ul>
<h3 id="-">评论排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(68)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05/1727644.html" target="_blank">2. IT外企那点儿事(4)：激动人心的入职演讲(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">3. IT外企那点儿事(6)：管理路线和技术路线(37)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">4. IT外企那点儿事(8)：又是一年加薪时(35)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">5. IT外企那点儿事(12)：也说跳槽(33)</a></li>
</ul>
<h3 id="-">推荐排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(55)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03/1726200.html" target="_blank">2. IT外企那点儿事(3)：奇怪的面试(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">3. IT外企那点儿事(8)：又是一年加薪时(36)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">4. IT外企那点儿事(12)：也说跳槽(34)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">5. IT外企那点儿事(6)：管理路线和技术路线(27)</a></li>
</ul>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/09/1730857.html" target="_blank">IT外企那点儿事(5)：像系统一样升级</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/30/1725341.html" target="_blank">IT外企那点儿事(1)：外企也就那么回事</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/02/1725948.html" target="_blank">IT外企那点儿事(2)：多种多样的外企</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03/1726200.html" target="_blank">IT外企那点儿事(3)：奇怪的面试</a></p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05/1727644.html" target="_blank">IT外企那点儿事(4)：激动人心的入职演讲</a></p>
<p>进行完入职培训，便开启了你在外企中的程序人生了，需要说明的是，此文章不仅限外企。</p>
<p>如果待足够长的时间，你将从程序员，高级程序员，team lead，一直到manager，甚至director。</p>
<p>我们姑且宏观审视一下此过程，然后再品味一个个细节。</p>
<p>然而审视的过程猛然发现，所谓程序员就是把自己作为程序的人。</p>
<p>《道德经》第四十二章：道生一，一生二，二生三，三生万物。</p>
<p>此句大概说明的是宇宙万物发展变化的过程，而道则为宇宙万物运行的规律。</p>
<p>万事万物都有自身的规律，万有引力是规律，相对论是规律，而天天陪伴在我们程序员身边的算法，操作系统，计算机组成等，也可以看成大自然众多规律中的一小部分，也只有掌握好这些规律，我们才能掌控好计算机的运行。</p>
<p>系统的开发，程序员的升级又何尝不是经历了这样一个过程呢？</p>
<h2 id="-"><strong>一、认识规律：道</strong></h2>
<p>做一个系统，首先要掌握此项目所需要的技术，如果相关技术没有使用过，则此项技术就是一门尚未认知的规律。在项目开始之前，必须要系统性的认知相关的技术，否则面临较大的风险。</p>
<p>做一个程序员，首先要掌握计算机方面的知识，对知识的掌握，同样需要系统性，否则职业生涯也会面临很大的困难。</p>
<p><strong>系统性在此阶段至关重要。</strong></p>
<p>如果在项目中，对相关的技术没有系统性的认识，则会造成以下后果：</p>
<ul>
<li>设计出的系统不具有扩展性</li>
<li>应用了笨拙的方式设计程序</li>
<li>出现Bug时无所适从</li>
</ul>
<p>不知道大家是否参加过这样的项目开发过程，由于时间紧任务重，项目组在没有一个人系统了解某项技术的时候就进行了开发，大家只好从网上下载一些Sample code来通过复制粘贴来拼凑程序，甚至连每一项配置或每一行代码都没搞清楚，就照猫画虎的拿过来用了，这样不但到了后期，系统几乎没有任何扩展性，并且任何不同于Sample code的灵活的改动都是一件十分痛苦的事情，项目组就像眉头苍蝇一样四处乱改乱闯，但并不清楚每一次改动的真正后果，这样要进行大量的尝试和返工，最后整的整个项目组很累，还没有效果，这个过程我称之为“盲试”，也即在不明白原理的情况下靠反复的体力劳动，逐一遍历所有自己认为可能的修改。</p>
<p>“盲试”是初入职场的程序员经常犯的错误，初入职场，信心百倍，情绪高涨，急于出成果是多数时候的心态，当一个任务下达到手中的时候，并不是系统的阅读文档，进行方案评估以及框架设计(这些其实都是磨刀不误砍柴工的事情)，而是急着上手来做，可能在项目的早期，能够很快的出效果，但是随着项目的进行，维护成本越来越大，经常加班，而效果甚微。而对有经验的程序员来讲，前期进行了良好的设计，后期添加模块，需求的灵活变动是相对轻松的事情。</p>
<p>其实也可以理解这种状况的出现，毕竟老板都是心狠手辣的，才不会给你那么多事件做调研，程序员总是有一种被皮鞭赶着走的感觉，从而根本无法系统性的掌握技术和框架设计。这也是面试了很多程序员，每每都号称做过A,B,C项目，分别应用了a,b,c的技术，然而往深入问的时候发现，他们对技术a,b,c的了解也就仅限于A,B,C项目中，对其他一无所知了。</p>
<p>没有系统性的认识技术，则可能写出很多笨拙的程序，丑陋的实现。因为你只知其一，不知其二，只知其然，不知其所以然，本来人家框架中有高效的现成的技术实现这一方面的功能，你不知道，于是根据自己了解的片面技术勉强拼凑成功能，自然也实现了效果，然而当自己开始看这方面的经典书籍的时候，不禁感慨：“咳，原来能够很简单搞定的，当时竟然笨笨的写N多的代码。”</p>
<p>没有系统性的认识技术，出现Bug的时候比添加新模块更痛苦，因为不明白原理，所以只能从表面现象去猜，然后又是进行“盲试”的过程。</p>
<p>因而对技术的系统性认识，实在是不但对项目负责，更是对自己负责的一件事情。如果老板是技术型的，在估计项目时间的时候，应该劝说其将这方面考虑进去，如果老板是非技术型的，则程序员也应该自己留下缓冲时间。不然你辛辛苦苦白天八小时给老板了，晚上再加班几个小时又给老板了，你自己如何进步呢？</p>
<p>如果对于程序员，对计算机方面的技术没有系统性的认识，同样存在上述的问题。</p>
<p>你的职业生涯同样没有扩展性。如果不能够系统的掌握算法，数据结构，操作系统，计算机网络，计算机组成等基础知识，在程序员的初期可能不明显，随便培训培训也能写出不错的程序，然而当转换方向或者平台的时候，会面临很大的痛苦。而我们能够看到的身边的优秀程序员们，无论让他们做C,C++还是Java，无论是linux还是windows，他们都能够很快的上手，是因为基础好的缘故。</p>
<p>项目和程序员认识规律的方式，其实也无非读书，文档，及原型开发(对于程序员来说，实习阶段相当于Prototyping)。</p>
<p><strong>总结：项目或程序员的第一阶段：悟道，关键词：“系统性”</strong></p>
<h2 id="-">#</h2>
<h2 id="-"><strong>二、道生一</strong></h2>
<p>当掌握了项目相关的道，也即技术的时候，就要真正的进入项目开发了。</p>
<p>当前的项目，仍然由一个进程组成的系统比较少了，由于数据量的增大，基本都会开发多节点的分布式系统，然而再复杂的系统，也基本是从单节点系统开始做的，也即所谓道生一的过程。</p>
<p>当掌握了计算机相关技术的时候，你就可以成为一个真正的程序员了。当然不可能让你一开始就管理一个项目组，此时唯一要管理好的，是你自己。</p>
<p><strong>开放性和扎实性是此阶段的重中之重。</strong></p>
<p>对于项目来讲，一个好的单节点系统，所谓开放，就是即便设计单节点的系统，也要站在设计多节点的系统的角度来考虑，使做出来的系统更加容易被扩展成多节点的系统。所谓扎实，就是单节点系统要麻雀虽小，五脏俱全，扎扎实实的实现大部分功能，并有相当量的测试用例来保证功能的正确。</p>
<p>否则会造成以下后果：</p>
<ul>
<li>当做多节点系统时候，发现单节点系统需要大量修改，甚至等于白做，重新开始。</li>
<li>单节点不稳定，以至于多节点时Bug丛生，但不知道是因为错误出在多节点实现部分，还是单节点部分，较难定位。</li>
<li>没有足够的测试用例，当为了多节点进行修改的时候，不能保证的功能实现仍然行为正确。</li>
</ul>
<p>假设做一个100个节点的项目，要100天时间的话，并非每个节点要1天的时间，而是第一个节点就需要30天的时间，当第一个节点做好之后，扩展后面是很自然的事情，然而如果第一个节点做不好，每天都做一个节点，每天都把昨天做的设计推翻然后重做，怕是100天也完不成100个节点。这个例子比较极端，然而在我们周围没有发生过吗？</p>
<p>对于程序员来讲，做一个好的螺丝钉，同样需要开放和扎实。</p>
<p>所谓开放，就是我们虽然仅仅是最最低级的员工，可能整个系统的架构根本轮不到我们，但是这并不表明我们只盯着自己的一亩三分地，完成功能了事，而是要经常站在整个项目的角度考虑问题。不想当将军的士兵不是好士兵，建议做一下几件事情：</p>
<ul>
<li>在项目的各种会议上，经常站在项目经理和架构师的角度考虑问题，要是自己会如何设计，前辈们为何这样设计，然后多问前辈问题。虽然最初的想法比较幼稚，但可以不说出来，但是长时间这样思考，会发现自己的设计水平会突飞猛进的，慢慢的，你会发现你能够在会议中给出一些建议，然后你会发现能够发现前辈设计中的一些缺陷，然后你会发现你能够对当前的设计提供恰当的改进方案，终于有一天你发现你不再是一个单节点的普通程序员了。</li>
<li>除了完成自己的功能外，多看一看前辈们实现过的代码，用自己的方式手绘一些他们的架构图，记下不太明白的部分及觉得很优秀可以借鉴的部分。</li>
<li>尝试在自己的模块中(可能最初是很小很小的模块)尝试使用学到架构。</li>
<li>可以重读或新读一些经典书籍，争取能够用业界内公认的理论来解释自己接触到的设计及架构，使得从感性认识上升到理性认识。比如原来前辈们写这些类，用的是这种设计模式，它还有以下的优点和缺点，适合设计怎么样的系统。这样不但有利于我们在以后的项目中恰当的使用已掌握的设计，而且也有利于向他人准确的描述项目。试想在面试中，一个专业术语要比杂七杂八的列一大筐类更显水平吧。</li>
<li>可以在餐桌上，向自己的同学，朋友描述一下学到的架构，让你的朋友往细节里问，不确定的回去再下功夫，争取做到虽然你只是项目中的一个螺丝钉，但是好像你从头到尾设计了这个系统一样。</li>
</ul>
<p>这里要提醒一下大家，并不是所有的上司都喜欢要当将军的士兵和老问问题的员工，适当把握火候吧。</p>
<p>所谓扎实，就是指对接触到的知识，都应该根据实践，结合理论，由点到面的掌握。在这个阶段，信息量是很大，要学的东西很多，往往对各种技术都接触一下，又对各种技术都浅尝辄止，最后形成样样通，样样松的局面，阻碍了自己的发展。面试的时候也经常发现一些应试者，掌握的东西仅仅局限于他做过的那个点上，相关知识的掌握非常弱，这自然会影响他从一个单节点程序员向多节点发展。因而每当在项目中接触到一方面的东西，除了上班完成项目外，下班后多看一些有关此方面的书，博客等，使得从知识点变成知识面，知其然，还要知其所以然，并了解存在的问题。当白天在MFC中拖完控件后，总应该读一些《深入浅出MFC》来了解其机制，读一下《windows核心编程》了解一下windows API及一些原理，最好读一下《windows internals》了解一下原理背后的故事，不然面试的时候如何向别人开口做过windows下的程序设计呢？总不能够创建过socket对象就声称会socket编程吧，至少看一下《UNIX Network Programming》。用过NFS怎么不把linux的filesystem的机制了解一下呢？</p>
<p>当然这样是很累很费时间的，然而刚毕业的我们，没有经验，没有人脉，没有资金，有的不就是时间吗？</p>
<p>珍惜刚毕业的这几年多多打实一下基础，等年纪大了，精力没这么旺盛了，很多事情要照顾了，还要靠这时候的老本啊。</p>
<p><strong>总结：项目或程序员的第二阶段：道生一，关键词：“开放性”“扎实性”</strong></p>
<h2 id="-">三、一生二</h2>
<p>对于项目来讲，当单节点系统足够稳定的时候，是应该向client/server或者master/slave结果扩展的时候了，也即一生二的过程。</p>
<p>对于程序员来讲，当你已经足够胜任个人工作的时候，是可以带一个实习生或者初级程序员了。</p>
<p><strong>此步的关键即&quot;communication&quot;，沟通。</strong></p>
<p>对于系统来讲，主要考虑的应该是节点之间如何通信，如何协作，采取何种协议。</p>
<ul>
<li>通信可以是面向连接的，也可以是不面向连接的。可以是同步的，也可以是异步的。</li>
<li>通信是分层次的，不同的情况应用不同层次的协议，heartbeat用何种协议，内部数据块传输用何种协议，发布成service向外提供服务用何种协议，都是应该考虑的。</li>
<li>数据的内部结构就想接口一样是要通过沟通商定的，便于解析又易于扩展，rpc? serialized object? xml? json? protocol buffer? 还是自己定义的格式？</li>
<li>对于要经常访问的客户端，连接池是必须的，每次建立连接是很耗时的</li>
<li>服务器端应该有对连接总数的限制，以及请求的分发，拥塞控制(并不一定是网络拥塞，而是某个阶段的处理相对较慢)</li>
<li>通信模块在项目中不应该是任何两个需要通信的模块都要开发的，而是应该作为基础性模块，经过大量的测试后达到稳定，使得需要应用通信模块的人员能够集中精力在本身的逻辑上，当模块间协作出现故障的时候，不用担心是通信模块传错了的问题。</li>
</ul>
<p>对于程序员来讲，同样要考虑和实习生或初级程序员之间的通信协议问题。</p>
<p>有的代码自己觉得写的很清楚，但是让新手上手的时候，如何能够准确的描述你的思路，想法，设计，遇到的困难呢？如何根据对方的反馈确认对方真实了解了你所表达的信息呢？有很多有经验的程序员，由于天天面对着电脑而疏于和人的沟通，可能会一肚子能耐却说不出来，非常可惜；而对于新人，他的回馈是懂了可并不一定代表他真的懂了，也可能是不懂又不敢说。</p>
<ul>
<li>重要的问题的沟通应该是同步的，也即面对面沟通，这样除了语言上的反馈，还能通过表情得到一定的反馈。任何问题都要事先划分为若干阶段，最好脑子中有张拓扑图，后一阶段的理解会依赖于前一阶段的理解，一股脑把所有的信息放在对方面前，任何人都会晕。每经历一个阶段，都要收集一次反馈，作为信息的发送方，可以通过事先准备一些关键点的问题来检测对方是否真正了解，作为接收方，可以通过&quot;你的意思是说。。。&quot;等以自己的方式重复对方的表达来进行反馈。</li>
<li>注意拥塞控制，每一次的讨论争取一个小时内完成，再长效果会下降，接受者感觉信息被塞了满满一脑子，没有头绪，难有清晰的思路了。</li>
<li>每次沟通都应该至少有会议记录和部分结论，不然讨论等于白讨论，否则会发生团队经常开会，但是总在讨论同样一些问题，感觉上好像每次都在头脑风暴，其实效率很差。</li>
<li>对于重要的结论应该是面向连接的，也即书面(邮件，文档，wiki)告知，并有书面回复(ok, I am following the bug XXX)。</li>
<li>可以建立一些连接池，也即沟通的特定上下文。经过一定时间的团队磨合，可以下意识的创造或达成共识的一些词汇来代替一定的上下文，可以提高沟通效率。比如&quot;明天甲系统出report&quot;，则程序员明白要有单元测试覆盖率报告，QA明白要有当前bug的报告，性能测试组应该有甲系统性能测试报告。</li>
<li>沟通也是分层次的，最容易犯的错误的无论针对谁，写的文档，发的邮件都是一样的。其实针对不同层次的人，应该提供的信息不同，对于本团队人员，原理，架构，设计，测试，每步怎么做，结果如何，具体数据都应该说明，而对于其他团队的人员，具体的数据和每步怎么做就不需要了，对于项目经理，仅仅说明原理，架构，结论就可以了，对于高层来视察工作，原理加结果就行了。这也是为什么一篇文档有abstract,  summary, overview, concepts, detail, appendix等等部分，其实是对不同的人员看的。</li>
</ul>
<p><strong>总结：项目或程序员的第三阶段：一生二，关键词：“沟通”</strong></p>
<h2 id="-">四、二生三</h2>
<p>对于项目来讲，当Client/Server或者Master/Slave已经运行稳定，是应该开发一个Master多个Slave的时候了，即二生三的过程。</p>
<p>对于程序员来讲，当你能够很好的带一个实习生或者初级程序员的时候，是可以成为一个小的Team lead了。</p>
<p><strong>此步的关键是load balance，平衡。</strong></p>
<p>对于系统来讲，负载均衡最重要的是两个目的：</p>
<ul>
<li>高可靠性：当一个服务器crash的时候，不至于影响对外提供服务。</li>
<li>高性能：多台服务器可以并行的做事情，提供服务，加快相应时间。</li>
</ul>
<p>其实说到底，负载均衡采用的是Data partitioning(数据分块)或Data replication(数据复制)的方法。数据分块即按照某种策略，将某类请求全部指向某个服务器，比如说按照时间分块，例如邮件备份系统，可以将某个时间段的邮件全部放在一个服务器内，对这个时间段的查询全部指向此服务器；再比如按照地区分块，例如地图信息管理系统，将某个地区的数据全部放在一个服务器内。数据复制即将同样一部分数据复制多份，放在不同的服务器上，既保证高可靠性，又能将请求平均的分配给多个服务器，例如Google File system中将数据复制三份，大型网站的服务器也一般会将同一内容放在不同的服务器上。</p>
<p>对于程序员来讲，沟通同样重要，但是不再是局限于一对一的沟通了，不再是能把问题表达清楚就可以了，而是要在团队内部保持平衡。无论是工作压力，项目有趣程度，培训机会，成长机会都应该平衡。</p>
<p>也无非是两个目的：</p>
<ul>
<li>高可靠性：项目不会因为一个人的生病，休假，离职而影响项目的进度。</li>
<li>高性能：整个团队的力量发挥出来，不至于一个人成为了瓶颈。</li>
</ul>
<p>所采用的不过也是数据分块和数据复制的方式。</p>
<p>所谓数据分块，即不同的人负责不同的模块，比如一个负责前端，一个负责后端，或者一个负责开发，一个负责测试等，这能够带来高性能，因为每个人的专业化和经验会使得效率提高，但是同时带来的问题是高可靠性，如果转负责这个模块的人离开，换一个人将大大降低效率。工作压力也不能很好的平衡，往往一个系统的初期阶段，后端的开发十分忙，而前端相对较闲，而到了后期，前端开发非常忙，而后端已经稳定，因而较闲。况且，人不是机器，是有边际效应的，当负责一个模块时间一长，兴趣会大大降低，觉得没有成就感，成长也少了。因而数据复制的方式也是必要的，也即通过伙伴开发，Knowledge sharing，code review等方式，让不同模块的人之间相互了解对方的模块，从而带来高可靠性，也即一个人不在，其他的人可以较快的跟上，也可以在一个模块压力大的时候，其他人帮忙做一些辅助的东西，比如各种tool，测试用例，性能测试，甚至改一些优先级较低的bug，不仅平衡了工作压力，而且接触新的模块会使得员工有较大成长，也是工作更加有趣。</p>
<p><strong>总结：项目或程序员的第四阶段：二生三，关键词：“平衡”</strong></p>
<h2 id="-">五、三生万物</h2>
<p>如果道生一，一生二，二生三是质变的过程，则三生万物是量变的过程。</p>
<p>对于计算机系统来讲，如果一个master能够很好的平衡两三个slave，则可以很好的扩展到十个甚至百个，千个。但是原理是理想的，现实却是，当master管理的slave的数量达到一定的数目的时候，master就是一个瓶颈，master的高性能和高可靠性又成了问题，这时候可以用多个master进行数据复制从而负载平衡，也可以使得多个master每个管理一个group的slave，这时候就应该有master的master了，也即系统出现了分层。Hadoop的Multirack cluster就是这样的一棵树。</p>
<p>对于团队的管理也是同样的，每个人的直接管理精力在10个人左右，多于这些人，往往会有很多疏漏的地方，或者疲惫不堪，因而，当一个团队成长的一定的程度的时候，也是需要分层的。当团队增长的15至20人的时候，应该考虑从现有的人员中选出master，也即team lead或者至少是coordinator，使得组织也成为了一棵树装。</p>
<p><strong>总结：项目或程序人生的第五阶段：三生万物，关键词：“分层”</strong></p>
<p>分类: <a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事</a></p>
<p>绿色通道： <a href="">好文要顶</a> <a href="">关注我</a> <a href="">收藏该文</a><a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">与我联系</a> <a href="&quot;分享至新浪微博&quot;"><img src="" alt=""></a>
<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank"><img src="" alt=""></a></p>
<p><a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followees" target="_blank">关注 - 3</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followers" target="_blank">粉丝 - 560</a></p>
<p>荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
<a href="">+加关注</a></p>
<p>18</p>
<p>0
(请您对文章做出评价)</p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/08/1730201.html" target="_blank">«</a> 上一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/08/1730201.html" title="发布于2010-05-08 00:21" target="_blank">Lucene学习总结之八：Lucene的查询语法，JavaCC及QueryParser(2)</a>
<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">»</a> 下一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" title="发布于2010-05-13 01:51" target="_blank">IT外企那点儿事(6)：管理路线和技术路线</a>
posted on 2010-05-09 01:10 <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a> 阅读(6603) 评论(28) <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?postid=1730857" target="_blank">编辑</a> <a href="">收藏</a></p>
<p><a href=""></a></p>
<h3 id="-">评论</h3>
<p><a href="">/#1楼</a><a href=""></a>  2010-05-09 01:29  <a href="http://www.cnblogs.com/Jax/">Jianqiang Bao</a> <a href="http://space.cnblogs.com/msg/send/Jianqiang+Bao" title="发送站内短消息" target="_blank"> </a></p>
<p>下一章是离职吧 ：)</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u13430.jpg" target="_blank">http://pic.cnitblog.com/face/u13430.jpg</a></p>
<p><a href="">/#2楼</a><a href=""></a>  2010-05-09 01:35  <a href="http://www.cnblogs.com/pinpkm/">个人知识管理</a> <a href="http://space.cnblogs.com/msg/send/%e4%b8%aa%e4%ba%ba%e7%9f%a5%e8%af%86%e7%ae%a1%e7%90%86" title="发送站内短消息" target="_blank"> </a></p>
<p>太好了。我是一字一句看完后才写下。
要是这样的资料能让更多程序员看到就好了。好的资料还是很稀缺的。
但愿所有的人至少能看上三遍。反复阅读是最基本的个人知识管理的学习技巧。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#3楼</a><a href=""></a>  2010-05-09 09:21  <a href="http://www.cnblogs.com/Mainz/">Mainz</a> <a href="http://space.cnblogs.com/msg/send/Mainz" title="发送站内短消息" target="_blank"> </a></p>
<p>顶了~看完留名</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u28306.png?id=23214645" target="_blank">http://pic.cnitblog.com/face/u28306.png?id=23214645</a></p>
<p><a href="">/#4楼</a><a href=""></a>  2010-05-09 11:01  <a href="http://www.cnblogs.com/wing011203/">李胜攀</a> <a href="http://space.cnblogs.com/msg/send/%e6%9d%8e%e8%83%9c%e6%94%80" title="发送站内短消息" target="_blank"> </a></p>
<p>太强了！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/26980/20130411124002.png" target="_blank">http://pic.cnitblog.com/face/26980/20130411124002.png</a></p>
<p><a href="">/#5楼</a><a href=""></a>  2010-05-09 11:29  <a href="http://home.cnblogs.com/u/56534/">o℃浪漫</a> <a href="http://space.cnblogs.com/msg/send/o%e2%84%83%e6%b5%aa%e6%bc%ab" title="发送站内短消息" target="_blank"> </a></p>
<p>一字一句，仔细斟酌过！谢谢总结！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#6楼</a><a href=""></a>  2010-05-09 12:04  <a href="http://www.cnblogs.com/coki/">Coki</a> <a href="http://space.cnblogs.com/msg/send/Coki" title="发送站内短消息" target="_blank"> </a></p>
<p>和前四节文风和主旨好像有点脱节
文章主旨似乎是在以软件工程的思路类比人的职业规划，但大量篇幅都是在讲软件开发的一些心得和要点，和职业规划没什么联动，对相似性的归纳描述不足。
而且文章标题关键词是“升级”，按照这个文章系列的侧重，重点应该是个人自我能力的变化和升职的技巧，文章内容好像并没有什么关系。
个人感觉这篇文章单独拉出来做一篇探讨项目管理心得的文章更好。
仅本人一家之言，如有错误，还请谅解。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#7楼</a><a href=""></a>[楼主]  2010-05-09 17:30  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>Coki
谢谢您的建议，会在以后的写作中注意。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#8楼</a><a href=""></a>  2010-05-09 21:32  <a href="http://www.cnblogs.com/fooxiaoqiang/">付晓强</a> <a href="http://space.cnblogs.com/msg/send/%e4%bb%98%e6%99%93%e5%bc%ba" title="发送站内短消息" target="_blank"> </a></p>
<p>好文章啊，很喜欢，如果转载了，不会说我什么吧。毕竟是好东西，开源一下吧。谢谢博主了。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u131747.jpg" target="_blank">http://pic.cnitblog.com/face/u131747.jpg</a></p>
<p><a href="">/#9楼</a><a href=""></a>[楼主]  2010-05-10 00:31  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>付晓强
转载没问题，写明出处和链接就可以了。
谢谢您关注</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#10楼</a><a href=""></a>  2010-05-10 08:43  <a href="http://www.cnblogs.com/yuphone/">.COM 缺氧®</a> <a href="http://space.cnblogs.com/msg/send/.COM+%e7%bc%ba%e6%b0%a7&amp;%23174%3b" title="发送站内短消息" target="_blank"> </a></p>
<p>果断留名。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u97502.jpg" target="_blank">http://pic.cnitblog.com/face/u97502.jpg</a></p>
<p><a href="">/#11楼</a><a href=""></a>  2010-05-10 09:55  <a href="http://www.cnblogs.com/jciwolf/">Jerry Qian</a> <a href="http://space.cnblogs.com/msg/send/Jerry+Qian" title="发送站内短消息" target="_blank"> </a></p>
<p>期待离职</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#12楼</a><a href=""></a>  2010-05-10 14:32  <a href="http://www.cnblogs.com/fit/">别爱上哥，哥只是个传说！</a> <a href="http://space.cnblogs.com/msg/send/%e5%88%ab%e7%88%b1%e4%b8%8a%e5%93%a5%ef%bc%8c%e5%93%a5%e5%8f%aa%e6%98%af%e4%b8%aa%e4%bc%a0%e8%af%b4%ef%bc%81" title="发送站内短消息" target="_blank"> </a></p>
<p>为我2亿7千万人民币而奋斗.</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#13楼</a><a href=""></a>  2010-05-10 17:21  <a href="http://www.cnblogs.com/starnc/">老子不服</a> <a href="http://space.cnblogs.com/msg/send/%e8%80%81%e5%ad%90%e4%b8%8d%e6%9c%8d" title="发送站内短消息" target="_blank"> </a></p>
<p>很有点哲学的味道</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u47315.jpg" target="_blank">http://pic.cnitblog.com/face/u47315.jpg</a></p>
<p><a href="">/#14楼</a><a href=""></a>  2010-05-10 22:13  <a href="http://www.cnblogs.com/liping13599168/">Leepy</a> <a href="http://space.cnblogs.com/msg/send/Leepy" title="发送站内短消息" target="_blank"> </a></p>
<p>写得不错，顶一顶！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u18497.jpg" target="_blank">http://pic.cnitblog.com/face/u18497.jpg</a></p>
<p><a href="">/#15楼</a><a href=""></a>  2010-05-11 12:57  <a href="http://www.cnblogs.com/chinese-zmm/">chinese_submarine</a> <a href="http://space.cnblogs.com/msg/send/chinese_submarine" title="发送站内短消息" target="_blank"> </a></p>
<p>不错，很受启发~</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u28698.png" target="_blank">http://pic.cnitblog.com/face/u28698.png</a></p>
<p><a href="">/#16楼</a><a href=""></a>  2010-05-13 10:48  <a href="http://www.cnblogs.com/millen/">赵文星</a> <a href="http://space.cnblogs.com/msg/send/%e8%b5%b5%e6%96%87%e6%98%9f" title="发送站内短消息" target="_blank"> </a></p>
<p>好文章，是经验积累的结晶。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#17楼</a><a href=""></a>  2010-05-13 22:56  <a href="http://www.cnblogs.com/likwo/">Likwo</a> <a href="http://space.cnblogs.com/msg/send/Likwo" title="发送站内短消息" target="_blank"> </a></p>
<p>好文。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#18楼</a><a href=""></a>  2010-05-14 00:54  <a href="http://www.cnblogs.com/Gildor/">Ken Wang</a> <a href="http://space.cnblogs.com/msg/send/Ken+Wang" title="发送站内短消息" target="_blank"> </a></p>
<p>写得很好。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#19楼</a><a href=""></a>  2010-05-14 08:45  <a href="http://www.cnblogs.com/cbcye/">Gary Zhang</a> <a href="http://space.cnblogs.com/msg/send/Gary+Zhang" title="发送站内短消息" target="_blank"> </a></p>
<p>写得很细，这么走下来估计得个十五，二十年的时间吧。在这样浮躁的环境，急功近利的社会，不知道这样走过来的有多少人？</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#20楼</a><a href=""></a>  2010-05-14 13:04  <a href="http://www.cnblogs.com/kongyiyun/">空逸云</a> <a href="http://space.cnblogs.com/msg/send/%e7%a9%ba%e9%80%b8%e4%ba%91" title="发送站内短消息" target="_blank"> </a></p>
<p>LZ.很感谢你能这样分享自己的经验,作为一名即将毕业的学生.以前,我不明白为什么说一个程序员到了30左右逐渐就不行了呢?除了体力跟不上,原来主要还是时间.您让我知道了外企与国企(或者说民企)的区别.在这之前.一直想着该怎么学下去,原本以为.只要一直持之以恒,努力专研.net Framework就可以.花个4~5年时间做到熟知,善用的地步..现在明白.学习不是只学框架,而更该注重思想的学习.总之.很感谢您.或者说.最后这两篇文章都与外企没多大的关系.但是还是很喜欢看.看着其他的前辈做过的路.能让我对前方的路看得更加清晰.能未雨绸缪.THX.希望LZ能多写些有关于程序员成长方面的文章,更多的把自己的经历记录下来,好让我们这些后生多多学习.</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u88464.jpg?id=20154053" target="_blank">http://pic.cnitblog.com/face/u88464.jpg?id=20154053</a></p>
<p><a href="">/#21楼</a><a href=""></a>[楼主]  2010-05-14 13:22  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>空逸云
谢谢啊</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#22楼</a><a href=""></a>  2010-05-17 13:23  <a href="http://home.cnblogs.com/u/125713/">东山飘雨，西关情</a> <a href="http://space.cnblogs.com/msg/send/%e4%b8%9c%e5%b1%b1%e9%a3%98%e9%9b%a8%ef%bc%8c%e8%a5%bf%e5%85%b3%e6%83%85" title="发送站内短消息" target="_blank"> </a></p>
<p>写的不错</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#23楼</a><a href=""></a>  2010-05-22 17:00  <a href="http://www.cnblogs.com/awen177/">Vincent Zhou</a> <a href="http://space.cnblogs.com/msg/send/Vincent+Zhou" title="发送站内短消息" target="_blank"> </a></p>
<p>文章写的非常好，想问下楼主是在外企工作了多久才有这般体会的？</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#24楼</a><a href=""></a>  2010-05-22 17:27  <a href="http://www.cnblogs.com/nbjkj/">nbjkj</a> <a href="http://space.cnblogs.com/msg/send/nbjkj" title="发送站内短消息" target="_blank"> </a></p>
<p>作为名刚入职场的程序员很高兴能拜读你的文章，很实用，理清了很多东西，谢谢！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u102166.jpg" target="_blank">http://pic.cnitblog.com/face/u102166.jpg</a></p>
<p><a href="">/#25楼</a><a href=""></a>  2010-05-29 22:28  <a href="http://www.cnblogs.com/ccnet/">CCNet</a> <a href="http://space.cnblogs.com/msg/send/CCNet" title="发送站内短消息" target="_blank"> </a></p>
<p>分享昰一種美德，留言亦是！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#26楼</a><a href=""></a>  2011-05-17 21:39  <a href="http://www.cnblogs.com/heshizhu/">Alex木头</a> <a href="http://space.cnblogs.com/msg/send/Alex%e6%9c%a8%e5%a4%b4" title="发送站内短消息" target="_blank"> </a></p>
<p>先佩服！
很喜欢你说得这句话：刚毕业的我们，没有经验，没有人脉，没有资金，有的不就是时间吗？珍惜刚毕业的这几年多多打实一下基础，等年纪大了，精力没这么旺盛了，很多事情要照顾了，还要靠这时候的老本啊。
说得多好啊！年轻的时候确实应该过努力下，想楼主学习。
谢谢您的分享精神。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#27楼</a><a href=""></a>  2011-10-23 23:46  <a href="http://www.cnblogs.com/God-froest/">牛_</a> <a href="http://space.cnblogs.com/msg/send/%e7%89%9b_" title="发送站内短消息" target="_blank"> </a></p>
<p>作为一个即将毕业的我来说，这文章无疑是我的航标，谢谢LZ，我会学习贵文章中的宝贵经验，并且做出总结或许自己也会无处其中新的道。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u306300.jpg?id=02194424" target="_blank">http://pic.cnitblog.com/face/u306300.jpg?id=02194424</a></p>
<p><a href="">/#28楼</a><a href=""></a>22259362011/10/23 23:51:28  2011-10-23 23:51  <a href="http://www.cnblogs.com/God-froest/">牛_</a> <a href="http://space.cnblogs.com/msg/send/%e7%89%9b_" title="发送站内短消息" target="_blank"> </a></p>
<p>为啥我的评论这么小？</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u306300.jpg?id=02194424" target="_blank">http://pic.cnitblog.com/face/u306300.jpg?id=02194424</a></p>
<p><a href="">刷新评论</a><a href="">刷新页面</a><a href="">返回顶部</a></p>
<p>注册用户登录后才能发表评论，请 <a href="">登录</a> 或 <a href="">注册</a>，<a href="http://www.cnblogs.com/" target="_blank">访问</a>网站首页。
<a href="http://www.cnblogs.com/" title="程序员的网上家园" target="_blank">博客园首页</a><a href="http://q.cnblogs.com/" title="程序员问答社区" target="_blank">博问</a><a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">新闻</a><a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a><a href="http://job.cnblogs.com/" target="_blank">程序员招聘</a><a href="http://kb.cnblogs.com/" target="_blank">知识库</a></p>
<p><strong>最新IT新闻</strong>:
· <a href="http://news.cnblogs.com/n/182486/" target="_blank">新硬硬整合时代</a>
· <a href="http://news.cnblogs.com/n/182485/" target="_blank">狗血的百度91并购案啊 阿里和周鸿祎都曾掺和</a>
· <a href="http://news.cnblogs.com/n/182483/" target="_blank">如何让搜索引擎抓取AJAX内容？</a>
· <a href="http://news.cnblogs.com/n/182482/" target="_blank">避免代码注释的五大理由</a>
· <a href="http://news.cnblogs.com/n/182481/" target="_blank">OpenWrt——适用于路由器的Linux系统</a>
» <a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">更多新闻...</a></p>
<p><strong>最新知识库文章</strong>:
· <a href="http://kb.cnblogs.com/page/141892/" target="_blank">阿里巴巴集团去IOE运动的思考与总结</a>
· <a href="http://kb.cnblogs.com/page/182265/" target="_blank">硅谷归来7点分享：创业者，做你自己</a>
· <a href="http://kb.cnblogs.com/page/182200/" target="_blank">我为什么不能坚持？</a>
· <a href="http://kb.cnblogs.com/page/168725/" target="_blank">成为高效程序员的7个重要习惯</a>
· <a href="http://kb.cnblogs.com/page/182047/" target="_blank">谈谈对BPM的理解</a>
» <a href="http://kb.cnblogs.com/" target="_blank">更多知识库文章...</a>
Powered by:
<a href="http://www.cnblogs.com/" target="_blank">博客园</a>
Copyright © 觉先</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/zhiya/">zhiya</a></li></span><span class="breadcrumb"><li><a href="/categories/职涯/">职涯</a></li><li><a href="/categories/职涯/IT外企/">IT外企</a></li></span></span> | <span class="tags">Tagged <a href="/tags/IT外企/" class="label label-primary">IT外企</a><a href="/tags/zhiya/" class="label label-success">zhiya</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事5：像系统一样升级/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-zhiya-IT外企--IT外企那点儿事5：像系统一样升级" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--Hadoop版本梳理/">Hadoop版本梳理</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--Hadoop版本梳理/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hadoop-">Hadoop版本梳理</h1>
<p>由于Hadoop版本混乱多变，因此，Hadoop的版本选择问题一直令很多初级用户苦恼。本文总结了Apache Hadoop和Cloudera Hadoop的版本衍化过程，并给出了选择Hadoop版本的一些建议。</p>
<h3 id="1-apache-hadoop">1. Apache Hadoop</h3>
<h3 id="1-1-apache-">1.1  Apache版本衍化</h3>
<p>截至目前（2012年12月23日），Apache Hadoop版本分为两代，我们将第一代Hadoop称为Hadoop 1.0，第二代Hadoop称为Hadoop 2.0。第一代Hadoop包含三个大版本，分别是0.20.x，0.21.x和0.22.x，其中，0.20.x最后演化成1.0.x，变成了稳定版，而0.21.x和0.22.x则NameNode HA等新的重大特性。第二代Hadoop包含两个版本，分别是0.23.x和2.x，它们完全不同于Hadoop 1.0，是一套全新的架构，均包含HDFS Federation和YARN两个系统，相比于0.23.x，2.x增加了NameNode HA和Wire-compatibility两个重大特性。</p>
<p>经过上面的大体解释，大家可能明白了Hadoop以重大特性区分各个版本的，总结起来，用于区分Hadoop版本的特性有以下几个：</p>
<p><strong>（1）Append</strong> 支持文件追加功能，如果想使用HBase，需要这个特性。</p>
<p><strong>（2）RAID </strong>在保证数据可靠的前提下，通过引入校验码较少数据块数目。详细链接：</p>
<p><a href="https://issues.apache.org/jira/browse/HDFS/component/12313080" target="_blank">https://issues.apache.org/jira/browse/HDFS/component/12313080</a></p>
<p><strong>（3）Symlink</strong> 支持HDFS文件链接，具体可参考： <a href="https://issues.apache.org/jira/browse/HDFS-245" target="_blank"><a href="https://issues.apache.org/jira/browse/HDFS-245">https://issues.apache.org/jira/browse/HDFS-245</a></a></p>
<p><strong>（4）Security</strong> Hadoop安全，具体可参考：<a href="https://issues.apache.org/jira/browse/HADOOP-4487" target="_blank"><a href="https://issues.apache.org/jira/browse/HADOOP-4487">https://issues.apache.org/jira/browse/HADOOP-4487</a></a></p>
<p><strong>（5） NameNode HA</strong> 具体可参考：<a href="https://issues.apache.org/jira/browse/HDFS-1064" target="_blank"><a href="https://issues.apache.org/jira/browse/HDFS-1064">https://issues.apache.org/jira/browse/HDFS-1064</a></a></p>
<p><strong>（6） HDFS Federation和YARN</strong></p>
<p><img src="&quot;apache-hadoop-versions&quot;" alt=""></p>
<p>需要注意的是，Hadoop 2.0主要由Yahoo独立出来的hortonworks公司主持开发。</p>
<h3 id="1-2-apache-">1.2  Apache版本下载</h3>
<p>（1） 各版本说明：<a href="http://hadoop.apache.org/releases.html" target="_blank"><a href="http://hadoop.apache.org/releases.html">http://hadoop.apache.org/releases.html</a></a>。</p>
<p>（2） 下载稳定版：找到一个镜像，下载stable文件夹下的版本。</p>
<p>（3） Hadoop最全版本：<a href="http://svn.apache.org/repos/asf/hadoop/common/branches/" target="_blank"><a href="http://svn.apache.org/repos/asf/hadoop/common/branches/">http://svn.apache.org/repos/asf/hadoop/common/branches/</a></a>，可直接导到eclipse中。</p>
<h3 id="2-cloudera-hadoop">2. Cloudera Hadoop</h3>
<h3 id="2-1-cdh-">2.1  CDH版本衍化</h3>
<p>Apache当前的版本管理是比较混乱的，各种版本层出不穷，让很多初学者不知所措，相比之下，Cloudera公司的Hadoop版本管理的要很多。</p>
<p>我们知道，Hadoop遵从Apache开源协议，用户可以免费地任意使用和修改Hadoop，也正因此，市面上出现了很多Hadoop版本，其中比较出名的一是Cloudera公司的发行版，我们将该版本称为CDH（Cloudera Distribution Hadoop）。截至目前为止，CDH共有4个版本，其中，前两个已经不再更新，最近的两个，分别是CDH3（在Apache Hadoop 0.20.2版本基础上演化而来的）和CDH4在Apache Hadoop 2.0.0版本基础上演化而来的），分别对应Apache的Hadoop 1.0和Hadoop 2.0，它们每隔一段时间便会更新一次。</p>
<p><img src="&quot;cloudera-hadoop-versions&quot;" alt=""></p>
<p>Cloudera以patch level划分小版本，比如patch level为923.142表示在原生态Apache Hadoop 0.20.2基础上添加了1065个patch（这些patch是各个公司或者个人贡献的，在Hadoop jira上均有记录），其中923个是最后一个beta版本添加的patch，而142个是稳定版发行后新添加的patch。由此可见，patch level越高，功能越完备且解决的bug越多。</p>
<p>Cloudera版本层次更加清晰，且它提供了适用于各种操作系统的Hadoop安装包，可直接使用apt-get或者yum命令进行安装，更加省事。</p>
<h3 id="2-2-cdh-">2.2 CDH版本下载</h3>
<p>（1） 版本含义介绍：</p>
<p><a href="https://ccp.cloudera.com/display/DOC/CDH+Version+and+Packaging+Information" target="_blank"><a href="https://ccp.cloudera.com/display/DOC/CDH+Version+and+Packaging+Information">https://ccp.cloudera.com/display/DOC/CDH+Version+and+Packaging+Information</a></a></p>
<p>（2）各版本特性查看：</p>
<p><a href="https://ccp.cloudera.com/display/DOC/CDH+Packaging+Information+for+Previous+Releases" target="_blank"><a href="https://ccp.cloudera.com/display/DOC/CDH+Packaging+Information+for+Previous+Releases">https://ccp.cloudera.com/display/DOC/CDH+Packaging+Information+for+Previous+Releases</a></a></p>
<p>（3）各版本下载：</p>
<p>CDH3：<a href="http://archive.cloudera.com/cdh/3/" target="_blank"><a href="http://archive.cloudera.com/cdh/3/">http://archive.cloudera.com/cdh/3/</a></a></p>
<p>CDH4：<a href="http://archive.cloudera.com/cdh4/cdh/4/" target="_blank"><a href="http://archive.cloudera.com/cdh4/cdh/4/">http://archive.cloudera.com/cdh4/cdh/4/</a></a></p>
<p>注意，Hadoop压缩包在这两个链接中的最上层目录中，不在某个文件夹里，很多人进到链接还找不到安装包！</p>
<h3 id="3-hadoop-">3. 如何选择Hadoop版本</h3>
<p>当前Hadoop版本比较混乱，让很多用户不知所措。实际上，当前Hadoop只有两个版本：Hadoop 1.0和Hadoop 2.0，其中，Hadoop 1.0由一个分布式文件系统HDFS和一个离线计算框架MapReduce组成，而Hadoop 2.0则包含一个支持NameNode横向扩展的HDFS，一个资源管理系统YARN和一个运行在YARN上的离线计算框架MapReduce。相比于Hadoop 1.0，Hadoop 2.0功能更加强大，且具有更好的扩展性、性能，并支持多种计算框架。</p>
<p>当我们决定是否采用某个软件用于开源环境时，通常需要考虑以下几个因素：</p>
<p>（1）是否为开源软件，即是否免费。</p>
<p>（2） 是否有稳定版，这个一般软件官方网站会给出说明。</p>
<p>（3） 是否经实践验证，这个可通过检查是否有一些大点的公司已经在生产环境中使用知道。</p>
<p>（4） 是否有强大的社区支持，当出现一个问题时，能够通过社区、论坛等网络资源快速获取解决方法。</p>
<p>如今Hadoop 2.0已经发布了最新的稳定版2.2.0，推荐使用该版本，具体介绍可阅读：“<a href="http://dongxicheng.org/mapreduce-nextgen/hadoop-2-2-0/" target="_blank">Hadoop 2.0稳定版本2.2.0新特性剖析</a>”，升级方法可参考：“<a href="http://dongxicheng.org/mapreduce-nextgen/hadoop-upgrade-to-version-2/" target="_blank">Hadoop升级方案（二）：从Hadoop 1.0升级到2.0（1）</a>”。
来源： <a href="[http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/](http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/)">[http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/](http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/)</a></p>
<p>另外一篇：</p>
<h1 id="-hadoop-http-www-cnblogs-com-xuxm2007-archive-2013-04-04-2999741-html-"><a href="http://www.cnblogs.com/xuxm2007/archive/2013/04/04/2999741.html" target="_blank">hadoop的版本问题</a></h1>
<p>现在hadoop的版本比较乱,常常搞不清楚版本之间的关系,下面简单的摘要了,apache hadoop和cloudera hadoop 的版本的演化.</p>
<p><strong>apache hadoop官方给出的版本说明是:</strong></p>
<p><strong>1.0.X -</strong>current stable version, 1.0 release</p>
<p><strong>1.1.X -</strong>current beta version, 1.1 release</p>
<p><strong>2.X.X -</strong>current alpha version</p>
<p><strong>0.23.X -</strong>simmilar to 2.X.X but missing NN HA.</p>
<p><strong>0.22.X -</strong>does not include security</p>
<p><strong>0.20.203.X -</strong>old legacy stable version</p>
<p><strong>0.20.X -</strong>old legacy version</p>
<p>下图来自<a href="http://blog.cloudera.com/blog/2012/01/an-update-on-apache-hadoop-1-0/" target="_blank"><a href="http://blog.cloudera.com/blog/2012/01/an-update-on-apache-hadoop-1-0/">http://blog.cloudera.com/blog/2012/01/an-update-on-apache-hadoop-1-0/</a></a></p>
<p>可以简单说明apache hadoop和cloudera hadoop版本之间的变化关系</p>
<p><a href="http://images.cnitblog.com/blog/73083/201304/04194843-67590ee16a15440497b1153b688fad40.png" target="_blank"><img src="&quot;diagram-3&quot;" alt="diagram-3"></a></p>
<p>0.20.x版本最后演化成了现在的1.0.x版本</p>
<p>0.23.x版本最后演化成了现在的2.x版本</p>
<p>hadoop 1.0 指的是1.x(0.20.x),0.21,0.22</p>
<p>hadoop 2.0 指的是2.x,0.23.x</p>
<p>CDH3,CDH4分别对应了hadoop1.0 hadoop2.0</p>
<p>董的博客有2篇文章也很清晰的解释了,hadoop版本以及各自的版本特性:</p>
<p><a href="http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/" target="_blank"><a href="http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/">http://dongxicheng.org/mapreduce-nextgen/how-to-select-hadoop-versions/</a></a></p>
<p><a href="http://dongxicheng.org/mapreduce-nextgen/hadoop-2-0-terms-explained/" target="_blank"><a href="http://dongxicheng.org/mapreduce-nextgen/hadoop-2-0-terms-explained/">http://dongxicheng.org/mapreduce-nextgen/hadoop-2-0-terms-explained/</a></a></p>
<p><a href="http://images.cnitblog.com/blog/73083/201304/04195633-b2c2d402daf94e2187a2130c24d441b1.jpg" target="_blank"><img src="&quot;apache-hadoop-versions&quot;" alt="apache-hadoop-versions"></a></p>
<p>最后给出常见的下载hadoop不同版本的地址:</p>
<p><a href="http://archive.apache.org/dist/hadoop/core/" target="_blank"><a href="http://archive.apache.org/dist/hadoop/core/">http://archive.apache.org/dist/hadoop/core/</a></a></p>
<p><a href="http://archive.cloudera.com/cdh/3/" target="_blank"><a href="http://archive.cloudera.com/cdh/3/">http://archive.cloudera.com/cdh/3/</a></a></p>
<p><a href="http://archive.cloudera.com/cdh4/cdh/4/" target="_blank"><a href="http://archive.cloudera.com/cdh4/cdh/4/">http://archive.cloudera.com/cdh4/cdh/4/</a></a></p>
<p>另外附注一个 hadoop各商业发行版的比较:</p>
<p><a href="http://www.xiaohui.org/archives/795.html" target="_blank"><a href="http://www.xiaohui.org/archives/795.html">http://www.xiaohui.org/archives/795.html</a></a>
来源： &lt;<a href="http://www.cnblogs.com/xuxm2007/archive/2013/04/04/2999741.html" target="_blank">hadoop的版本问题 - 阿笨猫 - 博客园</a>&gt;  </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--Hadoop版本梳理/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--Hadoop版本梳理" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--mapred_tutorial/">mapred_tutorial</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--mapred_tutorial/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="mapred_tutorial">mapred_tutorial</h1>
<p>Map/Reduce Tutorial
Table of contents
1 2 3 4 5
Purpose...............................................................................................................................2 Pre-requisites......................................................................................................................2 Overview............................................................................................................................2 Inputs and Outputs............................................................................................................. 3 Example: WordCount v1.0................................................................................................ 3
5.1 5.2 5.3
Source Code...................................................................................................................3 Usage............................................................................................................................. 6 Walk-through.................................................................................................................7 Payload.......................................................................................................................... 9 Job Configuration........................................................................................................ 13 Task Execution &amp; Environment.................................................................................. 14 Job Submission and Monitoring..................................................................................21 Job Input...................................................................................................................... 22 Job Output................................................................................................................... 23 Other Useful Features..................................................................................................25 Source Code.................................................................................................................31 Sample Runs................................................................................................................37 Highlights.................................................................................................................... 39
6
Map/Reduce - User Interfaces............................................................................................9
6.1 6.2 6.3 6.4 6.5 6.6 6.7
7
Example: WordCount v2.0.............................................................................................. 30
7.1 7.2 7.3
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</p>
<ol>
<li>Purpose
This document comprehensively describes all user-facing facets of the Hadoop Map/Reduce framework and serves as a tutorial.</li>
<li>Pre-requisites
Ensure that Hadoop is installed, configured and is running. More details: • Hadoop Quick Start for first-time users. • Hadoop Cluster Setup for large, distributed clusters.</li>
<li>Overview
Hadoop Map/Reduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner. A Map/Reduce job usually splits the input data-set into independent chunks which are processed by the map tasks in a completely parallel manner. The framework sorts the outputs of the maps, which are then input to the reduce tasks. Typically both the input and the output of the job are stored in a file-system. The framework takes care of scheduling tasks, monitoring them and re-executes the failed tasks. Typically the compute nodes and the storage nodes are the same, that is, the Map/Reduce framework and the Hadoop Distributed File System (see HDFS Architecture ) are running on the same set of nodes. This configuration allows the framework to effectively schedule tasks on the nodes where data is already present, resulting in very high aggregate bandwidth across the cluster. The Map/Reduce framework consists of a single master JobTracker and one slave TaskTracker per cluster-node. The master is responsible for scheduling the jobs&#39; component tasks on the slaves, monitoring them and re-executing the failed tasks. The slaves execute the tasks as directed by the master. Minimally, applications specify the input/output locations and supply map and reduce functions via implementations of appropriate interfaces and/or abstract-classes. These, and other job parameters, comprise the job configuration. The Hadoop job client then submits the job (jar/executable etc.) and configuration to the JobTracker which then assumes the responsibility of distributing the software/configuration to the slaves, scheduling tasks and monitoring them, providing status and diagnostic information to the job-client.
Page 2
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
Although the Hadoop framework is implemented in JavaTM, Map/Reduce applications need not be written in Java. • Hadoop Streaming is a utility which allows users to create and run jobs with any executables (e.g. shell utilities) as the mapper and/or the reducer. • Hadoop Pipes is a SWIG- compatible C++ API to implement Map/Reduce applications (non JNITM based).</li>
<li>Inputs and Outputs
The Map/Reduce framework operates exclusively on <key, value> pairs, that is, the framework views the input to the job as a set of <key, value> pairs and produces a set of <key, value> pairs as the output of the job, conceivably of different types. The key and value classes have to be serializable by the framework and hence need to implement the Writable interface. Additionally, the key classes have to implement the WritableComparable interface to facilitate sorting by the framework. Input and Output types of a Map/Reduce job: (input) <k1, v1> -&gt; map -&gt; <k2, v2> -&gt; combine -&gt; <k2, v2> -&gt; reduce -&gt; <k3, v3> (output)</li>
<li>Example: WordCount v1.0
Before we jump into the details, lets walk through an example Map/Reduce application to get a flavour for how they work. WordCount is a simple application that counts the number of occurences of each word in a given input set. This works with a local-standalone, pseudo-distributed or fully-distributed Hadoop installation(see Hadoop Quick Start).
5.1. Source Code
WordCount.java 1. 2. 3. 4. import java.io.IOException; import java.util./*; package org.myorg;
Page 3
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable> { private final static IntWritable one = new IntWritable(1); private Text word = new Text(); public class WordCount { import org.apache.hadoop.fs.Path; import org.apache.hadoop.conf./<em>; import org.apache.hadoop.io./</em>; import org.apache.hadoop.mapred./<em>; import org.apache.hadoop.util./</em>;</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li>18.
public void map(LongWritable key, Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { String line = value.toString(); StringTokenizer tokenizer = new StringTokenizer(line); while (tokenizer.hasMoreTokens()) { word.set(tokenizer.nextToken());</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>25.
output.collect(word, one); } }
Page 4
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li>28.
}
public static class Reduce extends MapReduceBase implements Reducer<Text, IntWritable, Text, IntWritable> { public void reduce(Text key, Iterator<IntWritable> values, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { int sum = 0; while (values.hasNext()) { sum += values.next().get(); } output.collect(key, new IntWritable(sum)); } }
29.</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>42.
public static void main(String[] args) throws Exception { JobConf conf = new JobConf(WordCount.class); conf.setJobName(&quot;wordcount&quot;);
conf.setOutputKeyClass(Text.class); 43. conf.setOutputValueClass(IntWritable.class); 44. 45. conf.setMapperClass(Map.class);
Page 5
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>conf.setCombinerClass(Reduce.class); 47. conf.setReducerClass(Reduce.class); 48. 49. conf.setInputFormat(TextInputFormat.class); 50. conf.setOutputFormat(TextOutputFormat.class); 51. 52. FileInputFormat.setInputPaths(conf, new Path(args[0])); 53. FileOutputFormat.setOutputPath(conf, new Path(args[1])); 54. 55. 57. 58. 59. } JobClient.runJob(conf); }
5.2. Usage
Assuming HADOOP_HOME is the root of the installation and HADOOP_VERSION is the Hadoop version installed, compile WordCount.java and create a jar: $ mkdir wordcount_classes $ javac -classpath ${HADOOP_HOME}/hadoop-${HADOOP_VERSION}-core.jar -d wordcount_classes WordCount.java $ jar -cvf /usr/joe/wordcount.jar -C wordcount_classes/ . Assuming that: • /usr/joe/wordcount/input - input directory in HDFS
Page 6
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
•
/usr/joe/wordcount/output - output directory in HDFS
Sample text-files as input: $ bin/hadoop dfs -ls /usr/joe/wordcount/input/ /usr/joe/wordcount/input/file01 /usr/joe/wordcount/input/file02 $ bin/hadoop dfs -cat /usr/joe/wordcount/input/file01 Hello World Bye World $ bin/hadoop dfs -cat /usr/joe/wordcount/input/file02 Hello Hadoop Goodbye Hadoop Run the application: $ bin/hadoop jar /usr/joe/wordcount.jar org.myorg.WordCount /usr/joe/wordcount/input /usr/joe/wordcount/output Output: $ bin/hadoop dfs -cat /usr/joe/wordcount/output/part-00000 Bye 1 Goodbye 1 Hadoop 2 Hello 2 World 2 Applications can specify a comma separated list of paths which would be present in the current working directory of the task using the option -files. The -libjars option allows applications to add jars to the classpaths of the maps and reduces. The -archives allows them to pass archives as arguments that are unzipped/unjarred and a link with name of the jar/zip are created in the current working directory of tasks. More details about the command line options are available at Hadoop Command Guide. Running wordcount example with -libjars and -files: hadoop jar hadoop-examples.jar wordcount -files cachefile.txt -libjars mylib.jar input output
5.3. Walk-through
The WordCount application is quite straight-forward. The Mapper implementation (lines 14-26), via the map method (lines 18-25), processes one line at a time, as provided by the specified TextInputFormat (line 49). It then splits the line into tokens separated by whitespaces, via the StringTokenizer, and emits a
Page 7
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
key-value pair of &lt; <word>, 1&gt;. For the given sample input the first map emits: &lt; Hello, 1&gt; &lt; World, 1&gt; &lt; Bye, 1&gt; &lt; World, 1&gt; The second map emits: &lt; Hello, 1&gt; &lt; Hadoop, 1&gt; &lt; Goodbye, 1&gt; &lt; Hadoop, 1&gt; We&#39;ll learn more about the number of maps spawned for a given job, and how to control them in a fine-grained manner, a bit later in the tutorial. WordCount also specifies a combiner (line 46). Hence, the output of each map is passed through the local combiner (which is same as the Reducer as per the job configuration) for local aggregation, after being sorted on the keys. The output of the first map: &lt; Bye, 1&gt; &lt; Hello, 1&gt; &lt; World, 2&gt; The output of the second map: &lt; Goodbye, 1&gt; &lt; Hadoop, 2&gt; &lt; Hello, 1&gt; The Reducer implementation (lines 28-36), via the reduce method (lines 29-35) just sums up the values, which are the occurence counts for each key (i.e. words in this example). Thus the output of the job is: &lt; Bye, 1&gt; &lt; Goodbye, 1&gt; &lt; Hadoop, 2&gt; &lt; Hello, 2&gt; &lt; World, 2&gt; The run method specifies various facets of the job, such as the input/output paths (passed via the command line), key/value types, input/output formats etc., in the JobConf. It then calls the JobClient.runJob (line 55) to submit the and monitor its progress.
Page 8
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
We&#39;ll learn more about JobConf, JobClient, Tool and other interfaces and classes a bit later in the tutorial.</li>
<li>Map/Reduce - User Interfaces
This section provides a reasonable amount of detail on every user-facing aspect of the Map/Reduce framwork. This should help users implement, configure and tune their jobs in a fine-grained manner. However, please note that the javadoc for each class/interface remains the most comprehensive documentation available; this is only meant to be a tutorial. Let us first take the Mapper and Reducer interfaces. Applications typically implement them to provide the map and reduce methods. We will then discuss other core interfaces including JobConf, JobClient, Partitioner, OutputCollector, Reporter, InputFormat, OutputFormat, OutputCommitter and others. Finally, we will wrap up by discussing some useful features of the framework such as the DistributedCache, IsolationRunner etc.
6.1. Payload
Applications typically implement the Mapper and Reducer interfaces to provide the map and reduce methods. These form the core of the job. 6.1.1. Mapper Mapper maps input key/value pairs to a set of intermediate key/value pairs. Maps are the individual tasks that transform input records into intermediate records. The transformed intermediate records do not need to be of the same type as the input records. A given input pair may map to zero or many output pairs. The Hadoop Map/Reduce framework spawns one map task for each InputSplit generated by the InputFormat for the job. Overall, Mapper implementations are passed the JobConf for the job via the JobConfigurable.configure(JobConf) method and override it to initialize themselves. The framework then calls map(WritableComparable, Writable, OutputCollector, Reporter) for each key/value pair in the InputSplit for that task. Applications can then override the Closeable.close() method to perform any required cleanup. Output pairs do not need to be of the same types as input pairs. A given input pair may map
Page 9
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
to zero or many output pairs. Output pairs are collected with calls to OutputCollector.collect(WritableComparable,Writable). Applications can use the Reporter to report progress, set application-level status messages and update Counters, or just indicate that they are alive. All intermediate values associated with a given output key are subsequently grouped by the framework, and passed to the Reducer(s) to determine the final output. Users can control the grouping by specifying a Comparator via JobConf.setOutputKeyComparatorClass(Class). The Mapper outputs are sorted and then partitioned per Reducer. The total number of partitions is the same as the number of reduce tasks for the job. Users can control which keys (and hence records) go to which Reducer by implementing a custom Partitioner. Users can optionally specify a combiner, via JobConf.setCombinerClass(Class), to perform local aggregation of the intermediate outputs, which helps to cut down the amount of data transferred from the Mapper to the Reducer. The intermediate, sorted outputs are always stored in a simple (key-len, key, value-len, value) format. Applications can control if, and how, the intermediate outputs are to be compressed and the CompressionCodec to be used via the JobConf.
6.1.1.1. How Many Maps?
The number of maps is usually driven by the total size of the inputs, that is, the total number of blocks of the input files. The right level of parallelism for maps seems to be around 10-100 maps per-node, although it has been set up to 300 maps for very cpu-light map tasks. Task setup takes awhile, so it is best if the maps take at least a minute to execute. Thus, if you expect 10TB of input data and have a blocksize of 128MB, you&#39;ll end up with 82,000 maps, unless setNumMapTasks(int) (which only provides a hint to the framework) is used to set it even higher. 6.1.2. Reducer Reducer reduces a set of intermediate values which share a key to a smaller set of values. The number of reduces for the job is set by the user via JobConf.setNumReduceTasks(int). Overall, Reducer implementations are passed the JobConf for the job via the JobConfigurable.configure(JobConf) method and can override it to initialize themselves. The
Page 10
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
framework then calls reduce(WritableComparable, Iterator, OutputCollector, Reporter) method for each <key, (list of values)> pair in the grouped inputs. Applications can then override the Closeable.close() method to perform any required cleanup. Reducer has 3 primary phases: shuffle, sort and reduce.
6.1.2.1. Shuffle
Input to the Reducer is the sorted output of the mappers. In this phase the framework fetches the relevant partition of the output of all the mappers, via HTTP.
6.1.2.2. Sort
The framework groups Reducer inputs by keys (since different mappers may have output the same key) in this stage. The shuffle and sort phases occur simultaneously; while map-outputs are being fetched they are merged.
Secondary Sort
If equivalence rules for grouping the intermediate keys are required to be different from those for grouping keys before reduction, then one may specify a Comparator via JobConf.setOutputValueGroupingComparator(Class). Since JobConf.setOutputKeyComparatorClass(Class) can be used to control how intermediate keys are grouped, these can be used in conjunction to simulate secondary sort on values.
6.1.2.3. Reduce
In this phase the reduce(WritableComparable, Iterator, OutputCollector, Reporter) method is called for each <key, (list of values)> pair in the grouped inputs. The output of the reduce task is typically written to the FileSystem via OutputCollector.collect(WritableComparable, Writable). Applications can use the Reporter to report progress, set application-level status messages and update Counters, or just indicate that they are alive. The output of the Reducer is not sorted.
6.1.2.4. How Many Reduces?
The right number of reduces seems to be 0.95 or 1.75 multiplied by (<no. of nodes> /<em> mapred.tasktracker.reduce.tasks.maximum).
Page 11
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
With 0.95 all of the reduces can launch immediately and start transfering map outputs as the maps finish. With 1.75 the faster nodes will finish their first round of reduces and launch a second wave of reduces doing a much better job of load balancing. Increasing the number of reduces increases the framework overhead, but increases load balancing and lowers the cost of failures. The scaling factors above are slightly less than whole numbers to reserve a few reduce slots in the framework for speculative-tasks and failed tasks.
6.1.2.5. Reducer NONE
It is legal to set the number of reduce-tasks to zero if no reduction is desired. In this case the outputs of the map-tasks go directly to the FileSystem, into the output path set by setOutputPath(Path). The framework does not sort the map-outputs before writing them out to the FileSystem. 6.1.3. Partitioner Partitioner partitions the key space. Partitioner controls the partitioning of the keys of the intermediate map-outputs. The key (or a subset of the key) is used to derive the partition, typically by a hash function. The total number of partitions is the same as the number of reduce tasks for the job. Hence this controls which of the m reduce tasks the intermediate key (and hence the record) is sent to for reduction. HashPartitioner is the default Partitioner. 6.1.4. Reporter Reporter is a facility for Map/Reduce applications to report progress, set application-level status messages and update Counters. Mapper and Reducer implementations can use the Reporter to report progress or just indicate that they are alive. In scenarios where the application takes a significant amount of time to process individual key/value pairs, this is crucial since the framework might assume that the task has timed-out and kill that task. Another way to avoid this is to set the configuration parameter mapred.task.timeout to a high-enough value (or even set it to zero for no time-outs). Applications can also update Counters using the Reporter.
Page 12
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
6.1.5. OutputCollector OutputCollector is a generalization of the facility provided by the Map/Reduce framework to collect data output by the Mapper or the Reducer (either the intermediate outputs or the output of the job). Hadoop Map/Reduce comes bundled with a library of generally useful mappers, reducers, and partitioners.
6.2. Job Configuration
JobConf represents a Map/Reduce job configuration. JobConf is the primary interface for a user to describe a Map/Reduce job to the Hadoop framework for execution. The framework tries to faithfully execute the job as described by JobConf, however: • f Some configuration parameters may have been marked as final by administrators and hence cannot be altered. • While some job parameters are straight-forward to set (e.g. setNumReduceTasks(int)), other parameters interact subtly with the rest of the framework and/or job configuration and are more complex to set (e.g. setNumMapTasks(int)). JobConf is typically used to specify the Mapper, combiner (if any), Partitioner, Reducer, InputFormat, OutputFormat and OutputCommitter implementations. JobConf also indicates the set of input files (setInputPaths(JobConf, Path...) /addInputPath(JobConf, Path)) and (setInputPaths(JobConf, String) /addInputPaths(JobConf, String)) and where the output files should be written (setOutputPath(Path)). Optionally, JobConf is used to specify other advanced facets of the job such as the Comparator to be used, files to be put in the DistributedCache, whether intermediate and/or job outputs are to be compressed (and how), debugging via user-provided scripts (setMapDebugScript(String)/setReduceDebugScript(String)) , whether job tasks can be executed in a speculative manner (setMapSpeculativeExecution(boolean))/(setReduceSpeculativeExecution(boolean)) , maximum number of attempts per task (setMaxMapAttempts(int)/setMaxReduceAttempts(int)) , percentage of tasks failure which can be tolerated by the job (setMaxMapTaskFailuresPercent(int)/setMaxReduceTaskFailuresPercent(int)) etc. Of course, users can use set(String, String)/get(String, String) to set/get arbitrary parameters needed by applications. However, use the DistributedCache for large amounts of
Page 13
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
(read-only) data.
6.3. Task Execution &amp; Environment
The TaskTracker executes the Mapper/ Reducer task as a child process in a separate jvm. The child-task inherits the environment of the parent TaskTracker. The user can specify additional options to the child-jvm via the mapred.child.java.opts configuration parameter in the JobConf such as non-standard paths for the run-time linker to search shared libraries via -Djava.library.path=&lt;&gt; etc. If the mapred.child.java.opts contains the symbol @taskid@ it is interpolated with value of taskid of the map/reduce task. Here is an example with multiple arguments and substitutions, showing jvm GC logging, and start of a passwordless JVM JMX agent so that it can connect with jconsole and the likes to watch child memory, threads and get thread dumps. It also sets the maximum heap-size of the child jvm to 512MB and adds an additional path to the java.library.path of the child-jvm. <property> <name>mapred.child.java.opts</name> <value> -Xmx512M -Djava.library.path=/home/mycompany/lib -verbose:gc -Xloggc:/tmp/@taskid@.gc -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false </value> </property> 6.3.1. Memory management Users/admins can also specify the maximum virtual memory of the launched child-task, and any sub-process it launches recursively, using mapred.child.ulimit. Note that the value set here is a per process limit. The value for mapred.child.ulimit should be specified in kilo bytes (KB). And also the value must be greater than or equal to the -Xmx passed to JavaVM, else the VM might not start. Note: mapred.child.java.opts are used only for configuring the launched child tasks from task tracker. Configuring the memory options for daemons is documented in cluster_setup.html The memory available to some parts of the framework is also configurable. In map and
Page 14
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
reduce tasks, performance may be influenced by adjusting parameters influencing the concurrency of operations and the frequency with which data will hit disk. Monitoring the filesystem counters for a job- particularly relative to byte counts from the map and into the reduce- is invaluable to the tuning of these parameters. 6.3.2. Map Parameters A record emitted from a map will be serialized into a buffer and metadata will be stored into accounting buffers. As described in the following options, when either the serialization buffer or the metadata exceed a threshold, the contents of the buffers will be sorted and written to disk in the background while the map continues to output records. If either buffer fills completely while the spill is in progress, the map thread will block. When the map is finished, any remaining records are written to disk and all on-disk segments are merged into a single file. Minimizing the number of spills to disk can decrease map time, but a larger buffer also decreases the memory available to the mapper.
Name io.sort.mb int Type Description The cumulative size of the serialization and accounting buffers storing records emitted from the map, in megabytes. The ratio of serialization to accounting space can be adjusted. Each serialized record requires 16 bytes of accounting information in addition to its serialized size to effect the sort. This percentage of space allocated from io.sort.mb affects the probability of a spill to disk being caused by either exhaustion of the serialization buffer or the accounting space. Clearly, for a map outputting small records, a higher value than the default will likely decrease the number of spills to disk. This is the threshold for the accounting and serialization buffers. When this percentage of either buffer has filled, their
io.sort.record.percent
float
io.sort.spill.percent
float
Page 15
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
contents will be spilled to disk in the background. Let io.sort.record.percent be r, io.sort.mb be x, and this value be q. The maximum number of records collected before the collection thread will spill is r /</em> x /<em> q /</em> 2^16. Note that a higher value may decrease the number of- or even eliminate- merges, but will also increase the probability of the map task getting blocked. The lowest average map times are usually obtained by accurately estimating the size of the map output and preventing multiple spills.
Other notes • If either spill threshold is exceeded while a spill is in progress, collection will continue until the spill is finished. For example, if io.sort.buffer.spill.percent is set to 0.33, and the remainder of the buffer is filled while the spill runs, the next spill will include all the collected records, or 0.66 of the buffer, and will not generate additional spills. In other words, the thresholds are defining triggers, not blocking. • A record larger than the serialization buffer will first trigger a spill, then be spilled to a separate file. It is undefined whether or not this record will first pass through the combiner. 6.3.3. Shuffle/Reduce Parameters As described previously, each reduce fetches the output assigned to it by the Partitioner via HTTP into memory and periodically merges these outputs to disk. If intermediate compression of map outputs is turned on, each output is decompressed into memory. The following options affect the frequency of these merges to disk prior to the reduce and the memory allocated to map output during the reduce.
Name io.sort.factor int Type Description Specifies the number of segments on disk to be merged at the same time. It limits the number of open files and compression codecs during the merge. If the number of files
Page 16
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
exceeds this limit, the merge will proceed in several passes. Though this limit also applies to the map, most jobs should be configured so that hitting this limit is unlikely there. mapred.inmem.merge.threshold int The number of sorted map outputs fetched into memory before being merged to disk. Like the spill thresholds in the preceding note, this is not defining a unit of partition, but a trigger. In practice, this is usually set very high (1000) or disabled (0), since merging in-memory segments is often less expensive than merging from disk (see notes following this table). This threshold influences only the frequency of in-memory merges during the shuffle. The memory threshold for fetched map outputs before an in-memory merge is started, expressed as a percentage of memory allocated to storing map outputs in memory. Since map outputs that can&#39;t fit in memory can be stalled, setting this high may decrease parallelism between the fetch and merge. Conversely, values as high as 1.0 have been effective for reduces whose input can fit entirely in memory. This parameter influences only the frequency of in-memory merges during the shuffle. The percentage of memoryrelative to the maximum heapsize as typically specified in mapred.child.java.optsthat can be allocated to storing
mapred.job.shuffle.merge.percentfloat
mapred.job.shuffle.input.buffer.percent float
Page 17
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
map outputs during the shuffle. Though some memory should be set aside for the framework, in general it is advantageous to set this high enough to store large and numerous map outputs. mapred.job.reduce.input.buffer.percent float The percentage of memory relative to the maximum heapsize in which map outputs may be retained during the reduce. When the reduce begins, map outputs will be merged to disk until those that remain are under the resource limit this defines. By default, all map outputs are merged to disk before the reduce begins to maximize the memory available to the reduce. For less memory-intensive reduces, this should be increased to avoid trips to disk.
Other notes • If a map output is larger than 25 percent of the memory allocated to copying map outputs, it will be written directly to disk without first staging through memory. • When running with a combiner, the reasoning about high merge thresholds and large buffers may not hold. For merges started before all map outputs have been fetched, the combiner is run while spilling to disk. In some cases, one can obtain better reduce times by spending resources combining map outputs- making disk spills small and parallelizing spilling and fetching- rather than aggressively increasing buffer sizes. • When merging in-memory map outputs to disk to begin the reduce, if an intermediate merge is necessary because there are segments to spill and at least io.sort.factor segments already on disk, the in-memory map outputs will be part of the intermediate merge. 6.3.4. Directory Structure The task tracker has local directory, ${mapred.local.dir}/taskTracker/ to create localized cache and localized job. It can define multiple local directories (spanning multiple disks) and then each filename is assigned to a semi-random local directory. When the job starts, task tracker creates a localized job directory relative to the local directory specified in
Page 18
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
the configuration. Thus the task tracker directory structure looks the following: • ${mapred.local.dir}/taskTracker/archive/ : The distributed cache. This directory holds the localized distributed cache. Thus localized distributed cache is shared among all the tasks and jobs • ${mapred.local.dir}/taskTracker/jobcache/$jobid/ : The localized job directory • ${mapred.local.dir}/taskTracker/jobcache/$jobid/work/ : The job-specific shared directory. The tasks can use this space as scratch space and share files among them. This directory is exposed to the users through the configuration property job.local.dir. The directory can accessed through api JobConf.getJobLocalDir(). It is available as System property also. So, users (streaming etc.) can call System.getProperty(&quot;job.local.dir&quot;) to access the directory. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/jars/ : The jars directory, which has the job jar file and expanded jar. The job.jar is the application&#39;s jar file that is automatically distributed to each machine. It is expanded in jars directory before the tasks for the job start. The job.jar location is accessible to the application through the api JobConf.getJar() . To access the unjarred directory, JobConf.getJar().getParent() can be called. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/job.xml : The job.xml file, the generic job configuration, localized for the job. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid : The task directory for each task attempt. Each task directory again has the following structure : • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid/job.xml : A job.xml file, task localized job configuration, Task localization means that properties have been set that are specific to this particular task within the job. The properties localized for each task are described below. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid/output : A directory for intermediate output files. This contains the temporary map reduce data generated by the framework such as map output files etc. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid/work : The curernt working directory of the task. With jvm reuse enabled for tasks, this directory will be the directory on which the jvm has started • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid/work/tmp : The temporary directory for the task. (User can specify the property mapred.child.tmp to set the value of temporary directory for map and reduce tasks. This defaults to ./tmp. If the value is not an absolute path, it is prepended with task&#39;s working directory. Otherwise, it is directly assigned. The directory will be created if it doesn&#39;t exist. Then, the child java tasks are executed
Page 19
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
with option -Djava.io.tmpdir=&#39;the absolute path of the tmp dir&#39;. Anp pipes and streaming are set with environment variable, TMPDIR=&#39;the absolute path of the tmp dir&#39;). This directory is created, if mapred.child.tmp has the value ./tmp
6.3.5. Task JVM Reuse Jobs can enable task JVMs to be reused by specifying the job configuration mapred.job.reuse.jvm.num.tasks. If the value is 1 (the default), then JVMs are not reused (i.e. 1 task per JVM). If it is -1, there is no limit to the number of tasks a JVM can run (of the same job). One can also specify some value greater than 1 using the api JobConf.setNumTasksToExecutePerJvm(int) The following properties are localized in the job configuration for each task&#39;s execution:
Name mapred.job.id mapred.jar job.local.dir mapred.tip.id mapred.task.id mapred.task.is.map mapred.task.partition map.input.file map.input.start map.input.length mapred.work.output.dir String String String String String boolean int String long long String Type The job id job.jar location in job directory The job specific shared scratch space The task id The task attempt id Is this a map task The id of the task within the job The filename that the map is reading from The offset of the start of the map input split The number of bytes in the map input split The task&#39;s temporary output directory Description
The standard output (stdout) and error (stderr) streams of the task are read by the TaskTracker and logged to ${HADOOP<em>LOG_DIR}/userlogs
Page 20
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
The DistributedCache can also be used to distribute both jars and native libraries for use in the map and/or reduce tasks. The child-jvm always has its current working directory added to the java.library.path and LD_LIBRARY_PATH. And hence the cached libraries can be loaded via System.loadLibrary or System.load. More details on how to load shared libraries through distributed cache are documented at native_libraries.html
6.4. Job Submission and Monitoring
JobClient is the primary interface by which user-job interacts with the JobTracker. JobClient provides facilities to submit jobs, track their progress, access component-tasks&#39; reports and logs, get the Map/Reduce cluster&#39;s status information and so on. The job submission process involves: 1. Checking the input and output specifications of the job. 2. Computing the InputSplit values for the job. 3. Setting up the requisite accounting information for the DistributedCache of the job, if necessary. 4. Copying the job&#39;s jar and configuration to the Map/Reduce system directory on the FileSystem. 5. Submitting the job to the JobTracker and optionally monitoring it&#39;s status. Job history files are also logged to user specified directory hadoop.job.history.user.location which defaults to job output directory. The files are stored in &quot;_logs/history/&quot; in the specified directory. Hence, by default they will be in mapred.output.dir/_logs/history. User can stop logging by giving the value none for hadoop.job.history.user.location User can view the history logs summary in specified directory using the following command $ bin/hadoop job -history output-dir This command will print job details, failed and killed tip details. More details about the job such as successful tasks and task attempts made for each task can be viewed using the following command $ bin/hadoop job -history all output-dir User can use OutputLogFilter to filter log files from the output directory listing. Normally the user creates the application, describes various facets of the job via JobConf, and then uses the JobClient to submit the job and monitor its progress. 6.4.1. Job Control Users may need to chain Map/Reduce jobs to accomplish complex tasks which cannot be
Page 21
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
done via a single Map/Reduce job. This is fairly easy since the output of the job typically goes to distributed file-system, and the output, in turn, can be used as the input for the next job. However, this also means that the onus on ensuring jobs are complete (success/failure) lies squarely on the clients. In such cases, the various job-control options are: • runJob(JobConf) : Submits the job and returns only after the job has completed. • submitJob(JobConf) : Only submits the job, then poll the returned handle to the RunningJob to query status and make scheduling decisions. • JobConf.setJobEndNotificationURI(String) : Sets up a notification upon job-completion, thus avoiding polling.
6.5. Job Input
InputFormat describes the input-specification for a Map/Reduce job. The Map/Reduce framework relies on the InputFormat of the job to: 1. Validate the input-specification of the job. 2. Split-up the input file(s) into logical InputSplit instances, each of which is then assigned to an individual Mapper. 3. Provide the RecordReader implementation used to glean input records from the logical InputSplit for processing by the Mapper. The default behavior of file-based InputFormat implementations, typically sub-classes of FileInputFormat, is to split the input into logical InputSplit instances based on the total size, in bytes, of the input files. However, the FileSystem blocksize of the input files is treated as an upper bound for input splits. A lower bound on the split size can be set via mapred.min.split.size. Clearly, logical splits based on input-size is insufficient for many applications since record boundaries must be respected. In such cases, the application should implement a RecordReader, who is responsible for respecting record-boundaries and presents a record-oriented view of the logical InputSplit to the individual task. TextInputFormat is the default InputFormat. If TextInputFormat is the InputFormat for a given job, the framework detects input-files with the .gz extensions and automatically decompresses them using the appropriate CompressionCodec. However, it must be noted that compressed files with the above extensions cannot be split and each compressed file is processed in its entirety by a single mapper.
Page 22
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
6.5.1. InputSplit InputSplit represents the data to be processed by an individual Mapper. Typically InputSplit presents a byte-oriented view of the input, and it is the responsibility of RecordReader to process and present a record-oriented view. FileSplit is the default InputSplit. It sets map.input.file to the path of the input file for the logical split. 6.5.2. RecordReader RecordReader reads <key, value> pairs from an InputSplit. Typically the RecordReader converts the byte-oriented view of the input, provided by the InputSplit, and presents a record-oriented to the Mapper implementations for processing. RecordReader thus assumes the responsibility of processing record boundaries and presents the tasks with keys and values.
6.6. Job Output
OutputFormat describes the output-specification for a Map/Reduce job. The Map/Reduce framework relies on the OutputFormat of the job to: 1. Validate the output-specification of the job; for example, check that the output directory doesn&#39;t already exist. 2. Provide the RecordWriter implementation used to write the output files of the job. Output files are stored in a FileSystem. TextOutputFormat is the default OutputFormat. 6.6.1. OutputCommitter OutputCommitter describes the commit of task output for a Map/Reduce job. The Map/Reduce framework relies on the OutputCommitter of the job to: 1. Setup the job during initialization. For example, create the temporary output directory for the job during the initialization of the job. Job setup is done by a separate task when the job is in PREP state and after initializing tasks. Once the setup task completes, the job will be moved to RUNNING state. 2. Cleanup the job after the job completion. For example, remove the temporary output directory after the job completion. Job cleanup is done by a separate task at the end of the
Page 23
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
job. Job is declared SUCCEDED/FAILED/KILLED after the cleanup task completes. 3. Setup the task temporary output. Task setup is done as part of the same task, during task initialization. 4. Check whether a task needs a commit. This is to avoid the commit procedure if a task does not need commit. 5. Commit of the task output. Once task is done, the task will commit it&#39;s output if required. 6. Discard the task commit. If the task has been failed/killed, the output will be cleaned-up. If task could not cleanup (in exception block), a separate task will be launched with same attempt-id to do the cleanup. FileOutputCommitter is the default OutputCommitter. Job setup/cleanup tasks occupy map or reduce slots, whichever is free on the TaskTracker. And JobCleanup task, TaskCleanup tasks and JobSetup task have the highest priority, and in that order. 6.6.2. Task Side-Effect Files In some applications, component tasks need to create and/or write to side-files, which differ from the actual job-output files. In such cases there could be issues with two instances of the same Mapper or Reducer running simultaneously (for example, speculative tasks) trying to open and/or write to the same file (path) on the FileSystem. Hence the application-writer will have to pick unique names per task-attempt (using the attemptid, say attempt_200709221812_0001_m_000000_0), not just per task. To avoid these issues the Map/Reduce framework, when the OutputCommitter is FileOutputCommitter, maintains a special ${mapred.output.dir}/_temporary/</em>${taskid} sub-directory accessible via ${mapred.work.output.dir} for each task-attempt on the FileSystem where the output of the task-attempt is stored. On successful completion of the task-attempt, the files in the ${mapred.output.dir}/<em>temporary/</em>${taskid} (only) are promoted to ${mapred.output.dir}. Of course, the framework discards the sub-directory of unsuccessful task-attempts. This process is completely transparent to the application. The application-writer can take advantage of this feature by creating any side-files required in ${mapred.work.output.dir} during execution of a task via FileOutputFormat.getWorkOutputPath(), and the framework will promote them similarly for succesful task-attempts, thus eliminating the need to pick unique paths per task-attempt. Note: The value of ${mapred.work.output.dir} during execution of a particular task-attempt is actually ${mapred.output.dir}/<em>temporary/</em>{$taskid}, and this value is set by the Map/Reduce framework. So, just create any side-files in the path returned by FileOutputFormat.getWorkOutputPath() from map/reduce task to take advantage
Page 24
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
of this feature. The entire discussion holds true for maps of jobs with reducer=NONE (i.e. 0 reduces) since output of the map, in that case, goes directly to HDFS. 6.6.3. RecordWriter RecordWriter writes the output <key, value> pairs to an output file. RecordWriter implementations write the job outputs to the FileSystem.
6.7. Other Useful Features
6.7.1. Submitting Jobs to Queues Users submit jobs to Queues. Queues, as collection of jobs, allow the system to provide specific functionality. For example, queues use ACLs to control which users who can submit jobs to them. Queues are expected to be primarily used by Hadoop Schedulers. Hadoop comes configured with a single mandatory queue, called &#39;default&#39;. Queue names are defined in the mapred.queue.names property of the Hadoop site configuration. Some job schedulers, such as the Capacity Scheduler, support multiple queues. A job defines the queue it needs to be submitted to through the mapred.job.queue.name property, or through the setQueueName(String) API. Setting the queue name is optional. If a job is submitted without an associated queue name, it is submitted to the &#39;default&#39; queue. 6.7.2. Counters Counters represent global counters, defined either by the Map/Reduce framework or applications. Each Counter can be of any Enum type. Counters of a particular Enum are bunched into groups of type Counters.Group. Applications can define arbitrary Counters (of type Enum) and update them via Reporter.incrCounter(Enum, long) or Reporter.incrCounter(String, String, long) in the map and/or reduce methods. These counters are then globally aggregated by the framework. 6.7.3. DistributedCache DistributedCache distributes application-specific, large, read-only files efficiently. DistributedCache is a facility provided by the Map/Reduce framework to cache files
Page 25
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
(text, archives, jars and so on) needed by applications. Applications specify the files to be cached via urls (hdfs://) in the JobConf. The DistributedCache assumes that the files specified via hdfs:// urls are already present on the FileSystem. The framework will copy the necessary files to the slave node before any tasks for the job are executed on that node. Its efficiency stems from the fact that the files are only copied once per job and the ability to cache archives which are un-archived on the slaves. DistributedCache tracks the modification timestamps of the cached files. Clearly the cache files should not be modified by the application or externally while the job is executing. DistributedCache can be used to distribute simple, read-only data/text files and more complex types such as archives and jars. Archives (zip, tar, tgz and tar.gz files) are un-archived at the slave nodes. Files have execution permissions set. The files/archives can be distributed by setting the property mapred.cache.{files|archives}. If more than one file/archive has to be distributed, they can be added as comma separated paths. The properties can also be set by APIs DistributedCache.addCacheFile(URI,conf)/ DistributedCache.addCacheArchive(URI,conf) and DistributedCache.setCacheFiles(URIs,conf)/ DistributedCache.setCacheArchives(URIs,conf) where URI is of the form hdfs://host:port/absolute-path/#link-name. In Streaming, the files can be distributed through command line option -cacheFile/-cacheArchive. Optionally users can also direct the DistributedCache to symlink the cached file(s) into the current working directory of the task via the DistributedCache.createSymlink(Configuration) api. Or by setting the configuration property mapred.create.symlink as yes. The DistributedCache will use the fragment of the URI as the name of the symlink. For example, the URI hdfs://namenode:port/lib.so.1/#lib.so will have the symlink name as lib.so in task&#39;s cwd for the file lib.so.1 in distributed cache. The DistributedCache can also be used as a rudimentary software distribution mechanism for use in the map and/or reduce tasks. It can be used to distribute both jars and native libraries. The DistributedCache.addArchiveToClassPath(Path, Configuration) or DistributedCache.addFileToClassPath(Path, Configuration) api can be used to cache files/jars and also add them to the classpath of child-jvm. The same can be done by setting the configuration properties mapred.job.classpath.{files|archives}. Similarly the cached files that are symlinked into the working directory of the task can be used to distribute native libraries and load them.
Page 26
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
6.7.4. Tool The Tool interface supports the handling of generic Hadoop command-line options. Tool is the standard for any Map/Reduce tool or application. The application should delegate the handling of standard command-line options to GenericOptionsParser via ToolRunner.run(Tool, String[]) and only handle its custom arguments. The generic Hadoop command-line options are: -conf <configuration file> -D <property=value> -fs <local|namenode:port> -jt <local|jobtracker:port> 6.7.5. IsolationRunner IsolationRunner is a utility to help debug Map/Reduce programs. To use the IsolationRunner, first set keep.failed.tasks.files to true (also see keep.tasks.files.pattern). Next, go to the node on which the failed task ran and go to the TaskTracker&#39;s local directory and run the IsolationRunner: $ cd <local path>/taskTracker/${taskid}/work $ bin/hadoop org.apache.hadoop.mapred.IsolationRunner ../job.xml IsolationRunner will run the failed task in a single jvm, which can be in the debugger, over precisely the same input. 6.7.6. Profiling Profiling is a utility to get a representative (2 or 3) sample of built-in java profiler for a sample of maps and reduces. User can specify whether the system should collect profiler information for some of the tasks in the job by setting the configuration property mapred.task.profile. The value can be set using the api JobConf.setProfileEnabled(boolean). If the value is set true, the task profiling is enabled. The profiler information is stored in the user log directory. By default, profiling is not enabled for the job. Once user configures that profiling is needed, she/he can use the configuration property mapred.task.profile.{maps|reduces} to set the ranges of map/reduce tasks to
Page 27
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
profile. The value can be set using the api JobConf.setProfileTaskRange(boolean,String). By default, the specified range is 0-2.
User can also specify the profiler configuration arguments by setting the configuration property mapred.task.profile.params. The value can be specified using the api JobConf.setProfileParams(String). If the string contains a %s, it will be replaced with the name of the profiling output file when the task runs. These parameters are passed to the task child JVM on the command line. The default value for the profiling parameters is -agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s 6.7.7. Debugging The Map/Reduce framework provides a facility to run user-provided scripts for debugging. When a map/reduce task fails, a user can run a debug script, to process task logs for example. The script is given access to the task&#39;s stdout and stderr outputs, syslog and jobconf. The output from the debug script&#39;s stdout and stderr is displayed on the console diagnostics and also as part of the job UI. In the following sections we discuss how to submit a debug script with a job. The script file needs to be distributed and submitted to the framework.
6.7.7.1. How to distribute the script file:
The user needs to use DistributedCache to distribute and symlink the script file.
6.7.7.2. How to submit the script:
A quick way to submit the debug script is to set values for the properties mapred.map.task.debug.script and mapred.reduce.task.debug.script, for debugging map and reduce tasks respectively. These properties can also be set by using APIs JobConf.setMapDebugScript(String) and JobConf.setReduceDebugScript(String) . In streaming mode, a debug script can be submitted with the command-line options -mapdebug and -reducedebug, for debugging map and reduce tasks respectively. The arguments to the script are the task&#39;s stdout, stderr, syslog and jobconf files. The debug command, run on the node where the map/reduce task failed, is: $script $stdout $stderr $syslog $jobconf Pipes programs have the c++ program name as a fifth argument for the command. Thus for the pipes programs the command is $script $stdout $stderr $syslog $jobconf $program
Page 28
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
6.7.7.3. Default Behavior:
For pipes, a default script is run to process core dumps under gdb, prints stack trace and gives info about running threads. 6.7.8. JobControl JobControl is a utility which encapsulates a set of Map/Reduce jobs and their dependencies. 6.7.9. Data Compression Hadoop Map/Reduce provides facilities for the application-writer to specify compression for both intermediate map-outputs and the job-outputs i.e. output of the reduces. It also comes bundled with CompressionCodec implementation for the zlib compression algorithm. The gzip file format is also supported. Hadoop also provides native implementations of the above compression codecs for reasons of both performance (zlib) and non-availability of Java libraries. More details on their usage and availability are available here.
6.7.9.1. Intermediate Outputs
Applications can control compression of intermediate map-outputs via the JobConf.setCompressMapOutput(boolean) api and the CompressionCodec to be used via the JobConf.setMapOutputCompressorClass(Class) api.
6.7.9.2. Job Outputs
Applications can control compression of job-outputs via the FileOutputFormat.setCompressOutput(JobConf, boolean) api and the CompressionCodec to be used can be specified via the FileOutputFormat.setOutputCompressorClass(JobConf, Class) api. If the job outputs are to be stored in the SequenceFileOutputFormat, the required SequenceFile.CompressionType (i.e. RECORD / BLOCK - defaults to RECORD) can be specified via the SequenceFileOutputFormat.setOutputCompressionType(JobConf, SequenceFile.CompressionType) api. 6.7.10. Skipping Bad Records Hadoop provides an option where a certain set of bad input records can be skipped when processing map inputs. Applications can control this feature through the SkipBadRecords
Page 29
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
class. This feature can be used when map tasks crash deterministically on certain input. This usually happens due to bugs in the map function. Usually, the user would have to fix these bugs. This is, however, not possible sometimes. The bug may be in third party libraries, for example, for which the source code is not available. In such cases, the task never completes successfully even after multiple attempts, and the job fails. With this feature, only a small portion of data surrounding the bad records is lost, which may be acceptable for some applications (those performing statistical analysis on very large data, for example). By default this feature is disabled. For enabling it, refer to SkipBadRecords.setMapperMaxSkipRecords(Configuration, long) and SkipBadRecords.setReducerMaxSkipGroups(Configuration, long). With this feature enabled, the framework gets into &#39;skipping mode&#39; after a certain number of map failures. For more details, see SkipBadRecords.setAttemptsToStartSkipping(Configuration, int). In &#39;skipping mode&#39;, map tasks maintain the range of records being processed. To do this, the framework relies on the processed record counter. See SkipBadRecords.COUNTER_MAP_PROCESSED_RECORDS and SkipBadRecords.COUNTER_REDUCE_PROCESSED_GROUPS. This counter enables the framework to know how many records have been processed successfully, and hence, what record range caused a task to crash. On further attempts, this range of records is skipped. The number of records skipped depends on how frequently the processed record counter is incremented by the application. It is recommended that this counter be incremented after every record is processed. This may not be possible in some applications that typically batch their processing. In such cases, the framework may skip additional records surrounding the bad record. Users can control the number of skipped records through SkipBadRecords.setMapperMaxSkipRecords(Configuration, long) and SkipBadRecords.setReducerMaxSkipGroups(Configuration, long). The framework tries to narrow the range of skipped records using a binary search-like approach. The skipped range is divided into two halves and only one half gets executed. On subsequent failures, the framework figures out which half contains bad records. A task will be re-executed till the acceptable skipped value is met or all task attempts are exhausted. To increase the number of task attempts, use JobConf.setMaxMapAttempts(int) and JobConf.setMaxReduceAttempts(int). Skipped records are written to HDFS in the sequence file format, for later analysis. The location can be changed through SkipBadRecords.setSkipOutputPath(JobConf, Path).</li>
<li>Example: WordCount v2.0
Page 30
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
Here is a more complete WordCount which uses many of the features provided by the Map/Reduce framework we discussed so far. This needs the HDFS to be up and running, especially for the DistributedCache-related features. Hence it only works with a pseudo-distributed or fully-distributed Hadoop installation.
7.1. Source Code
WordCount.java 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable> { public class WordCount extends Configured implements Tool { import org.apache.hadoop.fs.Path; import org.apache.hadoop.filecache.DistributedCache; import org.apache.hadoop.conf./<em>; import org.apache.hadoop.io./</em>; import org.apache.hadoop.mapred./<em>; import org.apache.hadoop.util./</em>; import java.io./<em>; import java.util./</em>; package org.myorg;</li>
<li><ol>
<li>static enum Counters { INPUT_WORDS }
Page 31
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>private boolean caseSensitive = true; private Set<String> patternsToSkip = new HashSet<String>(); private final static IntWritable one = new IntWritable(1); private Text word = new Text();</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>public void configure(JobConf job) { caseSensitive = job.getBoolean(&quot;wordcount.case.sensitive&quot;, true); inputFile = job.get(&quot;map.input.file&quot;); private long numRecords = 0; private String inputFile;</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li>32.
if (job.getBoolean(&quot;wordcount.skip.patterns&quot;, false)) { Path[] patternsFiles = new Path[0]; try { patternsFiles = DistributedCache.getLocalCacheFiles(job); } catch (IOException ioe) { System.err.println(&quot;Caught</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li>37.
Page 32
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
exception while getting cached files: &quot; + StringUtils.stringifyException(ioe)); 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. private void parseSkipFile(Path patternsFile) { try { BufferedReader fis = new BufferedReader(new FileReader(patternsFile.toString())); String pattern = null; while ((pattern = fis.readLine()) != null) { patternsToSkip.add(pattern); } } catch (IOException ioe) { System.err.println(&quot;Caught exception while parsing the cached file &#39;&quot; + patternsFile + &quot;&#39; : &quot; + StringUtils.stringifyException(ioe)); } } } for (Path patternsFile : patternsFiles) { parseSkipFile(patternsFile); } } }</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>53.</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li>57.
public void map(LongWritable key,
Page 33
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { 58. String line = (caseSensitive) ? value.toString() : value.toString().toLowerCase();</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li>&quot;&quot;); 62. 63. 64. 65. 66. word.set(tokenizer.nextToken()); 67. 68. reporter.incrCounter(Counters.INPUT_WORDS, 1); 69. 70. 71. 72. if ((++numRecords % 100) == 0) { reporter.setStatus(&quot;Finished processing &quot; + numRecords + &quot; records &quot; + &quot;from the input file: &quot; + inputFile); } } } } output.collect(word, one); StringTokenizer tokenizer = new StringTokenizer(line); while (tokenizer.hasMoreTokens()) { } for (String pattern : patternsToSkip) { line = line.replaceAll(pattern,</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li>75.
Page 34
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
<li><ol>
<li>public static class Reduce extends MapReduceBase implements Reducer<Text, IntWritable, Text, IntWritable> { public void reduce(Text key, Iterator<IntWritable> values, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { int sum = 0; while (values.hasNext()) { sum += values.next().get(); } output.collect(key, new IntWritable(sum)); } }
78.</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>91.
public int run(String[] args) throws Exception { JobConf conf = new JobConf(getConf(), WordCount.class); conf.setJobName(&quot;wordcount&quot;);
conf.setOutputKeyClass(Text.class); 92. conf.setOutputValueClass(IntWritable.class); 93. 94. 95. conf.setMapperClass(Map.class);
Page 35
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
conf.setCombinerClass(Reduce.class); 96. conf.setReducerClass(Reduce.class); 97. 98. conf.setInputFormat(TextInputFormat.class); 99. conf.setOutputFormat(TextOutputFormat.class); 100. 101. 102. 103. 104. DistributedCache.addCacheFile(new Path(args[++i]).toUri(), conf); 105. conf.setBoolean(&quot;wordcount.skip.patterns&quot;, true); 106. 107. 108. 109. 110. 111. FileInputFormat.setInputPaths(conf, new Path(other_args.get(0))); 112. FileOutputFormat.setOutputPath(conf, new Path(other_args.get(1))); 113. } else { other_args.add(args[i]); } } List<String> other_args = new ArrayList<String>(); for (int i=0; i &lt; args.length; ++i) { if (&quot;-skip&quot;.equals(args[i])) {
Page 36
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>119.
JobClient.runJob(conf); return 0; }
public static void main(String[] args) throws Exception { int res = ToolRunner.run(new Configuration(), new WordCount(), args); System.exit(res); } }</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li>123.
7.2. Sample Runs
Sample text-files as input: $ bin/hadoop dfs -ls /usr/joe/wordcount/input/ /usr/joe/wordcount/input/file01 /usr/joe/wordcount/input/file02 $ bin/hadoop dfs -cat /usr/joe/wordcount/input/file01 Hello World, Bye World! $ bin/hadoop dfs -cat /usr/joe/wordcount/input/file02 Hello Hadoop, Goodbye to hadoop. Run the application: $ bin/hadoop jar /usr/joe/wordcount.jar org.myorg.WordCount /usr/joe/wordcount/input /usr/joe/wordcount/output Output: $ bin/hadoop dfs -cat /usr/joe/wordcount/output/part-00000 Bye 1 Goodbye 1 Hadoop, 1 Hello 2
Page 37
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
World! 1 World, 1 hadoop. 1 to 1 Notice that the inputs differ from the first version we looked at, and how they affect the outputs. Now, lets plug-in a pattern-file which lists the word-patterns to be ignored, via the DistributedCache. $ hadoop dfs -cat /user/joe/wordcount/patterns.txt . \, ! to Run it again, this time with more options: $ bin/hadoop jar /usr/joe/wordcount.jar org.myorg.WordCount -Dwordcount.case.sensitive=true /usr/joe/wordcount/input /usr/joe/wordcount/output -skip /user/joe/wordcount/patterns.txt As expected, the output: $ bin/hadoop dfs -cat /usr/joe/wordcount/output/part-00000 Bye 1 Goodbye 1 Hadoop 1 Hello 2 World 2 hadoop 1 Run it once more, this time switch-off case-sensitivity: $ bin/hadoop jar /usr/joe/wordcount.jar org.myorg.WordCount -Dwordcount.case.sensitive=false /usr/joe/wordcount/input /usr/joe/wordcount/output -skip /user/joe/wordcount/patterns.txt Sure enough, the output: $ bin/hadoop dfs -cat /usr/joe/wordcount/output/part-00000 bye 1
Page 38
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
goodbye 1 hadoop 2 hello 2 world 2
7.3. Highlights
The second version of WordCount improves upon the previous one by using some features offered by the Map/Reduce framework: • Demonstrates how applications can access configuration parameters in the configure method of the Mapper (and Reducer) implementations (lines 28-43). • Demonstrates how the DistributedCache can be used to distribute read-only data needed by the jobs. Here it allows the user to specify word-patterns to skip while counting (line 104). • Demonstrates the utility of the Tool interface and the GenericOptionsParser to handle generic Hadoop command-line options (lines 87-116, 119). • Demonstrates how applications can use Counters (line 68) and how they can set application-specific status information via the Reporter instance passed to the map (and reduce) method (line 72). Java and JNI are trademarks or registered trademarks of Sun Microsystems, Inc. in the United States and other countries.
Page 39
Copyright © 2008 The Apache Software Foundation. All rights reserved.</li>
</ol>
</li>
</ol>
</li>
</ol>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--mapred_tutorial/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--mapred_tutorial" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/113/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/111/">111</a></li><li><a class="page-number" href="/page/112/">112</a></li><li><a class="page-number" href="/page/113/">113</a></li><li class="active"><li><span class="page-number current">114</span></li><li><a class="page-number" href="/page/115/">115</a></li><li><a class="page-number" href="/page/116/">116</a></li><li><a class="page-number" href="/page/117/">117</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/161/">161</a></li><li><a class="page-number" href="/page/162/">162</a></li><li><a class="extend next" href="/page/115/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Site powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a>  update time: <em>2014-04-07 17:30:37</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
