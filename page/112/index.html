
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 112 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--OpenStack_Hadoop/">OpenStack_Hadoop</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--OpenStack_Hadoop/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="openstack_hadoop">OpenStack_Hadoop</h1>
<p>针对OpenStack、Hadoop种不同领域软件的分析</p>
<p>1 <img src="" alt=""> OpenStack</p>
<p>1.1 简介</p>
<p>一款管理分布在多台物理机器上的多台虚拟机的开源虚拟机管理软件。</p>
<p>虚拟化是指在同一台物理机器上提供多台虚拟机器的技术。</p>
<p>其可以在多台计算机（PC或者小型机）组成的网络集群上不跨物理机器的前提下自由调配单机资源以虚拟化成一台或者多台个人PC机器、局域网供用户使用和服务。</p>
<p>优点：可自由调配、定制以几乎单机全部的有限资源合理应对模拟几乎无限种可能的低运算量业务处理环境。</p>
<p>缺点：当全部资源都被使用后，实际资源有效利用率低（考虑多个虚拟机重复的操作系统环境、分布式虚拟机镜像文件存储的冗余备份、虚拟机技术本身的VM运行机制）。</p>
<p>其更适用于办公、开发、测试环境使用。</p>
<p>1.2 网文：虚拟化的误区</p>
<p>服务器虚拟化技术之十大误区</p>
<p>2008-09-08 10:20 摘自<a href="http://datacenter.chinabyte.com/280/8297280.shtml" target="_blank">http://datacenter.chinabyte.com/280/8297280.shtml</a></p>
<p>[导读]服务器虚拟化技术之十大误区</p>
<p>误区1：虚拟化技术可以实现多台物理服务器资源整合，从而实现单个应用通过虚拟化技术而运行在多台物理硬件上</p>
<p>实际上，虚拟化技术不能将一个应用分布运行在多台物理硬件上，那是分布式计算要去解决的问题。分布式计算环境和虚拟化环境是两种不同的资源整合方式。当然，如果想通过虚拟化技术实现一个应用跨物理平台运行技术上来说是可行的，只是为了解决不同硬件之间的CPU和内存级指令、数据的同步，需要使用一些特别的技术，比如Infiniband等，这会极大地增加系统的复杂性和成本。实际上，基于这种理念的虚拟化产品曾在实验室实现，但是由于成本等因素无法投入市场。今天能看到的所有服务器虚拟化技术解决方案都不提供一个应用跨物理服务器运行，也就是说，虚拟化环境下一个应用能使用的最大资源就是一台独立的物理服务器。</p>
<p>误区2：服务器虚拟化技术就会陷入将多个鸡蛋放到一个篮子的尴尬</p>
<p>通过虚拟化技术，提高了服务器的利用效率和灵活性。但同时也使得单台服务器上运行了多个独立的虚拟机，也就是多个不同的应用。我们原来在一台服务器上只运行一个应用，服务器维护和升级时只会影响单个应用。通过运行虚拟化技术，我们在维护和升级服务器时会影响该服务器上运行的所有虚拟机和应用。这导致很多人认为的问题：多个虚拟机放置在一台服务器上的“鸡蛋和篮子”问题。</p>
<p>实际上，VMware很早就意识到了这个问题，这个问题可以通过两个方面的能力去解决。一是怎么保证虚拟化后的服务器物理硬件维护和升级的问题。二是物理服务器故障时如何保护这些虚拟机的安全。</p>
<p>首先，VMware创造性的发明了VMotion的技术，解决了虚拟化后物理服务器的升级和维护问题。通过VMotion，VMware可以在服务器需要维护升级时动态将虚拟机迁移到其他的物理服务器，通过内存复制技术，确保每台虚拟机任何对外的服务都不发生中断，从而实现了：停物理硬件、不停应用。下图是VMotion的具体实现，已经有超过50%的VMware客户部署了VMotion技术。</p>
<p><img src="" alt=""></p>
<p>其次，VMware推出了VMware HA的功能来保护物理服务器的安全。一旦发生物理服务器故障，VMware HA可以智能检测到这一事件，及时快速地在其他物理服务器上重新启用这些虚拟机，从而保证虚拟机的安全性和可靠性。</p>
<p><img src="" alt=""></p>
<p>误区3：动态在线虚拟机迁移可以跨越任何硬件进行</p>
<p>目前VMware在业界推出了标志性的创新产品功能VMotion，可以实现虚拟机动态在线跨越硬件服务器进行迁移。但是这是有一个兼容前提，也就是两台物理服务器要达到CPU指令级的兼容，或者是完全一样的CPU，或者是同一家族的CPU。如果CPU指令不兼容，进行内存复制后新机器CPU不能识别这些指令就会导致系统崩溃。当然，具体CPU指令级是否兼容，VMotion会自动进行判定。</p>
<p>当然，如果您可以离线进行虚拟机的迁移，就可以跨越任何ESX兼容的硬件进行迁移，就没有CPU型号等的制约。</p>
<p>误区4：数据中心虚拟化后可以节约虚拟机里运行软件许可证的成本</p>
<p>虚拟化技术并未改变软件许可证的发放方式，因此虚拟化技术并不意味着操作系统或应用软件许可证成本的节约，除非操作系统、应用软件厂商重新调整了软件许可证策略。因此，想通过使用虚拟化技术来减少应用软件许可成本的想法是错误的。当然，实施虚拟化技术也不会增加操作系统或应用软件的许可证成本。</p>
<p>误区5：数据中心虚拟化只使用于边缘应用，对关键应用或资源消耗较大的应用目前还不能虚拟化</p>
<p>PC服务器的虚拟化技术已经相当成熟，在美国和欧洲已经获得了广泛应用。实际上，很多关键的业务应用已经运行在虚拟化的平台上。对于资源消耗比较高的应用，需要进行合理的规划才能迁移到虚拟化上来，即使某个机器的资源消耗特别巨大，仍然可以通过升级服务器的内存、CPU来使它顺利迁移到高端PC服务器上来。当然，某个虚拟机能够支持的最大资源仍然是有限制的，比如运行在VMware的ESX Server 3.0上的虚拟机，最多可以支持16GB内存和4颗虚拟CPU。如果这些资源仍然无法满足某个应用的需求，该应用还是不能运行在虚拟化的平台上。基于一般考虑，大多数资源消耗较大的应用仍然能够安全运行到虚拟化平台上。</p>
<p>误区6：英特尔和AMD都开始在CPU级支持虚拟化技术，已不需要再购买虚拟化软件了</p>
<p>CPU的厂商英特尔和AMD都在推行基于CPU的虚拟化，实际上CPU级的虚拟化就是在CPU指令级增加了许多虚拟化的指令而已，这并非说用户可以不需要购买虚拟化软件了，CPU级的虚拟化需要虚拟化软件才能使用起来。目前所有的常用操作系统都不支持CPU级的虚拟化。而VMware提供的虚拟化平台正是通过利用英特尔和AMD提供的CPU指令的虚拟化，进而提高了虚拟化的效率，有效提高了虚拟机的性能，降低了虚拟化带来的损耗，大大加速数据中心虚拟化的进程。所以说，CPU的虚拟化是对服务器虚拟化的极大推动，而不是限制VMware这样的虚拟化产品的推广。</p>
<p>误区7：数据中心虚拟化会极大地降低服务器的性能</p>
<p>虚拟化有两种基本架构：寄居架构和裸金属架构，两种架构如下图所示。寄居架构由于基于传统的操作系统之上，所以性能消耗大，往往会对服务器性能影响很大。而裸金属架构基于专门为虚拟化而设计的虚拟化层而实现，大大降低了虚拟化引入的损耗，可以极大改善虚拟机的性能，是企业级数据中心进行虚拟化的首选架构。</p>
<p>因此，对用户来说，为了满足应用对性能的追求，建议采用企业级虚拟化架构――裸金属架构，这可以尽可能降低数据中心虚拟化对服务器性能的影响，一般影响可以降到10%以下。</p>
<p><img src="" alt=""></p>
<p>下图是采用裸金属架构虚拟化对应用性能的影响情况，这是VMware在中国某个用户现场的实测结果，已经很好说明了虚拟化带来的消耗是很低的。</p>
<p><img src="" alt=""></p>
<p>误区8：虚拟化技术仍然不成熟，数据中心虚拟化还不能提上议事日程</p>
<p>虚拟化技术已经获得了广泛地应用，财富100强的所有用户都已经部署了VMware的虚拟化解决方案，财富1000强中超过800家都是VMware的用户。实际上，VMware的企业级用户数量已经超过20000家，而所有用户的数量已经超过四百万家。VMware的服务器虚拟化方案已经久经考验，成为整个IT业界津津乐道的热点，虚拟化已经成为企业级用户构建新型数据中心的利器，成为值得信赖的可靠、稳定的企业级解决方案。</p>
<p>误区9：虚拟化由于引入了新的层次，会增加数据中心的管理难度</p>
<p>在数据中心引入虚拟化确实增加了一个虚拟化层，但并非因此而增加了管理难度。由于虚拟化的管理软件能够很好的管理控制虚拟平台的同时，简化了杂乱的服务器的管理，从而大大降低了大型数据中心的管理复杂性。如VMware  VirtualCenter就是很好的例证，Virtual Center提供了直观的管理界面，提供了丰富的资料和数据来监控整合虚拟化中心，为数据中心高效管理提供了强大的手段，成为新型虚拟化数据中心的必备工具。下图是Virtual center对虚拟机的管理界面。</p>
<p><img src="" alt=""></p>
<p>误区10：服务器虚拟化技术很美好，从原来架构迁移到虚拟架构耗时费力，而且可能风险巨大</p>
<p>如果迁移到虚拟化平台是很多用户的顾虑之一，因为虚拟化是一种架构决策。VMware已经进行了大量工作来简化从物理架构向虚拟架构的迁移，VMware Converter可以让用户不需要重新安装操作系统和应用，通过打包方式，将原来的物理服务器轻松迁移到虚拟平台上来。这不仅简化了流程，也降低了整个的迁移风险，目前很多企业级的用户都在享受VMware Converter所带来的好处。下图是VMware Converter的一个操作主界面，用户可以从VMware的网站免费下载VMware Converter的试用版来进行迁移试验。</p>
<p>1.3 网文：同类系统及其原理</p>
<p>最近笼统地学习和试用了几款比较有名的虚拟化管理软件。学习的内容包括Eucalyptus,  OpenNebula, OpenStack,  OpenQRM, XenServer, Oracle VM, CloudStack, ConVirt。借这一系列文章，对过去一个月的学习内容作一个阶段性的总结。</p>
<p>摘自<a href="http://zhumeng8337797.blog.163.com/blog/static/1007689142011112035330566/" target="_blank"><a href="http://zhumeng8337797.blog.163.com/blog/static/1007689142011112035330566/">http://zhumeng8337797.blog.163.com/blog/static/1007689142011112035330566/</a></a></p>
<p>（1）授权协议、许可证管理、购买价格等方面的比较</p>
<p><strong>授权协议</strong></p>
<p><strong>许可证管理</strong></p>
<p><strong>商业模式</strong> <strong>Eucalyptus</strong></p>
<p>社区版采用GPLv3授权协议</p>
<p>企业版使用自定义的商业授权协议</p>
<p>社区版不需要安装许可证</p>
<p>企业版需要在云控制器（CLC）节点上安装许可证</p>
<p>社区版免费使用</p>
<p>企业版按处理器核心总数收费，用户购买的许可证针对特定版本永久有效。 <strong>OpenStack</strong></p>
<p>Apache 2.0授权协议</p>
<p>不需要许可证</p>
<p>免费使用 <strong>OpenNebula</strong></p>
<p>Apache 2.0授权协议</p>
<p>不需要许可证</p>
<p>社区版免费使用</p>
<p>企业版将社区版重新打包，提供补丁等程序的访问权限，使得用户能够更容易的安装、配置和管理，以订阅的模式提供服务。</p>
<p>企业版按物理服务器总数收费，每台物理服务器器的服务价格为250欧元每年。 <strong>OpenQRM</strong></p>
<p>社区版使用GPLv2授权协议</p>
<p>企业版使用自定义的商业授权协议</p>
<p>不需要许可证</p>
<p>社区版免费使用</p>
<p>企业版将社区版重新打包，提供补丁等程序的访问权限，使得用户能够更容易的安装、配置和管理，以订阅的模式提供服务。基本、标准和高级服务的价格分别为480、960、1920欧元每月。 <strong>XenServer</strong></p>
<p>Citrix  XenServer系列产品均使用自定义的商业授权协议</p>
<p>基于XenServer的Xen Cloud  Platform使用GPLv2授权协议</p>
<p>不管是XenServer还是Xen Cloud  Platform都需要在每台服务器安装许可证</p>
<p>许可证每年更新一次</p>
<p>XenServer免费版本和开源版本的Xen Cloud Platform可以免费使用</p>
<p>XenServer高级版、企业版和白金版按物理服务器数量收费，分别是1000、2500和5000美元。购买的许可证针对特定版本永久有效 <strong>Oracle VM</strong></p>
<p>Oracle VM  Server是基于Xen开发的，使用GPLv2协议发布，从Oracle的网站可以下载到源代码，但是Oracle并不宣传这一点。</p>
<p>Oracle VM  Manager使用自定义的商业授权协议。</p>
<p>Oracle VM  VirtualBox的二进制版本使用自定义的商业授权协议，源代码使用GPLv2授权协议。</p>
<p>不需要许可证</p>
<p>免费使用，可以购买技术支持。技术支持的费用为每台物理服务器8184人民币每年。 <strong>CloudStack</strong></p>
<p>社区版采用GPLv3授权协议企业版使用自定义的商业授权协议</p>
<p>社区版不需要安装许可证</p>
<p>企业版需要在管理服务器上安装许可证</p>
<p>社区版免费使用企业版提供增强功能和技术支持，收费模式不详。 <strong>ConVirt</strong></p>
<p>社区版使用GPLv2授权协议</p>
<p>企业版使用自定义的商业授权协议</p>
<p>社区版不需要安装许可证</p>
<p>企业版需要在管理服务器上安装许可证</p>
<p>社区版免费使用</p>
<p>企业版提供增强功能和技术支持，按物理服务器数量收费，每个节点费用1090美元。购买的许可证针对特定版本永久有效。</p>
<p>（2）项目历史与运营团队、社区规模和活跃程度、沟通交流等方面的比较</p>
<p>   项目历史与运营团队社区规模和活跃程度沟通交流</p>
<p><strong>项目历史与运营团队</strong></p>
<p><strong>社区规模和活跃程度</strong></p>
<p><strong>沟通交流</strong> <strong>Eucalyptus</strong></p>
<p>最 初是UCSB的HPC研究项目，2009年初成立公司来支持该项目的商业化运营。现任CEO是曾担任MySQL CEO的Marten Mickos，现任工程部门SVP的Tim Cramerc曾担任  Sun公司NetBeans和OpenSolaris项目的执行总监。整个管理团队对开放源代码项目的管理和运营方面具有丰富的经验。</p>
<p>在 同类开放源代码项目当中，Eucalyptus的社区规模最大，活跃程度也最高。主要原因是该项目起源于大学研究项目，次要原因是管理团队对开放源代码理 念的高度认同。Ubuntu 10.04服务器版选择Eucalyptus作为UEC的基础构架，大大地促进了Eucalyptu的推广。</p>
<p>社区发表在论坛上的问题通常在48小时内得到回应，通过技术支持电子邮件提出的问题通常在24小时内得到回应。</p>
<p>Eucalyptus在北京和深圳设有办事处，在中国有工程师提供支持团队。 <strong>OpenStack</strong></p>
<p>OpenStack 是服务器托管公司RackSpace与NASA共同发起的开放源代码项目。在开放源代码项目的管理和运营方面，RackSpace和NASA显然缺乏足够  的经验。针对OpenStack项目的批评集中在（1）RackSpace对项目有过于强烈的控制欲，（2）OpenStack项目的运作对于社区成员来 说基本上是不透明的，（3）OpenStack项目对同类开放源代码项目的攻击性过強。</p>
<p>社 区规模较小，主要参与者为支持／参与该项目的公司人员。有几个公开的邮件列表，流量很小。由于该项目比较新，在网络上可以参考的安装与配置方面的文章不 多。Ubuntu 11.04服务器版同时支持Eucalyptus和OpenStack作为UEC的基础构架，将有助于OpenStack的推广。</p>
<p>通过邮件列表进行技术方面的沟通，通常在48小时内得到回应。商务方面的邮件沟通，没有得到回应。 <strong>OpenNebula</strong></p>
<p>2005年启动的研究性项目，2008年初发布第一个开放源代码版本，2010年初大力推进开源社区的建设。</p>
<p>社区规模较小，主要参与者为支持／参与该项目的公司人员，以及少量的用户。有几个公开的邮件列表，流量比OpenStack项目的流量稍大。在网络上搜索到一些中文版安装和配置方面的文章，基本上是以讹传讹，缺乏可操作性。英文版的相关文章也不多，可操作的更少。</p>
<p>通过邮件列表进行技术方面的沟通，通常在48小时内得到回应。 <strong>OpenQRM</strong></p>
<p>起源于集群管理方面的软件，2006年公开源代码，2008年免费发布，目前版本为4.8。</p>
<p>项目的运营团队较小，似乎只有Matt  Rechenburg一个人。</p>
<p>有一些零星的用户，基本上没有形成社区。虽然功能还在不断更新，但是用户文档的日期是2008年的。相关论坛的活跃程度比OpenStack和OpenNebula更差。</p>
<p>在论坛发布的问题，大约有50％左右没有得到回应。通过电子邮件进行商务沟通，反应迅速，在24小时以内得到回应。 <strong>XenServer</strong></p>
<p>Citrix公司的产品，与Xen项目的发展基本同步。</p>
<p>围绕Xen Cloud Platform有一些开放源代码的项目，用于替代XenCentor提供基于桌面或者是浏览器的管理功能。</p>
<p>初期商务沟通的速度比较快。 <strong>Oracle  VM</strong></p>
<p>Oracle公司的产品，用户量较小。Oracle  VM仅仅是Oracle用户生态系统中的一部分，不是Oracle的关键业务。</p>
<p>有一定数量的用户，但是没有形成社区。在网络上缺少与Oracle相关的讨论与交流。Oracle VM团队有一个博客网站，但是最近两篇文章的日期分别是2010年11月和2008年1 月。产品下载的速度很慢。</p>
<p>初期商务沟通的速度比较快。在技术方面的沟通，Oracle在国内没有相应的技术人员提供支持。 <strong>CloudStack</strong></p>
<p>源于2008年成立的VMOps公司，2010年五月启用cloud.com域名，2010年6 月共同启动OpenStack项目。</p>
<p>用户数量较少，论坛不是很活跃。官方文档非常完备，按照文档操作至少能够顺利地完成安装和配置过程。网络上可以搜索到一些可操作的安装和配置文档（得益于CloudStack的安装和配置比较简单）。</p>
<p>商务沟通比较困难，通过社区论坛和电子邮件提出的问题都没有得到回应。 <strong>ConVirt</strong></p>
<p>起源于2006年发起的XenMan项目，与Xen项目的发展基本同步。目前的版本为ConVirt 2.0。现任CEO和工程部门EVP均来自Oracle。</p>
<p>用户规模与Eucalyptus相当，论坛的活跃程度很高。官方文档非常完备，按照文档操作至少能够顺利地完成安装和配置过程。在网络上搜索到的中英文的安装配置教程也基本可用。</p>
<p>商务沟通非常顺畅，社区发表在论坛上的问题通常在48小时内得到回应，通过技术支持电子邮件提出的问题通常在24小时内得到回应。</p>
<p>（3）综合评估</p>
<p>总 的来说，虚拟化管理软件的用户还不是很多。大部分虚拟化管理软件的社区规模较小，活跃程度也不高。除了Eucalyptus积极地鼓励社区用户参与项目的 开发与测试之外，其他项目选择开放源代码只是一种营销策略。如果排除技术和价格方面的因素，最值得选择的软件无疑是Eucalyptus和  ConVirt。这两个项目拥有最大和最活跃的用户社区，其开发／运营团队与潜在客户之间的沟通最为顺畅。XenServer也是一个值得考虑的对象，但 是XenServer社区版要求对每台物理服务器都要每年更新一次许可证。对于拥有大量物理服务器的公司来说，管理和维护成千上百个许可证将是一个令人头 疼的问题。</p>
<p>架构篇：</p>
<p>（1）系统构架比较</p>
<p><strong>系统构架</strong> <strong>Eucalyptus</strong></p>
<p>Eucalyptus 是一个与Amazon EC2兼容的IaaS系统。Eucalyptus包括云控制器（CLC）、Walrus、集群控制器（CC）、存储控制器（SC）和节点控制器（NC）。 CLC是整个Eucalyptu系统的核心，负责高层次的资源调度，例如向CC请求计算资源。Walrus是 一个与Amazon S3类似的存储服务，主要用于存储虚拟机映像和用户数据。CC是一个集群的前端，负责协调一个集群内的计算资源，并且管理集群内的网络流量。SC是一个与 Amazon EBS类似的存储块设备服务，可以用来存储业务数据。NC是最终的计算节点，通过调用操作系统层的虚拟化技术来启动和关闭虚拟机。在同一个集群（CC）内 的所有计算节点（NC）必须在同一个子网内。 在一个集群（CC）内通常需要部署一台存储服务器（SC），为该集群内的计算节点提供数据存储服务。</p>
<p>Eucalyptus 通过Agent的方式来管理计算资源。在每一个计算节点上，都需要运行一个eucalyptus-nc的服务。该服务在集群控制器（CC）上注册后，云控 制器（CLC）即可通过集群控制器（CLC）将需要运行的虚拟机映像文件（EMI）拷贝到该计算节点上运行。</p>
<p>Eucalyptus 将虚拟机映像文件存储在Walrus上。当用户启动一个虚拟机实例的时候，Eucalyptus首先将相应的虚拟机映像（EMI）从Walrus拷贝到将 要运行该实例的计算节点（NC）上。当用户关闭（或者是由于意外而重启）一个虚拟机实例的时候，对虚拟机所做的修改并不会被写回到Walrus上原来的虚 拟机映像（EMI）上，所有对该虚拟机的修改都会丢失。如果用户需要保存修改过的虚拟机，就需要利用工具（euca2ools）将该虚拟机实例保存为新的  虚拟机映像（EMI）。如果用户需要保存数据，则需要利用存储服务器（SC）所提供的弹性块设备来完成。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/eee_arch.jpg" target="_blank"><img src="" alt=""></a> <strong>OpenStack</strong></p>
<p>OpenStack是一个与Amazon EC2兼容的IaaS系统。OpenStack包括OpenStack  Compute和OpenStack Object Storage两个部分。</p>
<p>OpenStack Compute又包含Web前端、计算服务、存储服务、身份认证服务、存储块设备（卷）服务、网络服务、任务调度等多个模块。OpenStack Compute的不同模块之间不共享任何信息，通过消息传递进行通讯。因此，不同的模块可以运行在不同的服务器上，也可以运行在同一台服务器上。
<a href="http://www.qyjohn.net/wp-content/uploads/2011/05/NOVA_ARCH.png" target="_blank"><img src="" alt=""></a></p>
<p>OpenStack Object Store可以利用通用服务器搭建可扩展的海量数据仓库，并且通过冗余来保证数据的安全性。同一份数据的在多台服务器上都有副本，将出现故障的服务器从集 群中撤除不会影响数据的完整性，加入新的服务器后系统会自动地在新的服务器上为相应的文件创建新的副本。从功能上讲，OpenStack Object Store同时具备Eucalyptus中的Walrus服务和弹性块设备（SC）服务。不过OpenStack Object Store不是一个文件系统，不能够保证数据的实时性。从这个方面来考虑，OpenStack Object Store更适合用于存储需要长期保存的静态数据，例如操作系统映像文件和多媒体数据。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/os-os.png" target="_blank"><img src="" alt=""></a></p>
<p>OpenStack通过Agent的方式来管理计算资源。在每一个计算节点上，都需要运行nova- network服务和nova-compute服务。这些服务启动之后，就可以通过消息队列来与云控制器进行交互。</p>
<p>  <strong>OpenNebula</strong></p>
<p>OpenNebula 的构架包括三个部分：驱动层、核心层、工具层。驱动层直接与操作系统打交道，负责虚拟机的创建、启动和关闭，为虚拟机分配存储，监控物理机和虚拟机的运行 状况。核心层负责对虚拟机、存储设备、虚拟网络等进行管理。工具层通过命令行界面／浏览器界面方式提供用户交互接口，通过API方式提供程序调用接口。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/one-architecture.png" target="_blank"><img src="" alt=""></a></p>
<p>OpenNebula 使用共享存储设备（例如NFS）来提供虚拟机映像服务，使得每一个计算节点都能够访问到相同的虚拟机映像资源。当用户需要启动或者是关闭某个虚拟机 时，OpenNebula通过SSH登陆到计算节点，在计算节点上直接运行相对应的虚拟化管理命令。这种模式也称为无代理模式，由于不需要在计算节点上安 装额外的软件（或者服务），系统的复杂度也相对降低了。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/one-sample-arch2.png" target="_blank"><img src="" alt=""></a> <strong>OpenQRM</strong></p>
<p>OpenQRM 是为了管理混合虚拟化环境而开发的一个虚拟化管理框架，包括基础层（框架层）和插件。基础层（框架）的作用是管理不同的插件，而对虚拟资源的管理（计算资 源，存储资源，映像资源）都是通过插件来实现的。OpenQRM的框架类似于Java语言中的Interface，定义了一系列虚拟机资源生命周期管理的 方法，例如创建、启动、关闭虚拟机等等。在个框架的基础上，OpenQRM针对不同的虚拟化平台（Xen、KVM)实现了不同的插件，用来管理不同的物理 和虚拟资源。当出现新的资源需要支持的时候，只需要为OpenQRM编写新的插件，就可以无缝地整合到原来的环境中去。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/openqrm-architecture.png" target="_blank"><img src="" alt=""></a></p>
<p>OpenQRM 插件也是使用无代理模式工作的。当需要管理的目标节点提供SSH登录方式时，OpenQRM插件通过SSH登陆到计算节点，在计算节点上直接运行相对应的 虚拟化管理命令。当需要管理的目标节点提供HTTP／HTTPS／XML－RPC远程调用接口时，OpenQRM插件通过目标节点所提供的远程调用接口实 现对目标平台的管理。</p>
<p>OpenQRM是一个虚拟化管理平台，不提供与Amazon EC2兼容的云管理接口。</p>
<p>  <strong>XenServer</strong></p>
<p>XenServer 是对Xen虚拟化技术的进一步封装，在Dom0上提供一系列命令行和远程调用接口，独立的管理软件XenCenter通过远程调用这些接口来管理多台物理 服务器。XenSever在标准Xen实现之上所实现的远程调用接口类似于其他虚拟化管理平台中所实现的Agent，因此XenServer是通过 Agent方式工作的。由于只考虑对Xen虚拟化技术的支持，XenServer的构架相对简单。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/xcp-architecture.png" target="_blank"><img src="" alt=""></a></p>
<p>XenServer 是一个虚拟化管理平台，不提供与Amazon EC2兼容的云管理接口。管理软件XenCenter是运行在Windows操作系统上的，对于需要随时随地访问管理功能的系统管理员来说有点不便。目前 有一些第三方提供的开放源代码的基于浏览器的XenServer管理工具，但是都还处于比较早期的阶段。</p>
<p>  <strong>Oracle  VM</strong></p>
<p>Oracle VM包括Oracle VM Server和Oracle VM Manager两个部分。Oracle VM Server在支持Xen的Oracle Linux上（Dom0）运行一个与Xen交互的Agent，该Agent为Oracle VM  Manager提供了远程调用接口。Oracle VM Manager通过一个Java应用程序来对多台Oracle VM Server上的虚拟资源进行管理和调度，同时提供基于浏览器的管理界面。由于只考虑对Xen虚拟化技术的支持，Oracle VM Server / Manager的构架相对简单。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/GW430.gif" target="_blank"><img src="" alt=""></a></p>
<p>Oracle VM是一个虚拟化管理平台，不提供与Amazon EC2兼容的云管理接口。</p>
<p>值 得注意的是，Oracle VM Manager还通过Web Service的方式提供了虚拟机软件生命周期管理的所有接口，使得用户可以自己使用不同的编程语言来调用这些接口来开发自己的虚拟化管理平台。不过由于 Oracle在开放源代码方面的负面形象，似乎没有看到有这方面的尝试。</p>
<p>  <strong>CloudStack</strong></p>
<p>与 OpenQRM类似，CloudStack采用了“框架 ＋ 插件”的系统构架，通过不同的插件来提供对不同虚拟化技术的支持。对于标准的Xen / KVM计算节点，CloudStack需要在计算节点上安装Agent与控制节点进行交互；对于XenServer / VMWare计算节点，CloudStack通过XenServer / VMWare所提供的XML-RPC远程调用接口与计算节点进行交互。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/Cloud.com-Architecture.jpg" target="_blank"><img src="" alt=""></a></p>
<p>CloudStack本身是一个虚拟化管理平台，但是它通过CloudBridge提供了与Amazon EC2相兼容的云管理接口，对外提供IaaS服务。</p>
<p>  <strong>ConVirt</strong></p>
<p>ConVirt 是一个虚拟化管理平台，使用无代理模式工作。当需要管理的目标节点提供SSH登录方式时，ConVirt通过SSH登陆到计算节点，在计算节点上直接运行 相对应的虚拟化管 理命令。当需要管理的目标节点提供HTTP／HTTPS／XML－RPC远程调用接口时，ConVirt插件通过目标节点所提供的远程调用接口实现对目标 平台的管理。</p>
<p><a href="http://www.qyjohn.net/wp-content/uploads/2011/05/799px-Architecture.png" target="_blank"><img src="" alt=""></a></p>
<p>ConVirt 是一个虚拟化管理平台，不提供与Amazon EC2兼容的云管理接口。但是ConVirt  3.0提供了与Amazon EC2 / Eucalyptus的用户接口，使得ConVirt用户能够在同一个Web  管理界面下同时管理Amazon EC2 / Eucalyptus提供的虚拟计算资源。</p>
<p>（2）云管理平台还是虚拟化管理平台？</p>
<p>在IaaS这个层面，云管理和虚拟化管理的概念非常接近，但是有一些细微的差别。</p>
<p>虚 拟化是指在同一台物理机器上提供多台虚拟机器（包括CPU、内存、存储、网络等计算资源）的能力。每一台虚拟机器都能够像普通的物理机器一样运行完整的操 作系统以及执行正常的应用程序。当需要管理的物理机器数量较小时，虚拟机生命周期管理（资源配置、启动、关闭等等）可以通过手工去操作。当需要管理的物理 机器数量较大时，就需要写一些脚本／程序来提高虚拟机生命周期管理的自动化程度。以管理和调度大量物理／虚拟计算资源为目的系统，属于虚拟化管理系统。这 样一个系统，通常用于管理企业内部计算资源。</p>
<p>云 计算是指通过网络访问物理／虚拟计算机并利用其计算资源的实践。通常来讲，云计算提供商以虚拟机的方式向用户提供计算资源。用户无须了解虚拟机背后实际的 物理资源状况，只需了解自己所能够使用的计算资源配额。因此，虚拟化技术是云计算的基础。任何一个云计算管理平台，都是构建在虚拟化管理平台的基础之上 的。如果某个虚拟化管理平台仅对某个集团内部提供服务，那么这个虚拟化管理平台也可以被称为“私有云”；如果某个虚拟化管理平台对公众提供服务，那么这个 虚拟化管理平台也可以被称为“公有云”。服务对象的不同，对虚拟化管理平台的构架和功能提出了不同的需求。</p>
<p>私 有云服务于集团内部的不同部门（或者应用），强调虚拟资源调度的灵活性。系统管理员需要为不同的部门（或者应用）定制不同的虚拟机，根据部门（或者应用） 对计算资源的需求对分配给某些虚拟机的计算资源进行调整。从这个意义上来讲，OpenQRM、XenServer、Oracle VM、CloudStack和ConVirt比较适合提供私有云服务。</p>
<p>公 有云服务于公众，强调虚拟资源的标准性。通过将计算资源切割成标准化的虚拟机配置（多个系列的产品，每个产品配置相同数量的CPU、内存、磁盘空间、网络 流量配额），公有云提供商可以通过标准的服务合同（Service  Level Agreement, SLA）以标准的价格出售计算资源。当用户对计算资源的需求出现改变的时候，用户只需要缩减或者是增加自己所使用的产品数量。由于Amazon  EC2是目前比较成功的公有云提供商，大部分云管理平台都在某种程度上模仿Amazon EC2的构架。从这个意义上来讲，Eucalyptus、OpenNebula和OpenStack提供了与Amazon EC2兼容或者是类似的接口，比较适合提供公有云服务。</p>
<p>公有云和私有云之间的界限，就像“内部／外部”和“部门／合作伙伴”的概念一样，并不十分明显。根据项目需求的不同，可能会有不同的解释。</p>
<p>功能篇：</p>
<p>（1）支持的虚拟化技术</p>
<p><strong>Xen</strong></p>
<p><strong>KVM</strong></p>
<p><strong>XenServer  / XCP</strong></p>
<p><strong>VMWare</strong></p>
<p><strong>LXC</strong></p>
<p><strong>openVZ</strong> <strong>Eucalyptus</strong></p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>  <strong>OpenStack</strong></p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>  <strong>OpenNebula</strong></p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>  <strong>OpenQRM</strong></p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>Y <strong>XenServer</strong></p>
<p>Y</p>
<p>  <strong>Oracle VM</strong></p>
<p>Y</p>
<p>  <strong>CloudStack</strong></p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>  <strong>ConVirt</strong></p>
<p>Y</p>
<p>Y</p>
<p>可以看出，Xen和KVM是目前获得最广泛的厂商虚拟化技术，紧随其后的是VMWare。需要注意的是，XenServer是对Xen的进一步封装，可以认为是一种新的虚拟化平台（用户在XenServer上不能直接执行Xend相关命令）。</p>
<p>（2）系统安装和配置</p>
<p>（3）前端  计算节点 备注</p>
<p><strong>前端</strong></p>
<p><strong>计算节点</strong></p>
<p><strong>备注</strong> <strong>Eucalyptus</strong></p>
<p>使用Ubuntu 10.04或者CentOS  5.5操作系统，通过apt-get  install或者yum install的方式直接安装二进制包，构建一个包含CLC、 Walrus、SC、CC的前端。根据官方网站提供的文档进行操作，是比较容易实现的。</p>
<p>使用Ubuntu 10.04或者CentOS 5.5操作系统，通过apt-get install或者yum  install的方式直接安装二进制包，构建一个提供NC服务的计算节点。根据官方网站提供的文档进行操作，是比较容易实现的。</p>
<p>Eucalyptus 包含了一个dhcpd，如果配置不好的话，会造成一定的麻烦。另外，计算节点（NC）与集群控制器（CC）必须在一个C类子网里（例如，掩码为  255.255.255.0）。如果NC和CC在一个超网里（例如，掩码为255.255.0.0），在注册服务的时候会出现一些问题。</p>
<p>  <strong>OpenStack</strong></p>
<p>在Ubuntu 10.04上利用官方网站提供的nova- install脚本进行安装，基本上没有遇到问题。</p>
<p>在Ubuntu 10.04上利用官方网站提供的nova- install脚本进行安装，基本上没有遇到问题。</p>
<p>对于一个简单的系统，安装配置比较简单。 <strong>OpenNebula</strong></p>
<p>使 用CentOS 5.5操作系统，配置好CentOS Karan源，启用kbs- CentOS- Testing条目。下载对应的rpm包，直接yum localinstall  -nogpgcheck  opennebula/*.rpm，就可以直接完成安装过程。按照官方文档创建/srv/cloud/one和/srv/cloud/images目录，通 过NFS共享/srv/cloud目录。创建cloud用户组和属于cloud用户组的oneadmin用户。</p>
<p>按照官方文档创建/srv/cloud/one和/srv/cloud/images目录，通过NFS共享/srv/cloud目录。创建cloud用户组和属于cloud用户组的oneadmin用户。</p>
<p>将前端服务器上oneadmin用户的ssh  key拷贝到计算节点上oneadmin用户的authorized_keys中。这样前端服务器才可以通过SSH登陆到计算节点上。</p>
<p>在CentOS  5.5 x86_64上进行安装的时候，如果按照官方网站提供的文档进行操作，先配置好必要的软件依赖关系再安装opennebula，就会出现xmlrpc-c包版本不对的错误。</p>
<p>网络上可以搜索到一些安装配置方面的文档和教程，但是对于熟悉Linux但是不熟悉OpenNebula的开发人员来说，很难按照这些文档完成安装和配置过程。</p>
<p>  <strong>OpenQRM</strong></p>
<p>在Ubuntu 10.04上通过SVN下载OpenQRM源代码，进入源代码目录后依次执行make / make  install / make start命令。按照官方文档的描述创建数据库，然后通过Web界面进行下一步的安装和配置。</p>
<p>计算节点配置好网桥和虚拟化支持之外不需要特别的安装和配置。在OpenQRM管理界面中启用相对应的插件即可通过插件对计算节点进行管理。</p>
<p>在Ubuntu  10.04上安装前端时，可能需要手工安装dhcp3- server。</p>
<p>启用插件管理虚拟资源的操作流程不够直观，并且缺乏详细的文档。</p>
<p>  <strong>XenServer</strong></p>
<p>前端为基于Windows操作系统的XenCenter。在Windows XP上可以安装，需要.NET  Framework Update 2的支持。安转过程非常简单，基本上不需要配置。</p>
<p>从Citrix的网站下载ISO，刻盘直接安装在裸机上即可。计算节点安装完毕后，在XenCenter中把新增计算资源添加到资源池即可。</p>
<p>每一台XenServer服务器都需要安装从Citrix获得License，并且每年更新一次。 <strong>Oracle VM</strong></p>
<p>在CentOS 5.5 x86_64上进行安装。将ISO文件mount起来后，执行runinstaller.sh即可。</p>
<p>从Oracle的网站下载ISO，刻盘直接安装在裸机上即可。计算节点安装完毕后，在Oracle VM Manager中把新增计算资源添加到资源池即可。</p>
<p>最好从Oracle的官方网站下载，不过速度很慢。通过迅雷等途径下载的文件，看起来似乎没有问题，但是ISO刻盘后在启动操作系统安装过程中会出现错误。</p>
<p>如果在Oracle  VM Server上安装Oracle  VM  Manager，建议分区的时候把/ 分得大一点，不然的话会由于磁盘空间不够而无法安装Oracle VM  Manager。</p>
<p>  <strong>CloudStack</strong></p>
<p>在CentOS 5.5和Ubuntu 10.4上，按照官方网站的安装文档顺序操作，基本没有问题。</p>
<p>计算节点上必须安装相应的Agent。</p>
<p>安装配置相对简单，但是在删除物理资源的时候存在较多的问题。 <strong>ConVirt</strong></p>
<p>在CentOS 5.5和Ubuntu 10.4上，按照官方网站的安装文档顺序操作，基本没有问题。</p>
<p>在Ubuntu 10.04上安装企业版，需要手工sudo apt- get install  libmysqlclient- dev。</p>
<p>在计算节点上的root用户必须允许管理节点上运行ConVirt服务的用户通过key auth方式登录。</p>
<p>安装配置相对简单。</p>
<p>不 同的虚拟化管理软件有不同的设计理念，采用不同的系统构架，类似的概念也采用不同的术语来表述，其学习曲线也各不相同。对于大部分用户来说，虚拟化管理软 件还是个新生事物。即使是粗略地尝试一下利用不同的虚拟化管理软件来安装、配置和测试一个最小规模的私有云系统，也需要花费不少的时间和精力。在这个过程 当中，遇见各种各样的问题都在所难免。不过，也只有亲身经验过这些形形色色的问题，才能够切身体会不同虚拟化管理软件的优点和缺点，并且在分析、总结、归 纳的基础上形成自己独特的观点。</p>
<p>用户界面</p>
<p><strong>概述</strong></p>
<p><strong>用户权限</strong></p>
<p><strong>资源池和虚拟机管理</strong> <strong>Eucalyptus</strong></p>
<p>Eucalyptus提供了一个基于浏览器的简单用户界面，可以完成用户注册，下载credentials，对提供的产品类型进行简单配置等。资源池和虚拟机生命周期管理需要通过euca2ools在命令行模式下完成。</p>
<p>euca2ools是一组基于命令行的工具，可以与Amazon  EC2/S3相兼容的Web  Service进行交互。该用具可以管理基于Amazon EC2、Eucalyptus和OpenStack，OpenNebula的云计算服务。</p>
<p>euca2tools的主要功能包括：</p>
<ul>
<li>查询可以使用的域</li>
<li>管理SSH Key</li>
<li>虚拟机生命周期管理</li>
<li>安全组管理</li>
<li>管理卷和快照</li>
<li>管理虚拟机映像</li>
<li>管理IP</li>
</ul>
<p>在Eucalyptus社区版中只有两种类型的用户：管理员，普通用户。在Eucalyptus企业版中进一步提供了用户组，属于某个用户组的用户可以管理属于该用户组的计算资源。</p>
<p>管理员可以通过注册或者是撤销注册某个计算节点，配置标准产品类型的计算资源（CPU、内存、存储）。普通用户只能够在标准配置的基础上创建、启动、关闭虚拟机，不能够定制化自己所需要的计算资源。</p>
<p>虚 拟机映像文件（EMI）的制作，以及虚拟机生命周期管理等等操作，需要通过euca2ools在命令行模式下完成。在FireFox浏览器中，可以利用 ElasticFox插件，在浏览器中启动、监控和关闭虚拟机。ElasticFox的界面不够美观，并且提供的功能非常有限。</p>
<p>Eucalyptus不提供console功能。用户可以通过SSH连接到自己所管理的虚拟机。</p>
<p>每一个公开发布的虚拟机映像（EMI），都是一个模板。用户创建虚拟机实例的时候，系统根据用户选择的EMI将相应的虚拟机映像拷贝到目标计算节点上运行。Eucalyptus根据某种算法自动决定用户的虚拟机将在哪个物理服务器上运行，用户对物理服务器的状况一无所知。</p>
<p>Eucalyptus 中的虚拟机实例只是原虚拟机映像（EMI）的一个副本，用户在运行的实例中对虚拟机所做的任何修改，不会被保存到原来的虚拟机映像中。如果用户将运行的虚  拟机实例关闭（例如：shutdown），用户对虚拟机所作的任何修改都会丢失。如果用户需要保存自己对虚拟机所做的修改，用户可以选择使用弹性块设备来 保存数据，或者将正在运行的虚拟机实例发布为新的EMI。（Amazon EC2自动地将停止运行的虚拟机实例保存为新的AMI，直到用户销毁该虚拟机实例为止。因此，用户可以shutdown自己的虚拟机实例，但是保存自己对 虚拟机所作的修改，直到用户选择销毁该虚拟机实例为止。）</p>
<p>  <strong>OpenStack</strong></p>
<p>OpenStack 不缺省地提供基于浏览器的用户界面。系统管理员需要手工创建用户。大部分的管理操作，需要在命令行下进行。 尽管OpenStack和Eucalyptus在构架上有很大的不同，但是所暴露给用户的界面是类似的（两者都模仿了Amazon EC2的用户接口规范）。因此，OpenStack同样可以使用Eucalyptus所提供的euca2ools进行管理。</p>
<p>OpenStack的openstack- dashboard项目和django- nova项目提供了一个基于浏览器的用户界面，没有被集成到OpenStack安装脚本中，需要单独安装。</p>
<p>OpenStack将用户分成如下几个类别：</p>
<p>admin - 云服务管理员，拥有所有管理权限。</p>
<p>itsec - IT安全管理员，具有隔离有问题的虚拟机实例的权限。</p>
<p>projectmanager - 项目管理员，可以增加属于该项目的新用户，管理虚拟机映像，管理虚拟机生命周期。</p>
<p>netadmin - 网络管理员，负责IP分配，管理防火墙。</p>
<p>developer - 开发人员，可以登录进入属于本项目的虚拟机，管理虚拟机生命周期</p>
<p>在模仿Amazon EC2的云平台（Eucalyptus,  OpenStack,  OpenNebula）中，OpenStack提供了颗粒度最细的用户权限管理模式。</p>
<p>与Eucalyptus类似，虚拟机映像文件（EMI）的制作，以及虚拟机生命周期管理等等操作，需要通过euca2ools在命令行模式下完成。同样，在FireFox浏览器中，可 以利用ElasticFox插件，在浏览器中启动、监控和关闭虚拟机。</p>
<p>OpenStack不提供虚拟机console功能。用户可以通过SSH连接到自己所管理的虚拟机。</p>
<p>正在开发中的openstack- dashboard，基于浏览器提供了比较完整的资源池管理功能和虚拟机生命周期管理功能。虽然界面还比较简单，但是已经处于可用的状态。</p>
<p>OpenStack的模板和虚拟机实例机制与Eucalyptus类似。与Eucalyptus类似，OpenStack根据某种算法自动决定用户的虚拟机将在哪个物理服务器上运行，用户对物理服务器的状况一无所知。</p>
<p>  <strong>OpenNebula</strong></p>
<p>OpenNebula不缺省地提供基于浏览器的用户界面。系统管理员需要手工创建用户。大部分的管理操作，需要在命令行下进行。</p>
<p>OpenNebula目前有两个基于浏览器的用户界面：SunStone和OneMC。这两个项目需要单独安装。</p>
<p>同样，OpenNebula提供了与Amazon EC2相兼容的Web Service接口。因此，可以通过FireFox所提供的ElasticFox插件和Eucalyptus提供的euca2ools工具集与OpenNebula云平台进行交互。</p>
<p>OpenNebula只有两种类型的用户：管理员，普通用户。</p>
<p>在早期版本中，OpenNebula管理员可以在后台通过命令行来管理资源池和虚拟机生命周期。 同样，在FireFox浏览器中，可 以利用ElasticFox插件，在浏览器中启动、监控和关闭虚拟机。</p>
<p>SunStone和OneMC这两个项目都提供了比较完整的资源池管理和虚拟机生命周期管理功能。两个项目的界面都比较简单，但是基本上处于可用的状态。SunStone没有提供虚拟机console功能，OneMC通过VNC协议提供了虚拟机console功能。</p>
<p>OpenNebula的模板和虚拟机实例机制与Eucalyptus类似。但是并不缺省地使用euca2ools作为工具。</p>
<p>与Eucalyptus类似，OpenNebula根据某种算法自动决定用户的虚拟机将在哪个物理服务器上运行，用户对物理服务器的状况一无所知。</p>
<p>  <strong>OpenQRM</strong></p>
<p>基于浏览器的用户界面，功能比较丰富。</p>
<p>OpenQRM的管理界面只有两种用户：管理用户，普通用户。普通用户只有查看权限，没有管理权限。</p>
<p>通过启用不同的插件，可以管理不同的计算资源。所有的资源池和虚拟机生命周期管理操作都可以通过浏览器界面完成。</p>
<p>OpenQRM的novnc插件可以提供基于VNC协议的虚拟机console功能。</p>
<p>  <strong>XenServer</strong></p>
<p>XenCenter是基于Windows的桌面应用，安装与操作都非常简单，界面美观，功能强大。</p>
<p>在参与评测的8 个软件中，XenCenter的用户界面是表现最出色的。基于Windows桌面的应用能够迅速地对用户的点击动作作出反应，从而提高用户体验的满意度。</p>
<p>系统管理员登录XenCenter之后，可以结合Active Directory在用户和用户组的层面分配管理权限。</p>
<p>授权用户可以通过图形界面方便地进行资源池和虚拟机生命周期管理。在图形界面上可以直观地监控物理服务器和虚拟机的计算资源使用情况（CPU、内存、存储、网络活动）。</p>
<p>提供基于VNC的虚拟机console。</p>
<p>可以基于模板的部署新的虚拟机。</p>
<p>  <strong>Oracle VM</strong></p>
<p>Oracle VM Manager提供了基于浏览器的管理界面。</p>
<p>Oracle VM Manager同时提供了role和group的概念。其中role定义了用户所具备的权限，属于同一个group的用户拥有该group所被授予的权限。</p>
<p>Oracle VM Manager提供了三种role：</p>
<p>user - 拥有指定资源池的虚拟机生命周期管理权限。</p>
<p>manager - 拥有除了用户管理之外的所有管理权限。</p>
<p>administrator - 拥有整个系统的管理权限。</p>
<p>授权用户可以通过图形界面方便地进行资源池和虚拟机生命周期管理。在图形界面上可以直观地监控物理服务器和虚拟机的计算资源使用情况（CPU、内存、存储、网络活动）。</p>
<p>提供基于VNC的虚拟机console。</p>
<p>可以基于模板的部署新的虚拟机。 <strong>CloudStack</strong></p>
<p>基于浏览器的用户界面，功能丰富，美观大方。</p>
<p>CloudStack根据用户的role将用户分成三个类型：</p>
<p>admin - 全局管理员。</p>
<p>domain－admin - 域管理员，可以对某个域下的物理和虚拟资源进行管理。</p>
<p>user - 个体用户，可以管理自己名下的虚拟机资源。</p>
<p>CloudStack 对物理资源的管理完整地模拟了一个物理机房的实际情况，按照“机房（Zones）－》机柜（Pods）－》集群（Cluster）－》服务器 （Server）”的结构对物理服务器进行组织，使得管理员能够在管理界面里面的计算资源和机房里面的计算资源建立起直观的一一对应关系。</p>
<p>授权用户可以通过图形界面方便地进行资源池和虚拟机生命周期管理。在图形界面上可以直观地监控物理服务器和虚拟机的计算资源使用情况（CPU、内存、存储、网络活动）。</p>
<p>提供基于VNC的虚拟机console。</p>
<p>可以基于模板的部署新的虚拟机。</p>
<p>  <strong>ConVirt</strong></p>
<p>基于浏览器的用户界面，功能丰富，美观大方。</p>
<p>社区版可以注册多个用户，并可将用户按照用户组进行分类，但是所有的用户拥有相同的全局管理权限。企业版则提供了更细致的用户权限管理机制。除此之外，企业版还提供了对LDAP的支持。</p>
<p>授权用户可以通过图形界面方便地进行资源池和虚拟机生命周期管理。在图形界面上可以直观地监控物理服务器和虚拟机的计算资源使用情况（CPU、内存、存储、网络活动）。提供基于VNC的虚拟机console。</p>
<p>可以基于模板的部署新的虚拟机。</p>
<p>ConVirt 的最大优点，在于其通过时程图的方式在不同的层次上直观地展示计算资源（包括物理资源和虚拟资源）的利用情况和健康状况。在整个数据中心和资源池的层 面，ConVirt实时显示资源池数量、物理服务器和虚拟机数量、虚拟机密度、存储资源使用状况、负载最高的N 台物理服务器和虚拟机。在物理服务器和虚拟机的层面，ConVirt实时显示CPU和内存使用情况，监控人员可以通过CPU和内存时程图及时地发现或者是 调查系统异常情况。</p>
<p>在 所有参与评测的虚拟化管理软件中，XenServer / XCP和ConVirt的图形用户界面是做的最好的。XenCenter的图形界面的优点在于提供了独一无二的用户体验，ConVirt的图形界面的优点 在于以图形的方式直观地展示了从机房到虚拟机的健康状况。CloudStack的图形界面非常大气，但是在功能上不如ConVirt那么实用。不过按照 CloudStack的目前的发展势头来看，下一个版本可能比较值得期待。</p>
<p>由于进行评测的时间较短，并且测试系统规模较小的原因，暂时无法对各个软件的稳定性、健壮性、扩展性等等关键问题作出评估。</p>
<p>商务篇：</p>
<p>目前市面上形形色色的虚拟化管理软件总数很多，这一系列文章所提及的几个软件仅仅其中的几个代表。作为一个机构、或者是一家企业，在向虚拟化过渡时都不可避免地要面临软件选型的问题。本文作为这一系列文章的最后一篇，从商务和功能两个方面提出自己的一点粗浅意见。</p>
<p>（1）商务评估</p>
<p>从 商务上进行软件选型，性价比通常是一个决定性的因素。在假定参与选型的软件全部满足技术要求的前提下，企业（机构）需要考虑的因素包括软件的授权协议是否 友好、许可证管理的难易程度、软件和服务的价格高低、运营团队在业界的声誉、开发者社区和用户社区的规模和活跃程度、商业与技术沟通的难易程度。</p>
<p>授 权协议/许可证管理 — 以全部开放源代码为10分，部分开放源代码（例如以企业版的形式提供某些高级功能，或者以服务的形式提供特别版本的安装包和补丁）扣1 分。商业版本需要在控制节点安装许可证不扣分，需要在所有计算节点安装许可证扣1 分，许可证需要每年更新者扣1 分。</p>
<p>价格指数 — 以全部功能免费使用为10分，以企业版的模式提供全部功能的软件，每台物理服务器每花费500美元扣1  分。</p>
<p>运营团队 — 以运营团队的规模、背景、影响力评分，存在的主观因素较多。</p>
<p>社区因素 — 以开发者和用户社区的规模和活跃程度评分，存在的主观因素较多。</p>
<p>沟通交流 — 以个人与运营团队、开发者社区、用户社区之间的沟通顺畅程度评分，存在的主观因素较多。</p>
<p>   授权协议</p>
<p><strong>授权协议</strong></p>
<p><strong>许可证管理</strong></p>
<p><strong>价格指数</strong></p>
<p><strong>运营团队</strong></p>
<p><strong>社区因素</strong></p>
<p><strong>沟通交流</strong></p>
<p><strong>总分</strong> <strong>Eucalyptus</strong></p>
<p>9</p>
<p>8</p>
<p>9</p>
<p>9</p>
<p>10</p>
<p>45 <strong>OpenStack</strong></p>
<p>10</p>
<p>10</p>
<p>8</p>
<p>8</p>
<p>7</p>
<p>43 <strong>OpenNebula</strong></p>
<p>9</p>
<p>9</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>42 <strong>OpenQRM</strong></p>
<p>9</p>
<p>8</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>37 <strong>XenServer</strong></p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>9</p>
<p>43 <strong>Oracle VM</strong></p>
<p>9</p>
<p>7</p>
<p>7</p>
<p>6</p>
<p>7</p>
<p>36 <strong>CloudStack</strong></p>
<p>9</p>
<p>8</p>
<p>7</p>
<p>6</p>
<p>7</p>
<p>37 <strong>ConVirt</strong></p>
<p>9</p>
<p>8</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>44</p>
<p>（2）功能评估</p>
<p>从功能上进行虚拟化管理软件选型，需要考虑的因素包括该软件所支持的虚拟化技术、安装配置的难易程度、开发和使用文档的详尽程度、所提供的功能是否全面以及用户界面是否直观友好、二次开发的难易程度、是否提供物理资源和虚拟资源的监控报表等等。</p>
<p>虚拟化技术支持 — 仅支持一种虚拟化技术为6 分，每增加一种虚拟化技术加1 分，10分封顶。</p>
<p>安装配置 — 以按照官方文档进行安装配置的难易程度评分，存在的主观因素较多。</p>
<p>开发/使用文档 — 以官方所提供的开发与使用文档的详尽程度评分，文档详尽程度越高者得分越高。</p>
<p>功能与界面 — 综合评分，涵盖用户进行物理资源和虚拟资源管理、虚拟机生命周期管理、访问虚拟机资源和存储资源的难易程度，用户界面的美观易用程度，以及综合用户体验。</p>
<p>二次开发 — 基础得分6 分，提供与Amazon EC2相兼容的程序调用接口者加3 分，提供二次开发接口但是与Amazon  EC2不兼容者加2 分。</p>
<p>监控报表 — 基础得分6 分，依系统所提供监控与分析功能的详尽程度加分。</p>
<p><strong>虚拟化技术支持</strong></p>
<p><strong>安装配置</strong></p>
<p><strong>开发／使用文档</strong></p>
<p><strong>功能与界面</strong></p>
<p><strong>二次开发</strong></p>
<p><strong>监控报表</strong></p>
<p><strong>总分</strong> <strong>Eucalyptus</strong></p>
<p>8</p>
<p>8</p>
<p>9</p>
<p>4</p>
<p>9  (Amazon  WS)</p>
<p>6</p>
<p>44 <strong>OpenStack</strong></p>
<p>10</p>
<p>8</p>
<p>8</p>
<p>4</p>
<p>9  (Amazon  WS)</p>
<p>6</p>
<p>45 <strong>OpenNebula</strong></p>
<p>8</p>
<p>8</p>
<p>7</p>
<p>4</p>
<p>9  (Amazon  WS)</p>
<p>6</p>
<p>42 <strong>OpenQRM</strong></p>
<p>10</p>
<p>9</p>
<p>5</p>
<p>10</p>
<p>6 (OS)</p>
<p>7</p>
<p>47 <strong>XenServer</strong></p>
<p>6</p>
<p>10</p>
<p>10</p>
<p>10</p>
<p>8 (Plugin)</p>
<p>9</p>
<p>53 <strong>Oracle VM</strong></p>
<p>6</p>
<p>9</p>
<p>8</p>
<p>7</p>
<p>8 (WS)</p>
<p>7</p>
<p>45 <strong>CloudStack</strong></p>
<p>8</p>
<p>9</p>
<p>8</p>
<p>10</p>
<p>6 (OS)</p>
<p>8</p>
<p>49 <strong>ConVirt</strong></p>
<p>7</p>
<p>10</p>
<p>10</p>
<p>10</p>
<p>8 (API)</p>
<p>10</p>
<p>55</p>
<p>（3）综合评估</p>
<p>从 商务上考虑，Eucalyptus和ConVirt以微弱 的优势领先于其他选项。Eucalyptus是私有云管理平台的先行者。Ubuntu 10.04选择捆绑Eucalyptus作为UEC的基础构架，使得Ecualyptus比其他的私有云管理平台拥有更多的用户和更加活跃的社区。此 外，Ecualyptus在中国国内有销售和技术支持人员，在沟通上比选择其他软件要更加容易。ConVirt排名第二，根本原因在于其销售和技术支持团 队与（潜在的）客户保持积极而有效的沟通。Citrix XenServer仅仅与其他两个选项并列排名第三，输在其过于严苛的许可证管理政策。的确，要给100台以上的服务器单独安装许可证并且每年更新一次， 可不是一件有意思的事情。</p>
<p>从 功能上考虑，ConVirt与XenServer遥遥领先于其他选项。虽然ConVirt仅仅支持Xen和KVM两种虚拟化技术，但是其安装配置相对简 单，文档详尽、功能齐全、界面美观、是比较容易上手的虚拟化管理软件。更重要的是，ConVirt的监控报表功能直观地展示了从数据中心到虚拟机的 CPU、内存利用情况，使得用户对整个数据中心的健康状况一目了然。同样，XenServer虽然仅支持Xen一种虚拟化技术，但是在安装配置、操作文 档、用户界面等方面都不亚于ConVirt。如果用户对基于Windows的界面没有强烈的抵触情绪的话，XenServer是比较值得考虑的一个选型。</p>
<p>综 合如上考虑，对于希望利用虚拟化管理软件提高硬件资源利用率和虚拟化管理自动化程度的企业（机构）来说，建议使用ConVirt来管理企业（机构）的计算 资源。如果网管人员不希望深入了解Linux操作系统，并且所管理的物理服务器数量有限的话，XenServer也是一个不错的选择。ConVirt的浏 览器界面是开放源代码的，用户可以对其进行定制化，将自己所需要的其他功能添加到同一个用户界面中去。XenCenter则提供了一种插件机制，用户可以 通过插件的方式讲自己的功能集成到XenCenter中。</p>
<p>不 过，你的基础设施是否需要与Amazon EC2相兼容呢？也就是说，你的用户是否需要使用他们用于访问和操作Amazon EC2的脚本和工具来访问你的计算资源呢？如果是这样的话，你可能需要在Eucalyptus和OpenStack之间作一个选择（CloudStack 和OpenNebula同样提供了与Amazon EC2兼容的操作接口，但是CloudStack在商务方面得分不高，OpenNebula在功能方面得分不高）。Eucalyptus的历史比 OpenStack稍长，用户群比OpenStack要大，社区的活跃程度也比OpenStack要高。不过OpenStack的后台老板NASA比 Eucalyptus要财大气粗，Ubuntu 11.04也集成了OpenStack作为其UEC的基础构架之一，表明OpenStack已经得到了社区的重视和支持。总的来说，开放源代码的云构架， 还是一个不断发展之中的新生食物。笔者只能够建议用户亲自去安装使用每一个软件，最终基于自己的经验以及需求达到一个最适合自己的选择。</p>
<p>虚拟化管理软件比较 －－ 幻灯片</p>
<p>结合前段时间对不同虚拟化管理软件的评测工作，准备了一套讲座用的幻灯片。PDF版本的文件可以从这里下载。如果有人需要ODP版本的文件，直接跟我联系吧。</p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p>1.4 对我司的作用</p>
<p>建议使用Convirt而不是OpenStack</p>
<p>当其与sunde等代表的云终端（支持由真实单机提供和分配多虚拟机的运行环境，最终用户通过sunde的非PC终端连结各自虚拟机）配合使用时。</p>
<p>可以组成OpenStack管理的真实计算机集群基础上按照业务类型（开发、测试、办公、演示、呼叫、培训）划分的虚拟母机，再分别在虚拟母机上运行sunde的管理端，以管理最终使用者的各个虚拟子机并分别组成各自虚拟子网和公司公关网络，最后由最终用户使用非PC终端接入各自使用的一个或者多个虚拟机进行合理工作。</p>
<p>非移动技术用环境：</p>
<p>比起开发、测试人员、销售使用的个人工作机相比，更紧缺的是各种服务器，譬如：</p>
<p>运维：线上完整模拟测试环境、线上环境备份、工作环境文件共享服务器，公司网站测试环境等。</p>
<p>开发：VS、PD、DB设计服务器、开发测试用完整模拟环境、架构测试实验室等。</p>
<p>测试：QC服务器、浏览器多版本环境测试服务器、独立项目测试用完整模拟环境等。</p>
<p>Call Center：简单应用而需多人处理的办公环境。</p>
<p>等用于管理多虚拟实例的环境管理节点（一台机器、一个环境）甚至线上备份。</p>
<p>但因其不能跨物理机调度、通信、资源整合、虚拟机效率低等原因，不可以用于：</p>
<p>分布式大数据量存储控制业务节点、分布式数据中心存储控制节点等需要整合物理机资源进行分布式并行处理的环境。</p>
<p>2 <img src="" alt=""> Hadoop</p>
<p>2.1 简介</p>
<p>一款分布式数据存储与业务系统架构平台，由Apache基金会开发。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力高速运算和存储。</p>
<p>其可以在多台计算机（PC或者小型机）组成的网络集群上跨物理机器统一调配单机资源以适应多种可分布并行处理的业务服务。</p>
<p>2.2 原理</p>
<p>其架构由低到高分为 HDFS-&gt;MapReduce+BigTable（NoSQLDB）</p>
<p>HDFS算法中</p>
<p>结构分为星型的NameNode核心与DataNode外围，其中NameNode为其瓶颈，当NameNode再大时，只能再整体复制一个集群出去做分布或者将单一机器的NameNode再通过把Key分级做Hadoop化处理。</p>
<p>有效容积率：</p>
<p>假设容许损坏的机器为x台，机器总数为y台</p>
<p>那么y台机器有效数据量为y/(x+1),其有效数据容积率为(y/(x+1))/y=1/(x+1)</p>
<p>健壮率：</p>
<p>假设容许损坏的机器为x台，机器总数为y台</p>
<p>那么y台机器健壮率(最小需要几台机器才能稳定)为1-(y-x)/y = x/y</p>
<p>如果综合考虑 有效容积率与健壮率 那么 1/(x+1)=x/y 所以y = x（x+1）。</p>
<p>MapReduce算法：</p>
<p>典型分散综合分布式处理算法。</p>
<p>基础是处理可以分散处理再综合统计数据的业务类型。</p>
<p>2.3 对我司的作用</p>
<p>其分布并行Map-reduce算法可以用于很多非即时反馈的非事务性业务处理：且不依赖HDFS一种实现，只要是支持节点运算即可。</p>
<p>其HDFS系统可用于大量数据文件的存储。但是不论其节点数量多少，其有效容积率都是由可容忍的宕机数量决定的。可见HDFS算法中更侧重的是稳定而不是并行处理高效和负载，更针对建立索引等搜索类业务处理要求而对少写多读商务类业务处理针对性不强，从百度淘宝的实践看也都证明这一点。</p>
<p>所以其HDFS系统设计之上应根据实际情况加入中央NOSQL缓存扩展与单数据节点线性NOSQL缓存负载。再配合业务服务器自身各种优化措施才能成为公司分布式DB、FS处理负载设计框架。hadoop设计思路可以借鉴不能照搬。</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--OpenStack_Hadoop/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--OpenStack_Hadoop" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事1：外企也就那么回事/">IT外企那点儿事(1)：外企也就那么回事</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事1：外企也就那么回事/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="it-1-">IT外企那点儿事(1)：外企也就那么回事</h1>
<p><a href=""></a></p>
<h1 id="-http-www-cnblogs-com-forfuture1978-"><a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a></h1>
<p>  <a href="http://www.cnblogs.com/" target="_blank">博客园</a> :: <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">首页</a> :: <a href="http://q.cnblogs.com/" target="_blank">博问</a> :: <a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?opt=1" target="_blank">新随笔</a> :: <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">联系</a> :: <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank">订阅</a> <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank"><img src="" alt="订阅"></a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx" target="_blank">管理</a> :: <img src="" alt="">   130 随笔 :: 0 文章 :: 544 评论 :: 0 引用
<a href="">&lt;</a>2010年4月<a href="">&gt;</a>日一二三四五六28293031123<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/04.html" target="_blank">4</a>56<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/07.html" target="_blank">7</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/08.html" target="_blank">8</a>9101112<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/13.html" target="_blank">13</a>14<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/15.html" target="_blank">15</a>161718192021<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/22.html" target="_blank">22</a>2324<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/25.html" target="_blank">25</a>26<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/27.html" target="_blank">27</a>28<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/29.html" target="_blank">29</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/30.html" target="_blank">30</a>12345678</p>
<h3 id="-">公告</h3>
<p>昵称：<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
园龄：<a href="http://home.cnblogs.com/u/forfuture1978/" title="入园时间：2009-12-10" target="_blank">3年7个月</a>
荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
粉丝：<a href="http://home.cnblogs.com/u/forfuture1978/followers/" target="_blank">560</a>
关注：<a href="http://home.cnblogs.com/u/forfuture1978/followees/" target="_blank">3</a></p>
<p><a href="">+加关注</a></p>
<h3 id="-">搜索</h3>
<h3 id="-">常用链接</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/MyPosts.html" target="_blank">我的随笔</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/MyComments.html" target="_blank">我的评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/OtherPosts.html" title="我发表过评论的随笔" target="_blank">我的参与</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/RecentComments.html" target="_blank">最新评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/tag/" target="_blank">我的标签</a></li>
</ul>
<h3 id="-">随笔分类</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300670.html" target="_blank">Hadoop原理与代码分析(7)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事(12)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345798.html" target="_blank">Java(2)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345797.html" target="_blank">Linux(14)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300665.html" target="_blank">Lucene原理与代码分析(38)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300666.html" target="_blank">长尾理论(16)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345794.html" target="_blank">管理学(10)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345800.html" target="_blank">经济学(4)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345796.html" target="_blank">算法(1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345795.html" target="_blank">闲话IT业(3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300667.html" target="_blank">心理学与管理学效应(9)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300668.html" target="_blank">组织行为学(15)</a></li>
</ul>
<h3 id="-">随笔档案</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11.html" target="_blank">2012年11月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/01.html" target="_blank">2012年1月 (5)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/12.html" target="_blank">2011年12月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/10.html" target="_blank">2011年10月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/09.html" target="_blank">2011年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11.html" target="_blank">2010年11月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/10.html" target="_blank">2010年10月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/09.html" target="_blank">2010年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08.html" target="_blank">2010年8月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/07.html" target="_blank">2010年7月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06.html" target="_blank">2010年6月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05.html" target="_blank">2010年5月 (22)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04.html" target="_blank">2010年4月 (18)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/03.html" target="_blank">2010年3月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02.html" target="_blank">2010年2月 (39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/01.html" target="_blank">2010年1月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12.html" target="_blank">2009年12月 (6)</a></li>
</ul>
<h3 id="-">相册</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/gallery/247104.html" target="_blank">IT外企那点儿事</a></li>
</ul>
<h3 id="-">最新评论</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2727561" target="_blank">1. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li>楼主怎么之后没有更新hadoop的相关信息了呢？是没有再研究了吗？</li>
<li>--lyeoswu</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html#2713121" target="_blank">2. Re:Lucene 原理与代码分析完整版</a></li>
<li>提个建议，你生成的pdf中没有目录，影响阅读，用office转制的过程中其实设置一下即可，方便大众嘛~，还望能发我一份，谢谢！
sendreams@hotmail.com</li>
<li>--sendreams</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2712415" target="_blank">3. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>mojunbin
现在这公司，本来做的Siverlight，我进去后没多久就转JAVA了，最近在公司折腾JAVA的一些东西，业余时间玩玩游戏，看看CLR、并折腾linux。现在观点有所转变，觉得学技术更多的是为了扩宽思维、提高眼界</li>
<li>--峰顶飞龙</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2711923" target="_blank">4. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>峰顶飞龙
您的经历和我差不多，呵呵。不晓得现在兄弟在搞C/C++呢？</li>
<li>--mojunbin</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/23/1884967.html#2708814" target="_blank">5. Re:Hadoop学习总结之五：Hadoop的运行痕迹</a></li>
<li>楼主你好，在远程调试MapReduce时，本地代码进入不了自定义的job类，而是进入到Credentials class中，此类在hadoop-core-1.0.4.jar中，请问楼主在调试过程可否遇到此问题？</li>
<li>--彭莉珊</li>
</ul>
<h3 id="-">阅读排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">1. IT外企那点儿事(8)：又是一年加薪时(26799)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">2. Lucene 原理与代码分析完整版(25616)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02/23/1671909.html" target="_blank">3. 从技术生命周期看IT历史(20878)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12/21/1628546.html" target="_blank">4. 101个著名的管理学及心理学效应(20828)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/14/1877086.html" target="_blank">5. Hadoop学习总结之三：Map-Reduce入门(18681)</a></li>
</ul>
<h3 id="-">评论排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(68)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05/1727644.html" target="_blank">2. IT外企那点儿事(4)：激动人心的入职演讲(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">3. IT外企那点儿事(6)：管理路线和技术路线(37)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">4. IT外企那点儿事(8)：又是一年加薪时(35)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">5. IT外企那点儿事(12)：也说跳槽(33)</a></li>
</ul>
<h3 id="-">推荐排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(55)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03/1726200.html" target="_blank">2. IT外企那点儿事(3)：奇怪的面试(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">3. IT外企那点儿事(8)：又是一年加薪时(36)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">4. IT外企那点儿事(12)：也说跳槽(34)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">5. IT外企那点儿事(6)：管理路线和技术路线(27)</a></li>
</ul>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/30/1725341.html" target="_blank">IT外企那点儿事(1)：外企也就那么回事</a></p>
<p>外企，一个听起来似乎充满光环的名字，每年众多大学毕业生向往的地方。</p>
<p>说起外企，总能让人联想到很多令人心动的名词：高薪，人性化，浮动工作制，年假，完善的流程，各种福利如：旅游，室内乒乓球台，健身房，按摩椅，小食品，酸奶……</p>
<p>然而真正进入了外企，时间长了，也就发现，其实外企也就那么回事。</p>
<h2 id="-">高薪</h2>
<p>所谓高薪，严格意义上来讲是高起薪，也即刚毕业的时候每个企业公开的秘密，同学们总能够从师哥师姐那里打听到这个数字，有的企业甚至爆出较去年惊人的数字来做宣传。一个个光鲜的数字吸引着尚未毕业的大学生们，宣讲会的人数是基本和这个数字成正比的。</p>
<p>然而由于大多数的外企，由于规模比较大，机构也相对的稳定，高起薪的背后是稳定的加薪，每年7%~10%是常道，20%则是皇恩浩荡了，除非你能够取得整个Team都认可的成就，然而如果不幸参与的项目是一个多年的产品，至多是修改一些Bug或者增加一些边边角角的功能，又有多少这样的机会呢？大约在下看到的是这样的，也许并不符合所有外企的情形。</p>
<p>于是当毕业生中的佼佼者很幸运的加入大的外企的时候，不如你的同学只有默默的加入了不算太大的民企。</p>
<p>这一直是你引以为豪的资本，并总在同学聚会的时候大说特说你们公司的薪水，福利，在你的同学抱怨民企的加班声中附和着，心中却莫名的产生了一种优越感。</p>
<p>这种优越感使得你进一步沉浸在美好的外企生活中，却发现越来越没有那么优越了。三年，五年，你一次次的听说你的同学升职了，又升职了，而你还是一个普通的engineer，因为外企的升职基本是由严格的年限的，有时候多少有些按资排辈的味道。你一次一次听说你的同学加薪了，又加薪了，薪水直逼你当前的薪水，甚至在五年的关头超过你。</p>
<p>你越来越发现你的同学逐渐的掌握了一个系统前前后后的模块，能够完整的负责起一个项目的时候，你却还是螺丝钉，每天接受外国人的指示，在yes, ok, no problem, i am 100% agree的声音中继续做你的螺丝钉般的小功能。</p>
<p>我不知道十年后会如何，在参加了多次的开发者大会后，我发现几乎所有的外企的演讲者都是外国人，中国的演讲者则多来自本土的创业企业，当听着他们如数家珍的谈着自己的创业企业如何一步步做大，系统如何一步步改进，直到今天的架构，他们外企的同学能有这种机会吗？</p>
<h2 id="-">人性化</h2>
<p>所谓人性化，用外企的语言就是我们是很Open的。</p>
<p>Open体现在很多方面，诸如高管的办公室的门始终是开着的，你可以在任何时刻走到任何的高官的办公室里发表自己的看法，只是你必须保证，当你满怀激情的走进高官的办公室，关上门，半个小时后同样满怀激情走出办公室，你的顶头上司对你没有看法，即便你确实没有说什么，仅仅谈论了一下午餐而已。</p>
<p>所以除非高层主动安排和你谈话，尽量不要没事跑到高层那里，在你的顶头上司控制范围之外和他的上司进行私密的谈话，要知道有一种关系叫表面上支持，心中的隔阂。即便是高层主动要和你谈话，最好事先和你的顶头上司事先沟通，当然不用太正式，比如在闲聊的时间抱怨一下：&quot;今天下午又要被老大找去One on One，项目这么忙，不知道有啥事情可谈的&quot;，呵呵，一些术而已，姑妄言之姑听之吧。</p>
<p>对你最重要的永远是你的顶头上司，当高层听完你的建议，OK, I will take it into consideration之后，便和你没有啥关系了，绝不会存在当你的顶头上司决定给你涨薪7%的时候，高层会出来说一句，我觉得他表现还不错，涨10%吧。</p>
<p>当然，按照公司的规定，你的顶头上司也会过一段时间和你来一次One on One，问问当前的情况，问问有啥意见等等，这可不是推心置腹的时候，需要把握火候，对当前的情况说的太满意，感觉不真诚，太不满意自然领导不爱听，说没意见显得对Team不够关心，说太多意见会让人感觉你不安全。</p>
<p>所以总的原则是：</p>
<ul>
<li>要多提改善性意见(&quot;code review预留的时间应该更长一些&quot;)，少提颠覆性意见(&quot;现在的项目流程有很大问题&quot;)，</li>
<li>多提有证据的具体意见(&quot;我们有几十个Bug，可能一个星期确实做不完&quot;)，少提抽象型意见(&quot;Team之间的沟通有问题&quot;)，</li>
<li>多说与项目相关的意见，少说与自己相关的意见(尤其不要太真实的说自己的人生规划)，</li>
<li>多说在领导意料范围之内的意见(这样会给领导以对Team的控制感，比如说天天加班到10点，领导也看在眼中，可以提一下)，少说在领导意料之外的意见(即便有，请事先沟通，让领导在One on One之前就心里有数)。</li>
</ul>
<p>Open还体现来另外的方面，比如领导会和员工一起参加各种工作之外的活动，比如打球，比如年会表演，比如一起健身等等，而且在此过程中，往往是充满的欢声笑语的，但一定不要忘记领导就是领导，哪怕不在项目中，千万不要因为你曾经是学校的篮球高手，或是文艺主干，就能在此类的活动中充当领袖角色，在你的项目领导面前指手画脚，虽然在活动中他会夸你，没想到你还有这方面的才能，但是在领导面前充老大，这笔账是迟早要还的，比如在项目的后期不能够完成美国派来的任务的时候，你会被冠以虽然前一阵成功组织了活动，但是耽误了一些项目进度的罪名，从而影响你的绩效。</p>
<p>如果你在健身房遇到领导，和你一起健身，你们可以边健身边聊的很开心，但是领导的心中的第一个想法一定是，这小子项目干完了吗，还有空工作时间健身？，并且会在以后的工作中反映出来，比如时常关心你的工作进度，加大你的工作量等。</p>
<h2 id="-">浮动工作制</h2>
<p>所谓浮动工作制，很好听的名字，就是你早上可以推迟来，晚上可以早些走，只要能够完成任务，每天工作6个小时都可以。</p>
<p>初入外企的时候，看到很多前辈可以早上十点，甚至十一点才到公司，认为浮动工作制太好了，于是拼命的工作，企图在6小时干完10个小时的活，然后有时间或学习或休息。然而最后发现，活是永远干不完的，资本家花钱请了你，会让你轻松应对？</p>
<p>浮动工作制，其实就是加班不给加班费的另一种说法，也即合同中也许会写着&quot;所有的加班费已经被计入了薪水中&quot;。只要能够完成任务，每天工作12个小时也是应该的。晚上留下来很晚，或是早上很早被拉起来和老美开会，也是浮动的时间之中，你无话可说。为了改美国客户的一个Bug，深夜加班，你无话可说。在中国是休息日，但美国不是休息日的时候派去美国，并不补偿你的休息日，也不给三倍工资，你无话可说。</p>
<h2 id="-">年假</h2>
<p>外企的年假是相对较多的，也是外企在校园宣讲中经常引以为豪的一点。然而年假又有多少真正能够落到实处呢？其时大部分是休不到的，项目不允许，领导不允许，外国人也不允许。</p>
<p>不允许当然不是显式的，而是潜规则的。项目永远是紧的，即便不那么紧，也会被人们喊得使大家觉得很紧，如果一个Team有很多人休很多假，对领导来说，好像对上面不太好交代。</p>
<p>如果Team中你单独休假，你会被提醒，现在大家都在赶进度，不要因为你这个模块把项目block了。</p>
<p>如果Team中大家想一起休假，领导会说，大家都在这个时候休，连backup都没有，出了事情找不到人啊。</p>
<p>如果你平时想休息一天，领导会说，有什么事情吗？没什么事情可以等项目闲了些集中休息一下，明天早上可以晚来些，可能这一阵确实太累了。</p>
<p>如果你想连着长假一起休，领导会说，本来就有一个星期了，还另外请，不如平时累的时候休息一天，效果好。</p>
<p>如果美国人放假(如圣诞)，中国不放假，美国人会在放假前有很多任务布置过来，要在这个期间赶上美国的进度。</p>
<p>如果美国不放假，中国放假(如过年)，总不能让美国老板找不到人吧。</p>
<p>当然以上借口只是在你提出请假的时候，以商量的口气被提及，如果你真想请假，领导还是会毫不犹豫的批准的，因为我们是Open的嘛。然而以上借口却会使得多数员工不太敢于请假，因为大家都明白，有一种关系叫表面上支持，心中的隔阂。</p>
<p>当然即便假期被批准，还是有条件的，比如&quot;没问题，好好休息，走之前把文档(报告，邮件，代码)发出来(提交到svn)就行了&quot;。一般这个附加条件都会耗费一些时间的，一般是第二天休，前一天晚上至少九十点走，早上请，中午才能走，中午请，下午三点多才能走。</p>
<h2 id="-">完善的流程</h2>
<p>外企的流程是非常完善的，甚至是极度的完善，过分的完善。</p>
<p>所以外企一般都会有会议室预定系统，会议室永远是被占着的，一天一天的总是开会，讨论。</p>
<p>例会就有模块组的，开发组的(包含多个模块)，项目组的(开发和测试)，Group的(同一个大老板的多个项目)，all-hands的(整个公司)。</p>
<p>写一篇文档要模块组review，开发组review，测试组review，和美国开会review，重新改了第二轮review。以及code review，bug review。</p>
<p>每个项目组作了一个阶段后给整个项目组的demo，甚至给整个group及老外demo，说是增加visualbility。</p>
<p>一般要到下午晚些时候才能够清净些写代码，晚餐后才是代码的高峰期。</p>
<p>这也是为什么小公司半年作出来的东西，大公司要做几年。当然大公司这样做自然有它的道理，大公司稳定，不愁客户资源，不差钱，今年做出来或是明年做出来，客户别无选择，员工也养得起。这些小公司都做不到，必须尽快的满足客户的需要，必须在钱花完之前拉到下一个项目。</p>
<p>然而这对程序员的职业生涯来说好么，我不敢评价。只是在和很多朋友讨论的时候，他们发现，自己一直在忙啊忙，当跳槽试图总结自己做了啥的时候，却发现就不多的东西，不多的技术，当他们去面创业公司的时候，经常会被问，你们这么长时间，怎么就做了这么个东西？</p>
<p>大公司完善的流程还有一个特点，就是这个流程是完全为此公司定制的，当然公司大，自然可以有钱从头到尾弄自己的东西，既不用常用的，也不用开源的，无论是开发工具，测试工具，代码管理工具。这也导致了员工的粘性特别强，当走出这家公司，就像换了一片天地，原来会的别人用不到，别人常用的，却不怎么会，最后只好在公司养老，好在薪水也不错，福利也不错。</p>
<h2 id="-">设施</h2>
<p>最后提及的是各种美好的设施，这是很有吸引力的。然而为了您的前途，虽不能说敬而远之，也要注意享用的时间，如中午，晚上。</p>
<p>尽量不要在工作时间娱乐，甚至喧哗，人民的眼睛是雪亮的，领导的眼睛也是雪亮的，尤其是对于软件这种成果极难量化的产品，有时候表现和态度反而成了一种指标，不像销售一样，给公司带来的是真金白银，我无论怎么玩，能拿回单子就行，然而对于软件，你有绝对的证据证明成果超越别人吗？</p>
<p>所以外企有个很有意思的现象，一个团队的座位，离食品的距离越近越好，离娱乐设备的距离越远越好。离食品近，取用方便，领导看到你拿吃的也不会说什么，然而离娱乐设备近，领导办公室的门都开着，有谁胆敢长时间玩耍啊。所以娱乐设备上面玩耍的人一般都是座位离得比较远的。</p>
<p>此篇就写到这里的，在外企多年，其实发生了很多有趣的事情和现象，当走过几个外企的时候，发现有很多相似的潜规则。</p>
<p>进入中国的外企，其实是有中国特色的外企。中华文化的强大，使得所有的东西一到中国就会中国化，甚至改变了味道。很多民族如满族，回族的很多人都失去了原来民族的特色。也只有在中国，才可能存在儒释道三教合一的说法，不知道释迦摩尼有何感想。上学的时候，一个我很佩服的大物老师，年纪很大，他是坚定的马克思主义者，但是他曾经说，上个星期我病的厉害，差点就去见马克思了。我笑道，马克思是唯物的，是不相信死后有鬼的，死后去见阎王是迷信，去见马克思就不是了？</p>
<p>等有空的时候，再接着给大家讲外企的故事。</p>
<p>分类: <a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事</a></p>
<p>绿色通道： <a href="">好文要顶</a> <a href="">关注我</a> <a href="">收藏该文</a><a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">与我联系</a> <a href="&quot;分享至新浪微博&quot;"><img src="" alt=""></a>
<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank"><img src="" alt=""></a></p>
<p><a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followees" target="_blank">关注 - 3</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followers" target="_blank">粉丝 - 560</a></p>
<p>荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
<a href="">+加关注</a></p>
<p>18</p>
<p>0
(请您对文章做出评价)</p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/29/1723417.html" target="_blank">«</a> 上一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/29/1723417.html" title="发布于2010-04-29 00:24" target="_blank">高级Linux程序设计第五章：进程间通信</a>
<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/01/1725761.html" target="_blank">»</a> 下一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/01/1725761.html" title="发布于2010-05-01 20:57" target="_blank">信息检索导论(译)：第一章 布尔检索(1)</a>
posted on 2010-04-30 21:30 <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a> 阅读(8943) 评论(26) <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?postid=1725341" target="_blank">编辑</a> <a href="">收藏</a></p>
<p><a href=""></a></p>
<h3 id="-">评论</h3>
<p><a href="">/#1楼</a><a href=""></a>  2010-04-30 21:54  <a href="http://www.cnblogs.com/lguyss/">土星的狗狗</a> <a href="http://space.cnblogs.com/msg/send/%e5%9c%9f%e6%98%9f%e7%9a%84%e7%8b%97%e7%8b%97" title="发送站内短消息" target="_blank"> </a></p>
<p>写的太好了，又学习了~哈哈，直接映射了我之前的日本公司。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u23929.jpg" target="_blank">http://pic.cnitblog.com/face/u23929.jpg</a></p>
<p><a href="">/#2楼</a><a href=""></a>  2010-04-30 23:57  <a href="http://www.cnblogs.com/wenjl520/">温景良(Jason)</a> <a href="http://space.cnblogs.com/msg/send/%e6%b8%a9%e6%99%af%e8%89%af(Jason" target="_blank"> </a> &quot;发送站内短消息&quot;)</p>
<p>没去过,期待中</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u33118.jpg" target="_blank">http://pic.cnitblog.com/face/u33118.jpg</a></p>
<p><a href="">/#3楼</a><a href=""></a>  2010-05-01 10:41  <a href="http://www.cnblogs.com/ilovedotnet/">ilovedotnet</a> <a href="http://space.cnblogs.com/msg/send/ilovedotnet" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>土星的狗狗
我觉得日企和韩企不能算是真正的外企，大家通常说的外企只包括欧美企业。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u26921.jpg" target="_blank">http://pic.cnitblog.com/face/u26921.jpg</a></p>
<p><a href="">/#4楼</a><a href=""></a>  2010-05-01 21:59  <a href="http://www.cnblogs.com/skyyang/">DarroldYang</a> <a href="http://space.cnblogs.com/msg/send/DarroldYang" title="发送站内短消息" target="_blank"> </a></p>
<p>说的很像
加入这样的工作环境没多久
他们一个项目也是做了几年了
后面就一直在bug</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u23975.png" target="_blank">http://pic.cnitblog.com/face/u23975.png</a></p>
<p><a href="">/#5楼</a><a href=""></a>  2010-05-04 09:26  <a href="http://www.cnblogs.com/peon/">加菲猫</a> <a href="http://space.cnblogs.com/msg/send/%e5%8a%a0%e8%8f%b2%e7%8c%ab" title="发送站内短消息" target="_blank"> </a></p>
<p>作者深得外企三味，不过假如你有心，在薪水上超过大部分民企的同学问题不大，华为腾讯的除外</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u28333.jpg" target="_blank">http://pic.cnitblog.com/face/u28333.jpg</a></p>
<p><a href="">/#6楼</a><a href=""></a>  2010-05-05 09:28  <a href="http://www.cnblogs.com/jciwolf/">Jerry Qian</a> <a href="http://space.cnblogs.com/msg/send/Jerry+Qian" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主打击人啦，我现在在学英语啊。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#7楼</a><a href=""></a>  2010-05-05 11:43  <a href="http://www.cnblogs.com/bobliu/">Bob Liu</a> <a href="http://space.cnblogs.com/msg/send/Bob+Liu" title="发送站内短消息" target="_blank"> </a></p>
<p>看看，了解一下外企～</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u126058.jpg" target="_blank">http://pic.cnitblog.com/face/u126058.jpg</a></p>
<p><a href="">/#8楼</a><a href=""></a>  2010-05-05 12:01  <a href="http://www.cnblogs.com/Aaron_Anubis/">Aaron_Aanubis</a> <a href="http://space.cnblogs.com/msg/send/Aaron_Aanubis" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主，太好了···把这些说出来，叫我们更加了解外企，我们就更能根据自身来进行职业规划了！！！3q</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#9楼</a><a href=""></a>  2010-05-05 12:25  <a href="http://www.cnblogs.com/Jong/">Caspar Jiong</a> <a href="http://space.cnblogs.com/msg/send/Caspar+Jiong" title="发送站内短消息" target="_blank"> </a></p>
<p>深有同感！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#10楼</a><a href=""></a>  2010-05-05 12:51  <a href="http://www.cnblogs.com/jerry_cong/">鸟瞰</a> <a href="http://space.cnblogs.com/msg/send/%e9%b8%9f%e7%9e%b0" title="发送站内短消息" target="_blank"> </a></p>
<p>对外企的经营模式，如果想老板的朋友们，某些地方还是比较值得借鉴的</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u122874.jpg?id=16080143" target="_blank">http://pic.cnitblog.com/face/u122874.jpg?id=16080143</a></p>
<p><a href="">/#11楼</a><a href=""></a>  2010-05-05 15:13  <a href="http://www.cnblogs.com/facingwaller/">撞破南墙</a> <a href="http://space.cnblogs.com/msg/send/%e6%92%9e%e7%a0%b4%e5%8d%97%e5%a2%99" title="发送站内短消息" target="_blank"> </a></p>
<p>看了觉得果然很中国化，不知道GG也是这样的吗？</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u69696.jpg?id=16133304" target="_blank">http://pic.cnitblog.com/face/u69696.jpg?id=16133304</a></p>
<p><a href="">/#12楼</a><a href=""></a>  2010-05-05 15:46  <a href="http://www.cnblogs.com/ArthasCui/">Arthas-Cui</a> <a href="http://space.cnblogs.com/msg/send/Arthas-Cui" title="发送站内短消息" target="_blank"> </a></p>
<p>你知道的太多了。。。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u37616.jpg?id=29112918" target="_blank">http://pic.cnitblog.com/face/u37616.jpg?id=29112918</a></p>
<p><a href="">/#13楼</a><a href=""></a>  2010-05-05 16:11  <a href="http://www.cnblogs.com/daxianren/">卡通一下</a> <a href="http://space.cnblogs.com/msg/send/%e5%8d%a1%e9%80%9a%e4%b8%80%e4%b8%8b" title="发送站内短消息" target="_blank"> </a></p>
<p>大家可能不太清楚，在美国顶头上司才是你真正的老板。他要开你走，董事会是不会举行表决的，哈哈！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#14楼</a><a href=""></a>  2010-05-05 16:15  <a href="http://www.cnblogs.com/daxianren/">卡通一下</a> <a href="http://space.cnblogs.com/msg/send/%e5%8d%a1%e9%80%9a%e4%b8%80%e4%b8%8b" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主文章的题目，<strong>“外企那点儿事”；“也就那么回事”</strong>，可以看出楼主当前的心态！
就好象世上有人说的，一不小心发财了！一不小心成功了......
呵呵！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#15楼</a><a href=""></a>[楼主]  2010-05-05 18:36  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>卡通一下
外企那点儿事是学了当前的流行语，明朝那点儿事，Java那点儿事...
及历史是什么玩意儿等，吸引人注意的一个噱头而已。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#16楼</a><a href=""></a>  2010-05-05 19:20  <a href="http://www.cnblogs.com/daxianren/">卡通一下</a> <a href="http://space.cnblogs.com/msg/send/%e5%8d%a1%e9%80%9a%e4%b8%80%e4%b8%8b" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看引用原文&quot;">引用</a>觉先：
@卡通一下
外企那点儿事是学了当前的流行语，明朝那点儿事，Java那点儿事...
及历史是什么玩意儿等，吸引人注意的一个噱头而已。
朋友间聊天我们也经常地说，只是在正式场合是不说的，呵呵！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#17楼</a><a href=""></a>  2010-05-09 21:17  <a href="http://www.cnblogs.com/dytes/">dytes</a> <a href="http://space.cnblogs.com/msg/send/dytes" title="发送站内短消息" target="_blank"> </a></p>
<p>不要一概而论，就我的经历而言，还是相当宽松的。-</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#18楼</a><a href=""></a>  2010-05-10 13:02  <a href="http://www.cnblogs.com/Koy/">Koy</a> <a href="http://space.cnblogs.com/msg/send/Koy" title="发送站内短消息" target="_blank"> </a></p>
<p>講得好好，頂一下。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#19楼</a><a href=""></a>  2010-05-10 22:53  <a href="http://home.cnblogs.com/u/127908/">小飞哥</a> <a href="http://space.cnblogs.com/msg/send/%e5%b0%8f%e9%a3%9e%e5%93%a5" title="发送站内短消息" target="_blank"> </a></p>
<p>哈哈楼主你知道得太多了</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#20楼</a><a href=""></a>  2010-05-13 10:56  <a href="http://www.cnblogs.com/KissKnife/">SnowToday</a> <a href="http://space.cnblogs.com/msg/send/SnowToday" title="发送站内短消息" target="_blank"> </a></p>
<p>基本上是这个样子，不过外企跟外企也不太一样，部门跟部门不太一样，项目跟项目不太一样，比如请假放假，我们这请假绝大多数不会有问题，请假就请了，不会有那么多顾虑，还有老外的一些重要节日我们也会跟着放比如圣诞、复活节。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u10907.jpg" target="_blank">http://pic.cnitblog.com/face/u10907.jpg</a></p>
<p><a href="">/#21楼</a><a href=""></a>  2010-05-13 11:11  <a href="http://home.cnblogs.com/u/132808/">足球王子</a> <a href="http://space.cnblogs.com/msg/send/%e8%b6%b3%e7%90%83%e7%8e%8b%e5%ad%90" title="发送站内短消息" target="_blank"> </a></p>
<p>在外企参与项目的机会会少很多，但是没有进过外企，就好像没怎么见过世面一样。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#22楼</a><a href=""></a>  2010-05-13 15:46  <a href="http://www.cnblogs.com/Abbott/">Abbott zhao</a> <a href="http://space.cnblogs.com/msg/send/Abbott+zhao" title="发送站内短消息" target="_blank"> </a></p>
<p>这也是为什么小公司半年作出来的东西，大公司要做几年。当然大公司这样做自然有它的道理，大公司稳定，不愁客户资源，不差钱，今年做出来或是明年做出来，客户别无选择，员工也养得起。这些小公司都做不到，必须尽快的满足客户的需要，必须在钱花完之前拉到下一个项目。
这句话有点偏。小公司做的产品真的不能恭维。</p>
<p><a href="">支持(1)</a><a href="">反对(0)</a></p>
<p><a href="">/#23楼</a><a href=""></a>  2010-05-13 21:28  <a href="http://www.cnblogs.com/417533880/">Forrest Liu</a> <a href="http://space.cnblogs.com/msg/send/Forrest+Liu" title="发送站内短消息" target="_blank"> </a></p>
<p>我也在一家小外企工作，最近遇到点事很郁闷。前两天女朋友来公司附近办事，我就带她在公司里待会，等着和我一起吃午饭。。结果她待了没有十分钟，公司老板从我身边过就看到她了，过了一会我的team leader就用communicater跟我说，让她出去，我就带她出去了。。回来后我的leader跟我说老板看到我女朋友了，很生气。因为我之前的公司很随便，以前也带朋友同学什么的进去过。当时也就觉得没什么。今天早上leader又跟我谈话，说客户那边反应对我的工作不满意。我当时很奇怪，因为我跟我的客户一直保持沟通，而且分配给我的task我也都完成的很不错。前一个月的时候我还特意问过客户对我的工作有什么意见，我在哪方面可以做的更好，结果客户给我回复说对我的工作很满意。我不知道是因为我得罪了谁或者我做错了什么。。现在很困惑，前辈给我指点一下吧~~</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u39386.jpg" target="_blank">http://pic.cnitblog.com/face/u39386.jpg</a></p>
<p><a href="">/#24楼</a><a href=""></a>  2010-05-14 18:32  <a href="http://www.cnblogs.com/cjc1021/">开心每一天ㄨ</a> <a href="http://space.cnblogs.com/msg/send/%e5%bc%80%e5%bf%83%e6%af%8f%e4%b8%80%e5%a4%a9%e3%84%a8" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>Forrest Liu
感觉比较没有人情味就是。做事都是规规矩矩的。
如果你在民企或者是小企，哪怕是国企可能都不一定。外企业也是不一样，但你目前所处的就是挺没人情味的感觉~</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u25669.jpg" target="_blank">http://pic.cnitblog.com/face/u25669.jpg</a></p>
<p><a href="">/#25楼</a><a href=""></a>  2010-05-14 23:16  <a href="http://www.cnblogs.com/qingteng1983/">无待</a> <a href="http://space.cnblogs.com/msg/send/%e6%97%a0%e5%be%85" title="发送站内短消息" target="_blank"> </a></p>
<p>有意思，受教了。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u131056.jpg?id=02141056" target="_blank">http://pic.cnitblog.com/face/u131056.jpg?id=02141056</a></p>
<p><a href="">/#26楼</a><a href=""></a>18306582010/5/22 21:08:21  2010-05-22 21:08  <a href="http://home.cnblogs.com/u/134973/">fyljf</a> <a href="http://space.cnblogs.com/msg/send/fyljf" title="发送站内短消息" target="_blank"> </a></p>
<p>有些点真是深有体会</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">刷新评论</a><a href="">刷新页面</a><a href="">返回顶部</a></p>
<p>注册用户登录后才能发表评论，请 <a href="">登录</a> 或 <a href="">注册</a>，<a href="http://www.cnblogs.com/" target="_blank">访问</a>网站首页。
<a href="http://www.cnblogs.com/" title="程序员的网上家园" target="_blank">博客园首页</a><a href="http://q.cnblogs.com/" title="程序员问答社区" target="_blank">博问</a><a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">新闻</a><a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a><a href="http://job.cnblogs.com/" target="_blank">程序员招聘</a><a href="http://kb.cnblogs.com/" target="_blank">知识库</a></p>
<p><strong>最新IT新闻</strong>:
· <a href="http://news.cnblogs.com/n/182486/" target="_blank">新硬硬整合时代</a>
· <a href="http://news.cnblogs.com/n/182485/" target="_blank">狗血的百度91并购案啊 阿里和周鸿祎都曾掺和</a>
· <a href="http://news.cnblogs.com/n/182483/" target="_blank">如何让搜索引擎抓取AJAX内容？</a>
· <a href="http://news.cnblogs.com/n/182482/" target="_blank">避免代码注释的五大理由</a>
· <a href="http://news.cnblogs.com/n/182481/" target="_blank">OpenWrt——适用于路由器的Linux系统</a>
» <a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">更多新闻...</a></p>
<p><strong>最新知识库文章</strong>:
· <a href="http://kb.cnblogs.com/page/141892/" target="_blank">阿里巴巴集团去IOE运动的思考与总结</a>
· <a href="http://kb.cnblogs.com/page/182265/" target="_blank">硅谷归来7点分享：创业者，做你自己</a>
· <a href="http://kb.cnblogs.com/page/182200/" target="_blank">我为什么不能坚持？</a>
· <a href="http://kb.cnblogs.com/page/168725/" target="_blank">成为高效程序员的7个重要习惯</a>
· <a href="http://kb.cnblogs.com/page/182047/" target="_blank">谈谈对BPM的理解</a>
» <a href="http://kb.cnblogs.com/" target="_blank">更多知识库文章...</a>
Powered by:
<a href="http://www.cnblogs.com/" target="_blank">博客园</a>
Copyright © 觉先</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/zhiya/">zhiya</a></li></span><span class="breadcrumb"><li><a href="/categories/职涯/">职涯</a></li><li><a href="/categories/职涯/IT外企/">IT外企</a></li></span></span> | <span class="tags">Tagged <a href="/tags/IT外企/" class="label label-primary">IT外企</a><a href="/tags/zhiya/" class="label label-success">zhiya</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事1：外企也就那么回事/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-zhiya-IT外企--IT外企那点儿事1：外企也就那么回事" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/">CentOS的Hadoop集群配置</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="centos-hadoop-">CentOS的Hadoop集群配置</h1>
<h3 id="-centos-hadoop-http-blog-csdn-net-inte_sleeper-article-details-6569985-"><a href="http://blog.csdn.net/inte_sleeper/article/details/6569985" target="_blank">CentOS的Hadoop集群配置（一）</a></h3>
<h3 id="-"> </h3>
<p>参考资料：</p>
<p><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/" target="_blank"><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/">http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/</a></a></p>
<p><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/" target="_blank"><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/">http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/</a></a></p>
<p><a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/" target="_blank"><a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/">http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/</a></a></p>
<p><a href="http://hadoop.apache.org/common/docs/current/cluster_setup.html" target="_blank"><a href="http://hadoop.apache.org/common/docs/current/cluster_setup.html">http://hadoop.apache.org/common/docs/current/cluster_setup.html</a></a></p>
<p>以下集群配置内容，以两台机器为例。其中一台是 master ，另一台是 slave1 。</p>
<p>master 上运行 name node, data node, task tracker, job tracker ， secondary name node ；</p>
<p>slave1 上运行 data node, task tracker 。</p>
<p>前面加 /* 表示对两台机器采取相同的操作</p>
<ol>
<li>安装 JDK /*</li>
</ol>
<p>yum install java-1.6.0-openjdk-devel</p>
<ol>
<li>设置环境变量 /*</li>
</ol>
<p>编辑 /etc/profile 文件，设置 JAVA_HOME 环境变量以及类路径：</p>
<p>export JAVA_HOME=&quot;/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64&quot;</p>
<p>export PATH=$PATH:$JAVA_HOME/bin</p>
<p>export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar</p>
<ol>
<li>添加 hosts 的映射 /*</li>
</ol>
<p>编辑 /etc/hosts 文件，<strong>注意</strong> <strong>host name **</strong>不要有下划线，见下步骤 9**</p>
<p>192.168.225.16 master</p>
<p>192.168.225.66 slave1</p>
<ol>
<li>配置 SSH /*</li>
</ol>
<p>cd /root &amp; mkdir .ssh</p>
<p>chmod 700 .ssh &amp; cd .ssh</p>
<p>创建密码为空的 RSA 密钥对：</p>
<p>ssh-keygen -t rsa -P &quot;&quot;</p>
<p>在提示的对称密钥名称中输入 id_rsa</p>
<p>将公钥添加至 authorized_keys 中：</p>
<p>cat id_rsa.pub &gt;&gt; authorized_keys</p>
<p>chmod 644 authorized_keys <strong>/#</strong> <strong>重要</strong></p>
<p>编辑 sshd 配置文件 /etc/ssh/sshd_config ，把 /#AuthorizedKeysFile  .ssh/authorized_keys 前面的注释取消掉。</p>
<p>重启 sshd 服务：</p>
<p>service sshd restart</p>
<p>测试 SSH 连接。连接时会提示是否连接，按回车后会将此公钥加入至 knows_hosts 中：</p>
<p>ssh localhost</p>
<ol>
<li>配置 master 和 slave1 的 ssh 互通</li>
</ol>
<p>在 slave1 中重复步骤 4 ，然后把 slave1 中的 .ssh/authorized_keys 复制至 master 的 .ssh/authorized_keys中。注意复制过去之后，要看最后的类似 root@localhost 的字符串，修改成 root@slave1 。同样将 master的 key 也复制至 slave1 ，并将最后的串修改成 root@master 。</p>
<p>或者使用如下命令：</p>
<p>ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave1</p>
<p>测试 SSH 连接：</p>
<p>在 master 上运行：</p>
<p>ssh slave1</p>
<p>在 slave1 上运行：</p>
<p>ssh master</p>
<ol>
<li>安装 Hadoop</li>
</ol>
<p>下载 hadoop 安装包：</p>
<p>wget <a href="http://mirror.bjtu.edu.cn/apache/hadoop/common/hadoop-0.20.203.0/hadoop-0.20.203.0rc1.tar.gz" target="_blank"><a href="http://mirror.bjtu.edu.cn/apache/hadoop/common/hadoop-0.20.203.0/hadoop-0.20.203.0rc1.tar.gz">http://mirror.bjtu.edu.cn/apache/hadoop/common/hadoop-0.20.203.0/hadoop-0.20.203.0rc1.tar.gz</a></a></p>
<p>复制安装包至 slave1 ：</p>
<p>scp hadoop-0.20.203.0rc1.tar.gz root@slave1:/root/</p>
<p>解压：</p>
<p>tar xzvf hadoop-0.20.203.0rc1.tar.gz</p>
<p>mkdir /usr/local/hadoop</p>
<p>mv hadoop-0.20.203.0//* /usr/local/hadoop</p>
<pre><code>     修改 .bashrc 文件（位于用户目录下，即 ~/.bashrc ，对于 root ，即为 /root/.bashrc ）

     添加环境变量：

     export HADOOP_HOME=/usr/local/hadoop

export PATH=$PATH:$HADOOP_HOME/bin
</code></pre><ol>
<li>配置 Hadoop 环境变量 /*</li>
</ol>
<p><strong>以下所有 hadoop **</strong>目录下的文件，均以相对路径 hadoop <strong>**开始</strong></p>
<p>修改 hadoop/conf/hadoop-env.sh 文件，将里面的 JAVA_HOME 改成步骤 2 中设置的值。</p>
<ol>
<li>创建 Hadoop 本地临时文件夹 /*</li>
</ol>
<p>mkdir /root/hadoop_tmp （<strong>注意这一步，千万不要放在</strong> <strong>/tmp **</strong>目录下面！！因为 <strong><strong>/tmp </strong></strong>默认分配的空间是很小的，往 <strong><strong>hdfs </strong></strong>里放几个大文件就会导致空间满了，就会报错）**</p>
<p>修改权限：</p>
<p>chown -R hadoop:hadoop /root/hadoop_tmp</p>
<p>更松地，也可以这样：</p>
<p>chmod –R 777 /root/hadoop_tmp</p>
<ol>
<li>配置 Hadoop</li>
</ol>
<p>修改 master 的 hadoop/conf/core-site.xml ，在 <configuration> 节中添加如下内容：</p>
<p>注意： <strong>fs.default.name **</strong>的值不能带下划线**</p>
<property>

    <name>hadoop.tmp.dir</name>

    <value>/root/hadoop<em>tmp/hadoop</em>${user.name}</value>

</property>

<property>

    <name>fs.default.name</name>

    <value>hdfs://localhost:54310</value> 

</property>

<property>

    <name>io.sort.mb</name>

    <value>1024</value> 

</property>

<pre><code>     其中 io.sort.mb 值，指定了排序使用的内存，大的内存可以加快 job 的处理速度。



     修改 hadoop/conf/mapred-site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>mapred.job.tracker</name>

    <value>localhost:54311</value>

</property>

<property>

    <name>mapred.map.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<property>

    <name>mapred.reduce.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<pre><code>     其中 mapred.map.child.java.opts, mapred.reduce.child.java.opts 分别指定 map/reduce 任务使用的最大堆内存。较小的内存可能导致程序抛出 OutOfMemoryException 。
</code></pre><p>修改 conf/hdfs -site.xml ，在 <configuration> 节中添加如下内容：</p>
<property>

    <name>dfs.replication</name>

    <value>2</value>

</property>



<p>同样，修改 slave1 的 /usr/local/hadoop/conf/core-site.xml ，在 <configuration> 节中添加如下内容：</p>
<property>

    <name>hadoop.tmp.dir</name>

    <value>/root/hadoop<em>tmp/hadoop</em>${user.name}</value>

</property>

<property>

    <name>fs.default.name</name>

    <value>hdfs://localhost:54310</value> 

</property>

<property>

    <name>io.sort.mb</name>

    <value>1024</value> 

</property>



<pre><code>     修改 conf/mapred-site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>mapred.job.tracker</name>

    <value>localhost:54311</value>

</property>

<property>

    <name>mapred.map.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<property>

    <name>mapred.reduce.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>



<pre><code>     修改 conf/hdfs -site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>dfs.replication</name>

    <value>2</value>

    </property>



<ol>
<li>修改 hadoop/bin/hadoop 文件</li>
</ol>
<p>把 221 行修改成如下。因为对于 root 用户， -jvm 参数是有问题的，所以需要加一个判断 ( 或者以非 root 用户运行这个脚本也没问题 )</p>
<p>HADOOP_OPTS=&quot;$HADOOP_OPTS -jvm server $HADOOP_DATANODE_OPTS&quot;  à</p>
<pre><code>/#for root, -jvm option is invalid.

CUR_USER=`whoami`

if [ &quot;$CUR_USER&quot; = &quot;root&quot; ]; then

    HADOOP_OPTS=&quot;$HADOOP_OPTS -server $HADOOP_DATANODE_OPTS&quot;

else

    HADOOP_OPTS=&quot;$HADOOP_OPTS -jvm server $HADOOP_DATANODE_OPTS&quot;

fi 
</code></pre><p>unset $CUR_USER</p>
<p>至此， master 和 slave1 都已经完成了 single_node 的搭建，可以分别在两台机器上测试单节点。</p>
<p>启动节点：</p>
<p>hadoop/bin/start-all.sh</p>
<p>运行 jps 命令，应能看到类似如下的输出：</p>
<p>937 DataNode</p>
<p>9232 Jps</p>
<p>8811 NameNode</p>
<p>12033 JobTracker</p>
<p>12041 TaskTracker
来源： <a href="[http://blog.csdn.net/inte_sleeper/article/details/6569985](http://blog.csdn.net/inte_sleeper/article/details/6569985)">[http://blog.csdn.net/inte_sleeper/article/details/6569985](http://blog.csdn.net/inte_sleeper/article/details/6569985)</a> </p>
<p><a href="http://blog.csdn.net/inte_sleeper/article/details/6569990" target="_blank">CentOS的Hadoop集群配置（二）</a>
下面的教程把它们合并至 multi-node cluster 。</p>
<ol>
<li>合并 single-node 至 multi-node cluster</li>
</ol>
<p>修改 master 的 hadoop/conf/core-site.xml ：</p>
<property>

    <name>hadoop.tmp.dir</name>

    <value>/root/hadoop<em>tmp/hadoop</em>${user.name}</value>

</property>

<property>

    <name>fs.default.name</name>

    <value>hdfs://<strong>master</strong> :54310</value>

</property>

<property>

    <name>io.sort.mb</name>

    <value>1024</value> 

</property>



<pre><code>     修改 conf/mapred-site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>mapred.job.tracker</name>

    <value><strong>master</strong> :54311</value>

</property>

<property>

    <name>mapred.map.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<property>

    <name>mapred.reduce.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<pre><code>     修改 conf/hdfs -site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>dfs.replication</name>

    <value>2</value>

</property>

<p>把这三个文件复制至 slave1 相应的目录 hadoop/conf 中 <strong>( **</strong>即 master <strong><strong>和 slave1 </strong></strong>的内容完全一致 )**</p>
<pre><code>     修改所有节点的 hadoop/conf/masters ，把文件内容改成： master

     修改所有节点的 hadoop/conf/slaves ，把文件内容改成：
</code></pre><p>master</p>
<pre><code>slave1



     分别删除 master 和 slave1 的 dfs/data 文件：

     rm –rf /root/hadoop_tmp/hadoop_root/dfs/data
</code></pre><p>重新格式化 namenode ：</p>
<pre><code>     hadoop/bin/hadoop namenode -format



     测试，在 master 上运行：

     hadoop/bin/start-all.sh

     在 master 上运行 jps 命令
</code></pre><p>此时输出应类似于：</p>
<pre><code>     11648 TaskTracker
</code></pre><p>11166 NameNode</p>
<p>11433 SecondaryNameNode</p>
<p>12552 Jps</p>
<p>11282 DataNode</p>
<p>11525 JobTracker</p>
<p>在 slave1 上运行 jps</p>
<p>此时输出应包含 ( 即至少有 DataNode, 否则即为出错 ) ：</p>
<p>3950 Jps</p>
<p>3121 TaskTracker</p>
<p>3044 DataNode</p>
<ol>
<li>测试一个 JOB</li>
</ol>
<p>首先升级 python( 可选，如果 JOB 是 python 写的 ) ：</p>
<p>cd /etc/yum.repos.d/</p>
<p>wget <a href="http://mirrors.geekymedia.com/centos/geekymedia.repo" target="_blank">http://mirrors.geekymedia.com/centos/geekymedia.repo</a></p>
<p>yum makecache</p>
<p>yum -y install python26</p>
<p><strong>升级 python **</strong>的教程，见另外一篇文档。如果已经通过以上方法安装了 python2.6 <strong>**，那需要先卸载：</strong></p>
<p>yum remove python26 python26-devel</p>
<pre><code>     CentOS 的 yum 依赖于 python2.4 ，而 /usr/bin 中 python 程序即为 python2.4 。我们需要把它修改成python2.6 。



     cd /usr/bin/

     编辑 yum 文件，把第一行的
</code></pre><p>/#!/usr/bin/python   à   /#!/usr/bin/python2.4  </p>
<p>保存文件。</p>
<pre><code>     删除旧版本的 python 可执行文件（这个文件跟该目录下 python2.4 其实是一样的，所以可以直接删除）

     rm -f python

     让 python 指向 python2.6 的可执行程序。

     ln -s python26 python  
</code></pre><ol>
<li>Word count python 版本</li>
</ol>
<p><strong>Map.py</strong></p>
<p>/#! /usr/bin/python</p>
<p>import sys;</p>
<p>for line in sys.stdin:</p>
<p>  line =  line.strip();</p>
<p>  words = line.split();</p>
<p>  for word in words:</p>
<pre><code>  print &#39;%s/t%s&#39; % (word,1);
</code></pre><p><strong>Reduce.py</strong></p>
<p>/#!/usr/bin/python</p>
<p>import sys;</p>
<p>wc = {};</p>
<p>for line in sys.stdin:</p>
<p>  line = line.strip();</p>
<p>  word,count = line.split(&#39;/t&#39;,1);</p>
<p>  try:</p>
<pre><code>  count = int(count);
</code></pre><p>  except Error:</p>
<pre><code>  pass;
</code></pre><p>  if wc.has_key(word):</p>
<pre><code>  wc[word] += count;
</code></pre><p>  else: wc[word] = count;</p>
<p>for key in wc.keys():</p>
<p>  print &#39;%s/t%s&#39; % (key, wc[key]);</p>
<p>本机测试：</p>
<p>echo &quot;foo foo bar bar foo abc&quot; | map.py</p>
<p>echo &quot;foo foo bar bar foo abc&quot; | map.py | sort | reduce.py</p>
<p>在 hadoop 中测试：</p>
<p>hadoop jar /usr/local/hadoop/contrib/streaming/hadoop-streaming-0.20.203.0.jar -file mapper.py -mapper mapper.py -file reducer.py -reducer reducer.py -input wc//* -output wc-out</p>
<p>Job 成功后，会在 HDFS 中生成 wc-out 目录。</p>
<p>查看结果：</p>
<p>hadoop fs –ls wc-out</p>
<p>hadoop fs –cat wc-out/part-00000</p>
<ol>
<li>集群增加新节点</li>
</ol>
<p>a.       执行步骤 1 ， 2.</p>
<p>b.       修改 hosts 文件，将集群中的 hosts 加入本身 /etc/hosts 中。并修改集群中其他节点的 hosts ，将新节点加入。</p>
<p>c.       master 的 conf/slaves 文件中，添加新节点。</p>
<p>d.       启动 datanode 和 task tracker 。</p>
<p>hadoop-daemon.sh start datanode</p>
<p>hadoop-daemon.sh start tasktracker</p>
<ol>
<li>Trouble-shooting</li>
</ol>
<p>hadoop 的日志在 hadoop/logs 中。</p>
<p>其中， logs 根目录包含的是 namenode, datanode, jobtracker, tasktracker 等的日志。分别以 hadoop-{username}-namenode/datanode/jobtracker/tasktracker-hostname.log 命名。</p>
<p>userlogs 目录里包含了具体的 job 日志，每个 job 有一个单独的目录，以 job<em>YYYYmmddHHmm_xxxx 命名。里面包含数个 attempt</em>{jobname}<em>m_xxxxx 或 attempt</em>{jobname}_r_xxxx 等数个目录。其中目录名中的m 表示 map 任务的日志， r 表示 reduce 任务的日志。因此，出错时，可以有针对性地查看特定的日志。</p>
<p>常见错误：</p>
<ol>
<li>出现类似：</li>
</ol>
<p><em>ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Incompatible namespaceIDs …</em></p>
<p>的异常，是因为先格式化了 namenode ，后来又修改了配置导致。将 dfs/data 文件夹内容删除，再重新格式化 namenode 即可。</p>
<ol>
<li>出现类似：</li>
</ol>
<p><em>INFO org.apache.hadoop.ipc.Client: Retrying connect to server:…</em></p>
<p>的异常，首先确认 name node 是否启动。如果已经启动，有可能是 master 或 slave1 中的配置出错，集群配置参考步骤 11 。也有可能是防火墙问题，需添加以下例外：</p>
<p>50010 端口用于数据传输， 50020 用于 RPC 调用， 50030 是 WEB 版的 JOB 状态监控， 54311 是job tracker ， 54310 是与 master 通信的端口。</p>
<p>完整的端口列表见：</p>
<p><a href="http://www.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/" target="_blank"><a href="http://www.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/">http://www.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/</a></a></p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 50010 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 50020 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 50030 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 50060 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 54310 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 54311 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 50010 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 50020 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 50010 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 50020 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 50030 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 50030 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 50060 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 50060 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 54310 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 54310 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 54311 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 54311 -j ACCEPT</p>
<p>保存规则：</p>
<p>/etc/init.d/iptables save</p>
<p>重启 iptables 服务：</p>
<p>service iptables restart</p>
<p>如果还是出现问题 2 的错误，那可能需要手工修改 /etc/sysconfig/iptables 的规则。手动添加这些规则。若有 ”reject-with icmp-host-prohibited” 的规则，需将规则加到它的前面。注意修改配置文件的时候，不需要带 iptables 命令。直接为类似于：</p>
<p>-A OUTPUT -p tcp -m tcp --sport 54311 -j ACCEPT</p>
<p>或关闭防火墙 <strong>( **</strong>建议，因为端口太多，要加的例外很多 )**</p>
<p>service iptables stop</p>
<ol>
<li><p>在 /etc/hosts 文件中，确保一个 host 只对应一个 IP ，否则会出错（如同时将 slave1 指向 127.0.0.1 和192.168.225.66 ），<strong>可能导致数据无法从一个节点复制至另一节点。</strong></p>
</li>
<li><p>出现类似：</p>
</li>
</ol>
<p><em>FATAL org.apache.hadoop.mapred.TaskTracker: Error running child : java.lang.OutOfMemoryError: Java heap space…</em></p>
<p>的异常，是因为堆内存不够。有以下几个地方可以考虑配置：</p>
<p>a.       conf/hadoop-env.sh 中， export HADOOP_HEAPSIZE=1000 这一行，默认为注释掉，堆大小为1000M ，可以取消注释，将这个值调大一些（对于 16G 的内存，可以调至 8G ）。</p>
<p>b.       conf/mapred-site.xml 中，添加 mapred.map.child.java.opts 属性，手动指定 JAVA 堆的参数值为 -Xmx2048m 或更大。这个值调整 map 任务的堆大小。即：</p>
<property>

    <name>mapred.map.child.java.opts </name>

    <value>-Xmx2048m</value>

</property>

<p>c.       conf/mapred-site.xml 中，添加 mapred.reduce.child.java.opts 属性，手动指定 JAVA 堆的参数值为 -Xmx2048m 或更大。这个值调整 reduce 任务的堆大小。即：</p>
<property>

    <name>mapred.reduce.child.java.opts </name>

    <value>-Xmx2048m</value>

</property>

<pre><code>               注意调整这些值之后，要重启 name node 。
</code></pre><p><em>5.       </em>出现类似： <em>java.io.IOException: File /user/root/pv_product_110124 could only be replicated to 0 nodes, instead of 1…</em></p>
<p>的异常，首先确保 hadoop 临时文件夹中有足够的空间，空间不够会导致这个错误。</p>
<p>如果空间没问题，那就尝试把临时文件夹中 dfs/data 目录删除，然后重新格式化 name node ：</p>
<p>hadoop namenode -format</p>
<p>注意：此命令会删除 hdfs 上的文件</p>
<p><em>6.       </em>出现类似： <em>java.io.IOException: Broken pipe…</em></p>
<p>的异常，检查你的程序吧，没准输出了不该输出的信息，如调试信息等。
来源： <a href="[http://blog.csdn.net/inte_sleeper/article/details/6569990](http://blog.csdn.net/inte_sleeper/article/details/6569990)">[http://blog.csdn.net/inte_sleeper/article/details/6569990](http://blog.csdn.net/inte_sleeper/article/details/6569990)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--CentOS的Hadoop集群配置" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--HDFS写入和读取流程/">HDFS写入和读取流程</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--HDFS写入和读取流程/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hdfs-">HDFS写入和读取流程</h1>
<p>您还未登录！|<a href="https://passport.csdn.net/account/login" target="_blank">登录</a>|<a href="https://passport.csdn.net/account/register" target="_blank">注册</a>|<a href="https://passport.csdn.net/help/faq" target="_blank">帮助</a></p>
<ul>
<li><a href="http://www.csdn.net/" target="_blank">首页</a></li>
<li><a href="http://news.csdn.net/" target="_blank">业界</a></li>
<li><a href="http://mobile.csdn.net/" target="_blank">移动</a></li>
<li><a href="http://cloud.csdn.net/" target="_blank">云计算</a></li>
<li><a href="http://sd.csdn.net/" target="_blank">研发</a></li>
<li><a href="http://bbs.csdn.net/" target="_blank">论坛</a></li>
<li><a href="http://blog.csdn.net/" target="_blank">博客</a></li>
<li><a href="http://download.csdn.net/" target="_blank">下载</a></li>
<li><h2 id="-"><a href="">更多</a></h2>
</li>
</ul>
<h1 id="-guisu-http-blog-csdn-net-hguisu-"><a href="http://blog.csdn.net/hguisu" target="_blank">guisu，程序人生。</a></h1>
<h2 id="-a-clever-person-solves-a-problem-a-wise-person-avoids-it-">能干的人解决问题。智慧的人绕开问题(A clever person solves a problem. A wise person avoids it)</h2>
<ul>
<li><a href="http://blog.csdn.net/hguisu?viewmode=contents" target="_blank"><img src="" alt="">目录视图</a></li>
<li><a href="http://blog.csdn.net/hguisu?viewmode=list" target="_blank"><img src="" alt="">摘要视图</a></li>
<li><a href="http://blog.csdn.net/hguisu/rss/list" target="_blank"><img src="" alt="">订阅</a>
<a href="http://blog.csdn.net/blogdevteam/article/details/11889881" target="_blank">2014年1月微软MVP申请开始啦！</a>      <a href="http://bbs.csdn.net/topics/390594487" target="_blank">CSDN社区中秋晒福利活动正式开始啦！</a>        <a href="http://www.csdn.net/article/2013-09-17/2816962" target="_blank">专访钟声：Java程序员，上班那点事儿</a>      <a href="http://blog.csdn.net/adali/article/details/9813651" target="_blank">独一无二的职位：开源社区经理</a>      <a href="http://blog.csdn.net/blogdevteam/article/details/11975399" target="_blank">“说说家乡的互联网”主题有奖征文</a></li>
</ul>
<h3 id="-hdfs-"><a href="">HDFS写入和读取流程</a></h3>
<p>分类： <a href="http://blog.csdn.net/hguisu/article/category/1072794" target="_blank">云计算hadoop</a>  2012-02-14 23:50 8282人阅读 <a href="">评论</a>(17) <a href="&quot;收藏&quot;">收藏</a> <a href="&quot;举报&quot;">举报</a>
<a href="http://blog.csdn.net/tag/details.html?tag=%e5%ad%98%e5%82%a8" target="_blank">存储</a><a href="http://blog.csdn.net/tag/details.html?tag=hadoop" target="_blank">hadoop</a><a href="http://blog.csdn.net/tag/details.html?tag=image" target="_blank">image</a><a href="http://blog.csdn.net/tag/details.html?tag=system" target="_blank">system</a><a href="http://blog.csdn.net/tag/details.html?tag=mysql" target="_blank">mysql</a></p>
<p>目录<a href="&quot;系统根据文章中H1到H6标签自动生成文章目录&quot;">(?)</a><a href="&quot;展开&quot;">[+]</a></p>
<ol>
<li><a href="">一HDFS</a></li>
<li><a href="">二HDFS的体系结构</a></li>
<li><p><a href="">三读写流程</a></p>
</li>
<li><p><a href="">GFS论文提到的文件读取简单流程</a></p>
</li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href="">详细流程</a></li>
<li><a href=""></a></li>
<li><p><a href="">GFS论文提到的写入文件简单流程</a></p>
</li>
<li><p><a href="">详细流程</a></p>
</li>
<li><a href=""></a><h2 id="-hdfs"><a href=""></a>一、HDFS</h2>
</li>
</ol>
<p>HDFS全称是Hadoop Distributed System。HDFS是为以流的方式存取大文件而设计的。适用于几百MB，GB以及TB，并写一次读多次的场合。而对于低延时数据访问、大量小文件、同时写和任意的文件修改，则并不是十分适合。</p>
<p>目前HDFS支持的使用接口除了Java的还有，Thrift、C、FUSE、WebDAV、HTTP等。HDFS是以block-sized chunk组织其文件内容的，默认的block大小为64MB，对于不足64MB的文件，其会占用一个block，但实际上不用占用实际硬盘上的64MB，这可以说是HDFS是在文件系统之上架设的一个中间层。之所以将默认的block大小设置为64MB这么大，是因为block-sized对于文件定位很有帮助，同时大文件更使传输的时间远大于文件寻找的时间，这样可以最大化地减少文件定位的时间在整个文件获取总时间中的比例 。</p>
<h2 id="-hdfs-"><a href=""></a>二、HDFS的体系结构</h2>
<p>构成HDFS主要是Namenode（master）和一系列的Datanode（workers）。Namenode是管理HDFS的目录树和相关的文件元数据，这些信息是以&quot;namespace image&quot;和&quot;edit log&quot;两个文件形式存放在本地磁盘，但是这些文件是在HDFS每次重启的时候重新构造出来的。Datanode则是存取文件实际内容的节点，Datanodes会定时地将block的列表汇报给Namenode。</p>
<p>由于Namenode是元数据存放的节点，如果Namenode挂了那么HDFS就没法正常运行，因此一般使用将元数据持久存储在本地或远程的机器上，或者使用secondary namenode来定期同步Namenode的元数据信息，secondary namenode有点类似于MySQL的Master/Salves中的Slave，&quot;edit log&quot;就类似&quot;bin log&quot;。如果Namenode出现了故障，一般会将原Namenode中持久化的元数据拷贝到secondary namenode中，使secondary namenode作为新的Namenode运行起来。</p>
<pre><code>                        ![]()
</code></pre><h2 id="-"><a href=""></a>三、读写流程</h2>
<h3 id="-gfs-"><a href=""></a>GFS论文提到的文件读取简单流程：</h3>
<h3 id="-"><a href=""></a></h3>
<h3 id="-"><a href=""></a>                <img src="" alt=""></h3>
<h3 id="-"><a href=""></a><em>**</em></h3>
<h3 id="-reading-data-from-hdfs-http-blog-endlesscode-com-wp-content-uploads-2010-06-reading-data-from-hdfs-png-reading-data-from-hdfs-"><a href=""></a><strong>详细流程：</strong><img src="http://blog.endlesscode.com/wp-content/uploads/2010/06/reading-data-from-hdfs.png" alt="reading data from hdfs" title="reading data from hdfs"></h3>
<p>文件读取的过程如下：</p>
<ol>
<li>使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求；</li>
<li>Namenode会视情况返回文件的部分或者全部block列表，对于每个block，Namenode都会返回有该block拷贝的DataNode地址；</li>
<li>客户端开发库Client会选取离客户端最接近的DataNode来读取block；如果客户端本身就是DataNode,那么将从本地直接获取数据.</li>
<li>读取完当前block的数据后，关闭与当前的DataNode连接，并为读取下一个block寻找最佳的DataNode；</li>
<li>当读完列表的block后，且文件读取还没有结束，客户端开发库会继续向Namenode获取下一批的block列表。</li>
<li>读取完一个block都会进行checksum验证，如果读取datanode时出现错误，客户端会通知Namenode，然后再从下一个拥有该block拷贝的datanode继续读。</li>
</ol>
<h3 id="-"><a href=""></a></h3>
<h3 id="-gfs-"><a href=""></a>GFS论文提到的写入文件简单流程：</h3>
<pre><code>                                 ![]()             
</code></pre><h2 id="-writing-data-to-hdfs-http-blog-endlesscode-com-wp-content-uploads-2010-06-writing-data-to-hdfs-png-writing-data-to-hdfs-"><a href=""></a>详细流程：<img src="http://blog.endlesscode.com/wp-content/uploads/2010/06/writing-data-to-hdfs.png" alt="writing data to hdfs" title="writing data to hdfs"></h2>
<p>写入文件的过程比读取较为复杂：</p>
<ol>
<li>使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求；</li>
<li>Namenode会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件<strong>创建一个记录</strong>，否则会让客户端抛出异常；</li>
<li>当客户端开始写入文件的时候，开发库会将文件切分成多个packets，并在内部以数据队列&quot;data queue&quot;的形式管理这些packets，并向Namenode申请新的blocks，获取用来存储replicas的合适的datanodes列表，列表的大小根据在Namenode中对replication的设置而定。</li>
<li>开始以pipeline（管道）的形式将packet写入所有的replicas中。开发库把packet以流的方式写入第一个datanode，该datanode把该packet存储之后，再将其传递给在此pipeline中的下一个datanode，直到最后一个datanode，这种写数据的方式呈流水线的形式。</li>
<li>最后一个datanode成功存储之后会返回一个ack packet，在pipeline里传递至客户端，在客户端的开发库内部维护着&quot;ack queue&quot;，成功收到datanode返回的ack packet后会从&quot;ack queue&quot;移除相应的packet。</li>
<li>如果传输过程中，有某个datanode出现了故障，那么当前的pipeline会被关闭，出现故障的datanode会从当前的pipeline中移除，剩余的block会继续剩下的datanode中继续以pipeline的形式传输，同时Namenode会分配一个新的datanode，保持replicas设定的数量。</li>
</ol>
<h2 id="-"><a href=""></a></h2>
<p>分享到： <a href="&quot;分享到新浪微博&quot;"></a><a href="&quot;分享到腾讯微博&quot;"></a></p>
<ol>
<li>上一篇：<a href="http://blog.csdn.net/hguisu/article/details/7256833" target="_blank">Hadoop Hive sql语法详解</a></li>
<li>下一篇：<a href="http://blog.csdn.net/hguisu/article/details/7261145" target="_blank">Hadoop HDFS分布式文件系统设计要点与架构</a></li>
</ol>
<p>顶 3 踩 1
查看评论<a href=""></a></p>
<p>3楼 <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-04-09 11:25发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>在写数据的过程中，一个文件被分割成很多blocks，这些block是按顺序一个个操作的，还是并发的进行传输的？Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-04-09 12:45发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：写数据的是以流的方式传输，即管道的方式，一个一个block顺序传输。而不是像树形拓扑结构那样分散传输。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-04-17 18:03发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：您好，很感谢您回答我，但是我仍有点疑惑，hdfs中的文件大小区分为：chunk&lt;packet&lt;block,在每个packet的传输到多个DN（datanode）的过程中是以pipeline方式，但是当其中一个block在以这种方式传输时，其他的block是要等待还是并发的进行呢？谢谢！Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-04-20 16:23发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：管道方式，即是队列方式传输。只能一个block传完了，接着传下个block。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-04-30 18:18发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：你好！如果这样，那hdfs的并发写实如何体现的呢？Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-05-02 09:29发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：hdfs没有并发写入。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-05-03 23:39发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：这样的话，那hadoop是比较适合大数据的处理了，对于文件的写的速度并没有多大的提高了?Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-05-04 09:40发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：hadoop本来就是通往云服务的捷径，为处理超大数据集而准备。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-05-07 10:57发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：这样hadoop的主要优势是在map/reduce那一块，而其文件系统有什么样的优势呢（在文件的读写方面，和其他的文件系统）？Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-05-07 11:50发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：hdfs可以存储超大数据，而map/reduce要处理的数据存储在hdfs上，即MR分布式运算。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-05-09 22:35发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu： 那多个文件同时向hdfs写入是如何进行的呢？Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-05-09 00:39发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：恩，hdfs相对于其他的文件系统，除了更适合存储大数据以外，而且有很强的容错能力，但是对数据的读写等，没有并发性，只是采用了管道的方式，这可能是它的一个小缺点吧。2楼 <a href="http://blog.csdn.net/CD_xiaoxin" target="_blank">CD_xiaoxin</a> 2012-03-19 09:44发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/CD_xiaoxin" target="_blank"><img src="" alt=""></a>很详细 很有帮助 谢谢1楼 <a href="http://blog.csdn.net/lin_FS" target="_blank">lin_FS</a> 2012-03-16 10:01发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/lin_FS" target="_blank"><img src="" alt=""></a>client端的那个queue是在内存中，还是写在临时文件里了？Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-03-19 09:43发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复lin_FS：client分割数据成一个个block（packet）这些数据都不在内存中，你可以想象，如果一个数据是100G，它你那个放进内存吗？Re: <a href="http://blog.csdn.net/lin_FS" target="_blank">lin_FS</a> 2012-03-21 17:26发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/lin_FS" target="_blank"><img src="" alt=""></a>在client端， 多个block（packet）组成一个队列，然后可以想象把文件（100G）分成若干个packet，如果队列满了就根本写不进去数据了，根本不会出现你想象的那种情况。我想了解的是，这个队列在内存中还是以文件的形式，呵呵Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-03-31 18:47发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复lin_FS：这个队列肯定是文件的形式存在的。
您还没有登录,请<a href="">[登录]</a>或<a href="http://passport.csdn.net/account/register?from=http%3A%2F%2Fblog.csdn.net%2Fhguisu%2Farticle%2Fdetails%2F7259716" target="_blank">[注册]</a></p>
<p>/* 以上用户言论只代表其个人观点，不代表CSDN网站的观点或立场<a href=""></a><a href=""></a></p>
<p><a href="">hguisu</a>
<a href="&quot;回到顶部&quot;"><img src="" alt="TOP"></a></p>
<p>个人资料</p>
<p><a href="http://my.csdn.net/hguisu" target="_blank"><img src="&quot;访问我的空间&quot;" alt=""></a>
<a href="http://my.csdn.net/hguisu" target="_blank">真实的归宿</a></p>
<p><a href="&quot;[加关注]&quot;"></a> <a href="&quot;[发私信]&quot;"></a>
<a href="http://medal.blog.csdn.net/allmedal.aspx" target="_blank"><img src="" alt=""></a></p>
<ul>
<li>访问：481035次</li>
<li>积分：6666分</li>
<li><p>排名：第614名</p>
</li>
<li><p>原创：190篇</p>
</li>
<li>转载：1篇</li>
<li>译文：0篇</li>
<li>评论：313条</li>
</ul>
<p>文章分类</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/category/1253451" target="_blank">操作系统</a>(5)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/796967" target="_blank">Linux</a>(17)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/796963" target="_blank">MySQL</a>(12)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/796962" target="_blank">PHP</a>(41)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1104862" target="_blank">PHP内核</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/796968" target="_blank">技术人生</a>(7)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1054628" target="_blank">数据结构与算法</a>(27)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1072794" target="_blank">云计算hadoop</a>(20)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1075597" target="_blank">网络知识</a>(7)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1080443" target="_blank">c/c++</a>(22)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1099674" target="_blank">memcache</a>(5)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1111071" target="_blank">HipHop</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1112019" target="_blank">计算机原理</a>(4)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1114530" target="_blank">Java</a>(7)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1122753" target="_blank">socket网络编程</a>(5)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1133340" target="_blank">设计模式</a>(26)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1151353" target="_blank">AOP</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1152364" target="_blank">重构</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1173389" target="_blank">重构与模式</a>(1)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1209788" target="_blank">大数据处理</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1230933" target="_blank">搜索引擎Search Engine</a>(15)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1302430" target="_blank">HTML5</a>(1)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1309674" target="_blank">Android</a>(1)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1422000" target="_blank">webserver</a>(3)</li>
<li><p><a href="http://blog.csdn.net/hguisu/article/category/1429288" target="_blank">NOSQL</a>(6)
文章存档</p>
</li>
<li><p><a href="http://blog.csdn.net/hguisu/article/month/2013/09" target="_blank">2013年09月</a>(2)</p>
</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/08" target="_blank">2013年08月</a>(1)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/07" target="_blank">2013年07月</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/06" target="_blank">2013年06月</a>(3)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/05" target="_blank">2013年05月</a>(3)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/03" target="_blank">2013年03月</a>(3)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/02" target="_blank">2013年02月</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/01" target="_blank">2013年01月</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/12" target="_blank">2012年12月</a>(4)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/11" target="_blank">2012年11月</a>(3)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/10" target="_blank">2012年10月</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/09" target="_blank">2012年09月</a>(15)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/08" target="_blank">2012年08月</a>(6)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/07" target="_blank">2012年07月</a>(8)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/06" target="_blank">2012年06月</a>(14)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/05" target="_blank">2012年05月</a>(29)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/04" target="_blank">2012年04月</a>(26)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/03" target="_blank">2012年03月</a>(27)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/02" target="_blank">2012年02月</a>(18)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2011/12" target="_blank">2011年12月</a>(7)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2011/01" target="_blank">2011年01月</a>(8)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2010/07" target="_blank">2010年07月</a>(6)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2007/12" target="_blank">2007年12月</a>(2)</li>
</ul>
<p>展开</p>
<p>阅读排行</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7237395" title="Hadoop集群配置（最全面总结）" target="_blank">Hadoop集群配置（最全面总结）</a>(23024)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7527842" title="设计模式（五）适配器模式Adapter（结构型）" target="_blank">设计模式（五）适配器模式Adapter（结构型）</a>(21421)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244413" title="hbase安装配置（整合到hadoop）" target="_blank">hbase安装配置（整合到hadoop）</a>(20780)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390" title="socket阻塞与非阻塞，同步与异步、I/O模型" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a>(12788)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7282050" title="Hadoop Hive与Hbase整合" target="_blank">Hadoop Hive与Hbase整合</a>(11869)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7558249" title="设计模式 ( 十八 ) 策略模式Strategy（对象行为型）" target="_blank">设计模式 ( 十八 ) 策略模式Strategy（对象行为型）</a>(11737)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7786014" title="B-树和B+树的应用：数据搜索和数据库索引" target="_blank">B-树和B+树的应用：数据搜索和数据库索引</a>(11507)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/5731880" title="Mysql 多表联合查询效率分析及优化" target="_blank">Mysql 多表联合查询效率分析及优化</a>(10454)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244991" title="谷歌三大核心技术（三）Google BigTable中文版" target="_blank">谷歌三大核心技术（三）Google BigTable中文版</a>(9958)</li>
<li><p><a href="&quot;HDFS写入和读取流程&quot;">HDFS写入和读取流程</a>(8282)
评论排行</p>
</li>
<li><p><a href="http://blog.csdn.net/hguisu/article/details/7558249" title="设计模式 ( 十八 ) 策略模式Strategy（对象行为型）" target="_blank">设计模式 ( 十八 ) 策略模式Strategy（对象行为型）</a>(33)</p>
</li>
<li><a href="&quot;HDFS写入和读取流程&quot;">HDFS写入和读取流程</a>(17)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7529194" title="设计模式（六）桥连模式Bridge（结构型）" target="_blank">设计模式（六）桥连模式Bridge（结构型）</a>(14)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7505909" title="设计模式（一）工厂模式Factory（创建型）" target="_blank">设计模式（一）工厂模式Factory（创建型）</a>(13)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7880288" title="海量数据处理算法—Bit-Map" target="_blank">海量数据处理算法—Bit-Map</a>(13)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7237395" title="Hadoop集群配置（最全面总结）" target="_blank">Hadoop集群配置（最全面总结）</a>(13)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7448528" title="PHP SOCKET编程" target="_blank">PHP SOCKET编程</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390" title="socket阻塞与非阻塞，同步与异步、I/O模型" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7282050" title="Hadoop Hive与Hbase整合" target="_blank">Hadoop Hive与Hbase整合</a>(10)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244413" title="hbase安装配置（整合到hadoop）" target="_blank">hbase安装配置（整合到hadoop）</a>(10)</li>
</ul>
<p>推荐文章
最新评论</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390#comments" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a></li>
</ul>
<p><a href="http://blog.csdn.net/ctqctq99" target="_blank">ctqctq99</a>: 他的意思可能是阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！这句话说反了。应该是非阻...</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7408047#comments" target="_blank">硬盘的读写原理</a></li>
</ul>
<p><a href="http://blog.csdn.net/m1013923728" target="_blank">m1013923728</a>: 写的通俗易懂！</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7470695#comments" target="_blank">C语言中的宏定义</a></li>
</ul>
<p><a href="http://blog.csdn.net/ouwen3536" target="_blank">ouwen3536</a>: 很半，转起！</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7470695#comments" target="_blank">C语言中的宏定义</a></li>
</ul>
<p><a href="http://blog.csdn.net/zhangyongbluesky" target="_blank">zhangyongbluesky</a>: good</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244413#comments" target="_blank">hbase安装配置（整合到hadoop）</a></li>
</ul>
<p><a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a>: @u012171806:conf/hbase-site.xml你应该看官方文档的快速入门。安装的东西...</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244413#comments" target="_blank">hbase安装配置（整合到hadoop）</a></li>
</ul>
<p><a href="http://blog.csdn.net/u012171806" target="_blank">JAVA_小陈</a>: 我把hbase下载了，你上面说的需要配置一个xml文件，请问配置在什么地方呢？然后启动的时候是在什么...</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7408047#comments" target="_blank">硬盘的读写原理</a></li>
</ul>
<p><a href="http://blog.csdn.net/mxhlee" target="_blank">mxhlee</a>: 好东西啊！！！（实际是斜切向运动）这句话让我纠结了很长时间、我自己就感觉是这运动 但是没有一个介绍...</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390#comments" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a></li>
</ul>
<p><a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a>: @liaokailin:并没有反。实际就是这样的。</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390#comments" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a></li>
</ul>
<p><a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a>: @liaokailin:实际就是这样的。</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390#comments" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a></li>
</ul>
<p><a href="http://blog.csdn.net/liaokailin" target="_blank">廖凯林</a>: 同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！阻塞IO和非阻塞IO的区别就在于：应用程...</p>
<p><a href="http://www.csdn.net/company/about.html" target="_blank">公司简介</a>|<a href="http://www.csdn.net/company/recruit.html" target="_blank">招贤纳士</a>|<a href="http://www.csdn.net/company/marketing.html" target="_blank">广告服务</a>|<a href="http://www.csdn.net/company/account.html" target="_blank">银行汇款帐号</a>|<a href="http://www.csdn.net/company/contact.html" target="_blank">联系方式</a>|<a href="http://www.csdn.net/company/statement.html" target="_blank">版权声明</a>|<a href="http://www.csdn.net/company/layer.html" target="_blank">法律顾问</a>|<a href="mailto:webmaster@csdn.net">问题报告</a><a href="http://wpa.qq.com/msgrd?v=3&amp;uin=2355263776&amp;site=qq&amp;menu=yes" target="_blank">QQ客服</a> <a href="http://e.weibo.com/csdnsupport/profile" target="_blank">微博客服</a> <a href="http://bbs.csdn.net/forums/Service" target="_blank">论坛反馈</a> <a href="mailto:webmaster@csdn.net">联系邮箱：webmaster@csdn.net</a> 服务热线：400-600-2320京 ICP 证 070598 号北京创新乐知信息技术有限公司 版权所有世纪乐知(北京)网络技术有限公司 提供技术支持江苏乐知网络技术有限公司 提供商务支持Copyright © 1999-2012, CSDN.NET, All Rights Reserved <a href="http://www.hd315.gov.cn/beian/view.asp?bianhao=010202001032100010" target="_blank"><img src="" alt="GongshangLogo"></a>
<img src="http://counter.csdn.net/pv.aspx?id=24" alt=""></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--HDFS写入和读取流程/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--HDFS写入和读取流程" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--hadoop/">hadoop</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--hadoop/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hadoop">hadoop</h1>
<p><img src="" alt=""></p>
<h1 id="hadoop">hadoop</h1>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1" target="_blank">1 hadoop</a></p>
</li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-1" target="_blank">1.1 FAQ</a></p>
</li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-1-1" target="_blank">1.1.1 Hadoop可以用来做什么</a></p>
</li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-2" target="_blank">1.1.2 Hadoop包括哪些组件</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-3" target="_blank">1.1.3 CDH和Apache Hadoop的关系</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-4" target="_blank">1.1.4 CDH产品组件构成</a></li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-1-5" target="_blank">1.1.5 CDH产品组件端口分布和配置</a></p>
</li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-1-5-1" target="_blank">1.1.5.1 Hadoop HDFS</a></p>
</li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-2" target="_blank">1.1.5.2 Hadoop MRv1</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-3" target="_blank">1.1.5.3 Hadoop YARN</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-4" target="_blank">1.1.5.4 HBase</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-5" target="_blank">1.1.5.5 Hive</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-6" target="_blank">1.1.5.6 Sqoop</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-7" target="_blank">1.1.5.7 Zookeeper</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-8" target="_blank">1.1.5.8 Hue</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-9" target="_blank">1.1.5.9 Ozzie</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-10" target="_blank">1.1.5.10 Ganglia</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-1-5-11" target="_blank">1.1.5.11 Kerberos</a></li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-2" target="_blank">1.2 观点</a></p>
</li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-2-1" target="_blank">1.2.1 Hadoop即将过时了吗？</a></p>
</li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-2-2" target="_blank">1.2.2 Best Practices for Selecting Apache Hadoop Hardware</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-2-3" target="_blank">1.2.3 The dark side of Hadoop - BackType Technology</a></li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-3" target="_blank">1.3 使用问题</a></p>
</li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-3-1" target="_blank">1.3.1 CDH3u3搭建单节点集群</a></p>
</li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-3-2" target="_blank">1.3.2 CDH4.2.0搭建单节点集群</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-3-3" target="_blank">1.3.3 CDH4.3.0</a></li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-3-4" target="_blank">1.3.4 Configuration</a></p>
</li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-3-4-1" target="_blank">1.3.4.1 .bash_profile</a></p>
</li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-3-4-2" target="_blank">1.3.4.2 core-site.xml</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-3-4-3" target="_blank">1.3.4.3 hdfs-site.xml</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-3-4-4" target="_blank">1.3.4.4 mapred-site.xml</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-3-4-5" target="_blank">1.3.4.5 hadoop-env.sh</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-3-4-6" target="_blank">1.3.4.6 hbase-site.xml</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-3-4-7" target="_blank">1.3.4.7 hbase-env.sh</a></li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-4" target="_blank">1.4 Hadoop权威指南</a></p>
</li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-4-1" target="_blank">1.4.1 初识Hadoop</a></p>
</li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-2" target="_blank">1.4.2 关于MapReduce</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-3" target="_blank">1.4.3 Hadoop分布式文件系统</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-4" target="_blank">1.4.4 Hadoop IO</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-5" target="_blank">1.4.5 MapReduce应用开发</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-6" target="_blank">1.4.6 MapReduce的工作机制</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-7" target="_blank">1.4.7 MapReduce的类型与格式</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-8" target="_blank">1.4.8 MapReduce的特性</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-9" target="_blank">1.4.9 构建Hadoop集群</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-4-10" target="_blank">1.4.10 管理Hadoop</a></li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-5" target="_blank">1.5 Benchmark</a></p>
</li>
<li><p><a href="http://dirlt.com/hadoop.html#sec-1-5-1" target="_blank">1.5.1 TestDFSIO</a></p>
</li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-5-2" target="_blank">1.5.2 TeraSort</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-5-3" target="_blank">1.5.3 nnbench</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-5-4" target="_blank">1.5.4 mrbench</a></li>
<li><a href="http://dirlt.com/hadoop.html#sec-1-5-5" target="_blank">1.5.5 hbase.PerformanceEvaluation</a></li>
</ul>
<h2 id="1-hadoop">1 hadoop</h2>
<p>参考资源</p>
<ul>
<li>Cloudera <a href="http://www.cloudera.com/" target="_blank"><a href="http://www.cloudera.com/">http://www.cloudera.com/</a></a></li>
<li>Apache Hadoop <a href="http://hadoop.apache.org/" target="_blank"><a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a></a></li>
<li>Apache Hadoop r1.0.3 文档 <a href="http://hadoop.apache.org/common/docs/r1.0.3/" target="_blank"><a href="http://hadoop.apache.org/common/docs/r1.0.3/">http://hadoop.apache.org/common/docs/r1.0.3/</a></a></li>
<li>Apache Hadoop r1.0.3 中文文档 <a href="http://hadoop.apache.org/common/docs/r1.0.3/cn" target="_blank"><a href="http://hadoop.apache.org/common/docs/r1.0.3/cn">http://hadoop.apache.org/common/docs/r1.0.3/cn</a></a></li>
<li>CDH Downloads <a href="https://ccp.cloudera.com/display/SUPPORT/Downloads" target="_blank"><a href="https://ccp.cloudera.com/display/SUPPORT/Downloads">https://ccp.cloudera.com/display/SUPPORT/Downloads</a></a></li>
<li>CDH Documentation <a href="https://ccp.cloudera.com/display/DOC/Documentation" target="_blank"><a href="https://ccp.cloudera.com/display/DOC/Documentation">https://ccp.cloudera.com/display/DOC/Documentation</a></a></li>
<li>CDH Tutorial <a href="https://ccp.cloudera.com/display/SUPPORT/Hadoop+Tutorial" target="_blank"><a href="https://ccp.cloudera.com/display/SUPPORT/Hadoop+Tutorial">https://ccp.cloudera.com/display/SUPPORT/Hadoop+Tutorial</a></a></li>
</ul>
<h3 id="1-1-faq">1.1 FAQ</h3>
<h3 id="1-1-1-hadoop-">1.1.1 Hadoop可以用来做什么</h3>
<p>Why Hadoop? <a href="http://www.cloudera.com/why-hadoop/" target="_blank"><a href="http://www.cloudera.com/why-hadoop/">http://www.cloudera.com/why-hadoop/</a></a></p>
<p>TODO(dirlt):translate it!!!</p>
<p>Simply put, Hadoop can transform the way you store and process data throughout your enterprise. According to analysts, about 80% of the data in the world is unstructured, and until Hadoop, it was essentially unusable in any systematic way. With Hadoop, for the first time you can combine all your data and look at it as one.</p>
<ul>
<li>Make All Your Data Profitable. Hadoop enables you to gain insight from all the data you already have; to ingest the data flowing into your systems 24/7 and leverage it to make optimizations that were impossible before; to make decisions based on hard data, not hunches; to look at complete data, not samples; to look at years of transactions, not days or weeks. In short, Hadoop will change the way you run your organization.</li>
<li>Leverage All Types of Data, From All Types of Systems. Hadoop can handle all types of data from disparate systems: structured, unstructured, log files, pictures, audio files, communications records, email– just about anything you can think of. Even when different types of data have been stored in unrelated systems, you can dump it all into your Hadoop cluster before you even know how you might take advantage of it in the future.</li>
<li>Scale Beyond Anything You Have Today. The largest social network in the world is built on the same open-source technology as Hadoop, and now exceeds 100 petabytes. It’s unlikely your organization has that much data. As you need more capacity, you just add more commodity servers and Hadoop automatically incorporates the new storage and compute capacity.</li>
</ul>
<h3 id="1-1-2-hadoop-">1.1.2 Hadoop包括哪些组件</h3>
<p>TODO(dirlt):translate it!!!</p>
<p>Apache Hadoop包括了下面这些组件：</p>
<ul>
<li><a href="http://hadoop.apache.org/common/" target="_blank">Hadoop Common</a> The common utilities that support the other Hadoop subprojects.</li>
<li><a href="http://hadoop.apache.org/hdfs/" target="_blank">Hadoop Distributed File System(HDFS)</a> A distributed file system that provides high-throughput access to application data.</li>
<li><a href="http://hadoop.apache.org/mapreduce/" target="_blank">Hadoop MapReduce</a> A software framework for distributed processing of large data sets on compute clusters.</li>
</ul>
<p>和Apache Hadoop相关的组件有：</p>
<ul>
<li><a href="http://avro.apache.org/" target="_blank">Avro</a> A data serialization system.</li>
<li><a href="http://cassandra.apache.org/" target="_blank">Cassandra</a> A scalable multi-master database with no single points of failure.</li>
<li><a href="http://incubator.apache.org/chukwa/" target="_blank">Chukwa</a> A data collection system for managing large distributed systems.</li>
<li><a href="http://hbase.apache.org/" target="_blank">HBase</a> A scalable, distributed database that supports structured data storage for large tables.</li>
<li><a href="http://hive.apache.org/" target="_blank">Hive</a> A data warehouse infrastructure that provides data summarization and ad hoc querying.</li>
<li><a href="http://mahout.apache.org/" target="_blank">Mahout</a> A Scalable machine learning and data mining library.</li>
<li><a href="http://pig.apache.org/" target="_blank">Pig</a> A high-level data-flow language and execution framework for parallel computation.</li>
<li><a href="http://zookeeper.apache.org/" target="_blank">ZooKeeper</a> A high-performance coordination service for distributed applications.<h3 id="1-1-3-cdh-apache-hadoop-">1.1.3 CDH和Apache Hadoop的关系</h3>
</li>
</ul>
<p>CDH Hadoop FAQ <a href="https://ccp.cloudera.com/display/SUPPORT/Hadoop+FAQ" target="_blank"><a href="https://ccp.cloudera.com/display/SUPPORT/Hadoop+FAQ">https://ccp.cloudera.com/display/SUPPORT/Hadoop+FAQ</a></a></p>
<p>TODO(dirlt):translate it!!!</p>
<ul>
<li>What exactly is included in CDH? / Cloudera&#39;s Distribution Including Apache Hadoop (CDH) is a certified release of Apache Hadoop. We include some stable patches scheduled to be included in future releases, as well as some patches we have developed for our supported customers, and are in the process of contributing back to Apache.</li>
<li>What license is Cloudera&#39;s Distribution Including Apache Hadoop released under? / Just like Hadoop, Cloudera&#39;s Distribution Including Apache Hadoop is released under the Apache Public License version 2.</li>
<li>Is Cloudera forking Hadoop? / Absolutely not. Cloudera is committed to the Hadoop project and the principles of the Apache Software License and Foundation. We continue to work actively with current releases of Hadoop and deliver certified releases to the community as appropriate.</li>
<li>Does Cloudera contribute their changes back to Apache? / We do, and will continue to contribute all eligible changes back to Apache. We occasionally release code we know to be stable even if our contribution to Apache is still in progress. Some of our changes are not eligible for contribution, as they capture the Cloudera brand, or link to our tools and documentation, but these do not affect compatibility with core project.</li>
</ul>
<h3 id="1-1-4-cdh-">1.1.4 CDH产品组件构成</h3>
<p><a href="http://www.cloudera.com/content/cloudera/en/products/cdh.html" target="_blank"><a href="http://www.cloudera.com/content/cloudera/en/products/cdh.html">http://www.cloudera.com/content/cloudera/en/products/cdh.html</a></a></p>
<p>从这里可以下载CDH4组件 <a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDHTarballs/3.25.2013/CDH4-Downloadable-Tarballs/CDH4-Downloadable-Tarballs.html" target="_blank"><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDHTarballs/3.25.2013/CDH4-Downloadable-Tarballs/CDH4-Downloadable-Tarballs.html">http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDHTarballs/3.25.2013/CDH4-Downloadable-Tarballs/CDH4-Downloadable-Tarballs.html</a></a></p>
<p><img src="" alt="./images/cloudera-enterprise-diagram.png"></p>
<h3 id="1-1-5-cdh-">1.1.5 CDH产品组件端口分布和配置</h3>
<p>The CDH4 components, and third parties such as Kerberos, use the ports listed in the tables that follow. Before you deploy CDH4, make sure these ports are open on each system.</p>
<h3 id="1-1-5-1-hadoop-hdfs">1.1.5.1 Hadoop HDFS</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentDataNode50010TCPExternaldfs.datanode.addressDataNode HTTP server portDataNodeSecure1004TCPExternaldfs.datanode.addressDataNode50075TCPExternaldfs.datanode.http.addressDataNodeSecure1006TCPExternaldfs.datanode.http.addressDataNode50020TCPExternaldfs.datanode.ipc.addressNameNode8020TCPExternalfs.default.name or fs.defaultFSfs.default.name is deprecated (but still works)NameNode50070TCPExternaldfs.http.address or dfs.namenode.http-addressdfs.http.address is deprecated (but still works)NameNodeSecure50470TCPExternaldfs.https.address or dfs.namenode.https-addressdfs.https.address is deprecated (but still works)Sec NameNode50090TCPInternaldfs.secondary.http.address or dfs.namenode.secondary.http-addressdfs.secondary.http.address is deprecated (but still works)Sec NameNodeSecure50495TCPInternaldfs.secondary.https.addressJournalNode8485TCPInternaldfs.namenode.shared.edits.dirJournalNode8480TCPInternal</p>
<h3 id="1-1-5-2-hadoop-mrv1">1.1.5.2 Hadoop MRv1</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentJobTracker8021TCPExternalmapred.job.trackerJobTracker50030TCPExternalmapred.job.tracker.http.addressJobTrackerThrift Plugin9290TCPInternaljobtracker.thrift.addressRequired by Hue and Cloudera Manager Activity MonitorTaskTracker50060TCPExternalmapred.task.tracker.http.addressTaskTracker0TCPLocalhostmapred.task.tracker.report.addressCommunicating with child (umbilical)</p>
<h3 id="1-1-5-3-hadoop-yarn">1.1.5.3 Hadoop YARN</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentResourceManager8032TCPyarn.resourcemanager.addressResourceManager8030TCPyarn.resourcemanager.scheduler.addressResourceManager8031TCPyarn.resourcemanager.resource-tracker.addressResourceManager8033TCPyarn.resourcemanager.admin.addressResourceManager8088TCPyarn.resourcemanager.webapp.addressNodeManager8040TCPyarn.nodemanager.localizer.addressNodeManager8042TCPyarn.nodemanager.webapp.addressNodeManager8041TCPyarn.nodemanager.addressMapReduce JobHistory Server10020TCPmapreduce.jobhistory.addressMapReduce JobHistory Server19888TCPmapreduce.jobhistory.webapp.address</p>
<h3 id="1-1-5-4-hbase">1.1.5.4 HBase</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentMaster60000TCPExternalhbase.master.portIPCMaster60010TCPExternalhbase.master.info.portHTTPRegionServer60020TCPExternalhbase.regionserver.portIPCRegionServer60030TCPExternalhbase.regionserver.info.portHTTPHQuorumPeer2181TCPhbase.zookeeper.property.clientPortHBase-managed ZK modeHQuorumPeer2888TCPhbase.zookeeper.peerportHBase-managed ZK modeHQuorumPeer3888TCPhbase.zookeeper.leaderportHBase-managed ZK modeRESTREST Service8080TCPExternalhbase.rest.portThriftServerThrift Server9090TCPExternalPass -p <port> on CLIAvro server9090TCPExternalPass –port <port> on CLI</p>
<h3 id="1-1-5-5-hive">1.1.5.5 Hive</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentMetastore9083TCPExternalHiveServer10000TCPExternal</p>
<h3 id="1-1-5-6-sqoop">1.1.5.6 Sqoop</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentMetastore16000TCPExternalsqoop.metastore.server.portSqoop 2 server12000TCPExternal</p>
<h3 id="1-1-5-7-zookeeper">1.1.5.7 Zookeeper</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentServer (with CDH4 and/or Cloudera Manager 4)2181TCPExternalclientPortClient portServer (with CDH4 only)2888TCPInternalX in server.N=host:X:YPeerServer (with CDH4 only)3888TCPInternalY in server.N=host:X:YPeerServer (with CDH4 and Cloudera Manager 4)3181TCPInternalX in server.N=host:X:YPeerServer (with CDH4 and Cloudera Manager 4)4181TCPInternalY in server.N=host:X:YPeerZooKeeper FailoverController (ZKFC)8019TCPInternalUsed for HAZooKeeper JMX port9010TCPInternal</p>
<p>As JMX port, ZooKeeper will also use another randomly selected port for RMI. In order for Cloudera Manager to monitor ZooKeeper, you must open up all ports when the connection originates from the Cloudera Manager server.</p>
<h3 id="1-1-5-8-hue">1.1.5.8 Hue</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentServer8888TCPExternalBeeswax Server8002InternalBeeswax Metastore8003Internal</p>
<h3 id="1-1-5-9-ozzie">1.1.5.9 Ozzie</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentOozie Server11000TCPExternalOOZIE_HTTP_PORT in oozie-env.shHTTPOozie Server11001TCPlocalhostOOZIE_ADMIN_PORT in oozie-env.shShutdown port</p>
<h3 id="1-1-5-10-ganglia">1.1.5.10 Ganglia</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentganglia-gmond8649UDP/TCPInternalganglia-web80TCPExternalVia Apache httpd</p>
<h3 id="1-1-5-11-kerberos">1.1.5.11 Kerberos</h3>
<p>ServiceQualifierPortProtocolAccess RequirementConfigurationCommentKRB5 KDC ServerSecure88UDP/TCPExternalkdc_ports and kdc_tcp_ports in either the [kdcdefaults] or [realms] sections of kdc.confBy default only UDPKRB5 Admin ServerSecure749TCPInternalkadmind_port in the [realms] section of kdc.conf</p>
<h3 id="1-2-">1.2 观点</h3>
<h3 id="1-2-1-hadoop-">1.2.1 Hadoop即将过时了吗？</h3>
<p><a href="http://www.kuqin.com/database/20120715/322528.html" target="_blank"><a href="http://www.kuqin.com/database/20120715/322528.html">http://www.kuqin.com/database/20120715/322528.html</a></a></p>
<p>google提出的三个东西都是解决hadoop的软肋，最终目的还是需要解决大数据上面的实时性问题。</p>
<ul>
<li>增量索引过滤器（Percolator for incremental indexing）和频繁变化数据集分析。Hadoop是一台大型“机器”，当启动并全速运转时处理数据的性能惊人，你唯一需要操心的就是硬盘的传输速度跟不上。但是每次你准备启动分析数据时，都需要把所有的数据都过一遍，当数据集越来越庞大时，这个问题将导致分析时间无限延长。那么Google是如何解决让搜索结果返回速度越来越接近实时的呢？答案是用增量处理引擎Percolator代替GMR。通过只处理新增的、改动过的或删除的文档和使用二级指数来高效率建目录，返回查询结果。Percolator论文的作者写道：“将索引系统转换成增量系统…将文档处理延迟缩短了100倍。”这意味着索引web新内容的速度比用MapReduce快100倍！类似大型强子对撞机产生的数据将不断变大，Twitter也是如此。这也是为什么HBase中会新增触发流程，而Twitter Storm正在成为实时处理流数据的热门技术。</li>
<li>用于点对点分析的Dremel。Google和Hadoop生态系统都致力于让MapReduce成为可用的点对点分析工具。从Sawzall到Pig和Hive，创建了大量的界面层，但是尽管这让Hadoop看上去更像SQL系统，但是人们忘记了一个基本事实——MapReduce(以及Hadoop)是为组织数据处理任务开发的系统，诞生于工作流内核，而不是点对点分析。今天有大量的BI/分析查询都是点对点模式，属于互动和低延迟的分析。Hadoop的Map和Reduce工作流让很多分析师望而却步，而且工作启动和完成工作流运行的漫长周期对于很多互动性分析来说意味着糟糕的用户体验。于是，Google发明了Dremel（业界也称之为BigQuery产品）专用工具，可以让分析师数秒钟内就扫描成PB（Petabyte）的数据完成点到点查询，而且还能支持可视化。Google在Dremel的论文中声称：“Dremel能够在数秒内完成数万亿行数据的聚合查询，比MapReduce快上100倍！”</li>
<li>分析图数据的Pregel。Google MapReduce的设计初衷是分析世界上最大的数据图谱——互联网。但是在分析人际网络、电信设备、文档和其他一些图数据时就没有那么灵光了，例如MapReduce在计算单源最短路径（SSSP）时效率非常低下，已有的并行图算法库Parallel BGL或者CGMgraph又没有容错。于是Google开发了Pregel，一个可以在分布式通用服务器上处理PB级别图数据的大型同步处理应用。与Hadoop经常在处理图数据时产生指数级数据放大相比，Pregel能够自然高效地处理SSSP或PageRank等图算法，所用时间要短得多，代码也简洁得多。目前唯一能与Pregel媲美的开源选择是Giraph，这是一个早期的Apache孵化项目，调用了HDFS和Zookeeper。Githb上还有一个项目Golden Orb可用。</li>
</ul>
<h3 id="1-2-2-best-practices-for-selecting-apache-hadoop-hardware">1.2.2 Best Practices for Selecting Apache Hadoop Hardware</h3>
<p><a href="http://hortonworks.com/blog/best-practices-for-selecting-apache-hadoop-hardware/" target="_blank"><a href="http://hortonworks.com/blog/best-practices-for-selecting-apache-hadoop-hardware/">http://hortonworks.com/blog/best-practices-for-selecting-apache-hadoop-hardware/</a></a></p>
<p>RAID cards, redundant power supplies and other per-component reliability features are not needed. Buy error-correcting RAM and SATA drives with good MTBF numbers. Good RAM allows you to trust the quality of your computations. Hard drives are the largest source of failures, so buy decent ones.（不需要选购RAID，冗余电源或者是一些满足高可靠性组件，但是选择带有ECC的RAM以及good MTBF的SATA硬盘却是非常需要的。ECC RAM可以让你确保计算结果的正确性，而SATA故障是大部分故障的主要原因）</p>
<ul>
<li>On CPU: It helps to understand your workload, but for most systems I recommend sticking with medium clock speeds and no more than 2 sockets. Both your upfront costs and power costs rise quickly on the high-end. For many workloads, the extra performance per node is not cost-effective.（没有特别要求，普通频率，dual-socket？？？）</li>
<li>On Power: Power is a major concern when designing Hadoop clusters. It is worth understanding how much power the systems you are buying use and not buying the biggest and fastest nodes on the market.In years past we saw huge savings in pricing and significant power savings by avoiding the fastest CPUs, not buying redundant power supplies, etc. Nowadays, vendors are building machines for cloud data centers that are designed to reduce cost and power and that exclude a lot of the niceties that bulk up traditional servers. Spermicro, Dell and HP all have such product lines for cloud providers, so if you are buying in large volume, it is worth looking for stripped-down cloud servers. （根据自己的需要尽量减少能耗开销，撇去一些不需要的部件。而且现在很多厂商也在尽量减少不必要的部件）</li>
<li>On RAM: What you need to consider is the amount of RAM needed to keep the processors busy and where the knee in the cost curve resides. Right now 48GB seems like a pretty good number. You can get this much RAM at commodity prices on low-end server motherboards. This is enough to provide the Hadoop framework with lots of RAM (~4 GB) and still have plenty to run many processes. Don’t worry too much about RAM, you’ll find a use for it, often running more processes in parallel. If you don’t, the system will still use it to good effect, caching disk data and improving performance.（RAM方面的话越大越好，对于48GB的RAM来说普通的主板也是支持的。如果RAM用的上的话那么允许多个进程并行执行，如果暂时永不上的话可以做cache来提高速度）</li>
<li>On Disk: Look to buy high-capacity SATA drives, usually 7200RPM. Hadoop is storage hungry and seek efficient but it does not require fast, expensive hard drives. Keep in mind that with 12-drive systems you are generally getting 24 or 36 TB/node. Until recently, putting this much storage in a node was not practical because, in large clusters, disk failures are a regular occurrence and replicating 24+TB could swamp the network for long enough to really disrupt work and cause jobs to miss SLAs. The most recent release of Hadoop 0.20.204 is engineered to handle the failure of drives more elegantly, allowing machines to continue serving from their remaining drives. With these changes, we expect to see a lot of 12+ drive systems. In general, add disks for storage and not seeks. If your workload does not require huge amounts of storage, dropping disk count to 6 or 4 per box is a reasonable way to economize.（高容量SATA硬盘，最好是7.2KRPM，并且最好单机上面挂在12个硬盘。对于hadoop之前这种方式并不实际，因为磁盘非常容易损坏并且备份这24TB的数据非常耗时。而hadoop可以很好地解决这个问题。</li>
</ul>
<p>小集群来说的话，通常单个机器上面挂在4-6个disk即可）</p>
<ul>
<li>On Network: This is the hardest variable to nail down. Hadoop workloads vary a lot. The key is to buy enough network capacity to allow all nodes in your cluster to communicate with each other at reasonable speeds and for reasonable cost. For smaller clusters, I’d recommend at least 1GB all-to-all bandwidth, which is easily achieved by just connecting all of your nodes to a good switch. With larger clusters this is still a good target although based on workload you can probably go lower. In the very large data centers the Yahoo! built, they are seeing 2/<em>10GB per 20 node rack going up to a pair of central switches, with rack nodes connected with two 1GB links. As a rule of thumb, watch the ratio of network-to-computer cost and aim for network cost being somewhere around 20% of your total cost. Network costs should include your complete network, core switches, rack switches, any network cards needed, etc. We’ve been seeing InfiniBand and 10GB Ethernet networks to the node now. If you can build this cost effectively, that’s great. However, keep in mind that Hadoop grew up with commodity Ethernet, so understand your workload requirements before spending too much on the network.（这个主要还是看需求。通常来说网络整体开销占据所有开销的20%，包括核心交换机，机架之间的交换机以及网卡设备等。yahoo大集群的部署方式是rack之间使用2/</em>10GB的核心交换机工作，而20个节点的rack之间内部使用1GB链路）。<h3 id="1-2-3-the-dark-side-of-hadoop-backtype-technology">1.2.3 The dark side of Hadoop - BackType Technology</h3>
</li>
</ul>
<p><a href="http://web.archive.org/web/20110510125644/http://tech.backtype.com/the-dark-side-of-hadoop" target="_blank"><a href="http://web.archive.org/web/20110510125644/http://tech.backtype.com/the-dark-side-of-hadoop">http://web.archive.org/web/20110510125644/http://tech.backtype.com/the-dark-side-of-hadoop</a></a></p>
<p>谈到了一些在使用hadoop出现的一些问题，而这些问题是hadoop本身的。</p>
<ul>
<li>Critical configuration poorly documented 一些关键的参数和配置并没有很好地说明清楚。</li>
<li><p>Terrible with memory usage 内存使用上面存在问题。hadoop里面有一些非常sloppy的实现，比如chmod以及ln -s等操作，并没有调用fs API而是直接创建一个shell进程来完成。因为fork出一个shell进程需要申请同样大小的内存（虽然实现上是COW），但是这样造成jvm出现oom。解决的办法是开辟一定空间的swap The solution to these memory problems is to allocate a healthy amount of swap space for each machine to protect you from these memory glitches. We couldn&#39;t believe how much more stable everything became when we added swap space to our worker machines.</p>
</li>
<li><p>Thomas Jungblut&#39;s Blog: Dealing with &quot;OutOfMemoryError&quot; in Hadoop <a href="http://codingwiththomas.blogspot.jp/2011/07/dealing-with-outofmemoryerror-in-hadoop.html" target="_blank"><a href="http://codingwiththomas.blogspot.jp/2011/07/dealing-with-outofmemoryerror-in-hadoop.html">http://codingwiththomas.blogspot.jp/2011/07/dealing-with-outofmemoryerror-in-hadoop.html</a></a> 作者给出的解决办法就是修改hadoop的代码，通过调用Java API而不是使用ProcessBuilder来解决。</p>
</li>
<li><strong>NOTE(dirlt):出现OOM的话必须区分JVM还是Linux System本身的OOM。JVM出现OOM是抛出异常，而Linux出现OOM是会触发OOM killer</strong></li>
<li>Zombies hadoop集群出现一些zombie进程，而这些进程会一直持有内存直到大量zombie进程存在最后需要重启。造成这些zombie进程的原因通常是因为jvm oom（增加了swap之后就没有出现这个问题了），但是奇怪的是tasktracker作为这些process的parent，并不负责cleanup这些zombie进程而是依赖这些zombie进程的自己退出，这就是hadoop设计方面的问题。</li>
</ul>
<p>Making Hadoop easy to deploy, use, and operate should be the /#1 priority for the developers of Hadoop.</p>
<h3 id="1-3-">1.3 使用问题</h3>
<h3 id="1-3-1-cdh3u3-">1.3.1 CDH3u3搭建单节点集群</h3>
<p>搭建单节点集群允许我们在单机做一些模拟或者是测试，还是非常有意义的。如何操作的话可以参考链接 <a href="http://localhost/utils/hadoop-0.20.2-cdh3u3/docs/single_node_setup.html" target="_blank"><a href="http://localhost/utils/hadoop-0.20.2-cdh3u3/docs/single_node_setup.html">http://localhost/utils/hadoop-0.20.2-cdh3u3/docs/single_node_setup.html</a></a></p>
<p>这里稍微总结一下：</p>
<ul>
<li>首先安装ssh和rsync /# sudo apt-get install ssh &amp;&amp; sudo apt-get install rsync</li>
<li>本机建立好信任关系 /# cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</li>
<li>将{hadoop-package}/conf配置文件修改如下：</li>
<li><p>conf/core-site.xml</p>
<configuration>

   <property>
       <name>fs.default.name</name>

       <value>hdfs://localhost:9000</value>
   </property>

</li>
</ul>
<p></configuration></p>
<ul>
<li><p>conf/hdfs-site.xml</p>
<configuration>

   <property>
       <name>dfs.replication</name>

       <value>1</value>
   </property>

</li>
</ul>
<p></configuration></p>
<ul>
<li><p>conf/mapred-site.xml</p>
<configuration>

   <property>
       <name>mapred.job.tracker</name>

       <value>localhost:9001</value>
   </property>

</li>
</ul>
<p></configuration></p>
<ul>
<li>格式化namenode /# bin/hadoop namenode -format</li>
<li>启动hadoop集群 /# bin/start-all.sh</li>
<li>停止hadoop集群 /# bin/stop-all.sh</li>
<li><p>webconsole</p>
</li>
<li><p>NameNode - <a href="http://localhost:50070/" target="_blank"><a href="http://localhost:50070/">http://localhost:50070/</a></a></p>
</li>
<li>JobTracker - <a href="http://localhost:50030/" target="_blank"><a href="http://localhost:50030/">http://localhost:50030/</a></a></li>
</ul>
<h3 id="1-3-2-cdh4-2-0-">1.3.2 CDH4.2.0搭建单节点集群</h3>
<p>基本流程和CDH3u3是相同的，但是有一些差异我记录下来。</p>
<ul>
<li><p>配置文件</p>
</li>
<li><p>配置文件在etc/hadoop，包括环境配置脚本比如hadoop-env.sh</p>
</li>
<li>bin/sbin目录下面有hadoop集群启动停止工具 <strong>NOTE（dirlt）：不要使用它们</strong></li>
<li>libexec目录下面是公用的配置脚本</li>
<li>mapred-site.xml中jobtracker地址配置key修改为 mapred.jobtracker.address <strong>NOTE(dirlt):this for yarn.如果是mr1那么不用修改,依然是mapred.job.tracker</strong></li>
<li>hadoop-daemons.sh会使用/sbin/slaves.sh来在各个节点启动，但是 /<em>不知道什么原因，很多环境变量没有设置/</em> ，所以在slaves.sh执行ssh命令部分最开始增加了 source ~/.shrc; 来强制设置我的环境变量</li>
<li><strong>NOTE(dirlt):不要使用shell脚本来启动，而是直接使用类似hadoop namenode这种方式来启动单个机器上的实例</strong></li>
<li><p>公共组件</p>
</li>
<li><p>CDH4.2.0 native-library都放在了目录lib/native下面，而不是CDH3u3的lib/native/Linux-amd64-64下面，这点需要注意。</p>
</li>
<li>CDH4.2.0 没有自带libhadoop.so, 所以启动的时候都会出现 ”Unable to load native-hadoop library for your platform… using builtin-java classes where applicable“ 这个警告。需要自己编译放到lib/native目录下面。</li>
<li>CDH4.2.0 lib下面没有任何文件，所有的lib都在share/hadoop//*/lib下面，比如share/hadoop/common/lib. 这点和CDH3有差别，CDH3所有的jar都放在lib目录下面。使用 hadoop classpath 命令可以察看</li>
<li><p>环境变量</p>
</li>
<li><p>JAVA_LIBRARY_PATH用来设置native library path</p>
</li>
<li>HADOOP_CLASSPATH可以用来设置hadoop相关的classpath（比如使用hadoop-lzo等）</li>
<li><p>准备工作</p>
</li>
<li><p>使用hdfs namenode -format来做格式化 <strong>注意如果使用sudo apt-get来安装的话，是其他用户比如hdfs,impala,mapred,yarn来启动的，所以必须确保目录对于这些用户是可写的</strong></p>
</li>
<li>使用命令 hadoop org/apache/hadoop/examples/QuasiMonteCarlo 1 1 确定集群是否可以正常运行。<h3 id="1-3-3-cdh4-3-0">1.3.3 CDH4.3.0</h3>
</li>
</ul>
<p>基本流程和CDH4.2.0是相同的，但是存在一些差异我记录下来的。从4.3.0开始将mr1和mr2分开存放，还是一个比较大的区别的。这里我以使用mr1为例。</p>
<ul>
<li>在libexec/hadoop-config.sh添加source ~/.shrc 来强制设置环境变量。</li>
<li><p>mr1和mr2分开存放主要有</p>
</li>
<li><p>etc目录，hadoop and hadoop-mapreduce1</p>
</li>
<li>bin目录，bin and bin-mapreduce1</li>
<li><p>lib目录。如果需要使用mr1的话，那么将cp -r share/hadoop/mapreduce1/ .</p>
</li>
<li><p><strong>NOTE（dirlt）：似乎只需要最顶层的一些jar文件即可</strong></p>
</li>
<li>在bin/hadoop-config.sh添加source ~/.shrc 来强制设置环境变量。</li>
<li><strong>NOTE（dirlt）：不要使用start-dfs.sh这些脚本启动，似乎这些脚本会去读取master,slaves这些文件然后逐个上去ssh启动。直接使用hadoop namenode这种方式可以只启动单个机器上的实例</strong></li>
</ul>
<h3 id="1-3-4-configuration">1.3.4 Configuration</h3>
<h3 id="1-3-4-1-bash_profile">1.3.4.1 .bash_profile</h3>
<p>export HADOOP_HOME=$HOME/dirlt/hadoop-2.0.0-cdh4.3.0/</p>
<p>export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HBASE_HOME=/home/alium_zhanyinan/dirlt/hbase-0.94.6-cdh4.3.0</p>
<p>export HBASE_CLASSPATH=$HBASE_HOME/hbase-0.94.6-cdh4.3.0-security.jar:$HBASE_HOME/conf
export ZK_HOME=/home/alium_zhanyinan/dirlt/zookeeper-3.4.5-cdh4.3.0</p>
<p>export ZK_CLASSPATH=$ZK_HOME/zookeeper-3.4.5-cdh4.3.0.jar
export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$HBASE_CLASSPATH:$ZK_CLASSPATH</p>
<p>export JAVA_HOME=/usr/java/default/</p>
<h3 id="1-3-4-2-core-site-xml">1.3.4.2 core-site.xml</h3>
<configuration>

  <property>
    <name>fs.default.name</name>

    <value>hdfs://umengds1.mob.cm3:8020</value>
  </property>


  <property>

    <name>fs.trash.interval</name>
    <value>1440</value>

  </property>
</configuration>


<h3 id="1-3-4-3-hdfs-site-xml">1.3.4.3 hdfs-site.xml</h3>
<configuration>

  <property>
    <name>dfs.name.dir</name>

    <value>/disk1/data/dfs/nn</value>
  </property>


  <property>

    <name>dfs.data.dir</name>
    <value>/disk1/data/dfs/dn</value>

  </property>


  <property>
    <name>fs.checkpoint.dir</name>

    <value>/disk1/data/dfs/snn</value>
  </property>


  <property>

    <name>dfs.replication</name>
    <value>3</value>

  </property>


  <property>
    <name>dfs.block.size</name>

    <value>134217728</value>
  </property>


  <property>

    <name>dfs.datanode.max.xcievers</name>
    <value>8192</value>

  </property>


  <property>
    <name>dfs.datanode.du.reserved</name>

    <value>21474836480</value>
  </property>


  <property>

    <name>dfs.namenode.handler.count</name>
    <value>64</value>

  </property>


  <property>
    <name>dfs.datanode.handler.count</name>

    <value>32</value>
  </property>


  <property>

    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>

  </property>
</configuration>



<h3 id="1-3-4-4-mapred-site-xml">1.3.4.4 mapred-site.xml</h3>
<configuration>

  <property>
    <name>mapred.job.tracker</name>

    <value>umengds2.mob.cm3:8021</value>
  </property>


  <property>

    <name>mapred.system.dir</name>
    <value>/tmp/mapred/system</value>

  </property>


  <property>
    <name>mapreduce.jobtracker.staging.root.dir</name>

    <value>/user</value>
  </property>


  <property>

    <name>mapred.local.dir</name>
    <value>/disk1/data/mapred/local</value>

  </property>


  <property>
    <name>mapred.submit.replication</name>

    <value>3</value>
    <final>true</final>

  </property>


  <property>
    <name>mapred.tasktracker.map.tasks.maximum</name>

    <value>6</value>
  </property>

  <property>
    <name>mapred.tasktracker.reduce.tasks.maximum</name>

    <value>8</value>
  </property>


  <property>

    <name>mapred.child.java.opts</name>
    <value> -Xmx2048M -XX:-UseGCOverheadLimit</value>

  </property>


  <property>
    <name>mapred.job.tracker.handler.count</name>

    <value>64</value>
  </property>


  <property>

    <name>io.sort.mb</name>
    <value>256</value>

  </property>


  <property>
    <name>io.sort.factor</name>

    <value>64</value>
  </property>

</configuration>

<h3 id="1-3-4-5-hadoop-env-sh">1.3.4.5 hadoop-env.sh</h3>
<p>/# The maximum amount of heap to use, in MB. Default is 1000.</p>
<p>export HADOOP_HEAPSIZE=6000</p>
<p>/# Extra Java runtime options. Empty by default.
/# if [&quot;$HADOOP_OPTS&quot; == &quot;&quot; ]; then export HADOOP_OPTS=-server; else HADOOP_OPTS+=&quot; -server&quot;</p>
<p>; fi</p>
<p>/# Command specific options appended to HADOOP_OPTS when specified
export HADOOP_NAMENODE_OPTS=&quot;-Xmx12000m $HADOOP_NAMENODE_OPTS&quot;export HADOOP_SECONDARYNAMENODE_OPTS=&quot;-Xmx12000m $HADOOP_SECONDARYNAMENODE_OPTS&quot;export HADOOP_DATANODE_OPTS=&quot;-Xmx6000m $HADOOP_DATANODE_OPTS&quot;export HADOOP_BALANCER_OPTS=&quot;-Xmx3000m $HADOOP_BALANCER_OPTS&quot;export HADOOP_JOBTRACKER_OPTS=&quot;-Xmx12000m $HADOOP_JOBTRACKER_OPTS&quot;</p>
<h3 id="1-3-4-6-hbase-site-xml">1.3.4.6 hbase-site.xml</h3>
<configuration>

  <property>
    <name>hbase.cluster.distributed</name>

    <value>true</value>
  </property>


  <property>

    <name>hbase.rootdir</name>
    <value>hdfs://umengds1.mob.cm3:8020/hbase</value>

  </property>


  <property>
    <name>hbase.zookeeper.quorum</name>

    <value>umengds1.mob.cm3,umengds2.mob.cm3</value>
  </property>


  <property>

    <name>hbase.hregion.memstore.mslab.enabled</name>
    <value>true</value>

  </property>


  <property>
    <name>hbase.regionserver.handler.count</name>

    <value>128</value>
  </property>


  <property>

    <name>hbase.client.write.buffer</name>
    <value>4194304</value>

  </property>


  <property>
    <name>hbase.hregion.memstore.block.multiplier</name>

    <value>8</value>
  </property>


  <property>

    <name>hbase.server.thread.wakefrequency</name>
    <value>1000</value>

  </property>


  <property>
    <name>hbase.regionserver.lease.period</name>

    <value>600000</value>
  </property>


  <property>

    <name>hbase.hstore.blockingStoreFiles</name>
    <value>15</value>

  </property>


  <property>
    <name>hbase.hregion.max.filesize</name>

    <value>2147483648</value>
  </property>


  <property>

    <name>hbase.ipc.client.tcpnodelay</name>
    <value>true</value>

  </property>


  <property>
    <name>ipc.ping.interval</name>

    <value>10000</value>
  </property>


  <property>

    <name>hbase.hregion.majorcompaction</name>
    <value>0</value>

  </property>


  <property>
    <name>hbase.regionserver.checksum.verify</name>

    <value>true</value>
  </property>

</configuration>

<h3 id="1-3-4-7-hbase-env-sh">1.3.4.7 hbase-env.sh</h3>
<p>/# The maximum amount of heap to use, in MB. Default is 1000.</p>
<p>export HBASE_HEAPSIZE=14000</p>
<p>/# Extra Java runtime options.
/# Below are what we set by default. May only work with SUN JVM.</p>
<p>/# For more on why as well as other possible settings,
/# see <a href="http://wiki.apache.org/hadoop/PerformanceTuning" target="_blank">http://wiki.apache.org/hadoop/PerformanceTuning</a></p>
<p>/# export HBASE_OPTS=
&quot;-ea -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode&quot;export HBASE_OPTS=&quot;-ea -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+UseCMSCompactAtFullCollection -XX:CMSInitiatingOccupancyFraction=90&quot;</p>
<h3 id="1-4-hadoop-">1.4 Hadoop权威指南</h3>
<h3 id="1-4-1-hadoop">1.4.1 初识Hadoop</h3>
<p>古代，人们用牛来拉中午，当一头牛拉不动一根圆木的时候，他们不曾想过培育更大更壮的牛。同样，我们也不需要尝试开发超级计算机，而应试着结合使用更多计算机系统。</p>
<h3 id="1-4-2-mapreduce">1.4.2 关于MapReduce</h3>
<ul>
<li>设置HADOOP_CLASSPATH就可以直接使用hadoop CLASSNAME来在本地运行mapreduce程序。</li>
<li><p>hadoop jar $HADOOP_HOME/contrib/streaming/hadoop-streaming-0.20.2-cdh3u3.jar 可以用来启动streaming任务</p>
</li>
<li><p>使用stdin/stdout来作为输入和输出</p>
</li>
<li><p><strong>NOTE（dirlt）：倒是可以探索一下如何使用，但是觉得能力有限</strong></p>
</li>
<li><p>Input/Output Format</p>
</li>
<li>外围环境的访问比如访问hdfs以及hbase</li>
<li>程序打包。比如使用很多第三方库的话在其他机器上面没有部署。</li>
<li><p>hadoop pipes 可以用来启动pipes任务</p>
</li>
<li><p>Hadoop的Pipes是Hadoop MapReduce的C++接口代称</p>
</li>
<li>使用Unix Domain Socket来作为输入和输出</li>
<li><p><strong>NOTE（dirlt）：可能使用上面还是没有native mr或者是streaming方式方便</strong></p>
<h3 id="1-4-3-hadoop-">1.4.3 Hadoop分布式文件系统</h3>
</li>
<li><p>使用hadoop archive能够将大量小文档打包，存档文件之能够只读访问</p>
</li>
<li><p>使用hadoop archive -archiveName <file>.har -p <parent-path> src dst</p>
</li>
<li><p>存档过程使用mapreduce完成，输出结果为目录</p>
</li>
<li><p>part-0 表示存档内容文件，应该是使用一个reduce做聚合。</p>
</li>
<li>_index,_masterindex 是对存档内容文件的索引文件。</li>
<li><p>har(hadoop archive)文件系统是建立在其他文件系统上面的，比如hdfs或者是local fs.</p>
</li>
<li><p>hadoop fs -ls har:///file.har 那么访问的是默认的文件系统上面的file.har</p>
</li>
<li>如果想显示地访问hdfs文件系统的话，那么可以hadoop fs -ls har://hdfs-localhost:9000/file.har</li>
<li>如果想显示地访问本地文件系统的话，那么可以使用hadoop fs -ls har://file-localhost/file.har</li>
<li>hadoop fs -ls har://schema-<host>/<path> 是通用的访问方式</li>
</ul>
<h3 id="1-4-4-hadoop-io">1.4.4 Hadoop IO</h3>
<ul>
<li><p>文件系统</p>
</li>
<li><p>ChecksumFileSystem</p>
</li>
<li><p>使用decorator设计模式，底层filesystem称为RawFileSystem</p>
</li>
<li>对于每个文件filename都会创建.filename.crc文件存储校验和</li>
<li>计算crc的单位大小通过io.bytes.per.checksum来进行控制</li>
<li>读取文件如果出现错误的话，那么会抛出ChecksumException</li>
<li><p>考虑到存在多副本的情况，如果读取某个副本出错的话，期间那么会调用reportChecksumFailure方法</p>
</li>
<li><p><strong>NOTE（dirlt）：这个部分的代码不太好读，非常绕</strong></p>
</li>
<li><p>RawLocalFileSystem</p>
</li>
<li><p>本地文件系统</p>
</li>
<li><p>LocalFileSystem</p>
</li>
<li><p>RawLocalFileSystem + ChecksumFileSystem</p>
</li>
<li>reportChecksumFailure实现为将校验和存在问题的文件移动到bad_files边际文件夹（side directory）</li>
<li><p>DistributedFileSystem</p>
</li>
<li><p>分布式文件系统</p>
</li>
<li><p>ChecksumDistributedFileSystem</p>
</li>
<li><p>DistributedFileSystem + ChecksumFileSystem</p>
</li>
<li><p>压缩解压</p>
</li>
<li><p>DEFLATE org.apache.hadoop.io.compress.DefaultCodec 扩展名.defalte</p>
</li>
<li>Gzip org.apache.hadoop.io.compress.GzipCodec 扩展名.gz 使用DEFLATE算法但是增加了额外的文件头。</li>
<li>bzip2 org.apache.hadoop.io.compress.BZip2Codec 扩展名.bz2 自身支持文件切分，内置同步点。</li>
<li><p>LZO com.hadoop.compression.lzo.LzopCodec 扩展名.lzo 和lzop工具兼容，LZO算法增加了额外的文件头。</p>
</li>
<li><p>LzopCodec则是纯lzo格式的codec,使用.lzo_deflate作为文件扩展名</p>
</li>
<li>因为LZO代码库拥有GPL许可，因此没有办法包含在Apache的发行版本里面。</li>
<li><p>运行MapReduce时候可能需要针对不同压缩文件解压读取，就需要构造CompressionCodec对象，我们可以通过CompressionCodecFactory来构造这个对象</p>
</li>
<li><p>CompressionCodecFactory读取变量io.compression.codecs</p>
</li>
<li>然后根据输入文件的扩展名来选择使用何种codec.</li>
<li>getDefaultExtension</li>
<li><p>压缩和解压算法可能同时存在Java实现和原生实现</p>
</li>
<li><p>如果是原生实现的话通常是.so，那么需要设置java.library.path或者是在环境变量里面设置LD_LIBRARY_PATH</p>
</li>
<li>如果同时有原生实现和Java实现，我们想只是使用原生实现的话，那么可以设置hadoop.native.lib = false来禁用原生实现。</li>
<li><p>压缩算法涉及到对应的InputFormat,也就涉及到是否支持切分</p>
</li>
<li><p>对于一些不支持切分的文件，可能存在一些外部工具来建立索引，从而支持切分。</p>
</li>
<li><p>下面这些选项可以针对map结果以及mapreduce结果进行压缩</p>
</li>
<li><p>mapred.output.compress = true 将mapreduce结果做压缩</p>
</li>
<li>mapred.output.compression.codec mapreduce压缩格式</li>
<li>mapred.output.compress.type = BLOCK/RECORD 如果输出格式为SequenceFile的话，那么这个参数可以控制是块压缩还是记录压缩</li>
<li><strong>NOTE（dirlt）：我现在强烈感觉MR的中间结果存储格式为SequenceFile</strong></li>
<li><strong>NOTE（dirlt）：应该是IFile，但是是否共享了这个配置呢？</strong></li>
<li>mapred.compress.map.output = true 将map结果做压缩</li>
<li><p>mapred.map.output.compression.codec map压缩格式</p>
</li>
<li><p>序列化</p>
</li>
<li><p>Hadoop的序列化都是基于Writable实现的，WritableComparable则是同时继承Writable,Comparable<T>.</p>
</li>
<li><p>序列化对象需要实现RawComparator，接口为public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2)进行二进制比较。</p>
</li>
<li><p>WritableComparator简化了这个实现，继承WritableComparator就实现了这个接口</p>
</li>
<li>但是这个接口实现起来非常naive，就是将两个byte stream反序列化然后调用对象的compareTo实现</li>
<li>如果想要提高效率的话，可以考虑通过直接比较两个byte stream来做优化。</li>
<li><p>基于文件的数据结构</p>
</li>
<li><p>SequenceFile 主要用来存储KV数据结构，多条记录之间会穿插一些同步标记，因此允许进行切分。</p>
</li>
<li><p>使用SequenceFileInputFormat和SequenceFileOutputFormat来读取和输出SequenceFile</p>
</li>
<li>hadoop fs -text 可以用来读取文件</li>
<li><p>mapred.output.compress.type = BLOCK/RECORD 可以用来控制压缩方式</p>
</li>
<li><p>如果没有使用压缩的话，那么格式为 recordLength(4byte) + keyLength(4byte) + key + value</p>
</li>
<li>如果使用记录压缩的话，那么格式为 recordLnegth(4byte) + keyLength(4byte) + key + compressedValue</li>
<li>如果使用块压缩的话，那么格式为 numberRecord(1-5byte) + keyLength(4byte) + compressedKeys + valueLength(4byte) + compressedValues.每个block之间会插入sync标记</li>
<li>块压缩大小可以使用io.seqfile.compress.blocksize来控制，默认1MB</li>
<li><p>MapFile 也是用来存储KV数据结构，但是可以认为已经按照了Key进行排序 <strong>NOTE（dirlt）：要求添加顺序就按照Key排序</strong></p>
</li>
<li><p>存储格式实际上也是SequenceFile，data，index都是。</p>
</li>
<li>底层会建立index，index在搜索的时候会加载到内存里面，这样可以减少data上的随机查询次数。</li>
<li>使用io.map.index.interval可以控制多少个item在index里面创建一个条目</li>
<li>使用io.map.index.skip = 0/1/2/n 可以控制skip几个index的item，如果为1的话那么表示只是使用1/2的索引。</li>
<li><p>从SequenceFile创建MapFile非常简单</p>
</li>
<li><p>首先使用sort将SequenceFile进行排序(可以使用hadoop example的sort）</p>
</li>
<li><p>然后调用hadoop MapFileFixer来建立索引</p>
<h3 id="1-4-5-mapreduce-">1.4.5 MapReduce应用开发</h3>
</li>
<li><p>Configuration用来读取配置文件，功能还是比较强大的，有变量替换的功能</p>
</li>
<li><property><name>…</name><value>…</value></property></li>
<li>如果使用<final>true</final>标记的话那么这个变量不允许被重置</li>
<li>变量替换可以使用${variable}</li>
<li><p>通过addResource来添加读取的配置文件</p>
</li>
<li><p>Hadoop集群有三种工作方式，分别为</p>
</li>
<li><p>standalone 使用单个JVM进程来模拟</p>
</li>
<li><p>如果不进行任何配置的话默认使用这个模式 <strong>NOTE（dirlt）：这个模式确实不错</strong></p>
</li>
<li>fs.default.name = file 本地文件系统</li>
<li>mapred.job.tracker = local</li>
<li><p>pseudo-distributed 本地启动单节点集群</p>
</li>
<li><p>fs.default.name = hdfs://localhost</p>
</li>
<li>mapred.job.tracker = localhost:8021</li>
<li><p>fully-distributed 完全分布式环境</p>
</li>
<li><p>fs.default.name = hdfs://<namenode></p>
</li>
<li><p>mapred.job.tracer = <jobtracker>:8021</p>
</li>
<li><p>使用hadoop启动MapReduce任务的常用参数</p>
</li>
</ul>
<ol>
<li>-D property=value 覆盖默认配置属性</li>
<li>-conf filename 添加配置文件</li>
<li>-fs uri 设置默认文件系统</li>
<li>-jt host:port 设置jobtracker</li>
<li>-files file,file2 这些文件可以在tasktracker工作目录下面访问</li>
<li>-archives archive,archive2 和files类似，但是是存档文件</li>
</ol>
<ul>
<li>突然觉得这个差别在files只能是平级结构，而archive可以是层级结构。</li>
<li>-libjars jar1,jar2 和files类似，通常这些JAR文件是MapReduce所需要的。</li>
</ul>
<p>如果希望运行时候动态创建集群的话，可以通过这几个类来创建</p>
<ul>
<li>MiniDFSCluster</li>
<li>MiniMRCluster</li>
<li>MiniHBaseCluster</li>
<li>MiniZooKeeperClutser</li>
<li><strong>NOTE(dirlt):都称为Mini???Cluster？</strong></li>
</ul>
<p>另外还有自带的ClusterMapReduceTestCase以及HBaseTestingUtility来帮助进行mapreduce的testcase. 这些类散步在hadoop,hbase,hadoop-test以及hbase-test里面。</p>
<p><strong>NOTE（dirlt）：但是个人觉得可能还是没有本地测试方便，不过倒是可以试试</strong></p>
<p>job，task and attempt</p>
<ul>
<li><p>jobID常见格式为 job_200904110811_0002</p>
</li>
<li><p>其中200904110811表示jobtracker从2009.04.11的08:11启动的</p>
</li>
<li>0002 表示第三个job,从0000开始计数。超过10000的话就不能够很好地排序</li>
<li><p>taskID常见格式为 task_200904110811_0002_m_000003</p>
</li>
<li><p>前面一串数字和jobID匹配，表示从属于这个job</p>
</li>
<li>m表示map任务，r表示reduce任务</li>
<li>000003表示这是第4个map任务。顺序是在初始化时候指定的，并不反应具体的执行顺序。</li>
<li><p>attemptID常见格式为 attempt_200904110811_0002_m_000003_0</p>
</li>
<li><p>前面一串数字和taskID匹配，表示从属与这个task</p>
</li>
<li>attempt出现的原因是因为一个task可能会因为失败重启或者是预测执行而执行多次</li>
<li>如果jobtracker重启而导致作业重启的话，那么做后面id从1000开始避免和原来的attempt冲突。</li>
</ul>
<p>作业调试</p>
<ul>
<li><p>相关配置</p>
</li>
<li><p>mapred.jobtracker.completeuserjobs.maximum 表示web页面下面展示completed jobs的个数，默认是100，超过的部分放到历史信息页。</p>
</li>
<li>mapred.jobtracker.restart.recover = true jobtracker重启之后自动恢复作业</li>
<li>hadoop.job.history.location 历史作业信息存放位置，超过30天删除，默认在_logs/history</li>
<li>hadoop.job.history.user.location 如果不为none那么历史作业信息在这里也会存在一份，不会删除。</li>
<li><p>相关命令</p>
</li>
<li><p>hadoop fs -getmerge <src> <dst> 能够将hdfs的src下面所有的文件merge合并成为一份文件并且copy到本地</p>
</li>
<li>hadoop job -history 察看作业历史</li>
<li>hadoop job -counter 察看作业计数器</li>
<li><p>相关日志</p>
</li>
<li><p>系统守护进程日志 写入HADOOP_LOG_DIR里面，可以用来监控namenode以及datanode的运行情况</p>
</li>
<li>MapReduce作业历史日志 _logs/history</li>
<li>MapReduce任务日志 写入HADOOP_LOG_DIR/userlogs里面，可以用来监控每个job的运行情况</li>
<li><p>分析任务</p>
</li>
<li><p>JobConf允许设置profile参数 <strong>NOTE（dirlt）：新的接口里面JobConf-&gt;JobContext-&gt;Job，Job没有这些接口，但是可以通过Configuration来设置</strong></p>
</li>
<li><p>setProfileEnabled 打开profile功能，默认false，属性 mapred.task.profile</p>
</li>
<li><p>setProfileParams 设置profile参数</p>
</li>
<li><p>属性 mapred.task.profile.params</p>
</li>
<li>默认使用hprof -agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s&quot;</li>
<li>其中%s会替换成为profile输出文件</li>
<li><strong>NOTE（dirlt）：其实这里似乎也可以设置成为jmxremote来通过jvisualvm来调试</strong></li>
<li><p>setProfileTaskRange(boolean,String)</p>
</li>
<li><p>参数1表示针对map还是reduce task做profile, true表示map, false表示reduce</p>
</li>
<li>参数2表示针对哪些tasks做优化，&quot;0-2&quot;表示针对0，1，2三个任务，默认也是&quot;0-2&quot;</li>
<li>map task对应属性mapred.task.profile.maps，reduce task对应属性mapred.task.profile.reduces</li>
<li><p>任务重现</p>
</li>
<li><p>首先将keep.failed.task.files设置为true,这样如果任务失败的话，那么这个任务的输入和输出都会保留下来</p>
</li>
<li><p>如果是map任务的话，那么输入分别会在本地保留</p>
</li>
<li>如果是reduce任务的话，那么对应的map任务输出会在本地保留</li>
<li>然后我们使用hadoop IsolationRunner job.xml来重新运行这个任务</li>
<li>可以修改HADOOP_OPTS添加远程调试选项来启动这个任务。</li>
<li>如果希望任务都保留而不仅仅是失败任务保留的话，那么可以设置 keep.task.files.pattern 为正则表达式（与保留的任务ID匹配）</li>
</ul>
<h3 id="1-4-6-mapreduce-">1.4.6 MapReduce的工作机制</h3>
<p>Hadoop运行MapReduce作业的工作原理</p>
<p><img src="" alt="./images/mapreduce-workflow-architecture.png"></p>
<p>其中有几点需要注意的：</p>
<ul>
<li>计算分片信息是在本地完成的，分片信息和其他resouce(包括jars,files,archives等）一起copy到HDFS上面，然后jobtracker直接读取分片信息。</li>
<li>提交的资源可以设置replication数目，高副本数目可以缓解tasktracker获取resource的压力。参数是mapred.submit.replication.</li>
<li>对于streaming以及pipes的实现，无非就是task并不直接执行任务，而是开辟另外一个子进程来运行streaming或者是pipes的程序。</li>
</ul>
<p><img src="" alt="./images/mapreduce-streamming-pipes.jpg"></p>
<p>进度和状态的更新</p>
<ul>
<li>map任务进度是已经处理输入的比例</li>
<li><p>reduce任务进度分为三个部分</p>
</li>
<li><p>shuffle 1/3</p>
</li>
<li>sort 1/3</li>
<li>reduce 1/3</li>
<li>也就是说如果刚运行完成sort的话，那么进度是2/3</li>
<li><p>状态的更新</p>
</li>
<li><p>触发事件</p>
</li>
<li><p>读取记录</p>
</li>
<li>输出记录</li>
<li>修改状态 reporter的setStatus</li>
<li>计数器修改</li>
<li>reporter的progress</li>
<li><p>子进程有单独线程每隔3秒检查progress位是否设置，如果设置的话那么和tasktracker发起心跳</p>
</li>
<li><p>通过mapred.task.timeout控制</p>
</li>
<li><p>tasktracker每隔5秒和jobtracker做心跳</p>
</li>
<li><p>心跳时间通过 mapred.tasktracker.expircy.interval 设置</p>
</li>
<li><p>jobClient定期会去jobtracker询问job是否完成</p>
</li>
<li><p>jobClient也可以设置属性job.end.notification.url,任务完成jobtracker会调用这个url</p>
</li>
<li>可以认为就是推拉方式的结合。</li>
</ul>
<p>失败检测和处理</p>
<ul>
<li><p>任务失败</p>
</li>
<li><p>子进程抛出异常的话，tasktracker将异常信息记录到日志文件然后标记失败</p>
</li>
<li>对于streaming任务的话非0退出表示出现问题，也可以使用stream.non.zero.exit.is.failure = false来规避（ <strong>这样是否就没有办法判断是否正常退出了？</strong> ）</li>
<li>如果长时间没有响应的话，没有和tasktracker有交互，那么也会认为失败。这个时间使用mapred.task.timeout控制，默认10min</li>
<li><p>如果任务失败的话，jobtracker会尝试进行多次重试</p>
</li>
<li><p>map重试次数通过 mapred.map.max.attempts 配置</p>
</li>
<li>reduce重试次数通过 mapre.reduce.max.attempts 配置</li>
<li><strong>任何任务重试超过4次的话那么会认为整个job失败</strong></li>
<li>另外需要区分KILLED状态和FAILED状态，对于KILLED状态可能是因为推测执行造成的，不会记录到failed attempts里面</li>
<li><p>如果我们希望允许少量任务失败的话，那么可以配置</p>
</li>
<li><p>mapred.max.map.failures.percent 允许map失败的最大比率</p>
</li>
<li>mapred.max.reduce.failures.percent 允许reduce失败的最大比率</li>
<li>如果一个job超过一定的task在某个tt上面运行失败的话，那么就会将这个tt加入到这个job的blacklist. mapred.max.tracker.failures = 4</li>
<li>如果job成功的话，检查运行task失败的tt并且标记，如果超过一定阈值的话，那么会将tt加入到全局的blacklist. mapred.max.tracker.blacklists = 4</li>
</ul>
<p>作业的调度</p>
<ul>
<li><p>fifo scheduler</p>
</li>
<li><p>可以通过mapred.job.priority或者是setJobPriority设置</p>
</li>
<li>当队列中有空闲的槽位需要执行任务时，从等待队列中选择优先级最高的作业</li>
<li>fair scheduler</li>
<li>capacity scheduler</li>
</ul>
<p>shuffle和排序</p>
<p><img src="" alt="./images/mapreduce-shuffle-sort.jpg"></p>
<p><img src="" alt="./images/mapreduce-shuffle-sort-2.png"></p>
<p>有下面这些参数控制shuffle和sort的过程 <strong>NOTE（dirlt）：书上倒是有很多参数，但是好多还是不太理解</strong></p>
<ul>
<li>io.sort.mb map输出缓存空间大小，默认是100MB. 建议设置10/* io.sort.factor.</li>
<li><p>io.sort.spill.percent 如果map输出超过了缓存空间大小的这个阈值的话，那么就会spill,默认是0.8</p>
</li>
<li><p>每次spill之前先会对这个文件进行排序，如果有combiner的话那么会在上面调用combiner</p>
</li>
<li>写磁盘是按照轮询的方式写到mapred.local.dir属性指定的目录下面</li>
<li>如果spill速度太慢的话，那么往缓存空间写入进程就会阻塞，直到spill腾出空间。</li>
<li><p>io.sort.factor 多路归并的数量，默认是10. 建议设置在25-32.</p>
</li>
<li><p>在map阶段，因为最终会存在多个spill文件，所以需要做多路归并。 <strong>TODO（dirlt）：如果归并数量少的话是否可能会多次merge？</strong></p>
</li>
<li>在reduce阶段的话，因为可能存在多路map输出的结果，所以需要做多路归并。</li>
<li>min.num.spill.for.combine 如果指定combiner并且spill次数超过这个值的话就会调用combine,默认为3</li>
<li>tasktracker.http.threads reduce通过HTTP接口来发起数据请求，这个就是HTTP接口相应线程数目，默认为40。 <strong>mapper as server</strong></li>
<li><p>mapred.reduce.parallel.copies reduce启动多少个线程去请求map输出，默认为5。 <strong>reducer as client</strong></p>
</li>
<li><p><strong>NOTE(dirlt):如果reduce和每个map都使用一个线程去请求输出结果的话，只要shuffle阶段没有出现network congestion，那么提高线程数量是有效果的</strong></p>
</li>
<li><strong>NOTE（dirlt）：可以设置到15-50</strong></li>
<li>mapred.reduce.copy.backoff = 300(s) reduce下载线程最大等待时间</li>
<li>mapred.job.shuffle.input.buffer.percent = 0.7 用来缓存shuffle数据的reduce task heap百分比</li>
<li>mapred.job.shuffle.merge.percent = 0.66 缓存的内存中多少百分比后开始做merge操作</li>
<li>mapred.job.reduce.input.buffer.percent = 0.0 sort完成后reduce计算阶段用来缓存数据的百分比. 默认来说不会使用任何内存来缓存，因此完全从磁盘上进行读取。</li>
</ul>
<p>任务的执行</p>
<ul>
<li><p>推测执行参数</p>
</li>
<li><p>如果某个任务执行缓慢的话会执行另外一个备份任务</p>
</li>
<li>mapred.map.tasks.speculative.execution true</li>
<li>mapred.reduce.tasks.speculative.execution true</li>
<li><p>JVM重用</p>
</li>
<li><p>一个JVM实例可以用来执行多个task.</p>
</li>
<li>mapred.job.reuse.jvm.num.tasks/setNumTasksToExecutePerJvm 单个JVM运行任务的最大数目</li>
<li>-1表示没有限制</li>
<li><p>任务执行环境</p>
</li>
<li><p>程序自身可以知道执行环境对于开发还是比较有帮助的</p>
</li>
<li><p>这些属性对于streaming可以通过环境变量获得</p>
</li>
<li><p><strong>对于streaming来说.替换成为_</strong></p>
</li>
<li>mapred.job.id string jobID</li>
<li>mapred.tip.id string taskID</li>
<li>mapred.task.id string attemptID</li>
<li>mapred.task.partition int 作业中任务编号</li>
<li>mapred.task.is.map boolean 是否为map</li>
<li>mapred.work.output.dir / FileOutputFormat.getWorkOutputPath 当前工作目录</li>
<li><p>杂项 <strong>NOTE（dirlt）：from misc articles</strong></p>
</li>
<li><p>mapred.job.map.capacity /# 最大同时运行map数量</p>
</li>
<li>mapred.job.reduce.capacity /# 最大同时运行reduce数量</li>
<li>mapred.job.queue.name /# 选择执行queue<h3 id="1-4-7-mapreduce-">1.4.7 MapReduce的类型与格式</h3>
</li>
</ul>
<p>MapReduce的类型</p>
<p>老API里面还有MapRunner这个类，这个类主要的作用是可以用来控制Mapper运行的方法，比如可以多线程来控制Mapper的运行。 但是在新API里面已经完全集成到Mapper实现里面来了，用户可以重写两个方法来完全控制mapper的运行</p>
<ul>
<li>map 如何处理kv</li>
<li><p>run 如何从context里面读取kv
protected void map(KEYIN key, VALUEIN value,</p>
<pre><code>             Context context) throws IOException, InterruptedException {
</code></pre><p>context.write((KEYOUT) key, (VALUEOUT) value);</p>
</li>
</ul>
<p>}
public void run(Context context) throws IOException, InterruptedException {</p>
<p>  setup(context);
  while (context.nextKeyValue()) {</p>
<pre><code>map(context.getCurrentKey(), context.getCurrentValue(), context);
</code></pre><p>  }</p>
<p>  cleanup(context);
}</p>
<p><strong>NOTE（dirlt）：觉得这个特性不是特别有用</strong></p>
<ul>
<li>mapred.input.format.class setInputFormat</li>
<li>mapred.mapoutput.key.class setMapOutputKeyClass</li>
<li>mapred.mapoutput.value.class setMapOutputValueClass</li>
<li>mapred.output.key.class setOutputKeyClass</li>
<li>mapred.output.value.class setOutputValueClass</li>
<li>mapred.mapper.class setMapperClass</li>
<li>mapred.map.runner.class setMapRunnerClass</li>
<li>mapred.combiner.class setCombinerClass</li>
<li>mapred.partitioner.class setPartitionerClass</li>
<li>mapred.output.key.comparator.class setOutputKeyComparatorClass</li>
<li>mapred.output.value.groupfn.class setOutputValueGroupingComparator</li>
<li>mapred.reducer.class setReducerClass</li>
<li>mapred.output.format.class setOutputFormat</li>
</ul>
<p>输入格式</p>
<p>对于InputFormat来说包含两个任务</p>
<ul>
<li>根据job描述来对输入进行切片（InputSplit）</li>
<li><p>根据切片信息来读取记录（RecordReader）
public abstract class InputFormat<K, V> {</p>
<p>public abstract
  List<InputSplit> getSplits(JobContext context</p>
<pre><code>                         ) throws IOException, InterruptedException;
</code></pre></li>
</ul>
<p>   public abstract
    RecordReader<K,V> createRecordReader(InputSplit split,</p>
<pre><code>                                     TaskAttemptContext context
                                    ) throws IOException,

                                             InterruptedException;
</code></pre><p>}</p>
<p>public abstract class InputSplit {
  public abstract long getLength() throws IOException, InterruptedException;</p>
<p>  public abstract</p>
<pre><code>String[] getLocations() throws IOException, InterruptedException;
</code></pre><p>}</p>
<p>public abstract class RecordReader<KEYIN, VALUEIN> implements Closeable {</p>
<p>  public abstract void initialize(InputSplit split,
                                  TaskAttemptContext context</p>
<pre><code>                              ) throws IOException, InterruptedException;
</code></pre><p>  public abstract
  boolean nextKeyValue() throws IOException, InterruptedException;</p>
<p>  public abstract</p>
<p>  KEYIN getCurrentKey() throws IOException, InterruptedException;</p>
<p>  public abstract
  VALUEIN getCurrentValue() throws IOException, InterruptedException;</p>
<p>  public abstract float getProgress() throws IOException, InterruptedException;</p>
<p>  public abstract void close() throws IOException;</p>
<p>}</p>
<p>下面是一些常见的InputFormat实现</p>
<ul>
<li><p>FileInputFormat</p>
</li>
<li><p>addInputPath或者是setInputPaths修改输入路径 mapred.input.dir</p>
</li>
<li><p>setInputPathFilter可以修改过滤器 mapred.input.path.Filter.class</p>
</li>
<li><p>基本实现会排除隐藏.或者是_开头文件。</p>
</li>
<li>自定义的过滤器是建立在默认过滤器的基础上的。</li>
<li><p>分片大小由下面三个参数控制</p>
</li>
<li><p>mapred.min.split.size 1</p>
</li>
<li>mapred.max.split.size MAX</li>
<li>dfs.block.size 64MB</li>
<li>算法是max(minSplitSize,min(maxSplitSize,blockSize))</li>
<li>isSplitable可以控制输入文件是否需要分片</li>
<li>CombineFileInputFormat 可以处理多个小文件输入，抽象类需要继承实现。</li>
<li><p>TextInputFormat</p>
</li>
<li><p>输入单位是行，key是LongWritable表示行偏移，value是Text表示行内容</p>
</li>
<li><p>KeyValueTextInputFormat</p>
</li>
<li><p>输入单位是行，按照key.value.seperator.in.input.line来进行分隔默认是\t</p>
</li>
<li>key和value的格式都是Text</li>
<li><p>NLineInputFormat</p>
</li>
<li><p>和TextInputFormat非常类似，大师使用多行输入默认为1行</p>
</li>
<li>通过mapred.line.input.format.linespermap来控制行数</li>
<li><p>XML</p>
</li>
<li><p>InputFormat使用StreamInputFormat,</p>
</li>
<li>设置RecordReader使用stream.recordreader.class来设置</li>
<li>RecordReader使用org.apache.hadoop.streaming.StreamXmlRecordReader</li>
<li><strong>NOTE（dirlt）：也有现成的XmlInputFormat的实现</strong></li>
<li>SequenceFileInputFormat</li>
<li><p>SequenceFileAsTextInputFormat</p>
</li>
<li><p>将输入的kv转换成为text对象适合streaming处理方式</p>
</li>
<li>SequenceFileAsBinaryInputFormat <strong>NOTE（dirlt）：似乎没有什么用！</strong></li>
<li>MultipleInputs</li>
<li>DBInputFormat/DBOutputFormat JDBC数据库输入输出</li>
<li>TableInputFormat/TableOutputFormat HBase输入输出</li>
</ul>
<p>输出格式</p>
<ul>
<li><p>TextOutputFormat</p>
</li>
<li><p>使用mpared.textoutputformat.seperator来控制kv的分隔，默认是\t</p>
</li>
<li>对应的输入格式为KeyValueTextInputFormat</li>
<li>可以使用NullWritable来忽略输出的k或者是v</li>
<li>SequenceFileOutputFormat</li>
<li>SequenceFileAsBinaryOutpuFormat <strong>NOTE（dirlt）：似乎没有什么用！</strong></li>
<li>MapFileOutputFormat</li>
<li>MultipleOutputFormat</li>
<li><p>MultipleOutputs</p>
</li>
<li><p>如果不像生成那写part-r-00000这些空文件的话，那么可以将OutputFormat设置成为NullOutputFormat</p>
</li>
<li>但是使用NullOutputFormat的话会没有输出目录，如果想保留目录的话那么可以使用LazyOutputFormat</li>
</ul>
<h3 id="1-4-8-mapreduce-">1.4.8 MapReduce的特性</h3>
<ul>
<li><p>计数器</p>
</li>
<li><p>streaming计数器和可以通过写stderr来提交</p>
</li>
<li><p>reporter:counter:<group>,<counter>,<amount></p>
</li>
<li>reporter:status:<message></li>
<li><p>连接</p>
</li>
<li><p>map端连接</p>
</li>
<li><p>必须确保多路输入文件的reduce数量相同以及键相同。</p>
</li>
<li>使用CompositeInputFormat来运行map端连接。</li>
<li><strong>NOTE（dirlt)；不过我稍微看了一下代码，实现上其实也是针对输入文件对每条记录读取，然后进行join包括inner或者是outer。感觉场景会有限，而且效率不会太高</strong></li>
<li><p>分布式缓存</p>
</li>
<li><p>使用-files以及-archives来添加缓存文件</p>
</li>
<li><p>也可以使用DistributedAPI来完成之间事情</p>
</li>
<li><p>addCacheFile/addCacheArchive</p>
</li>
<li>然后在task里面通过configuration的getLocalCacheFiles以及getLocalCacheArchives来获得这些缓存文件</li>
<li><p>工作原理</p>
</li>
<li><p>缓存文件首先被放到hdfs上面</p>
</li>
<li><p>task需要的话那么会尝试下载，之后会对这个缓存文件进行引用计数，如果为0那么删除</p>
</li>
<li><p>这也就意味着缓存文件可能会被多次下载</p>
</li>
<li>但是运气好的话多个task在一个node上面的话那么就不用重复下载</li>
<li>缓存文件存放在${mapred.local.dir}/taskTracker/archive下面，但是通过软连接指向工作目录</li>
<li>缓存大小通过local.cache.size来配置</li>
<li><p>MapReduce库类</p>
</li>
<li><p>ChainMapper/ChainReducer 能够在一个mapper以及reducer里面运行多次mapper以及reducer</p>
</li>
<li><p>ChainMapper 允许在Map阶段，多个mapper组成一个chain,然后连续进行调用</p>
</li>
<li>ChainReducer 允许在Reuduce阶段，reducer完成之后执行一个mapper chain.</li>
<li>最终达到的效果就是 M+ -&gt; R -&gt; M/* （1个或者是多个mapper, 一个reducer，然后0个或者是多个mapper)</li>
<li><p><strong>TODO(dirlt):这样做倒是可以将各个mapper组合起来用作adapter.</strong></p>
<h3 id="1-4-9-hadoop-">1.4.9 构建Hadoop集群</h3>
</li>
<li><p>很多教程说hadoop集群需要配置ssh,但是配置这个前提是你希望使用start-all.sh这个脚本来启动集群</p>
</li>
<li><p>我现在的公司使用apt-get来安装，使用cssh来登陆到所有的节点上面进行配置，因此没有配置这个信任关系</p>
</li>
<li><p>Hadoop配置</p>
</li>
<li><p>配置文件</p>
</li>
<li><p>hadoop-env.sh 环境变量脚本</p>
</li>
<li>core-site.xml core配置，包括hdfs以及mapred的IO配置等</li>
<li>hdfs-site.xml hadoop进程配置比如namenode以及datanode以及secondary namenode</li>
<li>mapred-site.xml mapred进程配置比如jobtracker以及tasktracker</li>
<li><p>masters 运行namenode（secondary namenode)的机器列表，每行一个, <strong>无需分发到各个节点</strong></p>
</li>
<li><p><strong>在本地启动primary namenode</strong></p>
</li>
<li><p>slaves 运行datanode以及tasktracker的机器列表，每行一个 <strong>无需分发到各个节点</strong></p>
</li>
<li><p><strong>在本地启动jobtracker</strong></p>
</li>
<li>hadoop-metrics.properties 对hadoop做监控的配置文件</li>
<li>log4j.properties 日志配置文件</li>
<li>这些文件在conf目录下面有，如果想使用不同的文件也可以使用-config来另行指定</li>
<li><strong>NOTE(dirlt):所以从上面这个脚本来看，还是具有一定的局限性的</strong></li>
<li><p>hadoop-env.sh</p>
</li>
<li><p>HADOOP_HEAPSIZE = 1000MB 守护进程大小</p>
</li>
<li>HADOOP_NAMENODE_OPTS</li>
<li>HADOOP_SECONDARYNAMENODE_OPTS</li>
<li>HADOOP_IDENT_STRING 用户名称标记，默认为${USER}</li>
<li>HADOOP_LOG_DIR hadoop日志文件，默认是HADOOP_INSTALL/logs</li>
<li><p>core-site.xml</p>
</li>
<li><p>io.file.buffer.size IO操作缓冲区大小，默认是4KB <strong>这个需要提高</strong></p>
</li>
<li><p>hdfs-site.xml</p>
</li>
<li><p>fs.default.name</p>
</li>
<li>hadoop.tmp.dir hadoop临时目录，默认是在/tmp/hadoop-${user.name}</li>
<li>dfs.name.dir namenode数据目录，一系列的目录，namenode内容会同时备份在所有指定的目录中。默认为${hadoop.tmp.dir}/dfs/name</li>
<li>dfs.data.dir datanode数据目录，一系列的目录，循环将数据写在各个目录里面。默认是${hadoop.tmp.dir}/dfs/data</li>
<li>fs.checkpoint.dir secondarynamenode数据目录，一系列目录，所有目录都会写一份。默认为${hadoop.tmp.dir}/dfs/namesecondary</li>
<li>dfs.namenode.handler.count namenode上用来处理请求的线程数目</li>
<li>dfs.datanode.ipc.address 0.0.0.0:50020 datanode的RPC接口，主要和namenode交互</li>
<li>dfs.datanode.address 0.0.0.0:50010 datanode的data block传输接口，主要和client交互</li>
<li>dfs.datanode.http.address 0.0.0.0:50075 datanode的HTTP接口，和user交互</li>
<li>dfs.datanode.handler.count datanode上用来处理请求的线程数目</li>
<li>dfs.datanode.max.xcievers datanode允许最多同时打开的文件数量</li>
<li>dfs.http.address 0.0.0.0:50070 namenode的HTTP接口</li>
<li>dfs.secondary.http.address 0.0.0.0:50090 secondard namenode的HTTP接口</li>
<li>dfs.datanode.dns.interface default 绑定的NIC，默认是绑定默认的NIC比如eth0</li>
<li>dfs.hosts / dfs.hosts.exclude 加入的datanode以及排除的datanode</li>
<li>dfs.replication = 3 副本数目</li>
<li>dfs.block.size = 64MB</li>
<li>dfs.datanode.du.reserved 默认datanode会使用目录所在磁盘所有空间，这个值可以保证有多少空间被reserved的</li>
<li><p>fs.trash.interval 单位分钟，如果不为0的话，那么删除文件会移动到回收站，超过这个单位时间的文件才会完全删除。</p>
</li>
<li><p>回收站位置/home/${user]/.Trash <strong>NOTE(dirlt):回收站这个功能只是对fs shell有效。fs shell remove时候会构造Trash这个类来处理删除文件的请求。如果调用Java API的话那么会直接删除文件</strong></p>
</li>
<li>haddop fs -expunge 强制删除</li>
<li><strong>NOTE（dirlt）：grep代码发现只有NameNode在TrashEmptier里面构造了Trash这个类，因此这个配置之需要在nn上配置即可，决定多久定期删除垃圾文件</strong></li>
<li><p>fs.trash.checkpoint.interval 单位分钟，namenode多久检查一次文件是否需要删除。</p>
</li>
<li><p><strong>NOTE（dirlt）：似乎没有这个参数。如果没有这个参数的话，那么两次检查时长应该是由参数fs.trasn.interval来决定</strong></p>
</li>
<li><p>mapred-site.xml</p>
</li>
<li><p>mapred.job.tracker</p>
</li>
<li>mapred.local.dir MR中间数据存储，一系列目录，分散写到各个目录下面，默认为${hadoop.tmp.dir}/mapred/local</li>
<li>mapred.system.dir MR运行期间存储，比如存放jar或者是缓存文件等。默认${hadoop.tmp.dir}/mapred/system</li>
<li>mapred.tasktracker.map.tasks.maximum = 2 单个tasktracker最多多少map任务</li>
<li>mapred.tasktracker.reduce.tasks.maximum = 2 单个tasktracker最多多少个reduce任务</li>
<li>mapred.tasktracker.dns.interface default 绑定的NIC，默认是绑定默认的NIC比如eth0</li>
<li>mapred.child.ulimit 单个tasktracker允许子进程占用的最大内存空间。通常为2-3/* mapred.child.java.opts.</li>
<li><p>mapred.child.java.opts = -Xmx200m 每个子JVM进程200M. <strong>NOTE（dirlt）：这个是在提交机器上面设置的，而不是每个tasktracker上面设置的，每个job可以不同</strong></p>
</li>
<li><p>不一定支持将map/reduce的jvm参数分开设置 <a href="http://hadoop-common.472056.n3.nabble.com/separate-JVM-flags-for-map-and-reduce-tasks-td743351.html" target="_blank"><a href="http://hadoop-common.472056.n3.nabble.com/separate-JVM-flags-for-map-and-reduce-tasks-td743351.html">http://hadoop-common.472056.n3.nabble.com/separate-JVM-flags-for-map-and-reduce-tasks-td743351.html</a></a></p>
</li>
<li><strong>NOTE（dirlt）：个人折中思路是限制内存大小为1G，然后大内存机器允许同时执行map/reduce数量上限提高，通过增加job的map/reduce数量来提高并发增加性能</strong></li>
<li><p><strong>NOTE（dirlt）：我grep了一下cdh3u3的代码，应该是将map/reduce的jvm参数分开进行了设置</strong></p>
</li>
<li><p>mapred.map.child.java.opts</p>
</li>
<li>mapred.reduce.child.java.opts</li>
<li>mapred.task.tracker.report.address 127.0.0.1:0 tasktracker启动子进程通信的端口，0表示使用任意端口</li>
<li>mapred.task.tracker.expiry.interval 600(sec) tt和jt之间的心跳间隔</li>
<li>mapred.job.tracker.handler.count. jobtracker用来处理请求的线程数目。</li>
<li>mapred.job.tracker.http.address 0.0.0.0:50030 jobtracker的HTTP接口</li>
<li>mapred.task.tracker.http.address 0.0.0.0:50060 tasktrackder的HTTP接口</li>
<li>mapred.hosts / mapred.hosts.exclude 加入的tasktracker以及排除的tasktracker.</li>
<li><p>Hadoop Benchmark <strong>NOTE（dirlt）：try it out</strong></p>
</li>
<li><p>在hadoop安装目录下面有jar可以来做基准测试</p>
</li>
<li>TestDFSIO测试HDFS的IO性能</li>
<li>Sort测试MapReduce性能</li>
<li>MRBench多次运行一个小作业来检验小作业能否快速相应</li>
<li>NNBench测试namenode硬件的负载</li>
</ul>
<h3 id="1-4-10-hadoop">1.4.10 管理Hadoop</h3>
<ul>
<li><p>永久性数据结构</p>
</li>
<li><p>namenode的目录结构</p>
</li>
<li><p>current表示当前的namenode数据（对于辅助节点上这个数据并不是最新的）</p>
</li>
<li><p>previous.checkpoint表示secondarynamenode完成checkpoint的数据（和current可能存在一些编辑差距）</p>
</li>
<li><p>hadoop dfsadmin -saveNamespace 可以强制创建检查点,仅仅在安全模式下面运行</p>
</li>
<li><p>辅助namenode每隔5分钟会检查</p>
</li>
<li><p>如果超过fs.checkpoint.period = 3600（sec），那么会创建检查点</p>
</li>
<li>如果编辑日志大小超过fs.checkpoint.size = 64MB,同样也会创建检查点</li>
<li>除了将文件copy到namenode之外，在辅助节点上面可以使用选项-importCheckpoint来载入</li>
<li><p>VERSION Java属性文件</p>
</li>
<li><p>namespaceID 每次格式化都会重新生成一个ID，这样可以防止错误的datanode加入</p>
</li>
<li>cTime namenode存储系统创建时间，对于刚格式化的存储系统为0.对于升级的话会更新到最新的时间戳</li>
<li>storageType NAME_NODE or DATA_NODE</li>
<li>layoutVersion 负整数表示hdfs文件系统布局版本号，对于hadoop升级的话这个版本号可能不会变化</li>
<li>edits 编辑日志文件</li>
<li>fsimage 镜像文件</li>
<li>fstime ???</li>
<li><p>datanode的目录结构</p>
</li>
<li><p>blk<em><id>以及blk</em><id>.meta 表示块数据以及对应的元信息，元数据主要包括校验和等内容</p>
</li>
<li>如果datanode文件非常多的话，超过dfs.datanode.numblocks = 64的话，那么会创建一个目录单独存放，最终结果就是形成树存储结构。</li>
<li>dfs.data.dir目录是按照round-robin的算法选择的。</li>
<li><p>安全模式</p>
</li>
<li><p>namenode启动的时候会尝试合并edit数据并且新建一个checkpoint，然后进入安全模式，在这个模式内文件系统是只读的</p>
</li>
<li>可以通过hadoop dfsadmin -safemode来操作安全模式</li>
<li><p>当达到下面几个条件的时候会离开安全模式</p>
</li>
<li><p>整个系统的副本数目大于某个阈值的副本数目比率超过一个阈值之后，然后继续等待一段时间就会离开安全模式</p>
</li>
<li>dfs.replication.min = 1 副本数目阈值</li>
<li>dfs.safemode.threshold.pct = 0.999 比率阈值</li>
<li>dfs.safemode.extension = 30000(ms) 等待时间</li>
<li><p>工具</p>
</li>
<li><p>dfsadmin</p>
</li>
<li>fsck</li>
<li><p>scanner</p>
</li>
<li><p>DataBlockScanner每隔一段时间会扫描本地的data block检查是否出现校验和问题</p>
</li>
<li>时间间隔是dfs.datanode.scan.period.hours = 504默认三周</li>
<li>可以通过页面访问每个datanode的block情况 <a href="http://localhost:50075/blockScannerReport" target="_blank"><a href="http://localhost:50075/blockScannerReport">http://localhost:50075/blockScannerReport</a></a></li>
<li>加上listblocks参数可以看每个block情况 <a href="http://localhost:50075/blockScannerReport?listblocks" target="_blank"><a href="http://localhost:50075/blockScannerReport?listblocks">http://localhost:50075/blockScannerReport?listblocks</a></a> <strong>NOTE（dirlt）：可能会很大</strong></li>
<li><p>balancer</p>
</li>
<li><p>通过start-balancer.sh来启动,集群中只允许存在一个均衡器</p>
</li>
<li>均衡的标准是datanode的利用率和集群平均利用率的插值，如果超过某个阈值就会进行block movement</li>
<li>-threshold可以执行阈值，默认为10%</li>
<li>dfs.balance.bandwidthPerSec = 1024 /* 1024 用于balance的带宽上限。</li>
<li><p>监控</p>
</li>
<li><p>日志</p>
</li>
<li><p>jobtracker的stack信息（thread-dump）<a href="http://localhost:50030/stacks" target="_blank"><a href="http://localhost:50030/stacks">http://localhost:50030/stacks</a></a></p>
</li>
<li><p>度量</p>
</li>
<li><p>度量从属于特性的上下文(context),包括下面几个</p>
</li>
<li><p>dfs</p>
</li>
<li>mapred</li>
<li>rpc</li>
<li>jvm</li>
<li><p>下面是几种常见的context</p>
</li>
<li><p>FileContext 度量写到文件</p>
</li>
<li>GangliaContext 度量写到ganglia <strong>(这个似乎比较靠谱）</strong></li>
<li>CompositeContext 组合context</li>
<li>度量可以从hadoop-metrics.properties进行配置</li>
</ul>
<h3 id="1-5-benchmark">1.5 Benchmark</h3>
<ul>
<li>Benchmarking and Stress Testing an Hadoop Cluster with TeraSort, TestDFSIO &amp; Co. - Michael G. Noll <a href="http://www.michael-noll.com/blog/2011/04/09/benchmarking-and-stress-testing-an-hadoop-cluster-with-terasort-testdfsio-nnbench-mrbench/" target="_blank"><a href="http://www.michael-noll.com/blog/2011/04/09/benchmarking-and-stress-testing-an-hadoop-cluster-with-terasort-testdfsio-nnbench-mrbench/">http://www.michael-noll.com/blog/2011/04/09/benchmarking-and-stress-testing-an-hadoop-cluster-with-terasort-testdfsio-nnbench-mrbench/</a></a></li>
<li>intel-hadoop/HiBench · GitHub <a href="https://github.com/intel-hadoop/HiBench" target="_blank"><a href="https://github.com/intel-hadoop/HiBench">https://github.com/intel-hadoop/HiBench</a></a></li>
<li>HBase Performance Testing at hstack <a href="http://hstack.org/hbase-performance-testing/" target="_blank"><a href="http://hstack.org/hbase-performance-testing/">http://hstack.org/hbase-performance-testing/</a></a></li>
<li>Performance testing / Benchmarking a HBase cluster – Sujee Maniyam <a href="http://sujee.net/tech/articles/hadoop/hbase-performance-testing/" target="_blank"><a href="http://sujee.net/tech/articles/hadoop/hbase-performance-testing/">http://sujee.net/tech/articles/hadoop/hbase-performance-testing/</a></a></li>
<li>new Put(&quot;lars&quot;.toBytes(&quot;UTF-8&quot;)) : Performance testing HBase using YCSB <a href="http://blog.lars-francke.de/2010/08/16/performance-testing-hbase-using-ycsb/" target="_blank"><a href="http://blog.lars-francke.de/2010/08/16/performance-testing-hbase-using-ycsb/">http://blog.lars-francke.de/2010/08/16/performance-testing-hbase-using-ycsb/</a></a></li>
<li>Hbase/PerformanceEvaluation - Hadoop Wiki <a href="http://wiki.apache.org/hadoop/Hbase/PerformanceEvaluation" target="_blank"><a href="http://wiki.apache.org/hadoop/Hbase/PerformanceEvaluation">http://wiki.apache.org/hadoop/Hbase/PerformanceEvaluation</a></a></li>
</ul>
<h3 id="1-5-1-testdfsio">1.5.1 TestDFSIO</h3>
<p>测试hdfs吞吐
hdfs@hadoop1:~$ hadoop jar /usr/lib/hadoop/hadoop-test-0.20.2-cdh3u3.jar TestDFSIO</p>
<p>Usage: TestDFSIO [genericOptions] -read | -write | -append | -clean [-nrFiles N] [-fileSize Size[B|KB|MB|GB|TB]] [-resFile resultFileName] [-bufferSize Bytes] [-rootDir]%</p>
<ul>
<li>read / write / append / clean 操作类型 <strong>append和write执行效率差别不大，但是write会创建新文件所以使用比较方便</strong> (default read)</li>
<li>nrFiles 文件数目(default 1) <strong>启动相同数量的map</strong></li>
<li>fileSize 每个文件大小(1MB)</li>
<li>resFile 结果报告文件(TestDFSIO_results.log)</li>
<li>bufferSize write buffer size(单次write写入大小）（1000000 bytes)</li>
<li><p>rootDir 操作文件根目录（/benchmarks/TestDFSIO/）
----- TestDFSIO ----- : write</p>
<pre><code>     Date &amp; time: Thu Apr 25 19:14:21 CST 2013
 Number of files: 2
</code></pre></li>
</ul>
<p>Total MBytes processed: 2.0
     Throughput mb/sec: 7.575757575757576</p>
<p>Average IO rate mb/sec: 7.61113977432251
IO rate std deviation: 0.5189420757292891</p>
<pre><code>Test exec time sec: 14.565
</code></pre><p>----- TestDFSIO ----- : read
           Date &amp; time: Thu Apr 25 19:15:13 CST 2013</p>
<pre><code>   Number of files: 2
</code></pre><p>Total MBytes processed: 2.0</p>
<pre><code> Throughput mb/sec: 27.77777777777778
</code></pre><p>Average IO rate mb/sec: 28.125</p>
<p>IO rate std deviation: 3.125
    Test exec time sec: 14.664</p>
<ul>
<li>throughtput = sum(filesize) / sum(time)</li>
<li>avaerage io rate = sum(filesize/time) / n</li>
<li>io rate std deviation<h3 id="1-5-2-terasort">1.5.2 TeraSort</h3>
</li>
</ul>
<p>通过排序测试MR执行效率 <strong>我看了一下代码map/reduce都有CPU操作，并且这个也非常依靠shuffle/copy.因此这个测试应该会是比较全面的</strong>
hdfs@hadoop1:~$ hadoop jar /usr/lib/hadoop/hadoop-examples-0.20.2-cdh3u3.jar <command></p>
<ul>
<li><p>teragen 产生排序数据</p>
</li>
<li><number of 100-byte rows>
</li>
<li><p>10 bytes key(random characters)</p>
</li>
<li>10 bytes rowid(right justified row id as a int)</li>
<li>78 bytes filler</li>
<li>\r\n</li>
<li><output dir></li>
<li><p>terasort 对数据排序</p>
</li>
<li><input dir></li>
<li><output dir></li>
<li>teravalidate 对排序数据做验证</li>
</ul>
<p>可以使用hadoop job -history all <job-output-dir>来观察程序运行数据，也可以通过web page来分析。</p>
<h3 id="1-5-3-nnbench">1.5.3 nnbench</h3>
<p>测试nn负载能力
➜  ~HADOOP_HOME  hadoop jar hadoop-test-0.20.2-cdh3u3.jar nnbench</p>
<p>NameNode Benchmark 0.4
Usage: nnbench <options></p>
<p>Options:
        -operation <Available operations are create_write open_read rename delete. This option is mandatory></p>
<pre><code>     /* NOTE: The open_read, rename and delete operations assume that the files they operate on, are already available. The create_write operation must be run before running the other operations.
    -maps &lt;number of maps. default is 1. This is not mandatory&gt;

    -reduces &lt;number of reduces. default is 1. This is not mandatory&gt;
    -startTime &lt;time to start, given in seconds from the epoch. Make sure this is far enough into the future, so all maps (operations) will start at the same time&gt;. default is launch time + 2 mins. This is not mandatory

    -blockSize &lt;Block size in bytes. default is 1. This is not mandatory&gt;
    -bytesToWrite &lt;Bytes to write. default is 0. This is not mandatory&gt;

    -bytesPerChecksum &lt;Bytes per checksum for the files. default is 1. This is not mandatory&gt;
    -numberOfFiles &lt;number of files to create. default is 1. This is not mandatory&gt;

    -replicationFactorPerFile &lt;Replication factor for the files. default is 1. This is not mandatory&gt;
    -baseDir &lt;base DFS path. default is /becnhmarks/NNBench. This is not mandatory&gt;

    -readFileAfterOpen &lt;true or false. if true, it reads the file and reports the average time to read. This is valid with the open_read operation. default is false. This is not mandatory&gt;
    -help: Display the help statement
</code></pre><ul>
<li>startTime 作用是为了能够让所有的map同时启动以便对nn造成压力
➜  ~HADOOP_HOME  hadoop jar hadoop-test-0.20.2-cdh3u3.jar nnbench -operation create_write -bytesToWrite 0 -numberOfFiles 1200</li>
</ul>
<p>➜  ~HADOOP_HOME  hadoop jar hadoop-test-0.20.2-cdh3u3.jar nnbench -operation open_read</p>
<p>结果报告文件是 NNBench_results.log</p>
<p>-------------- NNBench -------------- :</p>
<pre><code>                           Version: NameNode Benchmark 0.4
                       Date &amp; time: 2013-04-25 19:41:02,873


                    Test Operation: create_write

                        Start time: 2013-04-25 19:40:21,70
                       Maps to run: 1

                    Reduces to run: 1
                Block Size (bytes): 1

                    Bytes to write: 0
                Bytes per checksum: 1

                   Number of files: 1200
                Replication factor: 1

        Successful file operations: 1200


    /# maps that missed the barrier: 0
                      /# exceptions: 0


           TPS: Create/Write/Close: 75
</code></pre><p>Avg exec time (ms): Create/Write/Close: 26.526666666666667
            Avg Lat (ms): Create/Write: 13.236666666666666</p>
<pre><code>               Avg Lat (ms): Close: 13.164166666666667


             RAW DATA: AL Total /#1: 15884
             RAW DATA: AL Total /#2: 15797

          RAW DATA: TPS Total (ms): 31832
   RAW DATA: Longest Map Time (ms): 31832.0

               RAW DATA: Late maps: 0
         RAW DATA: /# of exceptions: 0
</code></pre><p>-------------- NNBench -------------- :</p>
<pre><code>                           Version: NameNode Benchmark 0.4
                       Date &amp; time: 2013-04-25 19:44:42,354


                    Test Operation: open_read

                        Start time: 2013-04-25 19:44:31,921
                       Maps to run: 1

                    Reduces to run: 1
                Block Size (bytes): 1

                    Bytes to write: 0
                Bytes per checksum: 1

                   Number of files: 1
                Replication factor: 1

        Successful file operations: 1


    /# maps that missed the barrier: 0
                      /# exceptions: 0


                    TPS: Open/Read: 500

     Avg Exec time (ms): Open/Read: 2.0
                Avg Lat (ms): Open: 2.0


             RAW DATA: AL Total /#1: 2

             RAW DATA: AL Total /#2: 0
          RAW DATA: TPS Total (ms): 2

   RAW DATA: Longest Map Time (ms): 2.0
               RAW DATA: Late maps: 0

         RAW DATA: /# of exceptions: 0
</code></pre><ul>
<li>maps that missed the barrier 从代码上分析是，在等待到start time期间中,如果sleep出现异常的话。</li>
<li>exceptions 表示在操作文件系统时候的exception数量</li>
<li>TPS transactions per second</li>
<li>exec（execution） 执行时间</li>
<li>lat（latency） 延迟时间</li>
<li>late maps 和 maps missed the barrier是一个概念。</li>
</ul>
<p>对于后面RAW DATA部分的话，从代码上看，就是为了计算出上面那些指标的，所以没有必要关注。</p>
<h3 id="1-5-4-mrbench">1.5.4 mrbench</h3>
<p>测试运行small mr jobs执行效率，主要关注响应时间。
MRBenchmark.0.0.2</p>
<p>Usage: mrbench [-baseDir <base DFS path for output/input, default is /benchmarks/MRBench>] [-jar <local path to job jar file containing Mapper and Reducer implementations, default is current jar file>] [-numRuns <number of times to run the job, default is 1>] [-maps <number of maps for each run, default is 2>] [-reduces <number of reduces for each run, default is 1>] [-inputLines <number of input lines to generate, default is 1>] [-inputType <type of input to generate, one of ascending (default), descending, random>] [-verbose]</p>
<ul>
<li>baseDir 输入输出目录</li>
<li>jar 通常不需要指定，用默认即可。</li>
<li>inputLines 输入条数</li>
<li>inputType 输入是否有序
hdfs@hadoop1:~$ hadoop jar /usr/lib/hadoop/hadoop-test-0.20.2-cdh3u3.jar mrbench -verbose</li>
</ul>
<p>结果直接输出在终端上面，</p>
<p>Total MapReduce jobs executed: 1</p>
<p>Total lines of data per job: 1
Maps per job: 2</p>
<p>Reduces per job: 1
Total milliseconds for task: 1 = 16452</p>
<p>DataLines       Maps    Reduces AvgTime (milliseconds)
1               2       1       16452</p>
<p>可以看到每个任务平均执行时间在16.452s.</p>
<h3 id="1-5-5-hbase-performanceevaluation">1.5.5 hbase.PerformanceEvaluation</h3>
<p>hdfs@hadoop1:~$ hbase org.apache.hadoop.hbase.PerformanceEvaluation</p>
<p>Usage: java org.apache.hadoop.hbase.PerformanceEvaluation \
  [--miniCluster] [--nomapred] [--rows=ROWS] <command> <nclients></p>
<p>Options:</p>
<p> miniCluster     Run the test on an HBaseMiniCluster
 nomapred        Run multiple clients using threads (rather than use mapreduce)</p>
<p> rows            Rows each client runs. Default: One million
 flushCommits    Used to determine if the test should flush the table.  Default: false</p>
<p> writeToWAL      Set writeToWAL on puts. Default: True</p>
<p>Command:
 filterScan      Run scan test using a filter to find a specific row based on it&#39;s value (make sure to use --rows=20)</p>
<p> randomRead      Run random read test
 randomSeekScan  Run random seek and scan 100 test</p>
<p> randomWrite     Run random write test
 scan            Run scan test (read every row)</p>
<p> scanRange10     Run random seek scan with both start and stop row (max 10 rows)
 scanRange100    Run random seek scan with both start and stop row (max 100 rows)</p>
<p> scanRange1000   Run random seek scan with both start and stop row (max 1000 rows)
 scanRange10000  Run random seek scan with both start and stop row (max 10000 rows)</p>
<p> sequentialRead  Run sequential read test
sequentialWrite Run sequential write test</p>
<p>Args:</p>
<p> nclients        Integer. Required. Total number of clients (and HRegionServers)
                 running: 1 &lt;= value &lt;= 500</p>
<p>Examples:
To run a single evaluation client:</p>
<p>$ bin/hbase org.apache.hadoop.hbase.PerformanceEvaluation sequentialWrite 1</p>
<p>从参数上看还是比较直接的。benchmark每个client通常对应10个mapper, 每个client操作<rows>个row,因此每个mapper操作<rows>/10个row,每个row大约1000bytes.</p>
<ul>
<li>filterScan 随机生成value，然后从头开始scan直到equal</li>
<li>randomRead 随机选取key读取</li>
<li>randomSeekScan 从某个随机位置开始scan最多100个</li>
<li>randomWrite 随即生成key写入</li>
<li>scan 每次scan 1个row，start随机</li>
<li>scan<num> 每次scan num个row，start随机</li>
<li>seqRead 顺序地读取每个key</li>
<li>seqWrite 顺序地写入每个key</li>
<li><strong>NOTE(dirlt):这里的key都非常简单，10个字符的数字，printf(&quot;%010d&quot;,row)</strong>
hdfs@hadoop1:~$ time hbase org.apache.hadoop.hbase.PerformanceEvaluation --rows=1000 sequentialWrite 2</li>
</ul>
<p>13/04/25 23:47:56 INFO mapred.JobClient:   HBase Performance Evaluation
13/04/25 23:47:56 INFO mapred.JobClient:     Row count=2000</p>
<p>13/04/25 23:47:56 INFO mapred.JobClient:     Elapsed time in milliseconds=258</p>
<p>输出结果是在counter里面，这里面row count = 2000, 占用时间为258 ms.
Date: 2013-12-15T10:28+0800</p>
<p><a href="http://orgmode.org/" target="_blank">Org</a> version 7.9.2 with <a href="http://www.gnu.org/software/emacs/" target="_blank">Emacs</a> version 24
<a href="http://validator.w3.org/check?uri=referer" target="_blank">Validate XHTML 1.0</a>
来源： <a href="[http://dirlt.com/hadoop.html/#sec-1-1-4](http://dirlt.com/hadoop.html#sec-1-1-4)">[http://dirlt.com/hadoop.html/#sec-1-1-4](http://dirlt.com/hadoop.html#sec-1-1-4)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--hadoop/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--hadoop" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/111/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/109/">109</a></li><li><a class="page-number" href="/page/110/">110</a></li><li><a class="page-number" href="/page/111/">111</a></li><li class="active"><li><span class="page-number current">112</span></li><li><a class="page-number" href="/page/113/">113</a></li><li><a class="page-number" href="/page/114/">114</a></li><li><a class="page-number" href="/page/115/">115</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/164/">164</a></li><li><a class="page-number" href="/page/165/">165</a></li><li><a class="extend next" href="/page/113/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Blog powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a> Theme <strong><a href='https://github.com/chenall/hexo-theme-chenall'>chenall</a></strong>(Some change in it)<span class="pull-right"> 更新时间: <em>2014-03-15 16:33:42</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
