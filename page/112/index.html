
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 112 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--mapred_tutorial/">mapred_tutorial</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--mapred_tutorial/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="mapred_tutorial">mapred_tutorial</h1>
<p>Map/Reduce Tutorial
Table of contents
1 2 3 4 5
Purpose...............................................................................................................................2 Pre-requisites......................................................................................................................2 Overview............................................................................................................................2 Inputs and Outputs............................................................................................................. 3 Example: WordCount v1.0................................................................................................ 3
5.1 5.2 5.3
Source Code...................................................................................................................3 Usage............................................................................................................................. 6 Walk-through.................................................................................................................7 Payload.......................................................................................................................... 9 Job Configuration........................................................................................................ 13 Task Execution &amp; Environment.................................................................................. 14 Job Submission and Monitoring..................................................................................21 Job Input...................................................................................................................... 22 Job Output................................................................................................................... 23 Other Useful Features..................................................................................................25 Source Code.................................................................................................................31 Sample Runs................................................................................................................37 Highlights.................................................................................................................... 39
6
Map/Reduce - User Interfaces............................................................................................9
6.1 6.2 6.3 6.4 6.5 6.6 6.7
7
Example: WordCount v2.0.............................................................................................. 30
7.1 7.2 7.3
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</p>
<ol>
<li>Purpose
This document comprehensively describes all user-facing facets of the Hadoop Map/Reduce framework and serves as a tutorial.</li>
<li>Pre-requisites
Ensure that Hadoop is installed, configured and is running. More details: • Hadoop Quick Start for first-time users. • Hadoop Cluster Setup for large, distributed clusters.</li>
<li>Overview
Hadoop Map/Reduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner. A Map/Reduce job usually splits the input data-set into independent chunks which are processed by the map tasks in a completely parallel manner. The framework sorts the outputs of the maps, which are then input to the reduce tasks. Typically both the input and the output of the job are stored in a file-system. The framework takes care of scheduling tasks, monitoring them and re-executes the failed tasks. Typically the compute nodes and the storage nodes are the same, that is, the Map/Reduce framework and the Hadoop Distributed File System (see HDFS Architecture ) are running on the same set of nodes. This configuration allows the framework to effectively schedule tasks on the nodes where data is already present, resulting in very high aggregate bandwidth across the cluster. The Map/Reduce framework consists of a single master JobTracker and one slave TaskTracker per cluster-node. The master is responsible for scheduling the jobs&#39; component tasks on the slaves, monitoring them and re-executing the failed tasks. The slaves execute the tasks as directed by the master. Minimally, applications specify the input/output locations and supply map and reduce functions via implementations of appropriate interfaces and/or abstract-classes. These, and other job parameters, comprise the job configuration. The Hadoop job client then submits the job (jar/executable etc.) and configuration to the JobTracker which then assumes the responsibility of distributing the software/configuration to the slaves, scheduling tasks and monitoring them, providing status and diagnostic information to the job-client.
Page 2
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
Although the Hadoop framework is implemented in JavaTM, Map/Reduce applications need not be written in Java. • Hadoop Streaming is a utility which allows users to create and run jobs with any executables (e.g. shell utilities) as the mapper and/or the reducer. • Hadoop Pipes is a SWIG- compatible C++ API to implement Map/Reduce applications (non JNITM based).</li>
<li>Inputs and Outputs
The Map/Reduce framework operates exclusively on <key, value> pairs, that is, the framework views the input to the job as a set of <key, value> pairs and produces a set of <key, value> pairs as the output of the job, conceivably of different types. The key and value classes have to be serializable by the framework and hence need to implement the Writable interface. Additionally, the key classes have to implement the WritableComparable interface to facilitate sorting by the framework. Input and Output types of a Map/Reduce job: (input) <k1, v1> -&gt; map -&gt; <k2, v2> -&gt; combine -&gt; <k2, v2> -&gt; reduce -&gt; <k3, v3> (output)</li>
<li>Example: WordCount v1.0
Before we jump into the details, lets walk through an example Map/Reduce application to get a flavour for how they work. WordCount is a simple application that counts the number of occurences of each word in a given input set. This works with a local-standalone, pseudo-distributed or fully-distributed Hadoop installation(see Hadoop Quick Start).
5.1. Source Code
WordCount.java 1. 2. 3. 4. import java.io.IOException; import java.util./*; package org.myorg;
Page 3
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable> { private final static IntWritable one = new IntWritable(1); private Text word = new Text(); public class WordCount { import org.apache.hadoop.fs.Path; import org.apache.hadoop.conf./<em>; import org.apache.hadoop.io./</em>; import org.apache.hadoop.mapred./<em>; import org.apache.hadoop.util./</em>;</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li>18.
public void map(LongWritable key, Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { String line = value.toString(); StringTokenizer tokenizer = new StringTokenizer(line); while (tokenizer.hasMoreTokens()) { word.set(tokenizer.nextToken());</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>25.
output.collect(word, one); } }
Page 4
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li>28.
}
public static class Reduce extends MapReduceBase implements Reducer<Text, IntWritable, Text, IntWritable> { public void reduce(Text key, Iterator<IntWritable> values, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { int sum = 0; while (values.hasNext()) { sum += values.next().get(); } output.collect(key, new IntWritable(sum)); } }
29.</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>42.
public static void main(String[] args) throws Exception { JobConf conf = new JobConf(WordCount.class); conf.setJobName(&quot;wordcount&quot;);
conf.setOutputKeyClass(Text.class); 43. conf.setOutputValueClass(IntWritable.class); 44. 45. conf.setMapperClass(Map.class);
Page 5
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>conf.setCombinerClass(Reduce.class); 47. conf.setReducerClass(Reduce.class); 48. 49. conf.setInputFormat(TextInputFormat.class); 50. conf.setOutputFormat(TextOutputFormat.class); 51. 52. FileInputFormat.setInputPaths(conf, new Path(args[0])); 53. FileOutputFormat.setOutputPath(conf, new Path(args[1])); 54. 55. 57. 58. 59. } JobClient.runJob(conf); }
5.2. Usage
Assuming HADOOP_HOME is the root of the installation and HADOOP_VERSION is the Hadoop version installed, compile WordCount.java and create a jar: $ mkdir wordcount_classes $ javac -classpath ${HADOOP_HOME}/hadoop-${HADOOP_VERSION}-core.jar -d wordcount_classes WordCount.java $ jar -cvf /usr/joe/wordcount.jar -C wordcount_classes/ . Assuming that: • /usr/joe/wordcount/input - input directory in HDFS
Page 6
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
•
/usr/joe/wordcount/output - output directory in HDFS
Sample text-files as input: $ bin/hadoop dfs -ls /usr/joe/wordcount/input/ /usr/joe/wordcount/input/file01 /usr/joe/wordcount/input/file02 $ bin/hadoop dfs -cat /usr/joe/wordcount/input/file01 Hello World Bye World $ bin/hadoop dfs -cat /usr/joe/wordcount/input/file02 Hello Hadoop Goodbye Hadoop Run the application: $ bin/hadoop jar /usr/joe/wordcount.jar org.myorg.WordCount /usr/joe/wordcount/input /usr/joe/wordcount/output Output: $ bin/hadoop dfs -cat /usr/joe/wordcount/output/part-00000 Bye 1 Goodbye 1 Hadoop 2 Hello 2 World 2 Applications can specify a comma separated list of paths which would be present in the current working directory of the task using the option -files. The -libjars option allows applications to add jars to the classpaths of the maps and reduces. The -archives allows them to pass archives as arguments that are unzipped/unjarred and a link with name of the jar/zip are created in the current working directory of tasks. More details about the command line options are available at Hadoop Command Guide. Running wordcount example with -libjars and -files: hadoop jar hadoop-examples.jar wordcount -files cachefile.txt -libjars mylib.jar input output
5.3. Walk-through
The WordCount application is quite straight-forward. The Mapper implementation (lines 14-26), via the map method (lines 18-25), processes one line at a time, as provided by the specified TextInputFormat (line 49). It then splits the line into tokens separated by whitespaces, via the StringTokenizer, and emits a
Page 7
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
key-value pair of &lt; <word>, 1&gt;. For the given sample input the first map emits: &lt; Hello, 1&gt; &lt; World, 1&gt; &lt; Bye, 1&gt; &lt; World, 1&gt; The second map emits: &lt; Hello, 1&gt; &lt; Hadoop, 1&gt; &lt; Goodbye, 1&gt; &lt; Hadoop, 1&gt; We&#39;ll learn more about the number of maps spawned for a given job, and how to control them in a fine-grained manner, a bit later in the tutorial. WordCount also specifies a combiner (line 46). Hence, the output of each map is passed through the local combiner (which is same as the Reducer as per the job configuration) for local aggregation, after being sorted on the keys. The output of the first map: &lt; Bye, 1&gt; &lt; Hello, 1&gt; &lt; World, 2&gt; The output of the second map: &lt; Goodbye, 1&gt; &lt; Hadoop, 2&gt; &lt; Hello, 1&gt; The Reducer implementation (lines 28-36), via the reduce method (lines 29-35) just sums up the values, which are the occurence counts for each key (i.e. words in this example). Thus the output of the job is: &lt; Bye, 1&gt; &lt; Goodbye, 1&gt; &lt; Hadoop, 2&gt; &lt; Hello, 2&gt; &lt; World, 2&gt; The run method specifies various facets of the job, such as the input/output paths (passed via the command line), key/value types, input/output formats etc., in the JobConf. It then calls the JobClient.runJob (line 55) to submit the and monitor its progress.
Page 8
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
We&#39;ll learn more about JobConf, JobClient, Tool and other interfaces and classes a bit later in the tutorial.</li>
<li>Map/Reduce - User Interfaces
This section provides a reasonable amount of detail on every user-facing aspect of the Map/Reduce framwork. This should help users implement, configure and tune their jobs in a fine-grained manner. However, please note that the javadoc for each class/interface remains the most comprehensive documentation available; this is only meant to be a tutorial. Let us first take the Mapper and Reducer interfaces. Applications typically implement them to provide the map and reduce methods. We will then discuss other core interfaces including JobConf, JobClient, Partitioner, OutputCollector, Reporter, InputFormat, OutputFormat, OutputCommitter and others. Finally, we will wrap up by discussing some useful features of the framework such as the DistributedCache, IsolationRunner etc.
6.1. Payload
Applications typically implement the Mapper and Reducer interfaces to provide the map and reduce methods. These form the core of the job. 6.1.1. Mapper Mapper maps input key/value pairs to a set of intermediate key/value pairs. Maps are the individual tasks that transform input records into intermediate records. The transformed intermediate records do not need to be of the same type as the input records. A given input pair may map to zero or many output pairs. The Hadoop Map/Reduce framework spawns one map task for each InputSplit generated by the InputFormat for the job. Overall, Mapper implementations are passed the JobConf for the job via the JobConfigurable.configure(JobConf) method and override it to initialize themselves. The framework then calls map(WritableComparable, Writable, OutputCollector, Reporter) for each key/value pair in the InputSplit for that task. Applications can then override the Closeable.close() method to perform any required cleanup. Output pairs do not need to be of the same types as input pairs. A given input pair may map
Page 9
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
to zero or many output pairs. Output pairs are collected with calls to OutputCollector.collect(WritableComparable,Writable). Applications can use the Reporter to report progress, set application-level status messages and update Counters, or just indicate that they are alive. All intermediate values associated with a given output key are subsequently grouped by the framework, and passed to the Reducer(s) to determine the final output. Users can control the grouping by specifying a Comparator via JobConf.setOutputKeyComparatorClass(Class). The Mapper outputs are sorted and then partitioned per Reducer. The total number of partitions is the same as the number of reduce tasks for the job. Users can control which keys (and hence records) go to which Reducer by implementing a custom Partitioner. Users can optionally specify a combiner, via JobConf.setCombinerClass(Class), to perform local aggregation of the intermediate outputs, which helps to cut down the amount of data transferred from the Mapper to the Reducer. The intermediate, sorted outputs are always stored in a simple (key-len, key, value-len, value) format. Applications can control if, and how, the intermediate outputs are to be compressed and the CompressionCodec to be used via the JobConf.
6.1.1.1. How Many Maps?
The number of maps is usually driven by the total size of the inputs, that is, the total number of blocks of the input files. The right level of parallelism for maps seems to be around 10-100 maps per-node, although it has been set up to 300 maps for very cpu-light map tasks. Task setup takes awhile, so it is best if the maps take at least a minute to execute. Thus, if you expect 10TB of input data and have a blocksize of 128MB, you&#39;ll end up with 82,000 maps, unless setNumMapTasks(int) (which only provides a hint to the framework) is used to set it even higher. 6.1.2. Reducer Reducer reduces a set of intermediate values which share a key to a smaller set of values. The number of reduces for the job is set by the user via JobConf.setNumReduceTasks(int). Overall, Reducer implementations are passed the JobConf for the job via the JobConfigurable.configure(JobConf) method and can override it to initialize themselves. The
Page 10
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
framework then calls reduce(WritableComparable, Iterator, OutputCollector, Reporter) method for each <key, (list of values)> pair in the grouped inputs. Applications can then override the Closeable.close() method to perform any required cleanup. Reducer has 3 primary phases: shuffle, sort and reduce.
6.1.2.1. Shuffle
Input to the Reducer is the sorted output of the mappers. In this phase the framework fetches the relevant partition of the output of all the mappers, via HTTP.
6.1.2.2. Sort
The framework groups Reducer inputs by keys (since different mappers may have output the same key) in this stage. The shuffle and sort phases occur simultaneously; while map-outputs are being fetched they are merged.
Secondary Sort
If equivalence rules for grouping the intermediate keys are required to be different from those for grouping keys before reduction, then one may specify a Comparator via JobConf.setOutputValueGroupingComparator(Class). Since JobConf.setOutputKeyComparatorClass(Class) can be used to control how intermediate keys are grouped, these can be used in conjunction to simulate secondary sort on values.
6.1.2.3. Reduce
In this phase the reduce(WritableComparable, Iterator, OutputCollector, Reporter) method is called for each <key, (list of values)> pair in the grouped inputs. The output of the reduce task is typically written to the FileSystem via OutputCollector.collect(WritableComparable, Writable). Applications can use the Reporter to report progress, set application-level status messages and update Counters, or just indicate that they are alive. The output of the Reducer is not sorted.
6.1.2.4. How Many Reduces?
The right number of reduces seems to be 0.95 or 1.75 multiplied by (<no. of nodes> /<em> mapred.tasktracker.reduce.tasks.maximum).
Page 11
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
With 0.95 all of the reduces can launch immediately and start transfering map outputs as the maps finish. With 1.75 the faster nodes will finish their first round of reduces and launch a second wave of reduces doing a much better job of load balancing. Increasing the number of reduces increases the framework overhead, but increases load balancing and lowers the cost of failures. The scaling factors above are slightly less than whole numbers to reserve a few reduce slots in the framework for speculative-tasks and failed tasks.
6.1.2.5. Reducer NONE
It is legal to set the number of reduce-tasks to zero if no reduction is desired. In this case the outputs of the map-tasks go directly to the FileSystem, into the output path set by setOutputPath(Path). The framework does not sort the map-outputs before writing them out to the FileSystem. 6.1.3. Partitioner Partitioner partitions the key space. Partitioner controls the partitioning of the keys of the intermediate map-outputs. The key (or a subset of the key) is used to derive the partition, typically by a hash function. The total number of partitions is the same as the number of reduce tasks for the job. Hence this controls which of the m reduce tasks the intermediate key (and hence the record) is sent to for reduction. HashPartitioner is the default Partitioner. 6.1.4. Reporter Reporter is a facility for Map/Reduce applications to report progress, set application-level status messages and update Counters. Mapper and Reducer implementations can use the Reporter to report progress or just indicate that they are alive. In scenarios where the application takes a significant amount of time to process individual key/value pairs, this is crucial since the framework might assume that the task has timed-out and kill that task. Another way to avoid this is to set the configuration parameter mapred.task.timeout to a high-enough value (or even set it to zero for no time-outs). Applications can also update Counters using the Reporter.
Page 12
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
6.1.5. OutputCollector OutputCollector is a generalization of the facility provided by the Map/Reduce framework to collect data output by the Mapper or the Reducer (either the intermediate outputs or the output of the job). Hadoop Map/Reduce comes bundled with a library of generally useful mappers, reducers, and partitioners.
6.2. Job Configuration
JobConf represents a Map/Reduce job configuration. JobConf is the primary interface for a user to describe a Map/Reduce job to the Hadoop framework for execution. The framework tries to faithfully execute the job as described by JobConf, however: • f Some configuration parameters may have been marked as final by administrators and hence cannot be altered. • While some job parameters are straight-forward to set (e.g. setNumReduceTasks(int)), other parameters interact subtly with the rest of the framework and/or job configuration and are more complex to set (e.g. setNumMapTasks(int)). JobConf is typically used to specify the Mapper, combiner (if any), Partitioner, Reducer, InputFormat, OutputFormat and OutputCommitter implementations. JobConf also indicates the set of input files (setInputPaths(JobConf, Path...) /addInputPath(JobConf, Path)) and (setInputPaths(JobConf, String) /addInputPaths(JobConf, String)) and where the output files should be written (setOutputPath(Path)). Optionally, JobConf is used to specify other advanced facets of the job such as the Comparator to be used, files to be put in the DistributedCache, whether intermediate and/or job outputs are to be compressed (and how), debugging via user-provided scripts (setMapDebugScript(String)/setReduceDebugScript(String)) , whether job tasks can be executed in a speculative manner (setMapSpeculativeExecution(boolean))/(setReduceSpeculativeExecution(boolean)) , maximum number of attempts per task (setMaxMapAttempts(int)/setMaxReduceAttempts(int)) , percentage of tasks failure which can be tolerated by the job (setMaxMapTaskFailuresPercent(int)/setMaxReduceTaskFailuresPercent(int)) etc. Of course, users can use set(String, String)/get(String, String) to set/get arbitrary parameters needed by applications. However, use the DistributedCache for large amounts of
Page 13
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
(read-only) data.
6.3. Task Execution &amp; Environment
The TaskTracker executes the Mapper/ Reducer task as a child process in a separate jvm. The child-task inherits the environment of the parent TaskTracker. The user can specify additional options to the child-jvm via the mapred.child.java.opts configuration parameter in the JobConf such as non-standard paths for the run-time linker to search shared libraries via -Djava.library.path=&lt;&gt; etc. If the mapred.child.java.opts contains the symbol @taskid@ it is interpolated with value of taskid of the map/reduce task. Here is an example with multiple arguments and substitutions, showing jvm GC logging, and start of a passwordless JVM JMX agent so that it can connect with jconsole and the likes to watch child memory, threads and get thread dumps. It also sets the maximum heap-size of the child jvm to 512MB and adds an additional path to the java.library.path of the child-jvm. <property> <name>mapred.child.java.opts</name> <value> -Xmx512M -Djava.library.path=/home/mycompany/lib -verbose:gc -Xloggc:/tmp/@taskid@.gc -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false </value> </property> 6.3.1. Memory management Users/admins can also specify the maximum virtual memory of the launched child-task, and any sub-process it launches recursively, using mapred.child.ulimit. Note that the value set here is a per process limit. The value for mapred.child.ulimit should be specified in kilo bytes (KB). And also the value must be greater than or equal to the -Xmx passed to JavaVM, else the VM might not start. Note: mapred.child.java.opts are used only for configuring the launched child tasks from task tracker. Configuring the memory options for daemons is documented in cluster_setup.html The memory available to some parts of the framework is also configurable. In map and
Page 14
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
reduce tasks, performance may be influenced by adjusting parameters influencing the concurrency of operations and the frequency with which data will hit disk. Monitoring the filesystem counters for a job- particularly relative to byte counts from the map and into the reduce- is invaluable to the tuning of these parameters. 6.3.2. Map Parameters A record emitted from a map will be serialized into a buffer and metadata will be stored into accounting buffers. As described in the following options, when either the serialization buffer or the metadata exceed a threshold, the contents of the buffers will be sorted and written to disk in the background while the map continues to output records. If either buffer fills completely while the spill is in progress, the map thread will block. When the map is finished, any remaining records are written to disk and all on-disk segments are merged into a single file. Minimizing the number of spills to disk can decrease map time, but a larger buffer also decreases the memory available to the mapper.
Name io.sort.mb int Type Description The cumulative size of the serialization and accounting buffers storing records emitted from the map, in megabytes. The ratio of serialization to accounting space can be adjusted. Each serialized record requires 16 bytes of accounting information in addition to its serialized size to effect the sort. This percentage of space allocated from io.sort.mb affects the probability of a spill to disk being caused by either exhaustion of the serialization buffer or the accounting space. Clearly, for a map outputting small records, a higher value than the default will likely decrease the number of spills to disk. This is the threshold for the accounting and serialization buffers. When this percentage of either buffer has filled, their
io.sort.record.percent
float
io.sort.spill.percent
float
Page 15
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
contents will be spilled to disk in the background. Let io.sort.record.percent be r, io.sort.mb be x, and this value be q. The maximum number of records collected before the collection thread will spill is r /</em> x /<em> q /</em> 2^16. Note that a higher value may decrease the number of- or even eliminate- merges, but will also increase the probability of the map task getting blocked. The lowest average map times are usually obtained by accurately estimating the size of the map output and preventing multiple spills.
Other notes • If either spill threshold is exceeded while a spill is in progress, collection will continue until the spill is finished. For example, if io.sort.buffer.spill.percent is set to 0.33, and the remainder of the buffer is filled while the spill runs, the next spill will include all the collected records, or 0.66 of the buffer, and will not generate additional spills. In other words, the thresholds are defining triggers, not blocking. • A record larger than the serialization buffer will first trigger a spill, then be spilled to a separate file. It is undefined whether or not this record will first pass through the combiner. 6.3.3. Shuffle/Reduce Parameters As described previously, each reduce fetches the output assigned to it by the Partitioner via HTTP into memory and periodically merges these outputs to disk. If intermediate compression of map outputs is turned on, each output is decompressed into memory. The following options affect the frequency of these merges to disk prior to the reduce and the memory allocated to map output during the reduce.
Name io.sort.factor int Type Description Specifies the number of segments on disk to be merged at the same time. It limits the number of open files and compression codecs during the merge. If the number of files
Page 16
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
exceeds this limit, the merge will proceed in several passes. Though this limit also applies to the map, most jobs should be configured so that hitting this limit is unlikely there. mapred.inmem.merge.threshold int The number of sorted map outputs fetched into memory before being merged to disk. Like the spill thresholds in the preceding note, this is not defining a unit of partition, but a trigger. In practice, this is usually set very high (1000) or disabled (0), since merging in-memory segments is often less expensive than merging from disk (see notes following this table). This threshold influences only the frequency of in-memory merges during the shuffle. The memory threshold for fetched map outputs before an in-memory merge is started, expressed as a percentage of memory allocated to storing map outputs in memory. Since map outputs that can&#39;t fit in memory can be stalled, setting this high may decrease parallelism between the fetch and merge. Conversely, values as high as 1.0 have been effective for reduces whose input can fit entirely in memory. This parameter influences only the frequency of in-memory merges during the shuffle. The percentage of memoryrelative to the maximum heapsize as typically specified in mapred.child.java.optsthat can be allocated to storing
mapred.job.shuffle.merge.percentfloat
mapred.job.shuffle.input.buffer.percent float
Page 17
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
map outputs during the shuffle. Though some memory should be set aside for the framework, in general it is advantageous to set this high enough to store large and numerous map outputs. mapred.job.reduce.input.buffer.percent float The percentage of memory relative to the maximum heapsize in which map outputs may be retained during the reduce. When the reduce begins, map outputs will be merged to disk until those that remain are under the resource limit this defines. By default, all map outputs are merged to disk before the reduce begins to maximize the memory available to the reduce. For less memory-intensive reduces, this should be increased to avoid trips to disk.
Other notes • If a map output is larger than 25 percent of the memory allocated to copying map outputs, it will be written directly to disk without first staging through memory. • When running with a combiner, the reasoning about high merge thresholds and large buffers may not hold. For merges started before all map outputs have been fetched, the combiner is run while spilling to disk. In some cases, one can obtain better reduce times by spending resources combining map outputs- making disk spills small and parallelizing spilling and fetching- rather than aggressively increasing buffer sizes. • When merging in-memory map outputs to disk to begin the reduce, if an intermediate merge is necessary because there are segments to spill and at least io.sort.factor segments already on disk, the in-memory map outputs will be part of the intermediate merge. 6.3.4. Directory Structure The task tracker has local directory, ${mapred.local.dir}/taskTracker/ to create localized cache and localized job. It can define multiple local directories (spanning multiple disks) and then each filename is assigned to a semi-random local directory. When the job starts, task tracker creates a localized job directory relative to the local directory specified in
Page 18
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
the configuration. Thus the task tracker directory structure looks the following: • ${mapred.local.dir}/taskTracker/archive/ : The distributed cache. This directory holds the localized distributed cache. Thus localized distributed cache is shared among all the tasks and jobs • ${mapred.local.dir}/taskTracker/jobcache/$jobid/ : The localized job directory • ${mapred.local.dir}/taskTracker/jobcache/$jobid/work/ : The job-specific shared directory. The tasks can use this space as scratch space and share files among them. This directory is exposed to the users through the configuration property job.local.dir. The directory can accessed through api JobConf.getJobLocalDir(). It is available as System property also. So, users (streaming etc.) can call System.getProperty(&quot;job.local.dir&quot;) to access the directory. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/jars/ : The jars directory, which has the job jar file and expanded jar. The job.jar is the application&#39;s jar file that is automatically distributed to each machine. It is expanded in jars directory before the tasks for the job start. The job.jar location is accessible to the application through the api JobConf.getJar() . To access the unjarred directory, JobConf.getJar().getParent() can be called. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/job.xml : The job.xml file, the generic job configuration, localized for the job. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid : The task directory for each task attempt. Each task directory again has the following structure : • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid/job.xml : A job.xml file, task localized job configuration, Task localization means that properties have been set that are specific to this particular task within the job. The properties localized for each task are described below. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid/output : A directory for intermediate output files. This contains the temporary map reduce data generated by the framework such as map output files etc. • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid/work : The curernt working directory of the task. With jvm reuse enabled for tasks, this directory will be the directory on which the jvm has started • ${mapred.local.dir}/taskTracker/jobcache/$jobid/$taskid/work/tmp : The temporary directory for the task. (User can specify the property mapred.child.tmp to set the value of temporary directory for map and reduce tasks. This defaults to ./tmp. If the value is not an absolute path, it is prepended with task&#39;s working directory. Otherwise, it is directly assigned. The directory will be created if it doesn&#39;t exist. Then, the child java tasks are executed
Page 19
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
with option -Djava.io.tmpdir=&#39;the absolute path of the tmp dir&#39;. Anp pipes and streaming are set with environment variable, TMPDIR=&#39;the absolute path of the tmp dir&#39;). This directory is created, if mapred.child.tmp has the value ./tmp
6.3.5. Task JVM Reuse Jobs can enable task JVMs to be reused by specifying the job configuration mapred.job.reuse.jvm.num.tasks. If the value is 1 (the default), then JVMs are not reused (i.e. 1 task per JVM). If it is -1, there is no limit to the number of tasks a JVM can run (of the same job). One can also specify some value greater than 1 using the api JobConf.setNumTasksToExecutePerJvm(int) The following properties are localized in the job configuration for each task&#39;s execution:
Name mapred.job.id mapred.jar job.local.dir mapred.tip.id mapred.task.id mapred.task.is.map mapred.task.partition map.input.file map.input.start map.input.length mapred.work.output.dir String String String String String boolean int String long long String Type The job id job.jar location in job directory The job specific shared scratch space The task id The task attempt id Is this a map task The id of the task within the job The filename that the map is reading from The offset of the start of the map input split The number of bytes in the map input split The task&#39;s temporary output directory Description
The standard output (stdout) and error (stderr) streams of the task are read by the TaskTracker and logged to ${HADOOP<em>LOG_DIR}/userlogs
Page 20
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
The DistributedCache can also be used to distribute both jars and native libraries for use in the map and/or reduce tasks. The child-jvm always has its current working directory added to the java.library.path and LD_LIBRARY_PATH. And hence the cached libraries can be loaded via System.loadLibrary or System.load. More details on how to load shared libraries through distributed cache are documented at native_libraries.html
6.4. Job Submission and Monitoring
JobClient is the primary interface by which user-job interacts with the JobTracker. JobClient provides facilities to submit jobs, track their progress, access component-tasks&#39; reports and logs, get the Map/Reduce cluster&#39;s status information and so on. The job submission process involves: 1. Checking the input and output specifications of the job. 2. Computing the InputSplit values for the job. 3. Setting up the requisite accounting information for the DistributedCache of the job, if necessary. 4. Copying the job&#39;s jar and configuration to the Map/Reduce system directory on the FileSystem. 5. Submitting the job to the JobTracker and optionally monitoring it&#39;s status. Job history files are also logged to user specified directory hadoop.job.history.user.location which defaults to job output directory. The files are stored in &quot;_logs/history/&quot; in the specified directory. Hence, by default they will be in mapred.output.dir/_logs/history. User can stop logging by giving the value none for hadoop.job.history.user.location User can view the history logs summary in specified directory using the following command $ bin/hadoop job -history output-dir This command will print job details, failed and killed tip details. More details about the job such as successful tasks and task attempts made for each task can be viewed using the following command $ bin/hadoop job -history all output-dir User can use OutputLogFilter to filter log files from the output directory listing. Normally the user creates the application, describes various facets of the job via JobConf, and then uses the JobClient to submit the job and monitor its progress. 6.4.1. Job Control Users may need to chain Map/Reduce jobs to accomplish complex tasks which cannot be
Page 21
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
done via a single Map/Reduce job. This is fairly easy since the output of the job typically goes to distributed file-system, and the output, in turn, can be used as the input for the next job. However, this also means that the onus on ensuring jobs are complete (success/failure) lies squarely on the clients. In such cases, the various job-control options are: • runJob(JobConf) : Submits the job and returns only after the job has completed. • submitJob(JobConf) : Only submits the job, then poll the returned handle to the RunningJob to query status and make scheduling decisions. • JobConf.setJobEndNotificationURI(String) : Sets up a notification upon job-completion, thus avoiding polling.
6.5. Job Input
InputFormat describes the input-specification for a Map/Reduce job. The Map/Reduce framework relies on the InputFormat of the job to: 1. Validate the input-specification of the job. 2. Split-up the input file(s) into logical InputSplit instances, each of which is then assigned to an individual Mapper. 3. Provide the RecordReader implementation used to glean input records from the logical InputSplit for processing by the Mapper. The default behavior of file-based InputFormat implementations, typically sub-classes of FileInputFormat, is to split the input into logical InputSplit instances based on the total size, in bytes, of the input files. However, the FileSystem blocksize of the input files is treated as an upper bound for input splits. A lower bound on the split size can be set via mapred.min.split.size. Clearly, logical splits based on input-size is insufficient for many applications since record boundaries must be respected. In such cases, the application should implement a RecordReader, who is responsible for respecting record-boundaries and presents a record-oriented view of the logical InputSplit to the individual task. TextInputFormat is the default InputFormat. If TextInputFormat is the InputFormat for a given job, the framework detects input-files with the .gz extensions and automatically decompresses them using the appropriate CompressionCodec. However, it must be noted that compressed files with the above extensions cannot be split and each compressed file is processed in its entirety by a single mapper.
Page 22
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
6.5.1. InputSplit InputSplit represents the data to be processed by an individual Mapper. Typically InputSplit presents a byte-oriented view of the input, and it is the responsibility of RecordReader to process and present a record-oriented view. FileSplit is the default InputSplit. It sets map.input.file to the path of the input file for the logical split. 6.5.2. RecordReader RecordReader reads <key, value> pairs from an InputSplit. Typically the RecordReader converts the byte-oriented view of the input, provided by the InputSplit, and presents a record-oriented to the Mapper implementations for processing. RecordReader thus assumes the responsibility of processing record boundaries and presents the tasks with keys and values.
6.6. Job Output
OutputFormat describes the output-specification for a Map/Reduce job. The Map/Reduce framework relies on the OutputFormat of the job to: 1. Validate the output-specification of the job; for example, check that the output directory doesn&#39;t already exist. 2. Provide the RecordWriter implementation used to write the output files of the job. Output files are stored in a FileSystem. TextOutputFormat is the default OutputFormat. 6.6.1. OutputCommitter OutputCommitter describes the commit of task output for a Map/Reduce job. The Map/Reduce framework relies on the OutputCommitter of the job to: 1. Setup the job during initialization. For example, create the temporary output directory for the job during the initialization of the job. Job setup is done by a separate task when the job is in PREP state and after initializing tasks. Once the setup task completes, the job will be moved to RUNNING state. 2. Cleanup the job after the job completion. For example, remove the temporary output directory after the job completion. Job cleanup is done by a separate task at the end of the
Page 23
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
job. Job is declared SUCCEDED/FAILED/KILLED after the cleanup task completes. 3. Setup the task temporary output. Task setup is done as part of the same task, during task initialization. 4. Check whether a task needs a commit. This is to avoid the commit procedure if a task does not need commit. 5. Commit of the task output. Once task is done, the task will commit it&#39;s output if required. 6. Discard the task commit. If the task has been failed/killed, the output will be cleaned-up. If task could not cleanup (in exception block), a separate task will be launched with same attempt-id to do the cleanup. FileOutputCommitter is the default OutputCommitter. Job setup/cleanup tasks occupy map or reduce slots, whichever is free on the TaskTracker. And JobCleanup task, TaskCleanup tasks and JobSetup task have the highest priority, and in that order. 6.6.2. Task Side-Effect Files In some applications, component tasks need to create and/or write to side-files, which differ from the actual job-output files. In such cases there could be issues with two instances of the same Mapper or Reducer running simultaneously (for example, speculative tasks) trying to open and/or write to the same file (path) on the FileSystem. Hence the application-writer will have to pick unique names per task-attempt (using the attemptid, say attempt_200709221812_0001_m_000000_0), not just per task. To avoid these issues the Map/Reduce framework, when the OutputCommitter is FileOutputCommitter, maintains a special ${mapred.output.dir}/_temporary/</em>${taskid} sub-directory accessible via ${mapred.work.output.dir} for each task-attempt on the FileSystem where the output of the task-attempt is stored. On successful completion of the task-attempt, the files in the ${mapred.output.dir}/<em>temporary/</em>${taskid} (only) are promoted to ${mapred.output.dir}. Of course, the framework discards the sub-directory of unsuccessful task-attempts. This process is completely transparent to the application. The application-writer can take advantage of this feature by creating any side-files required in ${mapred.work.output.dir} during execution of a task via FileOutputFormat.getWorkOutputPath(), and the framework will promote them similarly for succesful task-attempts, thus eliminating the need to pick unique paths per task-attempt. Note: The value of ${mapred.work.output.dir} during execution of a particular task-attempt is actually ${mapred.output.dir}/<em>temporary/</em>{$taskid}, and this value is set by the Map/Reduce framework. So, just create any side-files in the path returned by FileOutputFormat.getWorkOutputPath() from map/reduce task to take advantage
Page 24
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
of this feature. The entire discussion holds true for maps of jobs with reducer=NONE (i.e. 0 reduces) since output of the map, in that case, goes directly to HDFS. 6.6.3. RecordWriter RecordWriter writes the output <key, value> pairs to an output file. RecordWriter implementations write the job outputs to the FileSystem.
6.7. Other Useful Features
6.7.1. Submitting Jobs to Queues Users submit jobs to Queues. Queues, as collection of jobs, allow the system to provide specific functionality. For example, queues use ACLs to control which users who can submit jobs to them. Queues are expected to be primarily used by Hadoop Schedulers. Hadoop comes configured with a single mandatory queue, called &#39;default&#39;. Queue names are defined in the mapred.queue.names property of the Hadoop site configuration. Some job schedulers, such as the Capacity Scheduler, support multiple queues. A job defines the queue it needs to be submitted to through the mapred.job.queue.name property, or through the setQueueName(String) API. Setting the queue name is optional. If a job is submitted without an associated queue name, it is submitted to the &#39;default&#39; queue. 6.7.2. Counters Counters represent global counters, defined either by the Map/Reduce framework or applications. Each Counter can be of any Enum type. Counters of a particular Enum are bunched into groups of type Counters.Group. Applications can define arbitrary Counters (of type Enum) and update them via Reporter.incrCounter(Enum, long) or Reporter.incrCounter(String, String, long) in the map and/or reduce methods. These counters are then globally aggregated by the framework. 6.7.3. DistributedCache DistributedCache distributes application-specific, large, read-only files efficiently. DistributedCache is a facility provided by the Map/Reduce framework to cache files
Page 25
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
(text, archives, jars and so on) needed by applications. Applications specify the files to be cached via urls (hdfs://) in the JobConf. The DistributedCache assumes that the files specified via hdfs:// urls are already present on the FileSystem. The framework will copy the necessary files to the slave node before any tasks for the job are executed on that node. Its efficiency stems from the fact that the files are only copied once per job and the ability to cache archives which are un-archived on the slaves. DistributedCache tracks the modification timestamps of the cached files. Clearly the cache files should not be modified by the application or externally while the job is executing. DistributedCache can be used to distribute simple, read-only data/text files and more complex types such as archives and jars. Archives (zip, tar, tgz and tar.gz files) are un-archived at the slave nodes. Files have execution permissions set. The files/archives can be distributed by setting the property mapred.cache.{files|archives}. If more than one file/archive has to be distributed, they can be added as comma separated paths. The properties can also be set by APIs DistributedCache.addCacheFile(URI,conf)/ DistributedCache.addCacheArchive(URI,conf) and DistributedCache.setCacheFiles(URIs,conf)/ DistributedCache.setCacheArchives(URIs,conf) where URI is of the form hdfs://host:port/absolute-path/#link-name. In Streaming, the files can be distributed through command line option -cacheFile/-cacheArchive. Optionally users can also direct the DistributedCache to symlink the cached file(s) into the current working directory of the task via the DistributedCache.createSymlink(Configuration) api. Or by setting the configuration property mapred.create.symlink as yes. The DistributedCache will use the fragment of the URI as the name of the symlink. For example, the URI hdfs://namenode:port/lib.so.1/#lib.so will have the symlink name as lib.so in task&#39;s cwd for the file lib.so.1 in distributed cache. The DistributedCache can also be used as a rudimentary software distribution mechanism for use in the map and/or reduce tasks. It can be used to distribute both jars and native libraries. The DistributedCache.addArchiveToClassPath(Path, Configuration) or DistributedCache.addFileToClassPath(Path, Configuration) api can be used to cache files/jars and also add them to the classpath of child-jvm. The same can be done by setting the configuration properties mapred.job.classpath.{files|archives}. Similarly the cached files that are symlinked into the working directory of the task can be used to distribute native libraries and load them.
Page 26
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
6.7.4. Tool The Tool interface supports the handling of generic Hadoop command-line options. Tool is the standard for any Map/Reduce tool or application. The application should delegate the handling of standard command-line options to GenericOptionsParser via ToolRunner.run(Tool, String[]) and only handle its custom arguments. The generic Hadoop command-line options are: -conf <configuration file> -D <property=value> -fs <local|namenode:port> -jt <local|jobtracker:port> 6.7.5. IsolationRunner IsolationRunner is a utility to help debug Map/Reduce programs. To use the IsolationRunner, first set keep.failed.tasks.files to true (also see keep.tasks.files.pattern). Next, go to the node on which the failed task ran and go to the TaskTracker&#39;s local directory and run the IsolationRunner: $ cd <local path>/taskTracker/${taskid}/work $ bin/hadoop org.apache.hadoop.mapred.IsolationRunner ../job.xml IsolationRunner will run the failed task in a single jvm, which can be in the debugger, over precisely the same input. 6.7.6. Profiling Profiling is a utility to get a representative (2 or 3) sample of built-in java profiler for a sample of maps and reduces. User can specify whether the system should collect profiler information for some of the tasks in the job by setting the configuration property mapred.task.profile. The value can be set using the api JobConf.setProfileEnabled(boolean). If the value is set true, the task profiling is enabled. The profiler information is stored in the user log directory. By default, profiling is not enabled for the job. Once user configures that profiling is needed, she/he can use the configuration property mapred.task.profile.{maps|reduces} to set the ranges of map/reduce tasks to
Page 27
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
profile. The value can be set using the api JobConf.setProfileTaskRange(boolean,String). By default, the specified range is 0-2.
User can also specify the profiler configuration arguments by setting the configuration property mapred.task.profile.params. The value can be specified using the api JobConf.setProfileParams(String). If the string contains a %s, it will be replaced with the name of the profiling output file when the task runs. These parameters are passed to the task child JVM on the command line. The default value for the profiling parameters is -agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s 6.7.7. Debugging The Map/Reduce framework provides a facility to run user-provided scripts for debugging. When a map/reduce task fails, a user can run a debug script, to process task logs for example. The script is given access to the task&#39;s stdout and stderr outputs, syslog and jobconf. The output from the debug script&#39;s stdout and stderr is displayed on the console diagnostics and also as part of the job UI. In the following sections we discuss how to submit a debug script with a job. The script file needs to be distributed and submitted to the framework.
6.7.7.1. How to distribute the script file:
The user needs to use DistributedCache to distribute and symlink the script file.
6.7.7.2. How to submit the script:
A quick way to submit the debug script is to set values for the properties mapred.map.task.debug.script and mapred.reduce.task.debug.script, for debugging map and reduce tasks respectively. These properties can also be set by using APIs JobConf.setMapDebugScript(String) and JobConf.setReduceDebugScript(String) . In streaming mode, a debug script can be submitted with the command-line options -mapdebug and -reducedebug, for debugging map and reduce tasks respectively. The arguments to the script are the task&#39;s stdout, stderr, syslog and jobconf files. The debug command, run on the node where the map/reduce task failed, is: $script $stdout $stderr $syslog $jobconf Pipes programs have the c++ program name as a fifth argument for the command. Thus for the pipes programs the command is $script $stdout $stderr $syslog $jobconf $program
Page 28
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
6.7.7.3. Default Behavior:
For pipes, a default script is run to process core dumps under gdb, prints stack trace and gives info about running threads. 6.7.8. JobControl JobControl is a utility which encapsulates a set of Map/Reduce jobs and their dependencies. 6.7.9. Data Compression Hadoop Map/Reduce provides facilities for the application-writer to specify compression for both intermediate map-outputs and the job-outputs i.e. output of the reduces. It also comes bundled with CompressionCodec implementation for the zlib compression algorithm. The gzip file format is also supported. Hadoop also provides native implementations of the above compression codecs for reasons of both performance (zlib) and non-availability of Java libraries. More details on their usage and availability are available here.
6.7.9.1. Intermediate Outputs
Applications can control compression of intermediate map-outputs via the JobConf.setCompressMapOutput(boolean) api and the CompressionCodec to be used via the JobConf.setMapOutputCompressorClass(Class) api.
6.7.9.2. Job Outputs
Applications can control compression of job-outputs via the FileOutputFormat.setCompressOutput(JobConf, boolean) api and the CompressionCodec to be used can be specified via the FileOutputFormat.setOutputCompressorClass(JobConf, Class) api. If the job outputs are to be stored in the SequenceFileOutputFormat, the required SequenceFile.CompressionType (i.e. RECORD / BLOCK - defaults to RECORD) can be specified via the SequenceFileOutputFormat.setOutputCompressionType(JobConf, SequenceFile.CompressionType) api. 6.7.10. Skipping Bad Records Hadoop provides an option where a certain set of bad input records can be skipped when processing map inputs. Applications can control this feature through the SkipBadRecords
Page 29
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
class. This feature can be used when map tasks crash deterministically on certain input. This usually happens due to bugs in the map function. Usually, the user would have to fix these bugs. This is, however, not possible sometimes. The bug may be in third party libraries, for example, for which the source code is not available. In such cases, the task never completes successfully even after multiple attempts, and the job fails. With this feature, only a small portion of data surrounding the bad records is lost, which may be acceptable for some applications (those performing statistical analysis on very large data, for example). By default this feature is disabled. For enabling it, refer to SkipBadRecords.setMapperMaxSkipRecords(Configuration, long) and SkipBadRecords.setReducerMaxSkipGroups(Configuration, long). With this feature enabled, the framework gets into &#39;skipping mode&#39; after a certain number of map failures. For more details, see SkipBadRecords.setAttemptsToStartSkipping(Configuration, int). In &#39;skipping mode&#39;, map tasks maintain the range of records being processed. To do this, the framework relies on the processed record counter. See SkipBadRecords.COUNTER_MAP_PROCESSED_RECORDS and SkipBadRecords.COUNTER_REDUCE_PROCESSED_GROUPS. This counter enables the framework to know how many records have been processed successfully, and hence, what record range caused a task to crash. On further attempts, this range of records is skipped. The number of records skipped depends on how frequently the processed record counter is incremented by the application. It is recommended that this counter be incremented after every record is processed. This may not be possible in some applications that typically batch their processing. In such cases, the framework may skip additional records surrounding the bad record. Users can control the number of skipped records through SkipBadRecords.setMapperMaxSkipRecords(Configuration, long) and SkipBadRecords.setReducerMaxSkipGroups(Configuration, long). The framework tries to narrow the range of skipped records using a binary search-like approach. The skipped range is divided into two halves and only one half gets executed. On subsequent failures, the framework figures out which half contains bad records. A task will be re-executed till the acceptable skipped value is met or all task attempts are exhausted. To increase the number of task attempts, use JobConf.setMaxMapAttempts(int) and JobConf.setMaxReduceAttempts(int). Skipped records are written to HDFS in the sequence file format, for later analysis. The location can be changed through SkipBadRecords.setSkipOutputPath(JobConf, Path).</li>
<li>Example: WordCount v2.0
Page 30
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
Here is a more complete WordCount which uses many of the features provided by the Map/Reduce framework we discussed so far. This needs the HDFS to be up and running, especially for the DistributedCache-related features. Hence it only works with a pseudo-distributed or fully-distributed Hadoop installation.
7.1. Source Code
WordCount.java 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable> { public class WordCount extends Configured implements Tool { import org.apache.hadoop.fs.Path; import org.apache.hadoop.filecache.DistributedCache; import org.apache.hadoop.conf./<em>; import org.apache.hadoop.io./</em>; import org.apache.hadoop.mapred./<em>; import org.apache.hadoop.util./</em>; import java.io./<em>; import java.util./</em>; package org.myorg;</li>
<li><ol>
<li>static enum Counters { INPUT_WORDS }
Page 31
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>private boolean caseSensitive = true; private Set<String> patternsToSkip = new HashSet<String>(); private final static IntWritable one = new IntWritable(1); private Text word = new Text();</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>public void configure(JobConf job) { caseSensitive = job.getBoolean(&quot;wordcount.case.sensitive&quot;, true); inputFile = job.get(&quot;map.input.file&quot;); private long numRecords = 0; private String inputFile;</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li>32.
if (job.getBoolean(&quot;wordcount.skip.patterns&quot;, false)) { Path[] patternsFiles = new Path[0]; try { patternsFiles = DistributedCache.getLocalCacheFiles(job); } catch (IOException ioe) { System.err.println(&quot;Caught</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li>37.
Page 32
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
exception while getting cached files: &quot; + StringUtils.stringifyException(ioe)); 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. private void parseSkipFile(Path patternsFile) { try { BufferedReader fis = new BufferedReader(new FileReader(patternsFile.toString())); String pattern = null; while ((pattern = fis.readLine()) != null) { patternsToSkip.add(pattern); } } catch (IOException ioe) { System.err.println(&quot;Caught exception while parsing the cached file &#39;&quot; + patternsFile + &quot;&#39; : &quot; + StringUtils.stringifyException(ioe)); } } } for (Path patternsFile : patternsFiles) { parseSkipFile(patternsFile); } } }</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>53.</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li>57.
public void map(LongWritable key,
Page 33
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { 58. String line = (caseSensitive) ? value.toString() : value.toString().toLowerCase();</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li>&quot;&quot;); 62. 63. 64. 65. 66. word.set(tokenizer.nextToken()); 67. 68. reporter.incrCounter(Counters.INPUT_WORDS, 1); 69. 70. 71. 72. if ((++numRecords % 100) == 0) { reporter.setStatus(&quot;Finished processing &quot; + numRecords + &quot; records &quot; + &quot;from the input file: &quot; + inputFile); } } } } output.collect(word, one); StringTokenizer tokenizer = new StringTokenizer(line); while (tokenizer.hasMoreTokens()) { } for (String pattern : patternsToSkip) { line = line.replaceAll(pattern,</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li>75.
Page 34
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
<li><ol>
<li>public static class Reduce extends MapReduceBase implements Reducer<Text, IntWritable, Text, IntWritable> { public void reduce(Text key, Iterator<IntWritable> values, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException { int sum = 0; while (values.hasNext()) { sum += values.next().get(); } output.collect(key, new IntWritable(sum)); } }
78.</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>91.
public int run(String[] args) throws Exception { JobConf conf = new JobConf(getConf(), WordCount.class); conf.setJobName(&quot;wordcount&quot;);
conf.setOutputKeyClass(Text.class); 92. conf.setOutputValueClass(IntWritable.class); 93. 94. 95. conf.setMapperClass(Map.class);
Page 35
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
conf.setCombinerClass(Reduce.class); 96. conf.setReducerClass(Reduce.class); 97. 98. conf.setInputFormat(TextInputFormat.class); 99. conf.setOutputFormat(TextOutputFormat.class); 100. 101. 102. 103. 104. DistributedCache.addCacheFile(new Path(args[++i]).toUri(), conf); 105. conf.setBoolean(&quot;wordcount.skip.patterns&quot;, true); 106. 107. 108. 109. 110. 111. FileInputFormat.setInputPaths(conf, new Path(other_args.get(0))); 112. FileOutputFormat.setOutputPath(conf, new Path(other_args.get(1))); 113. } else { other_args.add(args[i]); } } List<String> other_args = new ArrayList<String>(); for (int i=0; i &lt; args.length; ++i) { if (&quot;-skip&quot;.equals(args[i])) {
Page 36
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li><ol>
<li><ol>
<li>119.
JobClient.runJob(conf); return 0; }
public static void main(String[] args) throws Exception { int res = ToolRunner.run(new Configuration(), new WordCount(), args); System.exit(res); } }</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><ol>
<li><ol>
<li>123.
7.2. Sample Runs
Sample text-files as input: $ bin/hadoop dfs -ls /usr/joe/wordcount/input/ /usr/joe/wordcount/input/file01 /usr/joe/wordcount/input/file02 $ bin/hadoop dfs -cat /usr/joe/wordcount/input/file01 Hello World, Bye World! $ bin/hadoop dfs -cat /usr/joe/wordcount/input/file02 Hello Hadoop, Goodbye to hadoop. Run the application: $ bin/hadoop jar /usr/joe/wordcount.jar org.myorg.WordCount /usr/joe/wordcount/input /usr/joe/wordcount/output Output: $ bin/hadoop dfs -cat /usr/joe/wordcount/output/part-00000 Bye 1 Goodbye 1 Hadoop, 1 Hello 2
Page 37
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
World! 1 World, 1 hadoop. 1 to 1 Notice that the inputs differ from the first version we looked at, and how they affect the outputs. Now, lets plug-in a pattern-file which lists the word-patterns to be ignored, via the DistributedCache. $ hadoop dfs -cat /user/joe/wordcount/patterns.txt . \, ! to Run it again, this time with more options: $ bin/hadoop jar /usr/joe/wordcount.jar org.myorg.WordCount -Dwordcount.case.sensitive=true /usr/joe/wordcount/input /usr/joe/wordcount/output -skip /user/joe/wordcount/patterns.txt As expected, the output: $ bin/hadoop dfs -cat /usr/joe/wordcount/output/part-00000 Bye 1 Goodbye 1 Hadoop 1 Hello 2 World 2 hadoop 1 Run it once more, this time switch-off case-sensitivity: $ bin/hadoop jar /usr/joe/wordcount.jar org.myorg.WordCount -Dwordcount.case.sensitive=false /usr/joe/wordcount/input /usr/joe/wordcount/output -skip /user/joe/wordcount/patterns.txt Sure enough, the output: $ bin/hadoop dfs -cat /usr/joe/wordcount/output/part-00000 bye 1
Page 38
Copyright © 2008 The Apache Software Foundation. All rights reserved.
Map/Reduce Tutorial
goodbye 1 hadoop 2 hello 2 world 2
7.3. Highlights
The second version of WordCount improves upon the previous one by using some features offered by the Map/Reduce framework: • Demonstrates how applications can access configuration parameters in the configure method of the Mapper (and Reducer) implementations (lines 28-43). • Demonstrates how the DistributedCache can be used to distribute read-only data needed by the jobs. Here it allows the user to specify word-patterns to skip while counting (line 104). • Demonstrates the utility of the Tool interface and the GenericOptionsParser to handle generic Hadoop command-line options (lines 87-116, 119). • Demonstrates how applications can use Counters (line 68) and how they can set application-specific status information via the Reporter instance passed to the map (and reduce) method (line 72). Java and JNI are trademarks or registered trademarks of Sun Microsystems, Inc. in the United States and other countries.
Page 39
Copyright © 2008 The Apache Software Foundation. All rights reserved.</li>
</ol>
</li>
</ol>
</li>
</ol>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--mapred_tutorial/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--mapred_tutorial" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事7：做一个优秀的基层/">IT外企那点儿事(7)：做一个优秀的基层</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事7：做一个优秀的基层/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="it-7-">IT外企那点儿事(7)：做一个优秀的基层</h1>
<p><a href=""></a></p>
<h1 id="-http-www-cnblogs-com-forfuture1978-"><a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a></h1>
<p>  <a href="http://www.cnblogs.com/" target="_blank">博客园</a> :: <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">首页</a> :: <a href="http://q.cnblogs.com/" target="_blank">博问</a> :: <a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?opt=1" target="_blank">新随笔</a> :: <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">联系</a> :: <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank">订阅</a> <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank"><img src="" alt="订阅"></a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx" target="_blank">管理</a> :: <img src="" alt="">   130 随笔 :: 0 文章 :: 544 评论 :: 0 引用
<a href="">&lt;</a>2010年5月<a href="">&gt;</a>日一二三四五六252627282930<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/01.html" target="_blank">1</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/02.html" target="_blank">2</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03.html" target="_blank">3</a>4<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05.html" target="_blank">5</a>67<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/08.html" target="_blank">8</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/09.html" target="_blank">9</a>101112<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13.html" target="_blank">13</a>1415<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/16.html" target="_blank">16</a>1718<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/19.html" target="_blank">19</a>2021<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/22.html" target="_blank">22</a>23<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/24.html" target="_blank">24</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/25.html" target="_blank">25</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/26.html" target="_blank">26</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/27.html" target="_blank">27</a>2829303112345</p>
<h3 id="-">公告</h3>
<p>昵称：<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
园龄：<a href="http://home.cnblogs.com/u/forfuture1978/" title="入园时间：2009-12-10" target="_blank">3年7个月</a>
荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
粉丝：<a href="http://home.cnblogs.com/u/forfuture1978/followers/" target="_blank">560</a>
关注：<a href="http://home.cnblogs.com/u/forfuture1978/followees/" target="_blank">3</a></p>
<p><a href="">+加关注</a></p>
<h3 id="-">搜索</h3>
<h3 id="-">常用链接</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/MyPosts.html" target="_blank">我的随笔</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/MyComments.html" target="_blank">我的评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/OtherPosts.html" title="我发表过评论的随笔" target="_blank">我的参与</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/RecentComments.html" target="_blank">最新评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/tag/" target="_blank">我的标签</a></li>
</ul>
<h3 id="-">随笔分类</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300670.html" target="_blank">Hadoop原理与代码分析(7)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事(12)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345798.html" target="_blank">Java(2)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345797.html" target="_blank">Linux(14)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300665.html" target="_blank">Lucene原理与代码分析(38)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300666.html" target="_blank">长尾理论(16)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345794.html" target="_blank">管理学(10)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345800.html" target="_blank">经济学(4)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345796.html" target="_blank">算法(1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345795.html" target="_blank">闲话IT业(3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300667.html" target="_blank">心理学与管理学效应(9)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300668.html" target="_blank">组织行为学(15)</a></li>
</ul>
<h3 id="-">随笔档案</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11.html" target="_blank">2012年11月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/01.html" target="_blank">2012年1月 (5)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/12.html" target="_blank">2011年12月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/10.html" target="_blank">2011年10月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/09.html" target="_blank">2011年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11.html" target="_blank">2010年11月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/10.html" target="_blank">2010年10月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/09.html" target="_blank">2010年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08.html" target="_blank">2010年8月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/07.html" target="_blank">2010年7月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06.html" target="_blank">2010年6月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05.html" target="_blank">2010年5月 (22)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04.html" target="_blank">2010年4月 (18)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/03.html" target="_blank">2010年3月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02.html" target="_blank">2010年2月 (39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/01.html" target="_blank">2010年1月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12.html" target="_blank">2009年12月 (6)</a></li>
</ul>
<h3 id="-">相册</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/gallery/247104.html" target="_blank">IT外企那点儿事</a></li>
</ul>
<h3 id="-">最新评论</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2727561" target="_blank">1. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li>楼主怎么之后没有更新hadoop的相关信息了呢？是没有再研究了吗？</li>
<li>--lyeoswu</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html#2713121" target="_blank">2. Re:Lucene 原理与代码分析完整版</a></li>
<li>提个建议，你生成的pdf中没有目录，影响阅读，用office转制的过程中其实设置一下即可，方便大众嘛~，还望能发我一份，谢谢！
sendreams@hotmail.com</li>
<li>--sendreams</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2712415" target="_blank">3. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>mojunbin
现在这公司，本来做的Siverlight，我进去后没多久就转JAVA了，最近在公司折腾JAVA的一些东西，业余时间玩玩游戏，看看CLR、并折腾linux。现在观点有所转变，觉得学技术更多的是为了扩宽思维、提高眼界</li>
<li>--峰顶飞龙</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2711923" target="_blank">4. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>峰顶飞龙
您的经历和我差不多，呵呵。不晓得现在兄弟在搞C/C++呢？</li>
<li>--mojunbin</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/23/1884967.html#2708814" target="_blank">5. Re:Hadoop学习总结之五：Hadoop的运行痕迹</a></li>
<li>楼主你好，在远程调试MapReduce时，本地代码进入不了自定义的job类，而是进入到Credentials class中，此类在hadoop-core-1.0.4.jar中，请问楼主在调试过程可否遇到此问题？</li>
<li>--彭莉珊</li>
</ul>
<h3 id="-">阅读排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">1. IT外企那点儿事(8)：又是一年加薪时(26799)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">2. Lucene 原理与代码分析完整版(25617)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02/23/1671909.html" target="_blank">3. 从技术生命周期看IT历史(20878)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12/21/1628546.html" target="_blank">4. 101个著名的管理学及心理学效应(20828)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/14/1877086.html" target="_blank">5. Hadoop学习总结之三：Map-Reduce入门(18682)</a></li>
</ul>
<h3 id="-">评论排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(68)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05/1727644.html" target="_blank">2. IT外企那点儿事(4)：激动人心的入职演讲(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">3. IT外企那点儿事(6)：管理路线和技术路线(37)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">4. IT外企那点儿事(8)：又是一年加薪时(35)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">5. IT外企那点儿事(12)：也说跳槽(33)</a></li>
</ul>
<h3 id="-">推荐排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(55)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03/1726200.html" target="_blank">2. IT外企那点儿事(3)：奇怪的面试(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">3. IT外企那点儿事(8)：又是一年加薪时(36)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">4. IT外企那点儿事(12)：也说跳槽(34)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">5. IT外企那点儿事(6)：管理路线和技术路线(27)</a></li>
</ul>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/22/1741547.html" target="_blank">IT外企那点儿事(7)：做一个优秀的基层</a></p>
<p>千里之行，始于足下，无论你有多么的豪情万丈，总要从最基础的东西做起。</p>
<p>然而要做一个好的基层工作人员，并不是低头认认真真写好代码就可以的，其中可大有学问。</p>
<p>按照余世维所论，一个好的下属应该：</p>
<ul>
<li>主动向上司汇报你的工作进度——让上司知道！</li>
<li>对上司的询问，有问必答，而且清楚——让上司放心！</li>
<li>充实自己，努力学习，才能了解上司的言语——让上司轻松！</li>
<li>接受批评，不犯两次过错——让上司省事！</li>
<li>不忙的时候，主动帮助他人——让上司有效!</li>
<li>毫无怨言的接受任务——让上司圆满!</li>
<li>对自己的业务，主动提出改善计划——让上司进步！</li>
</ul>
<p>我也总结了如下几点，欢迎大家补充。</p>
<h2 id="-1-">(1) 做得快还是做得好？</h2>
<p>当前的项目管理中，多是强调结果的，号称结果导向或者结果驱动。</p>
<p>作为一个基层，做人重要，做事更重要，除了良好的沟通能力，能拿得出真金白银的成果，更是每个项目经理愿意看到的事情。</p>
<p>然而怎么叫好的结果呢？</p>
<p>一九五八年党的八大二次会议上，提出多快好省的建设社会主义。多快好省四个字即体现了前辈革命家的理想壮志，也成为后来中国管理者心中的梦。所以我们时常听到如下的话：&quot;这些功能下个月一定要出来&quot;，&quot;代码质量要高，要有详细的注释，测试用例，code review&quot;，&quot;最好提前一周至少三天，可以准备demo&quot;，&quot;项目现在经费相对比较紧张，希望大家克服一下&quot;。</p>
<p>然而现代的项目管理给我们画出了如下的三角形：</p>
<p><img src="" alt=""></p>
<p>范围，预算，时间三者相互制约，牵一发而动全身。欲范围大(多)，就应该增加项目预算(不省)，如增加人手，增加资源，买第三方成品，或者应该延长时间(不快)，如推迟release的时间等。欲按期完成(快)，则可以增加预算(不省)，或者减少功能(不多)。</p>
<p>然而现实中，老板可不这样想，预算是早就做好了的，时间也是确定了的，功能缺一不可，作为基层的程序员我们唯一可以影响的就是用加班换来更多的时间，当然还有中间的一个圆圈——项目的质量。</p>
<p>到底是尽快的做出一个实现基本功能但设计稍有缺陷，测试不太完备，有少量的Bug的版本出来然后慢慢改进呢，还是经过慢慢的精心设计，做出有完备的测试用例，经过严格测试少有Bug的版本呢？</p>
<p>这个问题如果你问程序员，大部分人会选择后者。尤其对于初涉职场，充满激情的程序员们，往往满脑设计模式，满口软件工程，几乎见不得注释中的错别字和没有覆盖到的测试边界，似乎一个不完美的方案就有辱于软件工程师的名号了，我们称之&quot;技术洁癖&quot;。</p>
<p>如果你问项目经理，也会告诉你后者，而且最好以后者的形式用前者的时间(多少有些多快好省的味道)。然而很少有项目经理会直接看你的代码，更不关心你用的何种设计模式，也不会一个个看你的测试用例来思考是否覆盖所有的边界，更不会看你写的注释了。</p>
<p>所以很不幸，除了少数精通技术，熟悉细节，了解程序员苦衷的项目经理外(这可是大多数程序员都翘首以待的领导啊)，大部分喜欢前者。</p>
<p>因为精心的设计，良好的文档是需要大量的时间，完备的测试用例的代码量几倍于实现本身，功能测试，性能测试以及Bug的修改更是难以估计时间的，所以总的时间将几倍于前者的时间，在此过程中，你献给项目经理的，除了等待，还是等待。</p>
<p>人是不喜欢等待的，尤其是很少反馈的等待，当我们用windows的时候，往往会出现估计时间相当不准确的进度条，然而我们还是喜欢看着进度条一直走到底，同样项目经理也是。</p>
<p>总是能够很快的做出项目经理能够看到的版本，便容易给人一种能力很强的感觉，至少大部分人会这样认为。</p>
<p>也许你会说：我做的版本Bug很少，后期维护成本低，QA一测不就能够看出孰优孰劣来了吗？</p>
<p>仍然很不幸，在大多数人看来，你一个月做了一个稳定的版本被认为是做了一件事情，而别人两个星期做了一个不稳定的版本，后两个星期改了三个Bug是做了四件事情，而且其每次的会议总有进度可以说，成绩斐然。</p>
<p>而且一个人身上所挂着的Bug的个数，实在不是一件值得羞愧的事情，反而是一件令人感到荣耀的事情，这说明了你重担在身，举足轻重。</p>
<p>如果你做了一个模块，用了一个月，后来半年都不曾出过Bug，而另一个人做一个模块两个星期，出过多个Bug，并且后来兼任其他模块的时候还在改Bug，还是很不幸，你会被认为所做的模块相对简单，不容易出Bug，并随着项目的进行而被淡忘，会被这样提及：&quot;他在半年前做过一个项目&quot;，而另一个人却会被认为所做的很复杂，有很多疑难杂症，而且后来会被认为身兼数职，会这样被提及：&quot;随着能力的提升，同时维护并负责多个模块，有并行工作的能力，有很强的解决问题的能力&quot;。</p>
<p>也许你觉得我说的太极端，那就举一个历史上的例子吧，有兴趣大家可以看李亚平的《前清秘史——入主中原之路》，其中是这样描写当时并称“南戚北李”的两位将军的：</p>
<p>李成梁屡立大功，受封为伯爵，跻身于帝国贵族行列。在当时，他的地位、名望等，很有可能已在戚继光之上。有一种看法，包括《明史》的作者们认为，恰恰因为戚继光威名太盛，坐镇蓟门十六年，使敌人从来不敢来犯(没有Bug啊)，于是转道入侵辽东，才给了李成梁屡立战功的机会。张居正死后，新政被废，受到张居正支持重用的戚继光被迅速边缘化，在郁郁寡欢中死去(可能明朝认为蓟门这个模块不需要再维护了)。而李成梁，他同样受到过张居正的支持和倚重，然而，可能由于下面的三个原因：其一，远离京师，与张居正没有过多的私人交往；其二，赫赫战功给万历皇帝留下了深刻印象(每次总有进度可说)；其三，动荡不安的辽东局势离不开这位骁将(辽东模块还需要维护啊)。从而，李成梁避免了池鱼之灾。</p>
<p>当前社会中，不是如此吗？是修了坚固的河堤的市长感动中国，还是和民众一起抗洪抢险的市长感动中国呢？是治理的地方路不拾遗的公安局长应该升职，还是让黑社会猖狂十年然后一举击溃的公安局长会升职呢？</p>
<p>如果你觉得你的项目经理英明过于历史甚至当朝首辅，那么恭喜你。</p>
<h2 id="-2-">(2) 有问题要尽早喊</h2>
<p>当一个模块或者一个任务交给你的时候，可能存在各种各样的困难，会出现各种各样的问题，需要各种各样的资源，这一切都应该慎重考虑后尽早提出。</p>
<p>问题的尽早提出，其实是风险控制的一种手段。</p>
<p>调配资源，排除干扰，风险控制是一个项目经理的重要责任之一，然而不要认为项目经理会英明神武到知道一切细节，也不要认为这是项目经理的事情，与你无关。其实一个模块，真正了解细节的是你。</p>
<p>所以对团队来讲，事先问题没有提出，到时候出现是你的甚至你的团队的责任，问题及早提出了，项目经理向相关人员请求资源，到时候没有解决就不是你的责任，甚至也不是你们团队的责任了。这个样子既帮助你的项目经理控制风险，又能够在外国人面前撇清责任，是每一个项目经理都欢迎的事情。</p>
<p>对你个人来讲，问题及早提出了，以后或有Bug，或有delay，都不会给人一种突然的感觉，也给项目经理一种对你，也对整个项目可控的感觉。</p>
<p>从心理学上来讲，人们多惯于先听坏消息，再听好消息，而不愿意先听好消息，再听坏消息，这就是我们常说的冷热水效应：一杯温水，保持温度不变，另有一杯冷水，一杯热水。当先将手放在冷水中，再放到温水中，会感到温水热；当先将手放在热水中，再放到温水中，会感到温水凉。</p>
<p>一个经常举得例子是：某汽车销售公司的老李，每月都能卖出30辆以上汽车，深得公司经理的赏识。由于种种原因，老李预计到这个月只能卖出10辆车。深懂人性奥妙的老李对经理说：“由于银根紧缩，市场萧条，我估计这个月顶多卖出5辆车。”经理点了点头，对他的看法表示赞成。没想到一个月过后，老李竟然卖了12辆汽车，公司经理对他大大夸奖一番。假若老李说本月可以卖15辆或者事先对此不说，结果只卖了12辆，公司经理会怎么认为呢？他会强烈地感受到老李失败了，不但不会夸奖，反而可能指责。在这个事例中，老李把最糟糕情况――顶多卖5辆车，报告给经理，使得经理心中的“秤砣”变小，因此当月绩出来以后，对老李的评价不但不会降低，反而提高了。</p>
<h2 id="-3-bug-">(3) 用Bug来说不</h2>
<p>不知从何时开始《致加西亚的信》以及《没有任何借口》此类的书开始畅销，从而以执行力的名义把责任全部推到被领导的一方，用军队的方式来要求自己的员工，不讲条件，没有借口，从不说不，来完成领导所给的任务。真不知道资本家有什么资格这样要求自己的员工，作为军人为祖国献身后至少能够成为烈士，家人受到抚慰，而资本家在员工连跳九人的情况下却在论证这个数字其实低于全国平均自杀率的。</p>
<p>然而大多数的领导的的确确喜欢没有借口的下属，也不喜欢听到说不。所以当一个任务下达的时候，或者一种方案被指定的时候，不要直接说不。</p>
<p>领导毕竟是领导，能做到现在的位置，毕竟有强于你的地方；领导毕竟也是人，提出的方案也可能是拍脑袋拍出来的，也许会有不合理性。</p>
<p>然而需要记住的一点是：上情下达可以拍脑袋，下情上达则要用证据。</p>
<p>当你认为领导给的任务或者方案有问题的时候，除了上面提到的喊难在前之外，一定要加一句，&quot;我试试看&quot;。</p>
<p>当你经过实验测试，有数据或者日志足以证明你的结论的时候，可以尝试说，&quot;我觉得可能有些问题&quot;。</p>
<p>然而有时候简单的测试并不能够证明的时候，或者领导再次坚持的时候，那就上手做吧，只是别忘了做的有扩展性一些，能在多种方案之间较容易的切换，并将领导坚持的方案暴露出来。当测试人员发现问题的时候，将比你说不有效果的多。这时候领导关心的便是如何Bug进行修复，不在纠结到底应该采用你的方案还是他的方案了，当然此时你千万不要得意洋洋的指出领导原来方案的不合理性，你不指出，领导其实是从心里认可了你的方案的，并且为你记了一功，如果你指出来，就适得其反了，大部分领导绝不会表面承认自己的错误的，可能会再次坚持自己的方案的合理性，并把因此带来的项目失败或者delay记在你的头上。也许大家清晰的记得曹操不承认&quot;鸡肋&quot;的退兵禁令而杀杨修的故事吧。如果你觉得你的领导气度大于曹操，那么再次恭喜你。</p>
<p>也许你会说：这不是浪费了一个过程吗？其实不然，你先做了领导的方案，然后改Bug的时候应用了自己的方案，在领导眼中，你是一个好的下属，好的执行者，你是做了两件事情的。</p>
<p>如果你坚持做了自己的方案而没有优先用领导的方案，则会有以下风险：</p>
<ul>
<li>你永远失去了证明你的方案优于领导的方案的机会</li>
<li>你会被认为固执，难于沟通，执行力差</li>
<li>一旦你的方案出现问题，你将单独的承担责任，甚至整个项目delay的责任。如果你优先采用了领导的方案出现问题的时候，一般合格的领导会勇于承担起责任，替你说好话：&quot;我们采取的方案是相对较优的，也是经过测试的，Bug是难免的&quot;，相反，如果你固执己见，则没有人会替你说话，反而会说：&quot;要是用原来的方案就不会出现这个问题&quot; 。</li>
<li>领导的方案一般是由一定原理上合理性的，你的方案可能是比较符合你的实际需要，然而当时过境迁，context不在的时候，你百口难辨。</li>
</ul>
<p>所以，毫无怨言的接受任务——让上司圆满，如果有问题，让Bug来说。</p>
<h2 id="-4-">(4) 该干什么的时候干什么</h2>
<p>在外企，一个常说的词叫&quot;professional&quot;，何为职业化，一个通俗的说法就是，该干什么的时候就干什么，当然无论干什么，永远不要忘记，你是一个程序员，一个基层的程序员。</p>
<p>前面说过，除了写程序，外企的生活是丰富多彩的，健身，按摩，小食品，饮料，旅游，年会，各种协会等等不一而足，而且外企的氛围是相对宽松的，你可以在任何时间尽情享用，没有人会有意见，当然是在你完成了工作的基础之上的。</p>
<p>然而永远需要记住的是，写程序才是你的天职，而多彩的生活是公司对员工的福利，是一种施舍，说的不好听一点，公司花钱请你来是写软件的，不是让你来娱乐的，公司让你娱乐是给你脸，你总不能给脸不要脸吧。话说的难听一点，但细想想，话糙理不糙，试想如果项目经理每次来巡查的时候都看到你或大声的说笑，或尽情的饮食，或玩桌上足球的时候，其内心不会有上面的想法？只不过是一种优雅的方式表达出来罢了。比如走到你的面前，微笑着问：&quot;你的feature做的如何了？&quot;，&quot;Bug XXX有没有结果？&quot;，顺便强调一下你所做的模块的难度和重要性：&quot;你做的这部分比较有难度，是对你能力的挑战&quot;，并在最后来一句：&quot;慢慢做，不着急&quot;。你可知晓此彬彬有礼下面的深意？经理两次到你这里来说&quot;不着急&quot;的间隔越短，其实是说明这件事情越着急的。</p>
<p>所以说在办公室的大部分时间，你都应该低头写程序，谈话也要讨论技术问题，娱乐要适度，除非你想被人觉得工作量太少，不努力，或者你有足够的信心自己负责的模块不会出问题。</p>
<p>另外在开会的时候，你由于任务太多，总是盯着自己的笔记本默默写自己的代码吗？不要这样，这样会让组织会议的人感到不被尊重，会让领导觉得你对项目组不够关心，不够投入，甚至不够忠诚。开会的时候，就要像开会的样子。你可以提前阅读材料来准备几个问题；你可以支持，补充或建议组织者的方案；你可以在外国人面前举出证据来维护中国团队的利益；实在没招，你至少可以记会议记录，会后发meeting minutes。这样你给人的印象永远是你是有想法的，你是有贡献的，你是关心项目的，你是热爱团队的。</p>
<p>一个Team出去吃饭，或者出去旅游的时候，你是得意忘形的放开手脚去玩吗？甚至脱离团队和要好的朋友去逛吗？不要这个样子。余世维在《经理人常犯的11个错误》的演讲中曾经说过，出去Team building，对于员工来说是休息，而对于经理来说是工作。的确，你要清楚资本家为什么会出钱让员工去做这些和工作看起来无关的事情？为什么要大家一起出去而不是每人发钱自己去玩？当然是要增加团队的凝聚力和归属感，为共同合作奠定基础。既然对于经理来讲是工作，难道你不应该有责任辅助你的经理做好工作吗？在大家一起吃饭的时候，如果冷场，积极的起一个话题吧；在经理提出玩一个团队游戏的时候，率先支持，主动去做吧；在外出旅游的时候，帮助你的经理订餐馆，清点人数，摄影照相吧；当爬到山峰，或者年会表演节目的时候，喊出增加团队凝聚力和影响力的口号吧；在活动结束后，整理资料，相片，发出email来进一步增加活动的效果吧。这样你就是有组织能力的，辅助经理成功的，有良好影响力的，也是热爱团队的。</p>
<p>这里提到了团队聚餐中的话题问题，这里顺便提一下，当然根据不同的Team的氛围以及当时的情况而定，话题的优先级依次如下：</p>
<ul>
<li>项目话题：如进度，难点，后面还会提到，学会喊累，喊忙，这是一个比较好的机会。当然此话题比较适合加班或者中午时的团队聚餐，不太适合旅游时候的团队聚餐。此话题可表明你对项目的关心。</li>
<li>技术话题：比如语言排名，那家公司被收购了，平台之间的差异等等。此话题可说明你对技术无限热爱。</li>
<li>员工生活话题：比如周末干什么了，介绍女朋友，结婚，孩子教育等，当然以当事人意愿为准，不要太当真。此话题可说明你关心同事。</li>
<li>娱乐话题：比如看什么电影，娱乐圈出来什么事情等，这是万能话题，也是最保险的话题。</li>
<li>员工敏感话题：比如非议其他Team，或者美国团队等，此类话题最好不要涉及，背后议人不太好。</li>
<li>公司敏感话题：如有的Team裁员，减薪，福利下降等，此话题千万不要提及，这是领导层想尽力遮盖的问题，甚至不在项目经理的权利范围之内。涉及此类话题将给人以你是一个不可托付大任的人。</li>
</ul>
<p>最后，如果你在学校中是演艺明星或者体育明星，那么年会的表演以及团队之间的比赛也不是你表现英雄主义的地方，而是体现团队意识的地方，也是交流沟通的好机会。所以不妨在节目中介绍一下自己团队的产品；不妨在角色设定的时候劝说core team的人加入扮演一个牛人角色(欢乐可以一定程度上冲淡马屁味道)；不妨申请印有团队logo的运动衣；不妨在运功过后和高层一同边走边聊(比平时冲到高层办公室里面好的多的机会)；不妨去敬HR一杯酒，被她们多灌几杯(HR的办公室是个敏感区，平时很难交流感情啊)；不妨去维护机房的团队那里敬酒以感谢他们的工作，去前台那里敬酒以夸赞她们的服装，发型等(他们对你来说真的很重要，想想几百人的团队，前台和运维都只有两三个人，还是那就话，当供需相差很大的时候，价格都会越来越高)。这将使你成为一个受欢迎的人。</p>
<h2 id="-5-">(5) 适当的增加影响力</h2>
<p>做一个好的基层程序员，除了完成自己的本职工作以外，也需不断增加自己的影响力，这既是你的品牌，也是日后加薪升职不可缺少的因素。</p>
<p>增加影响力主要有以下几种方式：</p>
<ul>
<li>在工作中，如果完成了一定的功能，或者测试有了详细的报告，可发邮件给领导并cc整个Team，让领导知道你的付出，和同事分享你的喜悦，让众人知道你的亮点。邮件或者报告要在开头做精炼的总结，使得大部分人能够尽快的了解结果，具体细节可放在后面，供同模块的员工详细查阅。千万不要默认你的上司和其他人都显而易见的知道你完成了什么，这也可能是很多人觉得怀才不遇，难遇明主的原因吧。台湾作家黄明坚有一个形象的比喻：“做完蛋糕要记得裱花。有很多做好的蛋糕，因为看起来不够漂亮，所以卖不出去。但是在上面涂满奶油，裱上美丽的花朵，人们自然就会喜欢来买。”</li>
<li>在各类的会议中，如上面所说，事先准备问题，合理提出建议，适时提供证据，都是在同事，领导，以及外国人面前展现自己的机会。</li>
<li>有时候美国有或管理或技术的老大来中国，都会召开all hands，这是一个不可多得的在整个公司面前展现自己的机会。而在外企，程序员的竞争力大约包括对产品的把握，对技术的把握和对英语的把握等能力。all handls也是展现这三种能力的好地方。也许你会发现这样的事实，在all hands上英语流利的提问者们，提出问题的目的也许并不是为了想弄明白什么，而是为了展现什么。他们大多是这样问的：&quot;As what you side A, but actually what we did in our project is B, so how/what/when C&quot;，你会发现，A和B会说的很具体，而C很抽象，显然A是为了展现产品把握能力(你讲的我都听懂了)，B是为了展现技术把握的能力(我们采取了什么样的技术)，整篇都用英语表达自然展现了英语的能力，最后问一个很Open的问题C，总不能问老大个很难的问题吧。</li>
<li>tech talk：当有了一定的技术积累，tech talk是一个很好的展现技术实力的平台，毕竟程序员是吃技术这碗饭的，所以良好的技术口碑对最初的升职至关重要。tech talk所讲的对象一般不是同项目的员工，因而难度要适当的把握，太简单则不足以体现你的技术实力，太难则大家会听的云里雾里，不能真正了解你的价值。在做tech talk的时候，最好一开始有一个整体的流程或者框架的介绍，以使得听众不会在途中迷路。一般有一个规律，就是在最前面几个slides的问题是最多的，大家总能够提出各种各样的问题，所以开始的几页，一定要是你最最熟悉的，最最有价值的，然而随着信息量的增大，后面就几乎提不出什么问题来了，到演讲最后，一般也就只能提出一些open question了，一般可以通过三个阶段轻松回答，其一，that is a good question，其二，it really depends，其三，I&#39;d like to give an example。</li>
<li>demo：在很多施行迭代开发的项目管理的公司里，一个阶段是会有一个demo的。很多程序员重代码，而轻demo，明明实现的非常优雅的功能，却懒得花时间生动的demo出来，中国有句古话：六十四拜都拜了，就差最后一哆嗦，多对不起你前面没黑没夜的工作啊。demo是应该好好准备的，应该有一个详细的demo流程，先录入什么数据，然后如何操作，最后应该看到什么等等。然而demo是容易失败的，似乎成为一个难以规避的定律，即无论原来demo如何准备，临阵总会有意想不到的结果，大概因为看demo的人可能会提出奇怪的尝试需求，而可能正是程序员没有考虑过的边界。所以demo中，应该事先将良好的过程录制下来，以防止真实demo过程中有差错，造成功亏一篑，至少可以证明原来是好的。在demo中一定要用近似真实的数据，如输入人名，就用真实身边的员工姓名，输入日期就用当天的真实日期，千万不要用aaa, bbb, 123456此类的数据，既不美观，也容易出问题。而且在demo的过程中，应该严格按照已经准备好的流程走，当完全走完流程后，方才可以处理现场提出的各种尝试，可保证能够完成demo任务。</li>
<li>帮助他人：在不耽误自己工作的情况下帮助他人解决技术难题，是比tech talk和demo更能够体现技术实力的地方，并会积累下人脉，当众望所归的时候，你的升职也就仅仅是时间和名额问题了。举个相似的例子，tech talk好比是保健医生，只不过是给你宣扬养生之道，而解决技术难题就如同主治医师，可以使你药到病除。很显然，如果一个人如果能够很好的按照保健医生的养生之道去做，就很少会去找主治医师去看病了。然而主治医师却比保健医生更受欢迎，一方面因为相对重要的事情，人们多会更重视紧急的事情，一方面可能因为只有在逆境，出现问题的时候，人们才会虚心接受他人的意见。试想听tech talk的人们，就如同6000点的股市中的股民，多抱有&quot;你懂，我可能比你还懂&quot;的想法，而出现了问题的人们，便如跌至2000点股市的股民，才会虚心向专家请教，并对给出的方案五体投地了。而且此点满足，不忙的时候，主动帮助他人——让上司有效!</li>
<li>培训新人：有时候公司会招来一些学校来的实习生，一年一度也会招很多应届毕业生。当然一般公司都会有各种的培训，然而一旦进入团队的时候，如何更快的上手项目，仍然需要一个过程，如果能有老员工指导一二，将会轻松很多。在项目比较紧的情况下，很多老员工不愿意培训新人，万事开头难，起步总是相对缓慢的，害怕因此而耽误进度。当然，以耽误自己的工作换来对新人的培训我也是不赞成的，这也是后面所说的要给自己留buffer的原因所在。但我需要指出的是，给一个饥饿的人一个烧饼要比其成为千万富翁后给一百万更加让人感恩。人的眼光应该长远一些，无论如何都不要轻视一个年轻人，因为你不知道其将来会是什么样子。有的人，年纪大，level高，但是基本可以看出其一辈子的轨迹了，有的人年纪轻，level低，却可能前途无量，你永远不能把握将来谁会是你的贵人。</li>
</ul>
<p>在增加的影响力的前面，我加了一个形容词——适当。要有和你的level相匹配的影响力，小心功高盖主啊。外国人有时候会强调leadership without authority，然而如果你果真这样做了，多半会招来同事的敌意(你凭什么指手画脚的啊)，也可能会招来你的lead心中的隔阂(没有authority你都能够lead啦，给你authoriy还不反了天了，你lead，那我干嘛)，所以还是不在其位，不谋其政的好。</p>
<h2 id="-6-">(6) 给别人光环</h2>
<p>当同事完成一项功能或修改完一个Bug的时候，你是否给过真诚的赞誉，帮其增加上述的影响力？</p>
<p>当同事帮助你解决了问题或者提出了优秀的方案，你是否公开表示感谢，让群众和领导都知晓？</p>
<p>当领导问及你做的模块的时候，你是否有意隐瞒了他人的功劳而突出自己的贡献？</p>
<p>当会议的时候，你是否会处心积虑的故意反对竞争对手的方案，虽然你觉得其实这真的是个好方案？</p>
<p>当发现其他人的Bug，Code reivew的时候发现他人的设计缺陷，你是否幸灾乐祸的大声疾呼，唯恐他人和领导不知？</p>
<p>你是否在同事，领导，HR的面前非议他人，嘲笑他人的设计，褒贬他人的缺陷，鄙视他人的技术，虽然的确你是此方面的大拿？</p>
<p>当你有幸获得一份荣誉的时候，你是否先谢国家(公司)，再谢政府(团队)，再谢领导，再谢同事？</p>
<p>给别人光环吧，别人也会给你光环。</p>
<p>一个只顾自己头上光环的人，以及一个别人给了光环而不知回报的人，最终都会孤立无援，难以开展工作，是涸泽而渔的做法。</p>
<p>我们必须承认的一点是，每个人都有自己的长处，也有自己的短处，每个模块都有优美的地方，也有不尽人意的地方，你有你擅长的技术，别人也有别人擅长的方向。如果大家互相向别人的头上套光环，则外人和领导看到的会多数是光环，从而大家精诚合作，团队蒸蒸日上。如果大家全部互相揭疮疤，则外人和领导则看到的会多数是负面的，从而大家互相猜忌，整个团队都没有希望。</p>
<p>历朝历代都有权臣，权臣之间必有党争，派别之间多知道对方的优势，也掌握了对方的把柄，如果派系之间相互合作，则大家都会壮大，皇帝则不会知道下面的暗流涌动，然而英明的皇帝多挑拨派系之间的关系，使他们互相揭露对方的把柄，从而下情上达，从中制衡。</p>
<p>我们也会经常看到，当一家公司的高管离开他的老东家而投奔新东家的时候，公开场合下，此高管多会十分赞誉在老东家中工作过的时光，赞誉工作过的团队，赞誉老东家的产品和项目，赞誉自己在老东家取得的进步，而老东家也多会给与此高管十分积极的评价，肯定其作出的贡献，其为公司带来的价值，其培养出的团队。其实如果两者之间如此的默契，如此的互相满意，就不会发生跳槽的事件了，既然选择分道扬镳，则其中必有隔阂，只不过互相心知肚明，各不言明罢了。这样无论对公司的发展，还是对此高管的职业生涯都有好处。试想，此高管必然是清清楚楚公司的优势劣势，公司也明明白白高管的功过是非，就像一对生活了很久的夫妻，既知道你能言善辩，也知道你鼾声震天，既知道你玉树临风，也知道你不爱洗澡，如果在公开场合互相指责，甚至谩骂，岂不家丑外扬？</p>
<h2 id="-7-daily-report-weekly-report-">(7) Daily report和weekly report很重要</h2>
<p>很多程序员宁愿多写程序，也不愿意写report，觉得十分麻烦，而又无聊。</p>
<p>但是Daily report，weekly report真的非常的重要。</p>
<p>首先report可以帮助你管理自己的时间。在时间管理中，我们知道，人总是有重要而紧急的事情，重要而不紧急的事情，不重要而紧急的事情，不重要而不紧急的事情之分。你是否总结和思考过自己真的总是做了重要而紧急的事情么？人们总是忙啊忙，从早忙到晚，天天加班，其实每天都在处理各种各样的突发紧急的事件，使得计划一拖再拖，而忽略了对自己很重要的事情。试想想吧，你原来计划过要读的书有多少是真正去读了的？你在朋友面前畅谈的宏图大志有多少是真正实践过的？你还记得儿时的梦想吗？你是一直向着自己想要的方向在不断的进步吗？时间管理的原则告诉我们，每个人应该有一张思考的床，不要穷忙、瞎忙、无心的忙。写daily report和weekly report不完全是应付上司的，也是自己思考总结的过程啊。我还记得最初每周定计划的情况，当一周过去进行回顾的时候，我当时吓了自己一跳，我原以为自己一直过的非常的充实，却发现计划做得事情真的只做了大概三分之一，照此下去，如何进步啊。有兴趣大家可是试着制定一下计划，越详细越好，工作方面的可以写给上司看，学习，社交等方面的可以自己写给自己，有时候多少有些身在江湖，身不由己的感觉。</p>
<p>其二report可以帮助你总结自己的进步。当天做的事情一般人还是记得的，一个星期做的事情，大概就模糊了，半年前做的事情，则很多细节都忘记了。很多的时候，当我们每年对自己进行年终总结以期待明年加薪的时候，当我们想要跳槽来总结自己忙碌了几年的成果的时候，往往会发现，report到用时方恨少啊。面试的时候，对于有经验的人，往往会将项目经验问的很细很细，当时你为什么选择这种方案呢？系统的速度如何一步步改进提高的？你发现你可能说不清楚了。平时尽量多详细的记录一下自己每天的进步吧，这可是影响到你薪水的闪光点啊，对方的公司正等着一个牛人来提高他们的性能呢，你明明取得很不错的结果，只是忘记了自己做了哪些改进，岂不可惜啊。</p>
<p>其三report可以帮助你增加自己的影响力。如上面所述，report不但可以让自己知道自己做了什么，也可以让上司知道你完成了什么，如果写到wiki上，还能让更多的人知道你的成绩。</p>
<p>其四report可以作为维护权利的证据。这一点前面也说过，作为初入职场的基层，作为相对美国来说弱势的中方，证据是非常重要的。当项目delay的时候，你如何证明你是提前schedule完成的？当性能遇到瓶颈，你如何证明你曾经高效且没有做过改动？在写程序的时候，我们知道，当context不在的时候，唯一能够定位问题的，就是log了，report就是你工作的log。</p>
<p>其五report可以使你的上司对你放心。很多初入职场的基层，埋怨上司过多的干预自己的工作，总是有事没事的过来问，做的如何了？有什么困难？这段时间在做什么？有时候这种询问会打断你的思路，着实让人困扰。其实情有可原，你刚来，不放心是可以理解的。如何做到你办事，他放心是你的责任。当有阶段性成果的时候实时报告自己的状态，每天写daily report报告自己的进度都是让上司放心的办法。一个有意思的现象是，当你一天一封daily report向他汇报的时候，他却不怎么过来干预你的工作了，甚至到最后daily report他也不怎么看了。</p>
<p>做到此一点，方能主动向上司汇报你的工作进度——让上司知道，对上司的询问，有问必答，而且清楚——让上司放心！</p>
<h2 id="-8-buffer-">(8) 给自己留buffer，学会喊累，学会喊忙</h2>
<p>初入职场，激情高涨，多喜欢将自己满负荷运作，无论是需求来自领导还是来自同事，都不好意思拒绝，最后弄得自己疲于奔命，焦头烂额。</p>
<p>其实工作中，是应该给自己留有一定的buffer的，一方面，可以在项目有了突发事件的时候，不至于临阵慌乱，尚有调整和处理的时间，不至于第二天demo，当天晚上代码才完成。另一方面，要做好以上所述的事情，还都是需要buffer的，绝不能够低头干个不停。</p>
<p>另外，公司是要对项目负责的，而自己的职业前途，却只有自己负责。除了每天忙于项目之外，总要有一定的时间进行自我进步，从而提升自己的价值。前面也说过，有的人面试的时候，仅仅知道项目中用到的知识点，而相关的却很少知道，从而使自己的职业生涯既不广，也不深。所以日常工作中，留有一定的buffer来将知识点变成知识面是很重要的。</p>
<p>所以如果你真的很忙，真的很累，要勇于喊出来，而不要默默的承受着，当然这不是让你装忙装累，而是向周围散发出一种信息，就是你已经负荷较满了。这样你的领导在安排任务的时候，会综合考虑，你的同事在向你提出需求的时候，也拒绝的合情合理。当然你不能总是喊忙，总是不出成果，如第一点中所说，result永远是最重要的。而总是喊忙，总是能出成果，确是一种工作努力的表现。有的人认为，只有相互说话才叫沟通，其实不然，殊不知自言自语，凝重的表情，同样是沟通的手段。</p>
<p>也只有在有buffer的情况下，你才能做到充实自己，努力学习，才能了解上司的言语——让上司轻松，你才能够做到对自己的业务，主动提出改善计划——让上司进步。</p>
<p>分类: <a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事</a></p>
<p>绿色通道： <a href="">好文要顶</a> <a href="">关注我</a> <a href="">收藏该文</a><a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">与我联系</a> <a href="&quot;分享至新浪微博&quot;"><img src="" alt=""></a>
<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank"><img src="" alt=""></a></p>
<p><a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followees" target="_blank">关注 - 3</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followers" target="_blank">粉丝 - 560</a></p>
<p>荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
<a href="">+加关注</a></p>
<p>25</p>
<p>0
(请您对文章做出评价)</p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/19/1738806.html" target="_blank">«</a> 上一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/19/1738806.html" title="发布于2010-05-19 02:35" target="_blank">Lucene学习总结之九：Lucene的查询对象</a>
<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/24/1742366.html" target="_blank">»</a> 下一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/24/1742366.html" title="发布于2010-05-24 00:02" target="_blank">乌合之众(大众心理研究)之一：民主直通独裁的心理机制</a>
posted on 2010-05-22 14:28 <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a> 阅读(6964) 评论(28) <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?postid=1741547" target="_blank">编辑</a> <a href="">收藏</a></p>
<p><a href=""></a></p>
<h3 id="-">评论</h3>
<p><a href="">/#1楼</a><a href=""></a>  2010-05-22 14:54  <a href="http://www.cnblogs.com/bluetooth/">Bluetooth</a> <a href="http://space.cnblogs.com/msg/send/Bluetooth" title="发送站内短消息" target="_blank"> </a></p>
<p>非常非常正确。
report非常重要，进度比质量更受领导欢迎，他希望最快的出成绩然后到处汇报和晋升，之后的bug是由其他人来负责的。
code 六年后我也总结出了这两点，虽然还没赢得收益。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#2楼</a><a href=""></a>  2010-05-22 15:15  <a href="http://www.cnblogs.com/z2002m/">不若相忘于江湖</a> <a href="http://space.cnblogs.com/msg/send/%e4%b8%8d%e8%8b%a5%e7%9b%b8%e5%bf%98%e4%ba%8e%e6%b1%9f%e6%b9%96" title="发送站内短消息" target="_blank"> </a></p>
<p>写的非常好。　</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u35315.jpg" target="_blank">http://pic.cnitblog.com/face/u35315.jpg</a></p>
<p><a href="">/#3楼</a><a href=""></a>  2010-05-22 16:03  <a href="http://www.cnblogs.com/evlon/">阿牛</a> <a href="http://space.cnblogs.com/msg/send/%e9%98%bf%e7%89%9b" title="发送站内短消息" target="_blank"> </a></p>
<p>深有感触呀，　我现在还在做技术洁僻，　晕．</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#4楼</a><a href=""></a>  2010-05-22 16:30  <a href="http://www.cnblogs.com/baiyanhuang/">Dbger</a> <a href="http://space.cnblogs.com/msg/send/Dbger" title="发送站内短消息" target="_blank"> </a></p>
<p>深有同感，极其赞同
楼主看来在外企有多年经验</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u64551.jpg" target="_blank">http://pic.cnitblog.com/face/u64551.jpg</a></p>
<p><a href="">/#5楼</a><a href=""></a>  2010-05-22 16:45  <a href="http://www.cnblogs.com/nbjkj/">nbjkj</a> <a href="http://space.cnblogs.com/msg/send/nbjkj" title="发送站内短消息" target="_blank"> </a></p>
<p>谢谢LZ，对于初入该职场的的我受益匪浅！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u102166.jpg" target="_blank">http://pic.cnitblog.com/face/u102166.jpg</a></p>
<p><a href="">/#6楼</a><a href=""></a>  2010-05-22 16:53  <a href="http://www.cnblogs.com/icerdesign/">冰河魔法师</a> <a href="http://space.cnblogs.com/msg/send/%e5%86%b0%e6%b2%b3%e9%ad%94%e6%b3%95%e5%b8%88" title="发送站内短消息" target="_blank"> </a></p>
<p>不错，很喜欢，顶一个。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#7楼</a><a href=""></a>  2010-05-22 16:56  <a href="http://www.cnblogs.com/ansiboy/">麦舒</a> <a href="http://space.cnblogs.com/msg/send/%e9%ba%a6%e8%88%92" title="发送站内短消息" target="_blank"> </a></p>
<p>写得不错，受益了。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u24769.jpg" target="_blank">http://pic.cnitblog.com/face/u24769.jpg</a></p>
<p><a href="">/#8楼</a><a href=""></a>  2010-05-22 20:47  <a href="http://www.cnblogs.com/cmt/">博客园团队</a> <a href="http://space.cnblogs.com/msg/send/%e5%8d%9a%e5%ae%a2%e5%9b%ad%e5%9b%a2%e9%98%9f" title="发送站内短消息" target="_blank"> </a></p>
<p>图片不能显示，麻烦上传一下图片。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/35695/20130121190936.png" target="_blank">http://pic.cnitblog.com/face/35695/20130121190936.png</a></p>
<p><a href="">/#9楼</a><a href=""></a>[楼主]  2010-05-22 20:59  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>博客园团队
你好，在我的浏览器里面，好像图片是可以显示的。
如何上传图片呢？
谢谢</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#10楼</a><a href=""></a>  2010-05-22 21:01  <a href="http://www.cnblogs.com/rayking/">爱在戏院前</a> <a href="http://space.cnblogs.com/msg/send/%e7%88%b1%e5%9c%a8%e6%88%8f%e9%99%a2%e5%89%8d" title="发送站内短消息" target="_blank"> </a></p>
<p>写的很好</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#11楼</a><a href=""></a>  2010-05-22 21:31  <a href="http://www.cnblogs.com/MaoBisheng/">MaoBisheng</a> <a href="http://space.cnblogs.com/msg/send/MaoBisheng" title="发送站内短消息" target="_blank"> </a></p>
<p>拜读了
不过图片没显示出来...</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u37118.jpg?id=10195626" target="_blank">http://pic.cnitblog.com/face/u37118.jpg?id=10195626</a></p>
<p><a href="">/#12楼</a><a href=""></a>  2010-05-22 21:43  <a href="http://www.cnblogs.com/MaoBisheng/">MaoBisheng</a> <a href="http://space.cnblogs.com/msg/send/MaoBisheng" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看引用原文&quot;">引用</a>觉先：
@博客园团队
你好，在我的浏览器里面，好像图片是可以显示的。
如何上传图片呢？
谢谢
后台写随笔的那个编辑器里有传图片的功能的，位置大概在设置字体颜色的下方。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u37118.jpg?id=10195626" target="_blank">http://pic.cnitblog.com/face/u37118.jpg?id=10195626</a></p>
<p><a href="">/#13楼</a><a href=""></a>  2010-05-22 22:03  <a href="http://www.cnblogs.com/chinese-zmm/">chinese_submarine</a> <a href="http://space.cnblogs.com/msg/send/chinese_submarine" title="发送站内短消息" target="_blank"> </a></p>
<p>很不错的一遍非技术文章，胜过很多技术文章。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u28698.png" target="_blank">http://pic.cnitblog.com/face/u28698.png</a></p>
<p><a href="">/#14楼</a><a href=""></a>[楼主]  2010-05-22 22:12  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看引用原文&quot;">引用</a>MaoBisheng：
引用觉先：
@博客园团队
你好，在我的浏览器里面，好像图片是可以显示的。
如何上传图片呢？
谢谢
后台写随笔的那个编辑器里有传图片的功能的，位置大概在设置字体颜色的下方。
谢谢，已经上传了图片了</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#15楼</a><a href=""></a>  2010-05-22 23:32  <a href="http://www.cnblogs.com/xjb/">xjb</a> <a href="http://space.cnblogs.com/msg/send/xjb" title="发送站内短消息" target="_blank"> </a></p>
<p>非常喜欢这个系列，甚至都适用于非外企的公司。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u12916.png?id=04113617" target="_blank">http://pic.cnitblog.com/face/u12916.png?id=04113617</a></p>
<p><a href="">/#16楼</a><a href=""></a>  2010-05-22 23:36  <a href="http://www.cnblogs.com/huxj/">steven hu</a> <a href="http://space.cnblogs.com/msg/send/steven+hu" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>觉先
用windows live writer，图片会自动上传</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u34974.jpg" target="_blank">http://pic.cnitblog.com/face/u34974.jpg</a></p>
<p><a href="">/#17楼</a><a href=""></a>[楼主]  2010-05-22 23:48  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看引用原文&quot;">引用</a>steven hu：
@觉先
用windows live writer，图片会自动上传
谢谢，我用的是windows live writer，只不过这次的图片是从网上搜的，没想到windows live writer并不是上传此图片，而是直接将网上的地址放在文章中，而且原图片好像地址又被移走了。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#18楼</a><a href=""></a>  2010-05-22 23:55  <a href="http://www.cnblogs.com/graphics/">zdd</a> <a href="http://space.cnblogs.com/msg/send/zdd" title="发送站内短消息" target="_blank"> </a></p>
<p>千古好文！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u64257.jpg?id=21102348" target="_blank">http://pic.cnitblog.com/face/u64257.jpg?id=21102348</a></p>
<p><a href="">/#19楼</a><a href=""></a>  2010-05-23 08:02  <a href="http://www.cnblogs.com/JerryKai/">JerryKai</a> <a href="http://space.cnblogs.com/msg/send/JerryKai" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主，很长的一篇文章啊！
不过，真的很好！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u59349.jpg?id=07201540" target="_blank">http://pic.cnitblog.com/face/u59349.jpg?id=07201540</a></p>
<p><a href="">/#20楼</a><a href=""></a>  2010-05-23 10:06  <a href="http://www.cnblogs.com/schoolers/">兔兔子</a> <a href="http://space.cnblogs.com/msg/send/%e5%85%94%e5%85%94%e5%ad%90" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主写得太好了！！！
学习了！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u121822.jpg?id=08205343" target="_blank">http://pic.cnitblog.com/face/u121822.jpg?id=08205343</a></p>
<p><a href="">/#21楼</a><a href=""></a>  2010-05-23 10:31  <a href="http://www.cnblogs.com/elwin/">elwin.wang</a> <a href="http://space.cnblogs.com/msg/send/elwin.wang" title="发送站内短消息" target="_blank"> </a></p>
<p>LZ是杭州华数的吗？</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#22楼</a><a href=""></a>  2010-05-23 10:49  <a href="http://www.cnblogs.com/wanjiabao/">JiabaoET</a> <a href="http://space.cnblogs.com/msg/send/JiabaoET" title="发送站内短消息" target="_blank"> </a></p>
<p>非常在理！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u102695.jpg" target="_blank">http://pic.cnitblog.com/face/u102695.jpg</a></p>
<p><a href="">/#23楼</a><a href=""></a>  2010-05-23 21:55  <a href="http://www.cnblogs.com/Lovepanda/">Pandaimp</a> <a href="http://space.cnblogs.com/msg/send/Pandaimp" title="发送站内短消息" target="_blank"> </a></p>
<p>mark！好东西，要多读</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u97216.jpg" target="_blank">http://pic.cnitblog.com/face/u97216.jpg</a></p>
<p><a href="">/#24楼</a><a href=""></a>  2010-05-25 09:48  <a href="http://www.cnblogs.com/coki/">Coki</a> <a href="http://space.cnblogs.com/msg/send/Coki" title="发送站内短消息" target="_blank"> </a></p>
<p>太经典了！这种有深度的文章真是少有啊！
LZ的每篇文章我都会拜读，确实是实践中总结出来的财富啊！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#25楼</a><a href=""></a>  2010-05-27 12:42  <a href="http://www.cnblogs.com/sincerefire/">木可</a> <a href="http://space.cnblogs.com/msg/send/%e6%9c%a8%e5%8f%af" title="发送站内短消息" target="_blank"> </a></p>
<p>very good</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#26楼</a><a href=""></a>  2010-05-30 15:32  <a href="http://www.cnblogs.com/gracestoney/">gracestoney</a> <a href="http://space.cnblogs.com/msg/send/gracestoney" title="发送站内短消息" target="_blank"> </a></p>
<p>多谢分享，很实用，有些东西可能我们都知道，有些在做了或者尚未开始做，楼主的文章很好地总结和整理出来，效果不同凡响！支持。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#27楼</a><a href=""></a>  2010-08-18 22:41  <a href="http://home.cnblogs.com/u/100736/">Zero Huang</a> <a href="http://space.cnblogs.com/msg/send/Zero+Huang" title="发送站内短消息" target="_blank"> </a></p>
<p>LZ很强很NB</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#28楼</a><a href=""></a>19213732010/9/20 13:36:36  2010-09-20 13:36  <a href="http://www.cnblogs.com/huyh/">hans.hu</a> <a href="http://space.cnblogs.com/msg/send/hans.hu" title="发送站内短消息" target="_blank"> </a></p>
<p>写得很有见地,可以出书了.</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">刷新评论</a><a href="">刷新页面</a><a href="">返回顶部</a></p>
<p>注册用户登录后才能发表评论，请 <a href="">登录</a> 或 <a href="">注册</a>，<a href="http://www.cnblogs.com/" target="_blank">访问</a>网站首页。
<a href="http://www.cnblogs.com/" title="程序员的网上家园" target="_blank">博客园首页</a><a href="http://q.cnblogs.com/" title="程序员问答社区" target="_blank">博问</a><a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">新闻</a><a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a><a href="http://job.cnblogs.com/" target="_blank">程序员招聘</a><a href="http://kb.cnblogs.com/" target="_blank">知识库</a></p>
<p><strong>最新IT新闻</strong>:
· <a href="http://news.cnblogs.com/n/182486/" target="_blank">新硬硬整合时代</a>
· <a href="http://news.cnblogs.com/n/182485/" target="_blank">狗血的百度91并购案啊 阿里和周鸿祎都曾掺和</a>
· <a href="http://news.cnblogs.com/n/182483/" target="_blank">如何让搜索引擎抓取AJAX内容？</a>
· <a href="http://news.cnblogs.com/n/182482/" target="_blank">避免代码注释的五大理由</a>
· <a href="http://news.cnblogs.com/n/182481/" target="_blank">OpenWrt——适用于路由器的Linux系统</a>
» <a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">更多新闻...</a></p>
<p><strong>最新知识库文章</strong>:
· <a href="http://kb.cnblogs.com/page/141892/" target="_blank">阿里巴巴集团去IOE运动的思考与总结</a>
· <a href="http://kb.cnblogs.com/page/182265/" target="_blank">硅谷归来7点分享：创业者，做你自己</a>
· <a href="http://kb.cnblogs.com/page/182200/" target="_blank">我为什么不能坚持？</a>
· <a href="http://kb.cnblogs.com/page/168725/" target="_blank">成为高效程序员的7个重要习惯</a>
· <a href="http://kb.cnblogs.com/page/182047/" target="_blank">谈谈对BPM的理解</a>
» <a href="http://kb.cnblogs.com/" target="_blank">更多知识库文章...</a>
Powered by:
<a href="http://www.cnblogs.com/" target="_blank">博客园</a>
Copyright © 觉先</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/zhiya/">zhiya</a></li></span><span class="breadcrumb"><li><a href="/categories/职涯/">职涯</a></li><li><a href="/categories/职涯/IT外企/">IT外企</a></li></span></span> | <span class="tags">Tagged <a href="/tags/IT外企/" class="label label-primary">IT外企</a><a href="/tags/zhiya/" class="label label-success">zhiya</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事7：做一个优秀的基层/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-zhiya-IT外企--IT外企那点儿事7：做一个优秀的基层" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-zhiya-IT外企--一直都在注意Oracle的招聘信息/">一直都在注意Oracle的招聘信息</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-zhiya-IT外企--一直都在注意Oracle的招聘信息/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-oracle-">一直都在注意Oracle的招聘信息</h1>
<p>一直都在注意Oracle的招聘信息，毕竟是世界第二大软件公司呀。可是，奇怪的是观察了很长的时间都没有发现任何招聘广告。并且，从我对它的初步了解来看，与微软，Google中国研发中心比起来，它显得那样的无声无息。终于有一天的早上，打开zhaopin.com，第一次发现了Oracle的招聘信息。高兴的是，里边包括若干个测试的职位。马上把简历投了过去。下午接到了电话，一听果然就是Oracle的，要跟我安排面试。Oracle的招聘比较奇怪，没有recruiter,都是hiring manager跟你联系。
面试当天，早了几分钟来到公司，被前台领到一间会议室里面，给了一套试题来做。同屋已经有好几个人在做题了，心理顿感不爽。本来以为是要单独给我面试的，没想到竟然会跟大家一起做题。更没想到的是，当我打开试题的时候，我好像基本都不会做。实话实说，我并没有什么Oracle的技术背景，可是我觉得做测试也不需要懂这么多试题上的知识吧？硬着头皮做了两道，实在做不下去了，起身就走。到了前台，告诉他们我感觉这个面试不对劲。他们才反应过来给搞错了。忙着给我的hiring manager打电话，让我去了她那里。
Hiring manager是个中年女士，看起来人就很nice。面试也是在一间会议室进行的，做了一屋子的人。看来对一个测试人员的面试也搞得挺隆重。Hiring manager并没有提问，第一个提问的是个技术大拿。他面试的场面我还从来没经历过。简单的说就是，他看着你简历问你问题，问得肯定是你做过的东西，但是，问得深度是特别的深，一般你还回答不上来。这种知识面，深度的人，到任何地方都是大拿。我是挺佩服的。第二个面试的可能是一个香港人，他主要是考察我的英文水平，用英文跟我聊了很长时间。第三个人主要是考察我的Linux的技术，很抱歉好久没有用Linux了，问我的很多简单的命令，本来我以前是会的，可是忘记了。不过，这个时候那个manager讲话了，说我的背景学Linux应该是很快的事情。然后我主要跟他们聊了自动化测试的东西，他们竟然还没有什么自动化的测试，基本还是靠手工测试。他们也希望我能够在自动化测试方面能够给公司带来些新鲜的东西。
第二天，manager给我打电话，说美国的老板想跟我聊聊。与此同时，我也接受到美国的一封email,要跟我电话面试，搞得我有点迷惑。最后才知道，是两个不同的老板要跟我面试。定了周末两天的上午，因为对方是在加州，我们合适的时间只有每天的上午。第一天面试是一个中国人，不过我们全是用英文交谈的。看得出他对我很满意，多次给我说这个职位不是在他的team，如果对方的不要我，我可以来他的team。他是做日本方面的项目，另一个team是做 open source的项目。一直谈的都很愉快，直到谈到待遇的问题。说实话，我当时的目标是每月2万，不过由于微软，Google的情况还不明朗，不想再错过这次机会，因此就要了每月1.5万。没想到他却明确回答不能满足，并跟我说他们有很多福利等等。最后问我要多少钱，我就回答算上福利全年20万。实际上当时有点傻，因为月薪1.5万和加上福利年薪20万应该是差不多的。对方就没有再说什么，我们结束了谈话。第二天是个老外，主要谈一些技术的问题吧，我也没感觉是好是坏，因为昨天的人已经说过不行就去他的team了。
不过，后来他们就再也没跟我联系过。我估计是我的要价太高了，而且我最近知道我一个朋友有多年的Oracle经验，刚刚进入他们那里，也不过是20万年薪。这样解释了我的一个疑惑。我当时就奇怪，堂堂一个Oracle怎么把研发中心放到上地。看来他们本身就不想投入太多。后来又听人说，这个中心的老板不地道，总之有一些rumor,不知道是真是假。
我想当时如果我真想进的话，开口小点应该是没什么问题的。这里给大家介绍一个面试的经验，对方的技术你不熟悉可能不是一个大问题。面试的时候，一定要有自信，让对方知道你有能力，有激情，有头脑。并且，一定要大胆跟他们讨论一些你擅长的技术问题。让他们更细致的了解你的能力，留下与其他人不一样的印象，就更容易打动他们。还有一个经验就是，谈待遇的时候，如果你真的想进这个公司，你就不要说具体数目了，就说我很珍惜这个工作进会，我一直都期望能进入你们的公司，你们可以按照标准给我工资就可以了，我没什么特殊的要求。我后来的面试在待遇上都是如此回答的，并且都得到了offer。
下次有时间，讲讲我去微软，北电面试的经验教训。</p>
<p>来源： <a href="[http://www.linuxdiyf.com/viewarticle.php?id=97760](http://www.linuxdiyf.com/viewarticle.php?id=97760)">[http://www.linuxdiyf.com/viewarticle.php?id=97760](http://www.linuxdiyf.com/viewarticle.php?id=97760)</a></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/zhiya/">zhiya</a></li></span><span class="breadcrumb"><li><a href="/categories/职涯/">职涯</a></li><li><a href="/categories/职涯/IT外企/">IT外企</a></li></span></span> | <span class="tags">Tagged <a href="/tags/IT外企/" class="label label-primary">IT外企</a><a href="/tags/zhiya/" class="label label-success">zhiya</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-zhiya-IT外企--一直都在注意Oracle的招聘信息/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-zhiya-IT外企--一直都在注意Oracle的招聘信息" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-DIV--利用DIV滚动条节约页面空间_山歌/">利用DIV滚动条节约页面空间_山歌</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-DIV--利用DIV滚动条节约页面空间_山歌/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-div-_-">利用DIV滚动条节约页面空间_山歌</h1>
<p><a href="http://hi.baidu.com/" target="_blank">百度空间</a> | <a href="http://www.baidu.com/" target="_blank">百度首页</a> | <a href="https://passport.baidu.com/?login&amp;tpl=sp&amp;tpl_reg=sp&amp;u=http://hi.baidu.com%2Fhbydzss%2Fblog%2Fitem%2Fa4e4f503cd41c8753812bb20%252Ehtml%2Fcmtid%2F7d67b37e9c014f310cd7da9b" target="_blank">登录</a></p>
<p><a href="http://hi.baidu.com/hbydzss" title="hbydzss的空间 http://hi.baidu.com/hbydzss" target="_blank">山歌</a></p>
<p>快速反应，立即行动，创意执行，持之以恒</p>
<p><a href="http://hi.baidu.com/hbydzss" target="_blank">主页</a><a href="http://hi.baidu.com/hbydzss/blog" target="_blank">博客</a><a href="http://hi.baidu.com/hbydzss/album" target="_blank">相册</a>|<a href="http://hi.baidu.com/hbydzss/profile" target="_blank">个人档案</a> |<a href="http://hi.baidu.com/hbydzss/friends" target="_blank">好友</a></p>
<p>  查看文章  </p>
<p>利用DIV滚动条节约页面空间</p>
<p>2007-07-14 17:21
所谓DIV滚动条，就是利用DIV标签，在里面嵌入CSS样式表，加入overflow的属性值，这样，当div所规范的区域内的内容达到一定程序时，滚动条就派上用场。其功能大约是为了节约页面空间，就是所谓的“缩地”了。看看效果如何吧，代码在下一楼提供。</p>
<p>参考核心代码：</p>
<DIV style="PADDING-RIGHT:10px;OVERFLOW-Y:auto;PADDING-LEFT:10px;SCROLLBAR-FACE-COLOR:/#ffffff;FONT-SIZE:11pt;PADDING-BOTTOM:0px;SCROLLBAR-HIGHLIGHT-COLOR:/#ffffff;OVERFLOW:auto;WIDTH:510px;SCROLLBAR-SHADOW-COLOR:/#919192;COLOR:blue;SCROLLBAR-3DLIGHT-COLOR:/#ffffff;LINE-HEIGHT:100%;SCROLLBAR-ARROW-COLOR:/#919192;PADDING-TOP:0px;SCROLLBAR-TRACK-COLOR:/#ffffff;FONT-FAMILY:宋体;SCROLLBAR-DARKSHADOW-COLOR:/#ffffff;LETTER-SPACING:1pt;HEIGHT:200px;TEXT-ALIGN:left">

<p>滚动条相关颜色属性：</p>
<p>face-color：滑块颜色</p>
<p>hightlight-color：高亮颜色</p>
<p>3dlight-color：三维光线颜色</p>
<p>darkshadow-color：暗影颜色</p>
<p>shadow-color：阴影颜色</p>
<p>arrow-color：箭头颜色</p>
<p>tack-color：滑道颜色</p>
<p>滚动条属性：</p>
<p>overflow：auto为自动，yes为有，no为无</p>
<p>overflow-x：横向滚动条</p>
<p>overflow-y：纵向滚动条</p>
<p>注意：</p>
<p>在论坛中，要成功使用DIV滚动条，需要在HTML编辑模式下编写代码，发布前将“自动修正”前的“√”去掉。
<a href="http://hi.baidu.com/hbydzss/blog/category/%CD%F8%D5%BE%BD%A8%C9%E8" title="查看该分类中所有文章" target="_blank">类别：网站建设</a> | <a href="http://cang.baidu.com/do/add" title="将此文章添加到百度搜藏" target="_blank">添加到搜藏</a> | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" title="将此文章分享到i贴吧" target="_blank">分享到i贴吧</a> | 浏览(17811) | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#send" target="_blank">评论</a> (11)</p>
<p>上一篇：<a href="http://hi.baidu.com/hbydzss/blog/item/e28032adfa2b2d0b4a36d65f.html" title="用户界面设计——用好的设计替代不好的" target="_blank">用户界面设计——用好的设计替代...</a>    下一篇：<a href="http://hi.baidu.com/hbydzss/blog/item/c381e3fead9cc2335d600854.html" title="如何在打开网页时全屏播放视屏？" target="_blank">如何在打开网页时全屏播放视屏？</a></p>
<p>相关文章：<a href="">•</a><a href="http://hi.baidu.com/quxxx2009/blog/item/47b6c6e6d9f5e127b93820ee.html" title="如何让DIV固定在页面的某个位置而不随着滚动条随意滚动" target="_blank">如何让DIV固定在页面的某个位置...</a>　　　　　　　　　<a href="">•</a><a href="http://hi.baidu.com/%BB%A8%BB%A8may/blog/item/f9b8698626d29f3866096e59.html" title="页面内div滚动条 浅蓝色 很好看" target="_blank">页面内div滚动条 浅蓝色 很好看</a><a href="">•</a>[<a href="http://hi.baidu.com/timmycheung/blog/item/09191850b353b567853524dd.html" title="[08-05-16 DIV 让DIV在页面中飘浮显示带滚动条 I]" target="_blank">08-05-16 DIV 让DIV在页面中飘...</a>　　　　　　　　　<a href="">•</a><a href="http://hi.baidu.com/qualylee/blog/item/691d8544e2aeff46510ffeeb.html" title="div滚动条样式一览" target="_blank">div滚动条样式一览</a><a href="">•</a><a href="http://hi.baidu.com/bensysu/blog/item/891b311f672b3c00304e1596.html" title="DIV滚动条样式大全" target="_blank">DIV滚动条样式大全</a>　　　　　　　　　<a href="">•</a><a href="http://hi.baidu.com/502219432/blog/item/9b88cc4b00cd08fa83025cd0.html" title="div滚动条属性及样式设置" target="_blank">div滚动条属性及样式设置</a><a href="">•</a><a href="http://hi.baidu.com/rentj1/blog/item/ad27d7291364f9f499250ab0.html" title="多个DIV在同一行出现水平滚动条(display:inline-block;)" target="_blank">多个DIV在同一行出现水平滚动条(...</a>　　　　　　　　　<a href="">•</a><a href="http://hi.baidu.com/kayzombie/blog/item/5bc50cfd7e5b7f4cd6887d0a.html" title="js实现随滚动条移动的DIV层" target="_blank">js实现随滚动条移动的DIV层</a><a href="">•</a><a href="http://hi.baidu.com/zhong8880/blog/item/fbe7c6ed8185e44679f05563.html" title="div 滚动条" target="_blank">div 滚动条</a>　　　　　　　　　<a href="">•</a><a href="http://hi.baidu.com/gmn2008/blog/item/44e0e0540dad5a51d00906d4.html" title="div overflow (添加滚动条)" target="_blank">div overflow (添加滚动条)</a><a href="http://hi.baidu.com/sys/search?pageno=1&amp;type=7&amp;sort=1&amp;word=%C0%FB%D3%C3DIV%B9%F6%B6%AF%CC%F5%BD%DA%D4%BC%D2%B3%C3%E6%BF%D5%BC%E4&amp;item=a4e4f503cd41c8753812bb20" target="_blank">更多&gt;&gt;</a></p>
<p>最近读者： <img src="" alt=""><a href="https://passport.baidu.com/?login&amp;tpl=sp&amp;tpl_reg=sp&amp;u=http%3A%2F%2Fhi.baidu.com%2Fhbydzss%2Fblog%2Fitem%2Fa4e4f503cd41c8753812bb20%252Ehtml%2Fcmtid%2F7d67b37e9c014f310cd7da9b" target="_blank">登录</a>后，您就出现在这里。<a href="http://hi.baidu.com/tainylong" target="_blank"><img src="" alt=""></a><a href="http://hi.baidu.com/fabian0123" target="_blank"><img src="" alt=""></a><a href="http://hi.baidu.com/%CC%EC%D3%EE%C1%F7%D4%C6" target="_blank"><img src="" alt=""></a><a href="http://hi.baidu.com/skyverd" target="_blank"><img src="" alt=""></a><a href="http://hi.baidu.com/deepwishly" target="_blank"><img src="" alt=""></a><a href="http://hi.baidu.com/weizhengjim" target="_blank"><img src="" alt=""></a><a href="http://hi.baidu.com/aabbccc007" target="_blank"><img src="" alt=""></a><a href="http://hi.baidu.com/tjpuhxy" target="_blank"><img src="" alt=""></a>  <a href="http://hi.baidu.com/tainylong" target="_blank">tainylong</a><a href="http://hi.baidu.com/fabian0123" target="_blank">fabian0123</a><a href="http://hi.baidu.com/%CC%EC%D3%EE%C1%F7%D4%C6" target="_blank">天宇流云</a><a href="http://hi.baidu.com/skyverd" target="_blank">Skyverd</a><a href="http://hi.baidu.com/deepwishly" target="_blank">deepwishly</a><a href="http://hi.baidu.com/weizhengjim" target="_blank">当骨牌泻下</a><a href="http://hi.baidu.com/aabbccc007" target="_blank">aabbccc007</a><a href="http://hi.baidu.com/tjpuhxy" target="_blank">tjpuhxy</a></p>
<p><a href=""></a></p>
<p>网友评论：
<a href=""></a> 1 网友:<a href="">过路者</a> 2007-10-25 16:32 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>不错</p>
<p><a href=""></a> 2 <a href="">匿名网友</a> 2007-10-25 16:33 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p><img src="" alt=""></p>
<p><a href=""></a> 3 网友:<a href="mailto:shenzhizhong1989@163.com" title="mailto:shenzhizhong1989@163.com">郁闷者</a> 2007-11-22 11:45 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>不错，谢谢了，</p>
<p><a href=""></a> 4 <a href="http://hi.baidu.com/shzhrui"><img src="" alt="">
shzhrui</a> 2007-12-23 18:27 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>高手</p>
<p><a href=""></a> 5 <a href="http://hi.baidu.com/ybzx211"><img src="" alt="">
ybzx211</a> 2008-02-15 20:31 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>太好了，我找的就是这个！</p>
<p><a href=""></a> 6 <a href="http://hi.baidu.com/%E7%8B%BC%E7%8E%8B%E7%9F%A5%E5%B7%B1"><img src="" alt="">
狼王知己</a> 2008-07-22 11:12 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>受教了</p>
<p><a href=""></a> 7 <a href="http://hi.baidu.com/awary"><img src="" alt="">
awary</a> 2008-12-17 17:06 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>很好,派上用场了</p>
<p><a href=""></a> 8 网友:<a href="">dengjx</a> 2009-01-13 10:31 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>高手，学习了</p>
<p><a href=""></a> 9 网友:<a href="http://www.diancms.com/" title="http://www.diancms.com">diancms</a> 2009-06-12 10:00 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>易点内容管理系统AC版（DianCMS.AC）是基于微软.NET2.0+Ajax1.0+Access数据库进行多层架构开发的内容管理系统，其功能设计主要针对各类中小型企业站点的建设和管理以及为追求低成本的个人站长而研发。使用本系统，您可以在不编程的情况下可以轻松、灵活的建立内容模型、会员模型、搜索表单等；所有模型都可以自定义字段从而建立新闻系统、房产系统、人才系统、音乐系统、供求系统、B2C商城、会员系统等一系列功能模块。程序特点如下：
一、自定义模型
二、自定义表单
三、自定义用户注册
四、自定义搜索
五、超强字段管理
六、超强表单设置
七、标签任意条件组合调用
八、单页管理
九、一条数据可属于多个栏目
十、SEO优化设置
十一、自定义Sitemap
十二、后台支持选项卡功能
............
官方唯一网站：<a href="http://www.diancms.com" target="_blank">http://www.diancms.com</a></p>
<p><a href=""></a> 10 网友:<a href="">yj</a> 2009-08-14 11:57 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p>不错，借用一下，呵呵</p>
<p><a href=""></a> 11 <a href="http://hi.baidu.com/%E5%A4%A9%E5%AE%87%E6%B5%81%E4%BA%91"><img src="" alt="">
天宇流云</a> 2009-12-10 14:38 | <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">回复</a></p>
<p><img src="" alt="">空间很漂亮</p>
<p><a href=""></a></p>
<p>发表评论：
姓　名：    <a href="http://hi.baidu.com/st/reg.html" target="_blank">注册</a> | <a href="https://passport.baidu.com/?login&amp;tpl=sp&amp;tpl_reg=sp&amp;u=http%3A%2F%2Fhi.baidu.com%2Fhbydzss%2Fblog%2Fitem%2Fa4e4f503cd41c8753812bb20%252Ehtml%2Fcmtid%2F7d67b37e9c014f310cd7da9b" target="_blank">登录</a></p>
<p>/*姓名最长为50字节   网址或邮箱： (选填)   内　容： 插入表情   验证码： 请点击后输入四位验证码，字母不区分大小写
<img src="" alt=""><a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" title="看不清左边的字符" target="_blank">看不清?</a>       <a href="http://hi.baidu.com/hbydzss/blog/item/a4e4f503cd41c8753812bb20.html/cmtid/7d67b37e9c014f310cd7da9b#" target="_blank">取消回复</a></p>
<p>©2009 Baidu   <img src="" alt=""></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/DIV/">DIV</a></li></span></span> | <span class="tags">Tagged <a href="/tags/DIV/" class="label label-primary">DIV</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-DIV--利用DIV滚动条节约页面空间_山歌/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-DIV--利用DIV滚动条节约页面空间_山歌" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-DIV--div显示滚动条和控制滚动条属性的css代码-老吧网/">div显示滚动条和控制滚动条属性的css代码 </a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-DIV--div显示滚动条和控制滚动条属性的css代码-老吧网/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="div-css-">div显示滚动条和控制滚动条属性的css代码 - 老吧网</h1>
<h2 id="-http-www-lao8-org-"><a href="http://www.lao8.org/" target="_blank">老吧</a></h2>
<ul>
<li>疲惫的一天，记录点滴的进步与成长，还在那个老吧，不见不散</li>
</ul>
<p><a href="http://www.lao8.org/" target="_blank">首页</a> <a href="http://www.lao8.org/user/8/seo/" title="seo技术 网站推广 搜索引擎优化" target="_blank">网站推广</a> <a href="http://www.lao8.org/user/8/photo/" title="摄影技术 摄影欣赏 摄影作品 原创摄影" target="_blank">摄影</a> <a href="http://www.lao8.org/user/8/design/" title="平面设计 创意作品" target="_blank">创意设计</a> <a href="http://www.lao8.org/user/8/asp/" title="asp ajax" target="_blank">网站技术</a> <a href="http://www.lao8.org/user/8/photoshop/" title="Photoshop教程 ps教程" target="_blank">Photoshop教程</a> <a href="http://www.lao8.org/user/8/20081413558/" title="营销" target="_blank">营销</a> <a href="http://www.lao8.org/user/8/200815112636/" title="艺术图库" target="_blank">艺术图库</a> <a href="http://www.lao8.org/user/8/2008214170947/" title="小游戏" target="_blank">小游戏</a> <a href="http://www.lao8.org/user/8/TradeEnglish/" title="外贸英语" target="_blank">外贸英语</a> <a href="http://www.lao8.org/user/8/2008815101140/" title="热播电影" target="_blank">热播电影</a> <a href="http://www.lao8.org/user/8/2008102493244/" title="ebay开店技巧" target="_blank">ebay开店技巧</a> <a href="http://www.lao8.org/user/8/2009719122450/" title="SQL数据库" target="_blank">SQL数据库</a> <a href="http://www.lao8.org/user/8/200986105026/" title="服务器安全" target="_blank">服务器安全</a> <a href="http://www.lao8.org/user/8/200987120553/" title="索尼 美能达 原厂定焦 广角镜头 sony minolta meinongda suoni" target="_blank">Alpha原厂定焦广角镜头</a> <a href="http://www.lao8.org/user/8/200987120644/" title="索尼 美能达 原厂定焦 标准镜头 sony minolta meinongda suoni 标头" target="_blank">Alpha原厂定焦标准镜头</a> <a href="http://www.lao8.org/user/8/200987120750/" title="索尼 美能达 原厂望远 定焦镜头 sony minolta meinongda suoni" target="_blank">Alpha原厂望远定焦镜头</a> <a href="http://www.lao8.org/user/8/200987120832/" title="索尼 美能达 原厂广角变焦镜头 sony minolta meinongda suoni" target="_blank">Alpha原厂广角变焦镜头</a> <a href="http://www.lao8.org/user/8/sony_fuchang/" title="sony 副厂镜头 索尼副厂镜头 索尼副厂变焦镜头 索尼副厂自动镜头 索尼副厂单反镜头 minolta meinongda suoni" target="_blank">索尼单反副厂变焦镜头</a> <a href="http://www.lao8.org/user/8/200981731112/" title="Godaddy(GD)美国空间" target="_blank">Godaddy(GD)美国空间</a> <a href="http://www.lao8.org/user/8/200981741553/" title="索尼副厂定焦镜头" target="_blank">索尼副厂定焦镜头</a> || <a href="http://s.lao8.org/" target="_blank">联合搜索</a> <a href="http://www.lao8.org/fanyi.asp" target="_blank">在线翻译</a> <a href="http://www.lao8.org/liuyan/" target="_blank">留言</a></p>
<h1 id="-div-css-"><a href="">div显示滚动条和控制滚动条属性的css代码</a></h1>
<p>分类：<a href="http://www.lao8.org/user/8/asp" target="_blank">网站技术</a> | <a href="http://www.lao8.org/user/8" target="_blank">lao8</a>发表于 2009-6-9 15:44:00</p>
<p><strong>div显示滚动条的css代码</strong></p>
<div style="width:260px;height:120px; overflow:scroll; border:1px solid;"> 这里是你要显示的内容 </div>

<p>效果如下：</p>
<h3 id="-">显示滚动条的代码</h3>
<p><strong>div显示上下滚动条的css代码</strong></p>
<p><div style="width:260px;height:120px; overflow-y:scroll; border:1px solid;"> 这里是你要显示的内容 </div></p>
<h3 id="div-">div只显示上下滚动条</h3>
<p>OVERFLOW-Y:scroll;这段是关键</p>
<p><strong>修改div滚动条颜色的css代码</strong></p>
<p><div style="width:260px;height:120px; overflow-y:scroll; scrollbar-base-color:/#ff6600; border:1px solid;"> 这里是你要显示的内容 </div>
修改滚动条颜色的代码</p>
<ul>
<li>SCROLLBAR-FACE-COLOR(立体滚动条凸出部分的颜色)</li>
<li>SCROLLBAR-HIGHLIGHT-COLOR(滚动条空白部分的颜色)</li>
<li>SCROLLBAR-SHADOW-COLOR(立体滚动条阴影的颜色)</li>
<li>SCROLLBAR-ARROW-COLOR(上下按钮上三角箭头的颜色)</li>
<li>SCROLLBAR-BASE-COLOR(滚动条的基本颜色)</li>
<li><p>SCROLLBAR-DARK-SHADOW-COLOR(立体滚动条强阴影的颜色)</p>
</li>
<li><p>来源：<strong>原创</strong></p>
</li>
<li><strong>版权声明：</strong>版权所有，转载时必须以链接形式注明作者和原始出处及本声明。</li>
<li>原创作者：<strong><a href="http://www.lao8.org/user/8" target="_blank">lao8</a></strong></li>
<li>本文链接地址：<a href="http://www.lao8.org/html/8/2009-6-9/div_css/" target="_blank">http://www.lao8.org/html/8/2009-6-9/div_css/</a></li>
<li>文章名：<a href="">div显示滚动条和控制滚动条属性的css代码</a>
标签:<a href="http://www.lao8.org/s_div.html" target="_blank">div</a> <a href="http://www.lao8.org/s_%E6%98%BE%E7%A4%BA%E6%BB%9A%E5%8A%A8%E6%9D%A1.html" target="_blank">显示滚动条</a></li>
</ul>
<p><a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt="收藏到收藏夹"></a></p>
<h3 id="-div-">相关&quot;div 显示滚动条&quot;文章</h3>
<ul>
<li><a href="http://www.lao8.org/html/8/2008-1-21/2008121182204.html" target="_blank">css控制DIV透明度</a></li>
<li><a href="http://www.lao8.org/html/8/2007-12-6/2007126174458.html" target="_blank">根据dreamweaver cs3 模板布局学习网站优化</a></li>
</ul>
<h3 id="-">网友点评</h3>
<p><strong><a href="http://www.lusongsong.com/" target="_blank">卢松松</a></strong> 2009-6-12 14:01:00 | <a href="http://www.lao8.org/huifu878.html" target="_blank">[回复]</a><a href=""> </a></p>
<p>拜读了老吧的创作。受益匪浅！
<strong><a href="http://www.gp173.com/" target="_blank">股票行情</a></strong> 2009-6-15 11:25:00 | <a href="http://www.lao8.org/huifu883.html" target="_blank">[回复]</a><a href=""> </a></p>
<p>学一个是一个 博主好崇拜你哦
<strong><a href="http://www.bgtieqi.cn/" target="_blank">本田摩托车</a></strong> 2009-6-15 11:26:00 | <a href="http://www.lao8.org/huifu884.html" target="_blank">[回复]</a><a href=""> </a></p>
<p>好想认真学学
<strong><a href="http://www.yigenangua.cn/" target="_blank">亦歌</a></strong> 2009-7-11 8:50:00 | <a href="http://www.lao8.org/huifu905.html" target="_blank">[回复]</a><a href=""> </a></p>
<p>不错，不过好像滚动条还是默认的好看。
<strong><a href="http://www.sknys.cn/" target="_blank">sknys</a></strong> 2009-7-16 13:51:00 | <a href="http://www.lao8.org/huifu911.html" target="_blank">[回复]</a><a href=""> </a></p>
<p>链你一下网页编程专题网www.sknys.cn</p>
<h3 id="-">发表见解</h3>
<p>username(必填)
email(必填)
website
提交</p>
<h3 id="-">站内搜索</h3>
<p>输入您的搜索字词   Web www.lao8.org 提交搜索表单</p>
<h3 id="-">按分类归档</h3>
<ul>
<li><a href="http://www.lao8.org/user/8/seo/" title="seo技术 网站推广 搜索引擎优化" target="_blank">网站推广</a> （114）</li>
<li><a href="http://www.lao8.org/user/8/photo/" title="摄影技术 摄影欣赏 摄影作品 原创摄影" target="_blank">摄影</a> （45）</li>
<li><a href="http://www.lao8.org/user/8/feel/" title="生活体会 情感记录 原创文学" target="_blank">感悟生活</a> （11）</li>
<li><a href="http://www.lao8.org/user/8/design/" title="平面设计 创意作品" target="_blank">创意设计</a> （9）</li>
<li><a href="http://www.lao8.org/user/8/cg/" title="cg插画 原创插画 cg插图 插图设计" target="_blank">插画设计</a> （1）</li>
<li><a href="http://www.lao8.org/user/8/asp/" title="asp ajax" target="_blank">网站技术</a> （42）</li>
<li><a href="http://www.lao8.org/user/8/life/" title="生活琐碎" target="_blank">生活杂记</a> （133）</li>
<li><a href="http://www.lao8.org/user/8/photoshop/" title="Photoshop教程 ps教程" target="_blank">Photoshop教程</a> （3）</li>
<li><a href="http://www.lao8.org/user/8/2007123171603/" title="房产" target="_blank">房产</a> （7）</li>
<li><a href="http://www.lao8.org/user/8/20071212164833/" title="老吧网改进进度" target="_blank">老吧网改进进度</a> （17）</li>
<li><a href="http://www.lao8.org/user/8/20081413558/" title="营销" target="_blank">营销</a> （18）</li>
<li><a href="http://www.lao8.org/user/8/200814112406/" title="社会评论" target="_blank">社会评论</a> （7）</li>
<li><a href="http://www.lao8.org/user/8/200815112636/" title="艺术图库" target="_blank">艺术图库</a> （5）</li>
<li><a href="http://www.lao8.org/user/8/200811490808/" title="网界动态" target="_blank">网界动态</a> （16）</li>
<li><a href="http://www.lao8.org/user/8/2008125162006/" title="搞笑娱乐" target="_blank">搞笑娱乐</a> （8）</li>
<li><a href="http://www.lao8.org/user/8/2008214170947/" title="小游戏" target="_blank">小游戏</a> （2）</li>
<li><a href="http://www.lao8.org/user/8/200835101334/" title="实用小软件" target="_blank">实用小软件</a> （0）</li>
<li><a href="http://www.lao8.org/user/8/TradeEnglish/" title="外贸英语" target="_blank">外贸英语</a> （6）</li>
<li><a href="http://www.lao8.org/user/8/2008815101140/" title="热播电影" target="_blank">热播电影</a> （4）</li>
<li><a href="http://www.lao8.org/user/8/2008102493244/" title="ebay开店技巧" target="_blank">ebay开店技巧</a> （6）</li>
<li><a href="http://www.lao8.org/user/8/2009719122450/" title="SQL数据库" target="_blank">SQL数据库</a> （8）</li>
<li><a href="http://www.lao8.org/user/8/200986105026/" title="服务器安全" target="_blank">服务器安全</a> （1）</li>
<li><a href="http://www.lao8.org/user/8/200987111345/" title="索尼单反专区" target="_blank">索尼单反专区</a> （0）</li>
<li><a href="http://www.lao8.org/user/8/200987120553/" title="索尼 美能达 原厂定焦 广角镜头 sony minolta meinongda suoni" target="_blank">Alpha原厂定焦广角镜头</a> （7）</li>
<li><a href="http://www.lao8.org/user/8/200987120644/" title="索尼 美能达 原厂定焦 标准镜头 sony minolta meinongda suoni 标头" target="_blank">Alpha原厂定焦标准镜头</a> （4）</li>
<li><a href="http://www.lao8.org/user/8/200987120750/" title="索尼 美能达 原厂望远 定焦镜头 sony minolta meinongda suoni" target="_blank">Alpha原厂望远定焦镜头</a> （4）</li>
<li><a href="http://www.lao8.org/user/8/200987120832/" title="索尼 美能达 原厂广角变焦镜头 sony minolta meinongda suoni" target="_blank">Alpha原厂广角变焦镜头</a> （17）</li>
<li><a href="http://www.lao8.org/user/8/sony_fuchang/" title="sony 副厂镜头 索尼副厂镜头 索尼副厂变焦镜头 索尼副厂自动镜头 索尼副厂单反镜头 minolta meinongda suoni" target="_blank">索尼单反副厂变焦镜头</a> （1）</li>
<li><a href="http://www.lao8.org/user/8/200981731112/" title="Godaddy(GD)美国空间" target="_blank">Godaddy(GD)美国空间</a> （3）</li>
<li><a href="http://www.lao8.org/user/8/200981741553/" title="索尼副厂定焦镜头" target="_blank">索尼副厂定焦镜头</a> （1）</li>
</ul>
<h3 id="lao8-">lao8 最新文章：</h3>
<ul>
<li><a href="http://www.lao8.org/html/8/2009-12-11/20091211125038.html" target="_blank">春运，又是春运，新版火车票貌似不能解决倒票吧</a></li>
<li><a href="http://www.lao8.org/html/8/2009-12-10/suoni_shengji_gujian/" target="_blank">sony索尼 a700 怎样升级固件？</a></li>
<li><a href="http://www.lao8.org/html/8/2009-12-10/a700/" target="_blank">怎样查看sony（索尼）a700 固件版本</a></li>
<li><a href="http://www.lao8.org/html/8/2009-10-28/20091028114200.html" target="_blank">2009天平山红枫节的时间</a></li>
<li><a href="http://www.lao8.org/html/8/2009-10-25/20091025100338.html" target="_blank">可恶的手机诈骗</a></li>
<li><a href="http://www.lao8.org/html/8/2009-10-24/20091024105546.html" target="_blank">Beta 是什么意思？</a></li>
<li><a href="http://www.lao8.org/html/8/2009-10-22/20091022234259.html" target="_blank">阿尔法、贝塔是怎么打出来的？</a></li>
<li><a href="http://www.lao8.org/html/8/2009-10-13/2009101330617.html" target="_blank">熬夜为什么会口臭？</a></li>
<li><a href="http://www.lao8.org/html/8/2009-10-10/2009101033225.html" target="_blank">柔光箱、反光伞、柔光伞的效果区别</a></li>
<li><a href="http://www.lao8.org/html/8/2009-10-10/2009101030532.html" target="_blank">爱上asp.net</a></li>
</ul>
<p><a href="http://www.miibeian.gov.cn/" target="_blank">苏ICP备07500238号</a> | <a href="mailto:tc_show@126.com">tc_show@126.com</a> <a href="http://www.51.la/?001536816" title="51.la 专业、免费、强健的访问统计" target="_blank">网站统计</a> <img src="http://web.51.la:82/go.asp?svid=1&amp;id=1536816&amp;tpages=1&amp;ttimes=1&amp;tzone=8&amp;tcolor=32&amp;sSize=1280,1024&amp;referrer=http%3A//www.google.cn/search%3Fhl%3Dzh-CN&amp;newwindow%3D1&amp;q%3Ddiv+%E6%BB%9A%E5%8A%A8%E6%9D%A1&amp;aq%3D2g&amp;oq%3Ddiv++&amp;vpage=http%3A//www.lao8.org/html/8/2009-6-9/div_css/" alt="">
<strong><a href="http://sitemap.cn.yahoo.com/search?p=http%3A%2F%2Fwww.lao8.org%2Fhtml%2F8%2F2009-6-9%2Fdiv_css%2F&amp;bwm=i" target="_blank">1</a></strong> 链向本页</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/DIV/">DIV</a></li></span></span> | <span class="tags">Tagged <a href="/tags/DIV/" class="label label-primary">DIV</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-DIV--div显示滚动条和控制滚动条属性的css代码-老吧网/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-DIV--div显示滚动条和控制滚动条属性的css代码-老吧网" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/111/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/109/">109</a></li><li><a class="page-number" href="/page/110/">110</a></li><li><a class="page-number" href="/page/111/">111</a></li><li class="active"><li><span class="page-number current">112</span></li><li><a class="page-number" href="/page/113/">113</a></li><li><a class="page-number" href="/page/114/">114</a></li><li><a class="page-number" href="/page/115/">115</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/161/">161</a></li><li><a class="page-number" href="/page/162/">162</a></li><li><a class="extend next" href="/page/113/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Site powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a>  update time: <em>2014-04-07 19:25:39</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
