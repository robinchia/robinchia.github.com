
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 115 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux--linux之cut用法/">linux之cut用法</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux--linux之cut用法/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="linux-cut-">linux之cut用法</h1>
<p>cut是一个选取命令，就是将一段数据经过分析，取出我们想要的。一般来说，选取信息通常是针对“行”来进行分析的，并不是整篇信息分析的。</p>
<p>（1）其语法格式为：
cut  [-bn] [file] 或 cut [-c] [file]  或  cut [-df] [file]</p>
<p>使用说明
cut 命令从文件的每一行剪切字节、字符和字段并将这些字节、字符和字段写至标准输出。
如果不指定 File 参数，cut 命令将读取标准输入。必须指定 -b、-c 或 -f 标志之一。</p>
<p>主要参数
-b ：以字节为单位进行分割。这些字节位置将忽略多字节字符边界，除非也指定了 -n 标志。
-c ：以字符为单位进行分割。
-d ：自定义分隔符，默认为制表符。
-f  ：与-d一起使用，指定显示哪个区域。
-n ：取消分割多字节字符。仅和 -b 标志一起使用。如果字符的最后一个字节落在由 -b 标志的 List 参数指示的<br />范围之内，该字符将被写出；否则，该字符将被排除。</p>
<p>（2）cut一般以什么为依据呢? 也就是说，我怎么告诉cut我想定位到的剪切内容呢?</p>
<p>cut命令主要是接受三个定位方法：</p>
<p>第一，字节（bytes），用选项-b</p>
<p>第二，字符（characters），用选项-c</p>
<p>第三，域（fields），用选项-f</p>
<p>（3）以“字节”定位</p>
<p>举个例子吧，当你执行ps命令时，会输出类似如下的内容：</p>
<p>[rocrocket@rocrocket programming]$ who
rocrocket :0           2009-01-08 11:07
rocrocket pts/0        2009-01-08 11:23 (:0.0)
rocrocket pts/1        2009-01-08 14:15 (:0.0)
如果我们想提取每一行的第3个字节，就这样：</p>
<p>[rocrocket@rocrocket programming]$ who|cut -b 3
c
c
c</p>
<p>（4） 如果“字节”定位中，我想提取第3，第4、第5和第8个字节，怎么办?</p>
<p>-b支持形如3-5的写法，而且多个定位之间用逗号隔开就成了。看看例子吧：</p>
<p>[rocrocket@rocrocket programming]$ who|cut -b 3-5,8
croe
croe
croe
但有一点要注意，cut命令如果使用了-b选项，那么执行此命令时，cut会先把-b后面所有的定位进行从小到大排序，然后再提取。可不能颠倒定位的顺序哦。这个例子就可以说明这个问题：</p>
<p>[rocrocket@rocrocket programming]$ who|cut -b 8,3-5
croe
croe
croe
（5） 还有哪些类似“3-5”这样的小技巧，列举一下吧!</p>
<p>[rocrocket@rocrocket programming]$ who
rocrocket :0           2009-01-08 11:07
rocrocket pts/0        2009-01-08 11:23 (:0.0)
rocrocket pts/1        2009-01-08 14:15 (:0.0)
[rocrocket@rocrocket programming]$ who|cut -b -3
roc
roc
roc
[rocrocket@rocrocket programming]$ who|cut -b 3-
crocket :0           2009-01-08 11:07
crocket pts/0        2009-01-08 11:23 (:0.0)
crocket pts/1        2009-01-08 14:15 (:0.0)
想必你也看到了，-3表示从第一个字节到第三个字节，而3-表示从第三个字节到行尾。如果你细心，你可以看到这两种情况下，都包括了第三个字节“c”。
如果我执行who|cut -b -3,3-，你觉得会如何呢？答案是输出整行，不会出现连续两个重叠的c的。看：</p>
<p>[rocrocket@rocrocket programming]$ who|cut -b -3,3-
rocrocket :0           2009-01-08 11:07
rocrocket pts/0        2009-01-08 11:23 (:0.0)
rocrocket pts/1        2009-01-08 14:15 (:0.0)
（6）给个以字符为定位标志的最简单的例子吧!</p>
<p>下面例子你似曾相识，提取第3，第4，第5和第8个字符：</p>
<p>[rocrocket@rocrocket programming]$ who|cut -c 3-5,8
croe
croe
croe
不过，看着怎么和-b没有什么区别啊？莫非-b和-c作用一样? 其实不然，看似相同，只是因为这个例子举的不好，who输出的都是单字节字符，所以用-b和-c没有区别，如果你提取中文，区别就看出来了，来，看看中文提取的情况：</p>
<p>[rocrocket@rocrocket programming]$ cat cut_ch.txt
星期一
星期二
星期三
星期四
[rocrocket@rocrocket programming]$ cut -b 3 cut_ch.txt
�
�
�
�
[rocrocket@rocrocket programming]$ cut -c 3 cut_ch.txt
一
二
三
四
看到了吧，用-c则会以字符为单位，输出正常；而-b只会傻傻的以字节（8位二进制位）来计算，输出就是乱码。
既然提到了这个知识点，就再补充一句，如果你学有余力，就提高一下。
当遇到多字节字符时，可以使用-n选项，-n用于告诉cut不要将多字节字符拆开。例子如下：</p>
<p>[rocrocket@rocrocket programming]$ cat cut_ch.txt |cut -b 2
�
�
�
�
[rocrocket@rocrocket programming]$ cat cut_ch.txt |cut -nb 2
[rocrocket@rocrocket programming]$ cat cut_ch.txt |cut -nb 1,2,3
星
星
星
星
（7）域是怎么回事呢？解释解释:)</p>
<p>为什么会有“域”的提取呢，因为刚才提到的-b和-c只能在固定格式的文档中提取信息，而对于非固定格式的信息则束手无策。这时候“域”就派上用场了。如果你观察过/etc/passwd文件，你会发现，它并不像who的输出信息那样具有固定格式，而是比较零散的排放。但是，冒号在这个文件的每一行中都起到了非常重要的作用，冒号用来隔开每一个项。</p>
<p>我们很幸运，cut命令提供了这样的提取方式，具体的说就是设置“间隔符”，再设置“提取第几个域”，就OK了！</p>
<p>以/etc/passwd的前五行内容为例：</p>
<p>[rocrocket@rocrocket programming]$ cat /etc/passwd|head -n 5
root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
daemon:x:2:2:daemon:/sbin:/sbin/nologin
adm:x:3:4:adm:/var/adm:/sbin/nologin
lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
[rocrocket@rocrocket programming]$ cat /etc/passwd|head -n 5|cut -d : -f 1
root
bin
daemon
adm
lp
看到了吧，用-d来设置间隔符为冒号，然后用-f来设置我要取的是第一个域，再按回车，所有的用户名就都列出来了！呵呵 有成就感吧！
当然，在设定-f时，也可以使用例如3-5或者4-类似的格式：</p>
<p>[rocrocket@rocrocket programming]$ cat /etc/passwd|head -n 5|cut -d : -f 1,3-5
root:0:0:root
bin:1:1:bin
daemon:2:2:daemon
adm:3:4:adm
lp:4:7:lp
[rocrocket@rocrocket programming]$ cat /etc/passwd|head -n 5|cut -d : -f 1,3-5,7
root:0:0:root:/bin/bash
bin:1:1:bin:/sbin/nologin
daemon:2:2:daemon:/sbin/nologin
adm:3:4:adm:/sbin/nologin
lp:4:7:lp:/sbin/nologin
[rocrocket@rocrocket programming]$ cat /etc/passwd|head -n 5|cut -d : -f -2
root:x
bin:x
daemon:x
adm:x
lp:x
（8）如果遇到空格和制表符时，怎么分辨呢？我觉得有点乱，怎么办？</p>
<p>有时候制表符确实很难辨认，有一个方法可以看出一段空格到底是由若干个空格组成的还是由一个制表符组成的。</p>
<p>[rocrocket@rocrocket programming]$ cat tab_space.txt
this is tab finish.
this is several space      finish.
[rocrocket@rocrocket programming]$ sed -n l tab_space.txt
this is tab\tfinish.$
this is several space      finish.$
看到了吧，如果是制表符（TAB），那么会显示为\t符号，如果是空格，就会原样显示。
通过此方法即可以判断制表符和空格了。
注意，上面sed -n后面的字符是L的小写字母哦，不要看错。</p>
<p>（9）我应该在cut -d中用什么符号来设定制表符或空格呢?</p>
<p>其实cut的-d选项的默认间隔符就是制表符，所以当你就是要使用制表符的时候，完全就可以省略-d选项，而直接用－f来取域就可以了。</p>
<p>如果你设定一个空格为间隔符，那么就这样：</p>
<p>[rocrocket@rocrocket programming]$ cat tab_space.txt |cut -d &#39; &#39; -f 1
this
this
注意，两个单引号之间可确实要有一个空格哦，不能偷懒。
而且，你只能在-d后面设置一个空格，可不许设置多个空格，因为cut只允许间隔符是一个字符。</p>
<p>[rocrocket@rocrocket programming]$ cat tab_space.txt |cut -d &#39; &#39; -f 1
cut: the delimiter must be a single character
Try `cut --help&#39; for more information.</p>
<p>（10）cut有哪些缺陷和不足？</p>
<p>猜出来了吧？对，就是在处理多空格时。
如果文件里面的某些域是由若干个空格来间隔的，那么用cut就有点麻烦了，因为cut只擅长处理“以一个字符间隔”的文本内容
来源： <a href="[http://www.cnblogs.com/dong008259/archive/2011/12/09/2282679.html](http://www.cnblogs.com/dong008259/archive/2011/12/09/2282679.html)">[http://www.cnblogs.com/dong008259/archive/2011/12/09/2282679.html](http://www.cnblogs.com/dong008259/archive/2011/12/09/2282679.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span></span> | <span class="tags">Tagged <a href="/tags/linux/" class="label label-primary">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux--linux之cut用法/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux--linux之cut用法" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux--linux之awk用法/">linux之awk用法</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux--linux之awk用法/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="linux-awk-">linux之awk用法</h1>
<p>awk是一个非常棒的数字处理工具。相比于sed常常作用于一整行的处理，awk则比较倾向于将一行分为数个“字段”来处理。运行效率高，而且代码简单，对格式化的文本处理能力超强。先来一个例子：
文件a，统计文件a的第一列中是浮点数的行的浮点数的平均值。用awk来实现只需要一句话就可以搞定
$cat a
1.021 33
1/#.ll   44
2.53 6
ss    7
awk &#39;BEGIN{total = 0;len = 0} {if($1~/^[0-9]+.[0-9]/<em>/){total += $1; len++}} END{print total/len}&#39; a
（分析：$1~/^[0-9]+.[0-9]/</em>/表示$1与“/ /”里面的正则表达式进行匹配，若匹配，则total加上$1，且len自增，即数目加1.“^[0-9]+.[0-9]/<em>”是个正则表达式，“^[0-9]”表示以数字开头，“.”是转义的意思，表示“.”为小数点的意思。“[0-9]/</em>”表示0个或多个数字）</p>
<p>awk的一般语法格式为：
awk [-参数 变量] &#39;BEGIN{初始化}条件类型1{动作1}条件类型2{动作2}。。。。END{后处理}&#39;
其中：BEGIN和END中的语句分别在开始读取文件（in_file）之前和读取完文件之后发挥作用，可以理解为初始化和扫尾。
<strong>（1）参数说明：</strong>
 -F re：允许awk更改其字段分隔符
      -v var=$v 把v值赋值给var，如果有多个变量要赋值，那么就写多个-v，每个变量赋值对应一个-v
e.g. 要打印文件a的第num行到num+num1行之间的行，
awk -v num=$num -v num1=$num1 &#39;NR==num,NR==num+num1{print}&#39; a
-f progfile：允许awk调用并执行progfile程序文件，当然progfile必须是一个符合awk语法的程序文件。</p>
<p><strong>（2）awk内置变量：</strong>
<strong>ARGC</strong>    命令行参数的个数
<strong>ARGV  </strong> 命令行参数数组
<strong>ARGIND</strong> 当前被处理文件的ARGV标志符
e.g 有两个文件a 和b
awk &#39;{if(ARGIND==1){print &quot;处理a文件&quot;} if(ARGIND==2){print &quot;处理b文件&quot;}}&#39; a b
文件处理的顺序是先扫描完a文件，再扫描b文件</p>
<p><strong>NR 　　</strong>已经读出的记录数
<strong>FNR</strong>   　当前文件的记录数
上面的例子也可以写成这样：
awk &#39;NR==FNR{print &quot;处理文件a&quot;} NR &gt; FNR{print &quot;处理文件b&quot;}&#39; a b
输入文件a和b，由于先扫描a，所以扫描a的时候必然有NR==FNR，然后扫描b的时候，FNR从1开始计数，而NR则接着a的行数继续计数，所以NR &gt; FNR</p>
<p>e.g 要显示文件的第10行至第15行
awk &#39;NR==10,NR==15{print}&#39; a</p>
<p><strong>FS 　　</strong>输入字段分隔符（缺省为:space:），相当于-F选项
awk -F &#39;:&#39; &#39;{print}&#39; a    和   awk &#39;BEGIN{FS=&quot;:&quot;}{print}&#39; a 是一样的</p>
<p><strong>OFS</strong>输出字段分隔符（缺省为:space:）
awk -F &#39;:&#39; &#39;BEGIN{OFS=&quot;;&quot;}{print $1,$2,$3}&#39; b
如果cat b为
1:2:3
4:5:6
那么把OFS设置成&quot;;&quot;后就会输出
1;2;3
4;5;6
（小注释：awk把分割后的第1、2、3个字段用$1,$2,$3...表示，$0表示整个记录（一般就是一整行））</p>
<p><strong>NF</strong>：当前记录中的字段个数
awk -F &#39;:&#39; &#39;{print NF}&#39; b的输出为
3
3
表明b的每一行用分隔符&quot;:&quot;分割后都3个字段
可以用NF来控制输出符合要求的字段数的行，这样可以处理掉一些异常的行
awk -F &#39;:&#39; &#39;{if (NF == 3)print}&#39; b</p>
<p><strong>RS</strong>：输入记录分隔符，缺省为&quot;\n&quot;
缺省情况下，awk把一行看作一个记录；如果设置了RS，那么awk按照RS来分割记录
例如，如果文件c，cat c为
hello world; I want to go swimming tomorrow;hiahia
运行 awk &#39;BEGIN{ RS = &quot;;&quot; } {print}&#39; c 的结果为
hello world
I want to go swimming tomorrow
hiahia
合理的使用RS和FS可以使得awk处理更多模式的文档，例如可以一次处理多行，例如文档d cat d的输出为
1 2
3 4 5
6 7
8 9 10
11 12</p>
<p>hello
每个记录使用空行分割，每个字段使用换行符分割，这样的awk也很好写
awk &#39;BEGIN{ FS = &quot;\n&quot;; RS = &quot;&quot;} {print NF}&#39; d 输出
2
3
1</p>
<p><strong>ORS</strong>：输出记录分隔符，缺省为换行符，控制每个print语句后的输出符号
awk &#39;BEGIN{ FS = &quot;\n&quot;; RS = &quot;&quot;; ORS = &quot;;&quot;} {print NF}&#39; d 输出
2;3;1
<strong>（3）awk读取shell中的变量</strong>
可以使用-v选项实现功能
     $b=1
     $cat f
     apple
$awk -v var=$b &#39;{print var, $var}&#39; f
1 apple
至于有没有办法把awk中的变量传给shell呢，这个问题我是这样理解的。shell调用awk实际上是fork一个子进程出来，而子进程是无法向父进程传递变量的，除非用重定向（包括管道）
a=$(awk &#39;{print $b, &#39;$b&#39;}&#39; f)
$echo $a
apple 1</p>
<p><strong>**（4）</strong>输出重定向**</p>
<p>awk的输出重定向类似于shell的重定向。重定向的目标文件名必须用双引号引用起来。
$awk &#39;$4 &gt;=70 {print $1,$2 &gt; &quot;destfile&quot; }&#39; filename
$awk &#39;$4 &gt;=70 {print $1,$2 &gt;&gt; &quot;destfile&quot; }&#39; filename</p>
<p><strong>（5）awk中调用shell命令：</strong></p>
<p>1)使用<strong>管道</strong>
awk中的管道概念和shell的管道类似，都是使用&quot;|&quot;符号。如果在awk程序中打开了管道，必须先关闭该管道才能打开另一个管道。也就是说一次只能打开一个管道。shell命令必须被双引号引用起来。“如果打算再次在awk程序中使用某个文件或管道进行读写，则可能要先关闭程序，因为其中的管道会保持打开状态直至脚本运行结束。注意，管道一旦被打开，就会保持打开状态直至awk退出。因此END块中的语句也会收到管道的影响。（可以在END的第一行关闭管道）”
awk中使用管道有两种语法，分别是：
awk output | shell input
shell output | awk input</p>
<p>对于awk output | shell input来说，shell接收awk的输出，并进行处理。需要注意的是，awk的output是先缓存在pipe中，等输出完毕后再调用shell命令 处理，shell命令只处理一次，而且处理的时机是“awk程序结束时，或者管道关闭时（需要显式的关闭管道）”
$awk &#39;/west/{count++} {printf &quot;%s %s\t\t%-15s\n&quot;, $3,$4,$1 | &quot;sort +1&quot;} END{close &quot;sort +1&quot;; printf &quot;The number of sales pers in the western&quot;; printf &quot;region is &quot; count &quot;.&quot; }&#39; datafile （解释：/west/{count++}表示与“wes”t进行匹配，若匹配，则count自增）
printf函数用于将输出格式化并发送给管道。所有输出集齐后，被一同发送给sort命令。必须用与打开时完全相同的命令来关闭管道(sort +1)，否则END块中的语句将与前面的输出一起被排序。此处的sort命令只执行一次。</p>
<p>在shell output | awk input中awk的input只能是getline函数。shell执行的结果缓存于pipe中，再传送给awk处理，如果有多行数据，awk的getline命令可能调用多次。
来源： <a href="[http://www.cnblogs.com/dong008259/archive/2011/12/06/2277287.html](http://www.cnblogs.com/dong008259/archive/2011/12/06/2277287.html)">[http://www.cnblogs.com/dong008259/archive/2011/12/06/2277287.html](http://www.cnblogs.com/dong008259/archive/2011/12/06/2277287.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span></span> | <span class="tags">Tagged <a href="/tags/linux/" class="label label-primary">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux--linux之awk用法/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux--linux之awk用法" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）/">基于Hadoop 2.2.0的高可用性集群搭建步骤（64位）</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-hadoop-2-2-0-64-">基于Hadoop 2.2.0的高可用性集群搭建步骤（64位）</h1>
<p> 内容概要: CentSO_64bit集群搭建， hadoop2.2(64位)编译，安装，配置以及测试步骤</p>
<p>新版亮点:基于yarn计算框架和高可用性DFS的第一个稳定版本。</p>
<p>注1：官网只提供32位release版本, 若机器为64位，需要手动编译。</p>
<p>注2：目前网上传的2.2版本的安装步骤几乎都有问题，没有一个版本是完全正确的。若不懂新框架内部机制，不要照抄网传的版本。</p>
<p><strong>0. 编译前的准备</strong></p>
<p><strong>虚拟机vmware准备，64bit CentOS准备</strong></p>
<p><strong>节点ip</strong></p>
<p>cluster1   172.16.102. 201</p>
<p>cluster2  172.16.102. 202</p>
<p>cluster3  172.16.102. 203</p>
<p>cluster4  172.16.102. 204</p>
<p><strong>各节点职能划分</strong>     </p>
<p>cluster1        resourcemanager, nodemanager,</p>
<p>proxyserver,historyserver, datanode, namenode,</p>
<p>cluster2        datanode, nodemanager</p>
<p>cluster3 datanode, nodemanager</p>
<p>cluster4 datanode, nodemanager</p>
<p><strong>说明</strong></p>
<p>以下关于修改hostname, 设置静态ip, ssh免登陆，关闭防火墙等步骤，放在文章末尾，这些内容并不是本文讨论的重点。</p>
<p><strong>1. hadoop2.2**</strong>编译**
1说明：标准的</p>
<p>bash</p>
<p>提示符，root用户为</p>
<p>&#39;/#&#39;</p>
<p>，普通用户为</p>
<p>&#39;%&#39;</p>
<p>，由于博客编辑器的缘故，</p>
<p>&#39;/#&#39;</p>
<p>提示符会被默认为comment, 因此在这篇博文中不再区分root和普通user的提示符， 默认全部为</p>
<p>&#39;$&#39;</p>
<p>因为我们安装的CentOS是64bit的，而官方release的hadoop2.2.0版本没有对应的64bit安装包，故需要自行编译。</p>
<p>首先需要去oracle下载64位jdk:
1</p>
<p>2
$</p>
<p>su</p>
<p>root</p>
<p>$wget http:</p>
<p>//download</p>
<p>.oracle.com</p>
<p>/otn-pub/java/jdk/7u45-b18/jdk-7u45-linux-x64</p>
<p>.</p>
<p>tar</p>
<p>.gz</p>
<p>注: prompt（提示符）为%默认为当前用户， /#则为root,注意以下各步骤中的prompt类型。</p>
<p>下面为hadoop编译步骤（注：中间部分的文本框里内容提要只是一些补充说明，不要执行框里的命令）</p>
<p>1.1 BOTPROTO改为”dhcp”
1</p>
<p>2
$</p>
<p>su</p>
<p>root</p>
<p>$</p>
<p>sed</p>
<p>–i  s</p>
<p>/static/dhcp/g</p>
<p>/etc/sysconfig/network-scripts/ifcfg-eth0</p>
<p>/#servicenetwork restart</p>
<p>1.2 下载hadoop2.2.0 源码</p>
<p>1</p>
<p>2
3$</p>
<p>su</p>
<p>grid</p>
<p>$</p>
<p>cd</p>
<p>~
wget  http:</p>
<p>//apache</p>
<p>.dataguru.cn</p>
<p>/hadoop/common/stable/hadoop-2</p>
<p>.2.0-src.</p>
<p>tar</p>
<p>.gz</p>
<p>1.3 安装maven</p>
<p>1</p>
<p>2
3</p>
<p>4
5$</p>
<p>su</p>
<p>root</p>
<p>$</p>
<p>cd</p>
<p>/opt
wget http:</p>
<p>//apache</p>
<p>.fayea.com</p>
<p>/apache-mirror/maven/maven-3/3</p>
<p>.1.1</p>
<p>/binaries/apache-maven-3</p>
<p>.1.1-bin.</p>
<p>tar</p>
<p>.gz</p>
<p>$</p>
<p>tar</p>
<p>zxvf apache-maven-3.1.1-bin.</p>
<p>tar</p>
<p>.gz
$</p>
<p>cd</p>
<p>apache-maven-3.1.1</p>
<p><em>**</em>修改系统环境变量有两种方式，修改/etc/profile， 或者在/etc/profile.d/下添加定制的shell文件，</p>
<p>鉴于profile文件的重要性，尽量不要在profile文件里添加内容，官方建议采用第二种，以保证profile文件的绝对安全。</p>
<p>下面采用第二种方式：</p>
<p>首先，创建一个简单shell脚脚本并添加相关内容进去：
1</p>
<p>2
$</p>
<p>cd</p>
<p>/etc/profile</p>
<p>.d/</p>
<p>$</p>
<p>touch</p>
<p>maven.sh     其次，maven.sh里添加内容如下：1</p>
<p>2
3/#environmentvariable settings for mavn2</p>
<p>export</p>
<p>MAVEN_HOME=</p>
<p>&#39;/opt/apache-maven-3.1.1&#39;</p>
<p>3
export</p>
<p>PATH=$MAVEN_HOME</p>
<p>/bin</p>
<p>:$PATH</p>
<p>最后，source一下</p>
<p>1$</p>
<p>source</p>
<p>/etc/profile</p>
<p><br><br>$</p>
<p>source</p>
<p>/etc/profile1</p>
<p>2
3&lt;em</p>
<p>id</p>
<p>=</p>
<p>&quot;__mceDel&quot;</p>
<blockquote>
<p>$mvn -version</p>
</blockquote>
<p>Apache Maven 3.1.1
&lt;</p>
<p>/em</p>
<p>&gt;</p>
<p>1.4 安装protobuf</p>
<p>注意apache官方网站上的提示“NOTE: You will need protoc 2.5.0 installed.”
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
$</p>
<p>su</p>
<p>root</p>
<p>$</p>
<p>cd</p>
<p>/opt
wget https:</p>
<p>//protobuf</p>
<p>.googlecode.com</p>
<p>/files/protobuf-2</p>
<p>.5.0.</p>
<p>tar</p>
<p>.bz2</p>
<p>$</p>
<p>tar</p>
<p>xvf protobuf-2.5.0.</p>
<p>tar</p>
<p>.bz2 (注意压缩文件后缀， maven安装包是—</p>
<p>gzip</p>
<p>文件，解压时需加–z)
$</p>
<p>cd</p>
<p>protobuf-2.5.0</p>
<p>.</p>
<p>/configure</p>
<p>安装protobuf时提示报错”configure: error: C++ preprocessor &quot;/lib/cpp&quot; failssanity check”</p>
<p>安装gcc
1$yum</p>
<p>install</p>
<p>gcc</p>
<p>1.5 编译hadoop</p>
<p>首先从官网下载hadoop2.2.0source code:
1</p>
<p>2
3$</p>
<p>su</p>
<p>grid;</p>
<p>$</p>
<p>cd</p>
<p>~grid/
wget http:</p>
<p>//apache</p>
<p>.dataguru.cn</p>
<p>/hadoop/common/stable/hadoop-2</p>
<p>.2.0-src.</p>
<p>tar</p>
<p>.gz</p>
<p>好了，痛苦的编译过程来了。</p>
<p>解压之：
1</p>
<p>2
$</p>
<p>tar</p>
<p>zxvf hadoop-2.2.0-src.</p>
<p>tar</p>
<p>.gz</p>
<p>$</p>
<p>cd</p>
<p>hadoop-2.2.0-src</p>
<p>1.6 给maven指定国内镜像源</p>
<p>1.6.1. 切换root权限, 修改/opt/apache-maven-3.1.1/conf/settings.xml
1</p>
<p>2
$</p>
<p>su</p>
<p>root</p>
<p>$vim</p>
<p>/opt/apache-maven-3</p>
<p>.1.1</p>
<p>/conf/settings</p>
<p>.xml</p>
<p>修改1. 在<mirrors>…</mirrors>里添加国内源（注意，保留原本就有的<mirrors>...</mirrors>）：</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
1  <mirrors> 2     <mirror>3         <id>nexus-osc</id>4         <mirrorOf>/*</mirrorOf>5     <name>Nexusosc</name>6     <url><a href="http://maven.oschina.net/content/groups/public/" target="_blank">http://maven.oschina.net/content/groups/public/</a></url>7     </mirror>8 </mirrors></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>修改2. 在<profiles>标签中增加以下内容（保留原来的<profiles>…</profiles>， jdk版本根据用户的情况填写）</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
 1  <profile> 2       <id>jdk-1.4</id> 3       <activation> 4         <jdk>1.4</jdk> 5       </activation> 6       <repositories> 7         <repository> 8           <id>nexus</id> 9           <name>local private nexus</name>10           <url><a href="http://maven.oschina.net/content/groups/public/">http://maven.oschina.net/content/groups/public/</a></url>11           <releases>12             <enabled>true</enabled>13           </releases>14           <snapshots>15             <enabled>false</enabled>16           </snapshots>17         </repository>18       </repositories>19       <pluginRepositories>20         <pluginRepository>21           <id>nexus</id>22           <name>local private nexus</name>23           <url><a href="http://maven.oschina.net/content/groups/public/" target="_blank">http://maven.oschina.net/content/groups/public/</a></url>24           <releases>25             <enabled>true</enabled>26           </releases>27           <snapshots>28             <enabled>false</enabled>29           </snapshots>30         </pluginRepository>31       </pluginRepositories>32     </profile>33 </profiles></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>   1.6.2 将刚才修改的配置文件拷到当前用户home目录下</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
$ su grid $ sudo cp /opt/apache-maven-3.1.1/conf/settings.xml ~/.m2//#若提示该用户不在sudoers里，执行以下步骤： $ su root  /#在sudoers里第99行添加当前用户（下面行号不要加）： $ cat /etc/sudoers98  root     ALL=(ALL)       ALL99  grid     ALL=(ALL)       ALL</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>1.7 现在执行官方的clean步骤： $mvn clean install –DskipTests</p>
<p>漫长的等待后发现安装一切正常。</p>
<p>1.8 安装3个依赖包
1</p>
<p>2
3Cmake</p>
<p>ncurses-devel
openssl-devel</p>
<p>执行以下步骤：</p>
<p>1</p>
<p>2
3</p>
<p>4
$</p>
<p>su</p>
<p>root</p>
<p>$yum</p>
<p>install</p>
<p>ncurses-devel
$yum</p>
<p>install</p>
<p>openssl-devel</p>
<p>$yum</p>
<p>install</p>
<p>cmake89</p>
<p>以上安装完成后，切回用户grid：</p>
<p>1</p>
<p>2
$</p>
<p>su</p>
<p>grid</p>
<p>$</p>
<p>cd</p>
<p>~</p>
<p>/hadoop-2</p>
<p>.2.0-src</p>
<p><em>**</em>1.9 所有依赖已安装完毕，开始编译</p>
<p>1$mvn package-Pdist,native -DskipTests -Dtar</p>
<p>漫长的等待后，编译成功，查看结果：</p>
<p><img src="http://m1.img.libdd.com/farm4/d/2013/1114/11/160569527B88184A5CFD1B4C6D260A60_B500_900_500_214.png" alt=""></p>
<p>一切正常。至此，hadoop2.2.0编译完成。</p>
<p><em>**</em>1.10 验证</p>
<p>下面验证编译结果是否符合预期, 注意我们当前是在目录~/hadoop-2.2.0-src下，
1</p>
<p>2
3$</p>
<p>cd</p>
<p>hadoop-dist/</p>
<p>$</p>
<p>ls
pom.xml  target</p>
<p>以上为maven编译的配置文件</p>
<p>1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
7$</p>
<p>cd</p>
<p>target</p>
<p>$</p>
<p>ls</p>
<p>-sF
total 276M</p>
<p>4.0K antrun/                    92M hadoop-2.2.0.</p>
<p>tar</p>
<p>.gz            4.0K maven-archiver/
4.0K dist-layout-stitching.sh  4.0K hadoop-dist-2.2.0.jar          4.0K</p>
<p>test</p>
<p>-</p>
<p>dir</p>
<p>/</p>
<p>4.0K dist-</p>
<p>tar</p>
<p>-stitching.sh     184M hadoop-dist-2.2.0-javadoc.jar
4.0K hadoop-2.2.0/             4.0K javadoc-bundle-options/</p>
<p>以上为maven编译后自动生成的目录文件，进入hadoop-2.2.0:</p>
<p>1</p>
<p>2
3$</p>
<p>cd</p>
<p>hadoop-2.2.023</p>
<p>$</p>
<p>ls
bin  etc  include  lib libexec  sbin  share</p>
<p>这才是和官方release2.2.0版本（官方只有32bit版本）的相同的目录结构。</p>
<p>1.10.1 下面主要验证两项：</p>
<p><em>**</em>a.验证版本号
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
7$bin</p>
<p>/hadoop</p>
<p>version</p>
<p>Hadoop 2.2.0
Subversion Unknown -r Unknown</p>
<p>Compiled by grid on 2013-11-06T13:51Z
Compiled with protoc 2.5.0</p>
<p>From</p>
<p>source</p>
<p>with checksum 79e53ce7994d1628b240f09af91e1af4
This</p>
<p>command</p>
<p>was run using</p>
<p>/home/grid/hadoop-2</p>
<p>.2.0-src</p>
<p>/hadoop-dist/target/hadoop-2</p>
<p>.2.0</p>
<p>/share/hadoop/common/hadoop-common-2</p>
<p>.2.0.jar</p>
<p>可以看到hadoop版本号，编译工具（protoc2.5.0版本号与官方要求一致）以及编译日期.</p>
<p><em>**</em>b.验证hadoop lib的位数
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
$</p>
<p>file</p>
<p>lib</p>
<p>//native/</p>
<p>/*</p>
<p>lib</p>
<p>//native/libhadoop</p>
<p>.a:        current ar archive
lib</p>
<p>//native/libhadooppipes</p>
<p>.a:   current ar archive</p>
<p>lib</p>
<p>//native/libhadoop</p>
<p>.so:       symbolic link to `libhadoop.so.1.0.0&#39;
lib</p>
<p>//native/libhadoop</p>
<p>.so.1.0.0:<strong>ELF 64-bitLSB&lt;</p>
<p>/strong</p>
<blockquote>
<p>shared object, x86-64, version 1 (SYSV), dynamically linked, notstripped1011 lib</p>
</blockquote>
<p>//native/libhadooputils</p>
<p>.a:   current ar archive1213 lib</p>
<p>//native/libhdfs</p>
<p>.a:          current ar archive1415 lib</p>
<p>//native/libhdfs</p>
<p>.so:         symbolic link to `libhdfs.so.0.0.0&#39;</p>
<p>lib</p>
<p>//native/libhdfs</p>
<p>.so.0.0.0:   <strong>ELF 64-bit LSB shared object&lt;</p>
<p>/strong</p>
<blockquote>
<p>, x86-64,version 1 (SYSV), dynamically linked, not stripped</p>
</blockquote>
<p>看到黑色的“ELF-64bit LSB”证明64bit hadoop2.2.0初步编译成功，查看我们之前的hadoop0.20.3版本，会发现lib//native/libhadoop.so.1.0.0是32bit，这是不正确的！。^_^</p>
<p><strong>2. hadoop2.2**</strong>配置**</p>
<p><strong>**</strong>2.1 home设置**</p>
<p>为了和MRv1区别， 2.2版本的home目录直接命名为yarn:
1</p>
<p>2
3</p>
<p>4
$</p>
<p>su</p>
<p>hadoop</p>
<p>$</p>
<p>cd</p>
<p>~
$</p>
<p>mkdir</p>
<p>–p yarn</p>
<p>/yarn_data67</p>
<p>$</p>
<p>cp</p>
<p>–a ~hadoop</p>
<p>/hadoop-2</p>
<p>.2.0-src</p>
<p>/hadoop-dist/target/hadoop-2</p>
<p>.2.0  ~hadoop</p>
<p>/yarn</p>
<p><strong>2.2 环境变量设置</strong></p>
<p>~/.bashrc里添加新环境变量：</p>
<p>1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
7</p>
<p>8
9</p>
<p>10
11</p>
<p>12
/# javaenv</p>
<p>export</p>
<p>JAVA_HOME=</p>
<p>&quot;/usr/java/jdk1.7.0_45&quot;</p>
<p>exportPATH=</p>
<p>&quot;$JAVA_HOME/bin:$PATH&quot;
/# hadoopvariable settings</p>
<p>export</p>
<p>HADOOP_HOME=</p>
<p>&quot;$HOME/yarn/hadoop-2.2.0&quot;
export</p>
<p>HADOOP_PREFIX=</p>
<p>&quot;$HADOOP_HOME/&quot;</p>
<p>export</p>
<p>YARN_HOME=$HADOOP_HOME
export</p>
<p>HADOOP_MAPRED_HOME=</p>
<p>&quot;$HADOOP_HOME&quot;</p>
<p>export</p>
<p>HADOOP_COMMON_HOME=</p>
<p>&quot;$HADOOP_HOME&quot;
export</p>
<p>HADOOP_HDFS_HOME=</p>
<p>&quot;$HADOOP_HOME&quot;</p>
<p>export</p>
<p>HADOOP_CONF_DIR=</p>
<p>&quot;$HADOOP_HOME/etc/hadoop/&quot;
export</p>
<p>YARN_CONF_DIR=$HADOOP_CONF_DIR</p>
<p>export</p>
<p>PATH=</p>
<p>&quot;$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH&quot;</p>
<p>以上操作注意2点：</p>
<ol>
<li>jdk一定要保证是64bit的</li>
</ol>
<p>2.HADOOP_PREFIX极其重要，主要是为了兼容MRv1，优先级最高（比 如寻找conf目录，即使我们配置了HADOOP_CONF_DIR,启动脚本依然会优先从$HADOOP_PREFIX/conf/里查找），一定要保 证此变量正确配置(也可不设置，则默认使用HADOOP_HOME/etc/hadoop/下的配置文件)</p>
<p><strong>**</strong>2.3 改官方启动脚本的bug**</p>
<p><em>**</em>说明：此版本虽然是release稳定版，但是依然有非常弱智的bug存在。</p>
<p>正常情况下，启动守护进程$YARN_HOME/sbin/hadoop-daemons.sh中可以指定node.</p>
<p>我们看下该启动脚本的说明：
1</p>
<p>2
$sbin</p>
<p>/hadoop-daemons</p>
<p>.sh</p>
<p>Usage:hadoop-daemons.sh [--config confdir] [--hosts hostlistfile] [start|stop]</p>
<p>command</p>
<p>args...</p>
<p>可以看到--hosts可以指定需要启动的存放节点名的文件名：</p>
<p>但这是无效的，此脚本调用的$YARN_HOME/libexec/hadoop-config.sh脚本有bug.</p>
<p>先建一个文件datanodefile 添加datanode节点，放入conf/文件夹下，然后执行一下启动脚本：
1</p>
<p>2
$sbin</p>
<p>/hadoop-daemons</p>
<p>.sh --hosts datanodefile start datanode</p>
<p>at:</p>
<p>/home/grid/yarn/hadoop-2</p>
<p>.2.0</p>
<p>/etc/hadoop//126571</p>
<p>:No such</p>
<p>file</p>
<p>or directory</p>
<p>分析脚本，定位到嵌套脚本$YARN_HOME/libexec/hadoop-config.sh第96行：</p>
<p>196        </p>
<p>export</p>
<p>HADOOP_SLAVES=</p>
<p>&quot;${HADOOP_CONF_DIR}/$$1&quot;</p>
<p>看到红色部分是不对的，应该修改为：</p>
<p>196        </p>
<p>export</p>
<p>HADOOP_SLAVES=</p>
<p>&quot;${HADOOP_CONF_DIR}/$1&quot;</p>
<p>备注1：此版本11月初发布至今，网上教程不论中文还是英文，均未提及此错误。</p>
<p>备注2：$YARN_HOME/libexec/hadoop-config.sh中分析hostfile的逻辑非常脑残：
1</p>
<p>2
3</p>
<p>4
593    </p>
<p>if</p>
<p>[</p>
<p>&quot;--hosts&quot;</p>
<p>=</p>
<p>&quot;$1&quot;</p>
<p>]</p>
<p>94    </p>
<p>then
95        </p>
<p>shift</p>
<p>96        </p>
<p>export</p>
<p>HADOOP_SLAVES=</p>
<p>&quot;${HADOOP_CONF_DIR}/%$1&quot;
97        </p>
<p>shift</p>
<p>因此，用户只能将自己的hostfile放在${HADOOP_CONF_DIR}/ 下面，放在其它地方是无效的。</p>
<p>备注3：按照$YARN_HOME/libexec/hadoop-config.sh脚本的逻辑，还有一种方式指定host
1$hadoop-daemons.sh –hostnames cluster1 start datanode</p>
<p>注意，因为bash脚本区分输入参数的分割符为\t或\s，所以限制了此种方式只能指定一个单独的节点</p>
<p>总结以上分析和修改步骤：
1</p>
<p>2
3</p>
<p>4
5$</p>
<p>cd</p>
<p>$YARN_HOME</p>
<p>/libexec/</p>
<p>$vim hadoop-config.sh
/#修改第96行代码为：</p>
<p>export</p>
<p>HADOOP_SLAVES=</p>
<p>&quot;${HADOOP_CONF_DIR}/$1&quot;
/#保存退出vim</p>
<p><strong>**</strong>2.4 配置文件设置**</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
 1 <!--$YARN_HOME/etc/hadoop/core-site.xml--> 2                                                                                                                                                                                                                                  3 &lt;?xml version=&quot;1.0&quot;?&gt; 4 &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; 5                                                                                                                                                                                                                                  6 <configuration> 7 <property> 8 <name>fs.defaultFS</name> 9   <value>hdfs://cluster1:9000</value>10 </property>11                                                                                                                                                                                                                                 12 <property>13 <name>hadoop.tmp.dir</name>14   <value>/home/grid/hadoop-2.2.0-src/hadoop-dist/target/hadoop-2.2.0//yarn_data/tmp/hadoop-grid</value>15 </property>16 </configuration>17   备注1：注意fs.defaultFS为新的变量，代替旧的：fs.default.name18 19  备注2：tmp文件夹放在我们刚才新建的$HOME/yarn/yarn_data/下面。20 21     <!--$YARN_HOME/etc/hadoop/hdfs-site.xml-->22 <configuration>23     <property>24     <name>dfs.replication</name>25     <value>3</value>26     </property>27 </configuration></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><em>**</em>备注1. 新：dfs.namenode.name.dir，旧：dfs.name.dir，新：dfs.datanode.name.dir，旧：dfs.data.dir</p>
<p><em>**</em>备注2. dfs.replication确定 data block的副本数目，hadoop基于rackawareness(机架感知)默认复制3份分block,（同一个rack下两个，另一个rack下一 份，按照最短距离确定具体所需block, 一般很少采用跨机架数据块，除非某个机架down了）</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
 1     <!--$YARN_HOME/etc/hadoop/yarn-site.xml--> 2                                                                                                                                                                                                                             3 <configuration> 4    <property> 5      <name>yarn.nodemanager.aux-services</name> 6      <value>mapreduce_shuffle</value> 7   </property> 8                                                                                                                                                                                                                             9   <property>10      <name>yarn.resourcemanager.address</name>11      <value>cluster1:8032</value>12   </property>13                                                                                                                                                                                                                            14   <property>15       <name>yarn.resourcemanager.resource-tracker.address</name>16       <value>cluster1:8031</value>17   </property>18                                                                                                                                                                                                                            19   <property>20       <name>yarn.resourcemanager.admin.address</name>21       <value>cluster1:8033</value>22   </property>23                                                                                                                                                                                                                            24   <property>25       <name>yarn.resourcemanager.scheduler.address</name>26       <value>cluster1:8030</value>27   </property>28                                                                                                                                                                                                                            29   <property>30       <name>yarn.nodemanager.loacl-dirs</name>31       <value>/home/grid/hadoop-2.2.0-src/hadoop-dist/target//hadoop-2.2.0/yarn_data/mapred/nodemanager</value>32       <final>true</final>33   </property>34                                                                                                                                                                                                                            35   <property>36       <name>yarn.web-proxy.address</name>37       <value>cluster1:8888</value>38   </property>39                                                                                                                                                                                                                            40   <property>41      <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>42      <value>org.apache.hadoop.mapred.ShuffleHandler</value>43   </property>44 </configuration></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>在此特意提醒：</strong></p>
<p>(1) 目前网上盛传的各种hadoop2.2的基于分布式集群的安装教程大部分都是错的,hadoop2.2配置里最重要的也莫过于yarn-site.xml里的变量了吧？</p>
<p>(2)不同于单机安装，基于集群的搭建必须设置</p>
<p>yarn-site.xml可选变量yarn.web-proxy.address
和</p>
<p>yarn.nodemanager.loacl-dirs
外的其它所有变量！后续会专门讨论yarn-site.xml里各个端口配置的含义。</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
1 <!--$YARN_HOME/etc/hadoop/mapred-site.xml-->2                                                                                                                                                                                                            3 <configuration>4     <property>5         <name>mapreduce.framework.name</name>6         <value>yarn</value>7     </property>8 </configuration></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>备注1：新的计算框架取消了实体上的jobtracker, 故不需要再指定mapreduce.jobtracker.addres，而是要指定一种框架，这里选择yarn. 备注2：hadoop2.2.还支持第三方的计算框架，但没怎么关注过。
          配置好以后将$HADOOP_HOME下的所有文件，包括hadoop目录分别copy到其它3个节点上。</p>
<p><strong>2.5**</strong>各节点功能规划**</p>
<p>确保在每主机的/etc/hosts里添加了所有node的域名解析表（i.e.cluster1   198.0.0.1）；iptables已关闭；/etc/sysconfig/network-script/ifcfg-eth0里 BOTPROTO=static；/etc/sysconfig/network文件里已设置了各台主机的hostname, 静态ip地址，且已经重启过每台机器；jdk和hadoop都为64bit；ssh免登陆已配置；完成以上几项后，就可以启动hadoop2.2.0了。</p>
<p>注意到从头到尾都没有提到Master, Slave,也没有提到namenode,datanode,是因为，新的计算框架，新的hdfs中不存在物理上的Master节点，所有的节点都是等价的。</p>
<p>各节点职能划分在篇首已有说明， 在此重提一下：
1</p>
<p>2
3</p>
<p>4
cluster1    resourcemanager, nodemanager, proxyserver,historyserver, datanode, namenode,</p>
<p>cluster2    datanode, nodemanager
cluster3    datanode, nodemanager</p>
<p>cluster4    datanode, nodemanager</p>
<p><strong>2.6 hdfs 格式化</strong></p>
<p>1$bin</p>
<p>/hdfs</p>
<p>namenode –</p>
<p>format</p>
<p>(注意：hadoop 2.2.0的格式化步骤和旧版本不一样，旧的为 $YARN_HOME/bin/hadoop namenode –format)</p>
<p><strong>2.7 hadoop整体启动</strong></p>
<p><em>**</em>启动方式（1）分别登录各自主机开启</p>
<p>在cluster1节点上，分别启动resourcemanager,nodemanager, proxyserver, historyserver, datanode, namenode,</p>
<p>在cluster2, cluster3, cluster4 节点主机上，分别启动datanode,nodemanager</p>
<p><strong>备注</strong>：如果resourcemanager是 独立的，则除了resourcemanager,其余每一个节点都需要一个nodemanager，我们可以在$YARN_HOME/etc /hadoop/下新建一个nodehosts, 在里面添加所有的除了resourcemanager外的所有node，因为此处我们配置的resourcemanager和namenode是同一台主 机，所以此处也需要添加nodemanager</p>
<p>执行步骤如下：
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
7</p>
<p>8
9</p>
<p>10
11</p>
<p>12
13$</p>
<p>hostname</p>
<p>/#查看host名字</p>
<p>cluster1
$sbin</p>
<p>/hadoop-daemon</p>
<p>.sh  --script hdfs start namenode</p>
<p>/# 启动namenode</p>
<p>$sbin</p>
<p>/hadoop-daemon</p>
<p>.sh --script hdfs start datanode</p>
<p>/# 启动datanode
$sbin</p>
<p>/yarndaemon</p>
<p>.shstart nodemanager</p>
<p>/#启动nodemanager</p>
<p>$sbin</p>
<p>/yarn-daemon</p>
<p>.sh   start resourcemanager</p>
<p>/# 启动resourcemanager
$sbin</p>
<p>/yarn-daemon</p>
<p>.shstart proxyserver</p>
<p>/# 启动web App proxy, 作用类似jobtracker,若yarn-site.xml里没有设置yarn.web-proxy.address的host和端口，或者设置了和 resourcemanager相同的host和端口，则hadoop默认proxyserver和resourcemanager共享 host:port</p>
<p>$sbin</p>
<p>/mr-jobhistory-daemon</p>
<p>.sh   start historyserver</p>
<p>/#你懂得
$</p>
<p>ssh</p>
<p>cluster2 </p>
<p>/#登录cluster2</p>
<p>$</p>
<p>hostname</p>
<p>/#查看host名字cluster2
$sbin</p>
<p>/yarndaemon</p>
<p>.shstart nodemanager</p>
<p>/# 启动nodemanager</p>
<p>$sbin</p>
<p>/hadoop-daemon</p>
<p>.sh  --script hdfs start datanode</p>
<p>/# 启动datanode
$</p>
<p>ssh</p>
<p>cluster3 </p>
<p>/#登录cluster3.../# cluster2, cluster3, cluster4启动方式和cluster2一样。</p>
<p>启动方式（2）使用hadoop自带的批处理脚本开启</p>
<p>Step1.确认已登录cluster1:
1$</p>
<p>hostname</p>
<p>cluster1</p>
<p>在$YARN_HOME/etc/hadoop/下新建namenodehosts,添加所有namenode节点</p>
<p>1</p>
<p>2</p>
<p>$</p>
<p>cat</p>
<p>$YARN_HOME</p>
<p>/etc/hadoop/namenodehosts</p>
<p>cluster1</p>
<p>在$YARN_HOME/etc/hadoop/下新建datanodehosts,添加所有datanode节点</p>
<p>1</p>
<p>2
3</p>
<p>4
$</p>
<p>cat</p>
<p>$YARN_HOME</p>
<p>/etc/hadoop/datanodehosts</p>
<p>cluster2
cluster3</p>
<p>cluster4</p>
<p>在$YARN_HOME/etc/hadoop/下新建nodehosts,添加所有datanode和namenode节点</p>
<p>1</p>
<p>2
3</p>
<p>4
5$</p>
<p>cat</p>
<p>$YARN_HOME</p>
<p>/etc/hadoop/datanodehosts</p>
<p>cluster1
cluster2</p>
<p>cluster3
cluster4</p>
<p><strong>备注</strong>：以上的hostfile名字是随便起的，可以是任意的file1,file2,file3, 但是必须放在$YARN_HOME/etc/hadoop/下面！</p>
<p>Step2.执行脚本
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
$sbin</p>
<p>/hadoop-daemons</p>
<p>.sh--hosts namenodehosts --script  hdfsstart  namenode</p>
<p>$sbin</p>
<p>/hadoop-daemons</p>
<p>.sh--hosts datanodehosts --script  hdfsstart  datanode
$sbin</p>
<p>/yarn-daemons</p>
<p>.sh--hostnames cluster1 start resourcemanager</p>
<p>$sbin</p>
<p>/yarn-daemons</p>
<p>.sh--hosts allnodehosts start nodemanager
$sbin</p>
<p>/yarn-daemons</p>
<p>.sh--hostnames cluster1 start proxyserver</p>
<p>$sbin</p>
<p>/mr-jobhistory-daemon</p>
<p>.sh   start  historyserver</p>
<p><strong>在这里不得不纠正一个其他教程上关于对hadoop2.2做相关配置和运行时的错误!</strong></p>
<p>我们在core-site.xml指定了default filesystem为cluster1, 并指定了其节点ip（或节点名）和端口号， 这意味着若启动hadoop时不额外添加配置（启动hadoop时命令行里加--conf指定用户配置文件的存放位置)，则默认的namenode就一 个，那就是cluster1, 如果随意指定namenode必然会出现错误！</p>
<p>如果你要还要再启动一个新的namenode(以cluster3为例)，则必须如下操作：</p>
<p>a. 新建一个core-site.xml，添加fs.defaultFS的value为hdfs://cluster3:9000</p>
<p>b. command：
1$sbin</p>
<p>/hadoop-daemon</p>
<p>.sh --hostnames cluster3 --conf you_conf_dir --script hdfs --start namenode</p>
<p>我们之前启动的namenode为cluster1, 假如要查看放在此文件系统根目录下的文件input_file，则它的完整路径为 hdfs://cluster1:9000/input_file</p>
<p>Step3.查看启动情况</p>
<p>在cluster1上：
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
$jps</p>
<p>22411 NodeManager
23356 Jps</p>
<p>22292 ResourceManager
22189 DataNode</p>
<p>22507 WebAppProxyServer</p>
<p>在cluster2上</p>
<p>1</p>
<p>2
3</p>
<p>4
$jps</p>
<p>8147 DataNode
8355 Jps</p>
<p>8234 NodeManagercluster3，cluster4上和cluster2一样。</p>
<p><em>**</em>Step4.查看各节点状态以及yarncluster运行状态</p>
<p>（1）查看各节点状态</p>
<p>FireFox进入： <a href="http://cluster1:50070(cluster1为namenode所在节点" target="_blank">http://cluster1:50070(cluster1为namenode所在节点</a>)</p>
<p>在主页面（第一张图）上点击Live Node，查看（第二张图）上各Live Node状态：</p>
<p><img src="http://m1.img.libdd.com/farm4/d/2013/1114/14/5D0856F11A09F93C0BD97246AE6DEE43_B500_900_500_218.png" alt=""></p>
<p>（2）查看resourcemanager上cluster运行状态</p>
<p>Firefox进入：<a href="http://cluster2:8088(node1为resourcemanager所在节点" target="_blank">http://cluster2:8088(node1为resourcemanager所在节点</a>)</p>
<p><img src="http://m3.img.libdd.com/farm4/d/2013/1114/14/5B46215F81D52CF3C3DB80D2DEFF8770_B500_900_500_195.png" alt=""></p>
<p><strong> </strong>Step5. Cluster上MapReduce测试</p>
<p>现提供3个test cases</p>
<p><strong>Test Case 1 testimated_value_of_pi</strong></p>
<p>command:
$sbin/yarnjar $YARN_HOME/share/hadoop//mapreduce/hadoop-mapreduce-examples-2.2.0.jar \pi 101000000</p>
<p>console输出：</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
Number of Maps  =10                        Samples per Map = 1000000                         Wrote input for Map /#0                          Wrote input for Map /#1                          Wrote input for Map /#2                         Wrote input for Map /#3                        Wrote input for Map /#4                       Wrote input for Map /#5                         Wrote input for Map /#6                        Wrote input for Map /#7                        Wrote input for Map /#8                        Wrote input for Map /#9                        Starting Job                        13/11/06 23:20:07 INFO Configuration.deprecation: mapred.map.tasksis deprecated. Instead, use mapreduce.job.maps                        13/11/06 23:20:07 INFO Configuration.deprecation:mapred.output.key.class is deprecated. Instead, usemapreduce.job.output.key.class                         13/11/06 23:20:07 INFO Configuration.deprecation:mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir                         13/11/06 23:20:11 INFO mapreduce.JobSubmitter: Submittingtokens for job: job_1383806445149_0001                         13/11/06 23:20:15 INFO impl.YarnClientImpl: Submittedapplication application_1383806445149_0001 to ResourceManager at /0.0.0.0:8032                       13/11/06 23:20:16 INFO mapreduce.Job: The url to trackthe job: <a href="http://Node1:8088/proxy/application_1383806445149_0001/" target="_blank">http://Node1:8088/proxy/application_1383806445149_0001/</a>                        13/11/06 23:20:16 INFO mapreduce.Job: Running job:job_1383806445149_0001                         13/11/06 23:21:09 INFO mapreduce.Job: Jobjob_1383806445149_0001 running in uber mode : false                        13/11/06 23:21:10 INFO mapreduce.Job:  map 0% reduce 0%                          13/11/06 23:24:28 INFO mapreduce.Job:  map 20% reduce 0%                         13/11/06 23:24:30 INFO mapreduce.Job:  map 30% reduce 0%                          13/11/06 23:26:56 INFO mapreduce.Job:  map 57% reduce 0%                          13/11/06 23:26:58 INFO mapreduce.Job:  map 60% reduce 0%                          13/11/06 23:28:33 INFO mapreduce.Job:  map 70% reduce 20%                         13/11/06 23:28:35 INFO mapreduce.Job:  map 80% reduce 20%                         13/11/06 23:28:39 INFO mapreduce.Job:  map 80% reduce 27%                         13/11/06 23:30:06 INFO mapreduce.Job:  map 90% reduce 27%                         13/11/06 23:30:09 INFO mapreduce.Job:  map 100% reduce 27%                         13/11/06 23:30:12 INFO mapreduce.Job:  map 100% reduce 33%                         13/11/06 23:30:25 INFO mapreduce.Job:  map 100% reduce 100%                          13/11/06 23:30:54 INFO mapreduce.Job: Jobjob_1383806445149_0001 completed successfully                          13/11/06 23:31:10 INFO mapreduce.Job: Counters: 43                                    File SystemCounters                                             FILE:Number of bytes read=226                                             FILE:Number of bytes written=879166                                              FILE:Number of read operations=0                                             FILE:Number of large read operations=0                                            FILE:Number of write operations=0                                             HDFS:Number of bytes read=2590                                               HDFS:Number of bytes written=215                                               HDFS:Number of read operations=43                                               HDFS:Number of large read operations=0                                                 HDFS:Number of write operations=3                                    JobCounters                                              Launchedmap tasks=10                                                Launchedreduce tasks=1                                               Data-localmap tasks=10                                                Totaltime spent by all maps in occupied slots (ms)=1349359                                             Totaltime spent by all reduces in occupied slots (ms)=190811                                    Map-ReduceFramework                                             Mapinput records=10                                              Mapoutput records=20                                                Mapoutput bytes=180                                                 Mapoutput materialized bytes=280                                                Inputsplit bytes=1410                                                 Combineinput records=0                                                Combineoutput records=0                                                  Reduceinput groups=2                                                 Reduceshuffle bytes=280                                              Reduceinput records=20                                                Reduceoutput records=0                                                 SpilledRecords=40                                                 ShuffledMaps =10                                                  FailedShuffles=0                                                MergedMap outputs=10                                                 GCtime elapsed (ms)=45355                                                 CPUtime spent (ms)=29860                                                 Physicalmemory (bytes) snapshot=1481818112                                                 Virtualmemory (bytes) snapshot=9214468096                                                 Totalcommitted heap usage (bytes)=1223008256                                        ShuffleErrors                                              BAD_ID=0                                              CONNECTION=0                                             IO_ERROR=0                                              WRONG_LENGTH=0                                               WRONG_MAP=0                                            WRONG_REDUCE=0                                    File InputFormat Counters                                              BytesRead=1180                                    File OutputFormat Counters                                             BytesWritten=97                           13/11/06 23:31:15 INFO mapred.ClientServiceDelegate:Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirectingto job history server                           Job Finished in 719.041 seconds                           Estimated value of Pi is 3.14158440000000000000</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>说明</strong>：可以看到最后输出值为该job使用了 10个maps, job id为job<em>1383806445149_000, 最后计算得Pi的值为13.14158440000000000000， job Id分配原则为job</em>年月日时分<em>job序列号，序列号从0开始，上限值为1000， task id分配原则为job</em>年月日时分<em>job序列号_task序列号_m, job</em>年月日时分_job序列号_task序列号_r, m代表map taskslot , r代表reduce task slot, task 序列号从0开始，上限值为1000.</p>
<p><strong>Test Case 2 random_writting</strong>
/#command line $sbin/yarnjar $YARN_HOME/share/hadoop//mapreduce/hadoop-mapreduce-examples-2.2.0.jar \randomwriter/user/grid/test/test_randomwriter/out</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>/#Console输出摘录：                                                                                                                                                    Running 10 maps.Job started: Wed Nov 0623:42:17 PST 201313/11/0623:42:17 INFO client.RMProxy: Connecting toResourceManager at /0.0.0.0:803213/11/0623:42:19 INFO mapreduce.JobSubmitter: number ofsplits:1013/11/0623:42:20 INFO mapreduce.JobSubmitter: Submittingtokens for job: job_1383806445149_000213/11/0623:42:21 INFO impl.YarnClientImpl: Submittedapplication application_1383806445149_0002 to ResourceManager at /0.0.0.0:803213/11/0623:42:21 INFO mapreduce.Job: The url to trackthe job: <a href="http://Master:8088/proxy/application_1383806445149_0002/13/11/0623:42:21" target="_blank">http://Master:8088/proxy/application_1383806445149_0002/13/11/0623:42:21</a> INFO mapreduce.Job: Running job:job_1383806445149_000213/11/0623:42:40 INFO mapreduce.Job: Jobjob_1383806445149_0002 running in uber mode : false13/11/0623:42:40 INFO mapreduce.Job:  map 0% reduce 0%                  13/11/0623:55:02 INFO mapreduce.Job:  map 10% reduce 0%                    13/11/0623:55:14 INFO mapreduce.Job:  map 20% reduce 0%                  13/11/0623:55:42 INFO mapreduce.Job:  map 30% reduce 0%                    13/11/0700:06:55 INFO mapreduce.Job:  map 40% reduce 0%                    13/11/0700:07:10 INFO mapreduce.Job:  map 50% reduce 0%                   13/11/0700:07:36 INFO mapreduce.Job:  map 60% reduce 0%                    13/11/0700:13:47 INFO mapreduce.Job:  map 70% reduce 0%                     13/11/0700:13:54 INFO mapreduce.Job:  map 80% reduce 0%                     13/11/0700:13:58 INFO mapreduce.Job:  map 90% reduce 0%                    13/11/0700:16:29 INFO mapreduce.Job:  map 100% reduce 0%                    13/11/0700:16:37 INFO mapreduce.Job: Jobjob_1383806445149_0002 completed successfully        File OutputFormat Counters                  BytesWritten=10772852496Job ended: Thu Nov 0700:16:40 PST 2013The job took 2062 seconds.</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>说明</strong>：电脑存储空间足够的话，可以从hdfs里down下来看看。</p>
<p>现只能看一看输出文件存放的具体形式：</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
./bin/hadoopfs -ls /user/grid/test/test_randomwriter/out/Found 11items-rw-r--r--   2 grid supergroup          02013-11-0700:16/user/grid/test/test_randomwriter/out/_SUCCESS-rw-r--r--   2 grid supergroup 10772782142013-11-0623:54 /user/grid/test/test_randomwriter/out/part-m-00000                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772827512013-11-0623:55 /user/grid/test/test_randomwriter/out/part-m-00001                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772802982013-11-0623:55 /user/grid/test/test_randomwriter/out/part-m-00002                                                                                                                                                   -rw-r--r--   2 grid supergroup 10773031522013-11-0700:07 /user/grid/test/test_randomwriter/out/part-m-00003                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772842402013-11-0700:06 /user/grid/test/test_randomwriter/out/part-m-00004                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772866042013-11-0700:07 /user/grid/test/test_randomwriter/out/part-m-00005                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772843362013-11-0700:13 /user/grid/test/test_randomwriter/out/part-m-00006                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772848292013-11-0700:13 /user/grid/test/test_randomwriter/out/part-m-00007                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772897062013-11-0700:13 /user/grid/test/test_randomwriter/out/part-m-00008                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772783662013-11-0700:16 /user/grid/test/test_randomwriter/out/part-m-00009</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>Test Case3 word_count</strong></p>
<p>（1）Locaol上创建文件：
$mkdirinput%echo ‘hello,world’ &gt;&gt; input/file1.in$echo ‘hello, ruby’ &gt;&gt; input/file2.in</p>
<p>（2）上传到hdfs上：
./bin/hadoop fs -mkdir -p /user/grid/test/test_wordcount/./bin/hadoop fs –put input/user/grid/test/test_wordcount/in</p>
<p>（3）用yarn新计算框架运行mapreduce：</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
/#command line $bin/yarn jar$YARN_HOME/share/hadoop//mapreduce/hadoop-mapreduce-examples-2.2.0.jarwordcount  /user/grid/test/test_wordcount/in/user/grid/test/test_wordcount/out                                                                                                                                             /#ConSole输出摘录：3/11/0700:35:03 INFO client.RMProxy:Connecting to ResourceManager at /0.0.0.0:803213/11/0700:35:05 INFO input.FileInputFormat:Total input paths to process : 213/11/0700:35:05 INFO mapreduce.JobSubmitter:number of splits:213/11/0700:35:06 INFO mapreduce.JobSubmitter:Submitting tokens for job: job_1383806445149_000313/11/0700:35:08 INFO impl.YarnClientImpl:Submitted application application_1383806445149_0003 to ResourceManager at /0.0.0.0:803213/11/0700:35:08 INFO mapreduce.Job: The urlto track the job: <a href="http://Master:8088/proxy/application_1383806445149_0003/13/11/0700:35:08" target="_blank">http://Master:8088/proxy/application_1383806445149_0003/13/11/0700:35:08</a> INFO mapreduce.Job: Runningjob: job_1383806445149_000313/11/0700:35:25 INFO mapreduce.Job: Jobjob_1383806445149_0003 running in uber mode : false13/11/0700:35:25 INFO mapreduce.Job:  map 0% reduce 0%                                                                                                                                              13/11/0700:37:50 INFO mapreduce.Job:  map 33% reduce 0%                                                                                                                                              13/11/0700:37:54 INFO mapreduce.Job:  map 67% reduce 0%                                                                                                                                              13/11/0700:37:55 INFO mapreduce.Job:  map 83% reduce 0%                                                                                                                                              13/11/0700:37:58 INFO mapreduce.Job:  map 100% reduce 0%                                                                                                                                              13/11/0700:38:51 INFO mapreduce.Job:  map 100% reduce 100%                                                                                                                                              13/11/0700:38:54 INFO mapreduce.Job: Jobjob_1383806445149_0003 completed successfully13/11/0700:38:56 INFO mapreduce.Job:Counters: 43</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>说明</strong>：查看word count的计算结果：
1</p>
<p>2
3</p>
<p>4
$bin</p>
<p>/hadoop</p>
<p>fs -</p>
<p>cat</p>
<p>/user/grid/test//test_wordcount/out/</p>
<p>/*</p>
<p>hadoop 1
hello  1</p>
<p>ruby</p>
<p><strong>补充</strong>：因为新的YARN为了保持与MRv1框 架的旧版本兼容性，很多老的API还是可以用，但是会有INFO。此处通过修改$YARN_HOME/etc/hadoop /log4j.properties可以turn offconfiguration deprecation warnings.</p>
<p>建议去掉第138行的注释（可选），确保错误级别为WARN（默认为INFO级别，详见第20行：hadoop.root.logger=INFO,console）：
1138 log4j.logger.org.apache.hadoop.conf.Configuration.deprecation=WARN</p>
<p>附文：</p>
<p><strong>集群搭建、配置步骤（基于CentOS_64bit）</strong></p>
<p><strong>0. 说明</strong></p>
<p>大体规划如下：</p>
<p>虚拟机： VMware-workstation-full-8.0.3-703057（VMware10中文版不完整，此版本内含vmware tools，为设定共享文件夹所必须）</p>
<p>电脑1，VMWare,内装2个虚拟系统，(cluster1, cluster2)</p>
<p>电脑2,，VMware内装2个虚拟系统，(cluster3, cluster4)</p>
<p>虚拟主机： CentOS x86 64bit</p>
<p>局域网IP设置：<em>**</em>
1</p>
<p>2
3</p>
<p>4</p>
<p>cluster1  172.16.102. 201</p>
<p>cluster2   172.16.102. 202
cluster3   172.16.102. 203</p>
<p>cluster4   172.16.102. 204</p>
<p>网关</p>
<p>1172.16.102.254</p>
<p><strong>1. Linux集群安装</strong></p>
<p>(1) 准备</p>
<p>Vmware: VMware-workstation-full-8.0.3-703057(此安装包自带VMWare Tools)</p>
<p>Linux:CentOS.iso</p>
<p>(2) VMWare配置</p>
<p>VMWare以及所有安装的虚拟机均为桥接</p>
<p>Step1. 配置VMWare 联网方式： Editor-&gt;Virtual Network Editor-&gt;选择Bridged， 点击确定</p>
<p>Step2. 安装虚拟机</p>
<p>Step3.配置各虚拟机接网方式：右键已安装虚拟机-&gt;点击NetworkAdapter, 选择桥接，确定</p>
<p>Step4. 为所有安装好的虚拟系统设置一个共享目录(类似FTP，但是设置共享目录更方便) ：右键已安装虚拟机-&gt;点击Virtual Machine Settings对话框上部Options， 选择Shared Folder， 在本地新建SharedFolder并添加进来,确定。</p>
<p>(3) linux下网卡以及IP配置</p>
<p>以下配置在三个虚拟系统里均相同, 以cluster1为例：</p>
<p>配置前需切换为root</p>
<p>Step1. 修改主机名， 设置为开启网络</p>
<p>配置/etc/sysconfig/network：
1</p>
<p>2
3[root@localhost ~]</p>
<p>/# cat /etc/sysconfig/network</p>
<p>NETWORKING=</p>
<p>yes
HOSTNAME=cluster1</p>
<p>Step2.修改当前机器的IP， 默认网关， IP分配方式， 设置网络接口为系统启动时有效：</p>
<p>a.查看配置前的ip:
1</p>
<p>2
3</p>
<p>4
[root@localhost ~]</p>
<p>/# ifconfig</p>
<p>eth0      Link encap:Ethernet  HWaddr 00:0C:29:E1:FB:95 
inet addr:172.16.102.3  Bcast:172.16.102.255  Mask:255.255.255.0</p>
<p>inet6 addr: fe80::20c:29ff:fee1:fb95</p>
<p>/64</p>
<p>Scope:Lin</p>
<p>b.配置/etc/sysconfig/network-scripts/ifcfg-eth0</p>
<p>注意以下几项：</p>
<p>BOOTPROTO=&quot;static&quot; (IP分配方式, 设为static则主机ip即为IPADDR里所设，若为”dhcp”, 此时只有局域网有效，则vmware会启动自带虚拟”dhcp”, 动态分配ip， 此时可以连接互联网 )</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
IPV6INIT=&quot;no&quot;  /#你懂得 IPADDR=&quot;172.16.102.201&quot; /#ip地址 GETEWAY=&quot;172.16.102.254&quot; /#默认网关地址 ONBOOT=&quot;yes&quot; /#系统启动时网络接口有效 [root@localhost ~]/# cat /etc/sysconfig/network-scripts/ifcfg-eth0  DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;HWADDR=&quot;00:0C:29:E1:FB:95&quot;BOOTPROTO=&quot;dhcp&quot;IPV6INIT=&quot;no&quot;IPADDR=&quot;172.16.102.201&quot;GETEWAY=&quot;172.16.102.254&quot;ONBOOT=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;TYPE=&quot;Ethernet&quot;UUID=&quot;79612b26-326b-472c-94af-9ab151fc2831</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>c.使当前设置生效：
$service network restart $ifdown eth0 /#关闭默认网卡 $ifup eth/#重新启用默认网卡 $service network restart; ifdown eth0; ifup eth0</p>
<p>d.查看新设置的ip:
$ifconfigeth0      Link encap:Ethernet  HWaddr 00:0C:29:E1:FB:95  inet addr:192.168.1.200  Bcast:192.168.1.255  Mask:255.255.255.0inet6 addr: fe80::20c:29ff:fee1:fb95/64 Scope:Link UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</p>
<p>Step3. 修改hosts文件，此文件会被ＤＮＳ解析，类似linux里的alias, 设置后以后，hostname就是ip地址， 两者可以互换。</p>
<p>配置/etc/hosts, 添加三行如下， （注意，此3行在3个虚拟主机里都相同，切必须全部都要加上）</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
[root@localhost ~]/# cat /etc/hosts127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6 cluster1   172.16.102. 201cluster2   172.16.102. 202cluster3   172.16.102. 203cluster4   172.16.102. 204</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>Step4. 按照以上3个步骤分别设置两外两个虚拟主机，</p>
<p>配置完以后必须按照之前的三个命令分别重启 network, ifeth0:
$service network restart $ifdown eth0 $ifup eth0</p>
<p>重新初始化以后查看各自主机的ip配置是否正确。</p>
<p>在任意一台主机上执行： ping cluster1; ping cluster2; ping cluster3; ping cluster4</p>
<p>若配置正确，一定可以ping通，否则，请检查各个主机的/etc/hosts文件是否已经添加新的映射！至此，linux集群已成功配置。</p>
<p><strong>2. 设置 ssh免登陆</strong></p>
<p>a. 新建一个用户</p>
<p>在三台主机上分别以root权限新建一个用户，此处默认为grid:</p>
<p>cluster1,cluster2, cluster3, cluster4上：
$useradd –m grid $passwd grid 1qaz!QAZ</p>
<p>注意一定要保证4台主机上有相同的用户名， 以实现同一个用户在4台主机上登录。</p>
<p>b. 在cluster1上生成RSA密钥</p>
<p>切换回user: grid
$su grid $cd ~</p>
<p>生成密钥对：</p>
<p>1</p>
<p>2
3$</p>
<p>ssh</p>
<p>-keygen –t rsa</p>
<p>/#一路回车到最后（ 此处生成无需密码的秘钥-公钥对）。
/#上一个步骤 ssh-keygen –t rsa会在grid的home目录下生成一个.ssh文件夹</p>
<p>之后：</p>
<p>$cd ~/.ssh/$cp id_rsa.pub authorized_keys</p>
<p>c. 在另外3个主机上的grid用户home目录下也声称相应的密钥对, 并在.ssh目录下生成一个</p>
<p>authorized_keys
文件</p>
<p>d. 想办法将4台主机grid用户下刚生成的</p>
<p>authorized_keys
里的内容整合成一个完整的</p>
<p>authorized_keys.</p>
<p>比如将4个authorized_keys里的内容全部复制到cluster1上的authorized_keys里， 然后：
$chmod 600 authorized_keys $scp .ssh/authorized_keys  cluster2:/home/grid/.ssh/$scp .ssh/authorized_keys  cluster3:/home/grid/.ssh/$scp .ssh/authorized_keys  cluster4:/home/grid/.ssh/</p>
<p>若要求输入密码，则输入之前新建用户grid时设置的密码， 一路回车到最后.</p>
<p>e. 下面尝试ssh无秘钥登录：</p>
<p>在cluster1主机上：ssh cluster2， 依次尝试登陆cluster2, cluster3, cluster4</p>
<p>若均可可以免密码登录，则直接跳到下一步骤，否则，请看下面的解决方案：</p>
<p>可能出现的问题有3，</p>
<p>第一种可能，.ssh文件夹非自动生成，而是你手动新建的，若如此，会出现.ssh的安全上下文问题， 解决方案， 在三个主机上以grid用户，删除刚才生成的.ssh文件夹，重新进入home目录，务必用 /# ssh-keygen –t rsa 生成秘钥， 此过程ssh程序会自动在home目录下成成一个.ssh文件夹</p>
<p>第二种可能, authorized_keys权限不一致。 在各自.ssh目录下：ls–alauthorizedkeys,查看此文件的权限，一定为600(−rw−−−−−−−),即只对当前用户grid开放可读可写权限，若不是，则修改authorizedkeys文件权限chmod 600 authorized_keys</p>
<p>若经过以上两步还不行，则执行以下命令，重新启动ssh-agent， 且加入当前用户秘钥id_rsa
$ssh-add ~grid/.ssh/id_rsa</p>
<p>经过以上三步，一定可以实现grid从cluster1到其它3个节点的免秘钥登录。</p>
<p>因为hadoop2.2新架构的缘故，我们还应该设置为每一个节点到其它任意节点免登陆。</p>
<p>具体步骤:</p>
<p>1.在将cluster2, cluster3, cluster4上各自的.ssh/id_rsa.pub 分别复制到cluster1的.ssh/下： scp id_rsa.pub cluster1:/home/grid/.ssh/tmp2, scp id_rsa.pub cluster1:/home/grid/.ssh/tmp3 ...</p>
<p>2.将cluster1节点/home/grid/.ssh/下的tmp2, tmp3, tmp4分别appand到authorized_keys里， 并请将各自节点上的id_rsa.pub也append到各自节点的authorized_keys里，以实现本地登陆（类似： ssh localhost)</p>
<p>至此，ssh免秘钥登陆设置完成。</p>
<p><strong>3. 安装jdk</strong></p>
<p>Step1. 记得之前在安装cluster1时在VMWare里设置的共享目录吗？</p>
<p>在Windows下将Hadoop安装包，jdk安装包Copy到共享目录下，然后在linux下从/mnt/hgfs/Data-shared/下cp到/home/grid/下，直接执行jdk安装包，不需要解压。</p>
<p>注意：若在安装过程中提示”Extracting… install.sfx 5414: /lib/ld-linux.50.2 No such file or directory, 则执行以下命令:</p>
<p>a.我们之前为了测试自定义的ip是否有效，已将各台主机的ip分配方式设为了BOOTPROTO=”static”, 这种方式是无法连入外部网络的，所以此时为了安装缺省的包，切换到root, 修改/etc/sysconfig/network-script/ifcfg-eth0，将BOOTPROTO=”static” 修改为BOOTPROTO=”dhcp”,</p>
<p>b.重启网络服务和网卡: 在root权限下:
$service network restart; ifdown eth0; ifup eth0 $yum install glibc.i686</p>
<p>d.切换回grid,重新安装jdk</p>
<p>$cd /usr/java/  /#注意必须进入java文件夹，因为java安装包默认安装在当前目录下 $./jdk-6u25-linux-i586.bin /#安装jdk</p>
<p>安装完以后，记得将eth0文件修改回来：</p>
<p>$sed -i s/dhcp/static/g /etc/sysconfig/network-scripts/ifcfg-eth0 /#此处用sed直接替换，若不放心也可以用编辑器修改 /#service network restart; ifdown eth0;ifup eth0</p>
<p>至此，jdk已在linux下安装完毕。</p>
<p>最后，将java安装好的路径append到$PATH变量里（处于个人习惯，新环境变量一律添加到所需用户的.bashrc文件里， 即只对当前用户有效）
$su grid $vim ~/.bashrc （修改.bashrc文件，添加如下两行：） $tail -2 ~/.bashrc export JAVA_HOME=&quot;/usr/java/jdk1.6.0_25/&quot;export PATH=&quot;${PATH}:${JAVA_HOME}/bin&quot;</p>
<p>测试一下java是否可以正常启动：</p>
<p>$source ~/.bashrc $which java $/usr/java/jdk1.6.0_25/bin/java</p>
<p>至此，jdk安装完毕。</p>
<p>用同样的方式在另外3台虚拟主机上安装jdk, 提示：先复制到home下
$scp -r /mnt/hgfs/Data-shared/Archive/jdk-6u25-linux-i586.bin  cluster2:/home/grid/$scp -r /mnt/hgfs/Data-shared/Archive/jdk-6u25-linux-i586.bin  cluster3:/home/grid/$scp -r /mnt/hgfs/Data-shared/Archive/jdk-6u25-linux-i586.bin  cluster4:/home/grid/</p>
<p>再切root, copy到/usr/java下， cd /usr/java, 然后再安装.</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux--Vim命令合集/">Vim命令合集</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux--Vim命令合集/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="vim-">Vim命令合集</h1>
<p>命令历史</p>
<p>以:和/开头的命令都有历史纪录，可以首先键入:或/然后按上下箭头来选择某个历史命令。</p>
<h1 id="-vim">启动vim</h1>
<p>在命令行窗口中输入以下命令即可</p>
<p>vim 直接启动vim</p>
<p>vim filename 打开vim并创建名为filename的文件</p>
<h1 id="-">文件命令</h1>
<p>打开单个文件</p>
<p>vim file</p>
<p>同时打开多个文件</p>
<p>vim file1 file2 file3 ...</p>
<p>在vim窗口中打开一个新文件</p>
<p>:open file</p>
<p>在新窗口中打开文件</p>
<p>:split file</p>
<p>切换到下一个文件</p>
<p>:bn</p>
<p>切换到上一个文件</p>
<p>:bp</p>
<p>查看当前打开的文件列表，当前正在编辑的文件会用[]括起来。</p>
<p>:args</p>
<p>打开远程文件，比如ftp或者share folder</p>
<p>:e ftp://192.168.10.76/abc.txt</p>
<p>:e \qadrive\test\1.txt</p>
<h1 id="vim-">vim的模式</h1>
<p>正常模式（按Esc或Ctrl+[进入） 左下角显示文件名或为空
插入模式（按i键进入） 左下角显示--INSERT--
可视模式（不知道如何进入） 左下角显示--VISUAL--</p>
<h1 id="-">导航命令</h1>
<p>% 括号匹配</p>
<h1 id="-">插入命令</h1>
<p>i 在当前位置生前插入</p>
<p>I 在当前行首插入</p>
<p>a 在当前位置后插入</p>
<p>A 在当前行尾插入</p>
<p>o 在当前行之后插入一行</p>
<p>O 在当前行之前插入一行</p>
<h1 id="-">查找命令</h1>
<p>/text　　查找text，按n健查找下一个，按N健查找前一个。</p>
<p>?text　　查找text，反向查找，按n健查找下一个，按N健查找前一个。</p>
<p>vim中有一些特殊字符在查找时需要转义　　./*[]^%/?~$</p>
<p>:set ignorecase　　忽略大小写的查找</p>
<p>:set noignorecase　　不忽略大小写的查找</p>
<p>查找很长的词，如果一个词很长，键入麻烦，可以将光标移动到该词上，按/*或/#键即可以该单词进行搜索，相当于/搜索。而/#命令相当于?搜索。</p>
<p>:set hlsearch　　高亮搜索结果，所有结果都高亮显示，而不是只显示一个匹配。</p>
<p>:set nohlsearch　　关闭高亮搜索显示</p>
<p>:nohlsearch　　关闭当前的高亮显示，如果再次搜索或者按下n或N键，则会再次高亮。</p>
<p>:set incsearch　　逐步搜索模式，对当前键入的字符进行搜索而不必等待键入完成。</p>
<p>:set wrapscan　　重新搜索，在搜索到文件头或尾时，返回继续搜索，默认开启。</p>
<h1 id="-">替换命令</h1>
<p>ra 将当前字符替换为a，当期字符即光标所在字符。</p>
<p>s/old/new/ 用old替换new，替换当前行的第一个匹配</p>
<p>s/old/new/g 用old替换new，替换当前行的所有匹配</p>
<p>%s/old/new/ 用old替换new，替换所有行的第一个匹配</p>
<p>%s/old/new/g 用old替换new，替换整个文件的所有匹配</p>
<p>:10,20 s/^/    /g 在第10行知第20行每行前面加四个空格，用于缩进。</p>
<p>ddp 交换光标所在行和其下紧邻的一行。</p>
<h1 id="-">移动命令</h1>
<p>h 左移一个字符
l 右移一个字符，这个命令很少用，一般用w代替。
k 上移一个字符
j 下移一个字符
以上四个命令可以配合数字使用，比如20j就是向下移动20行，5h就是向左移动5个字符，在Vim中，很多命令都可以配合数字使用，比如删除10个字符10x，在当前位置后插入3个！，3a！<Esc>，这里的Esc是必须的，否则命令不生效。</p>
<p>w 向前移动一个单词（光标停在单词首部），如果已到行尾，则转至下一行行首。此命令快，可以代替l命令。</p>
<p>b 向后移动一个单词 2b 向后移动2个单词</p>
<p>e，同w，只不过是光标停在单词尾部</p>
<p>ge，同b，光标停在单词尾部。</p>
<p>^ 移动到本行第一个非空白字符上。</p>
<p>0（数字0）移动到本行第一个字符上，</p>
<p><HOME> 移动到本行第一个字符。同0健。</p>
<p>$ 移动到行尾 3$ 移动到下面3行的行尾</p>
<p>gg 移动到文件头。 = [[</p>
<p>G（shift + g） 移动到文件尾。 = ]]</p>
<p>f（find）命令也可以用于移动，fx将找到光标后第一个为x的字符，3fd将找到第三个为d的字符。</p>
<p>F 同f，反向查找。</p>
<p>跳到指定行，冒号+行号，回车，比如跳到240行就是 :240回车。另一个方法是行号+G，比如230G跳到230行。</p>
<p>Ctrl + e 向下滚动一行</p>
<p>Ctrl + y 向上滚动一行</p>
<p>Ctrl + d 向下滚动半屏</p>
<p>Ctrl + u 向上滚动半屏</p>
<p>Ctrl + f 向下滚动一屏</p>
<p>Ctrl + b 向上滚动一屏</p>
<h1 id="-">撤销和重做</h1>
<p>u 撤销（Undo）
U 撤销对整行的操作
Ctrl + r 重做（Redo），即撤销的撤销。</p>
<h1 id="-">删除命令</h1>
<p>x 删除当前字符</p>
<p>3x 删除当前光标开始向后三个字符</p>
<p>X 删除当前字符的前一个字符。X=dh</p>
<p>dl 删除当前字符， dl=x</p>
<p>dh 删除前一个字符</p>
<p>dd 删除当前行</p>
<p>dj 删除上一行</p>
<p>dk 删除下一行</p>
<p>10d 删除当前行开始的10行。</p>
<p>D 删除当前字符至行尾。D=d$</p>
<p>d$ 删除当前字符之后的所有字符（本行）</p>
<p>kdgg 删除当前行之前所有行（不包括当前行）</p>
<p>jdG（jd shift + g）   删除当前行之后所有行（不包括当前行）</p>
<p>:1,10d 删除1-10行</p>
<p>:11,$d 删除11行及以后所有的行</p>
<p>:1,$d 删除所有行</p>
<p>J(shift + j)　　删除两行之间的空行，实际上是合并两行。</p>
<h1 id="-">拷贝和粘贴</h1>
<p>yy 拷贝当前行</p>
<p>nyy 拷贝当前后开始的n行，比如2yy拷贝当前行及其下一行。</p>
<p>p  在当前光标后粘贴,如果之前使用了yy命令来复制一行，那么就在当前行的下一行粘贴。</p>
<p>shift+p 在当前行前粘贴</p>
<p>:1,10 co 20 将1-10行插入到第20行之后。</p>
<p>:1,$ co $ 将整个文件复制一份并添加到文件尾部。</p>
<p>正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按y即可复制</p>
<p>ddp交换当前行和其下一行</p>
<p>xp交换当前字符和其后一个字符</p>
<h1 id="-">剪切命令</h1>
<p>正常模式下按v（逐字）或V（逐行）进入可视模式，然后用jklh命令移动即可选择某些行或字符，再按d即可剪切</p>
<p>ndd 剪切当前行之后的n行。利用p命令可以对剪切的内容进行粘贴</p>
<p>:1,10d 将1-10行剪切。利用p命令可将剪切后的内容进行粘贴。</p>
<p>:1, 10 m 20 将第1-10行移动到第20行之后。</p>
<h1 id="-">退出命令</h1>
<p>:wq 保存并退出</p>
<p>ZZ 保存并退出</p>
<p>:q! 强制退出并忽略所有更改</p>
<p>:e! 放弃所有修改，并打开原来文件。</p>
<h1 id="-">窗口命令</h1>
<p>:split或new 打开一个新窗口，光标停在顶层的窗口上</p>
<p>:split file或:new file 用新窗口打开文件</p>
<p>split打开的窗口都是横向的，使用vsplit可以纵向打开窗口。</p>
<p>Ctrl+ww 移动到下一个窗口</p>
<p>Ctrl+wj 移动到下方的窗口</p>
<p>Ctrl+wk 移动到上方的窗口</p>
<p>关闭窗口</p>
<p>:close 最后一个窗口不能使用此命令，可以防止意外退出vim。</p>
<p>:q 如果是最后一个被关闭的窗口，那么将退出vim。</p>
<p>ZZ 保存并退出。</p>
<p>关闭所有窗口，只保留当前窗口</p>
<p>:only</p>
<p>录制宏</p>
<p>按q键加任意字母开始录制，再按q键结束录制（这意味着vim中的宏不可嵌套），使用的时候@加宏名，比如qa。。。q录制名为a的宏，@a使用这个宏。</p>
<h1 id="-shell-">执行shell命令</h1>
<p>:!command</p>
<p>:!ls 列出当前目录下文件</p>
<p>:!perl -c script.pl 检查perl脚本语法，可以不用退出vim，非常方便。</p>
<p>:!perl script.pl 执行perl脚本，可以不用退出vim，非常方便。</p>
<p>:suspend或Ctrl - Z 挂起vim，回到shell，按fg可以返回vim。</p>
<h1 id="-">注释命令</h1>
<p>perl程序中/#开始的行为注释，所以要注释某些行，只需在行首加入/#</p>
<p>3,5 s/^//#/g 注释第3-5行</p>
<p>3,5 s/^/#//g 解除3-5行的注释</p>
<p>1,$ s/^//#/g 注释整个文档。</p>
<p>:%s/^//#/g 注释整个文档，此法更快。</p>
<h1 id="-">帮助命令</h1>
<p>:help or F1 显示整个帮助
:help xxx 显示xxx的帮助，比如 :help i, :help CTRL-[（即Ctrl+[的帮助）。
:help &#39;number&#39; Vim选项的帮助用单引号括起
:help <Esc> 特殊键的帮助用&lt;&gt;扩起
:help -t Vim启动参数的帮助用-
：help i<em><Esc> 插入模式下Esc的帮助，某个模式下的帮助用模式</em>主题的模式
帮助文件中位于||之间的内容是超链接，可以用Ctrl+]进入链接，Ctrl+o（Ctrl + t）返回</p>
<h1 id="-">其他非编辑命令</h1>
<p>. 重复前一次命令</p>
<p>:set ruler?　　查看是否设置了ruler，在.vimrc中，使用set命令设制的选项都可以通过这个命令查看</p>
<p>:scriptnames　　查看vim脚本文件的位置，比如.vimrc文件，语法文件及plugin等。</p>
<p>:set list 显示非打印字符，如tab，空格，行尾等。如果tab无法显示，请确定用set lcs=tab:&gt;-命令设置了.vimrc文件，并确保你的文件中的确有tab，如果开启了expendtab，那么tab将被扩展为空格。</p>
<p>Vim教程
在Unix系统上
$ vimtutor
在Windows系统上
:help tutor
:syntax 列出已经定义的语法项
:syntax clear 清除已定义的语法规则
:syntax case match 大小写敏感，int和Int将视为不同的语法元素
:syntax case ignore 大小写无关，int和Int将视为相同的语法元素，并使用同样的配色方案</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span></span> | <span class="tags">Tagged <a href="/tags/linux/" class="label label-primary">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux--Vim命令合集/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux--Vim命令合集" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux--Linux大文件传输/">Linux大文件传输</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux--Linux大文件传输/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="linux-">Linux大文件传输</h1>
<ul>
<li><p><a href="http://www.yankay.com/" target="_blank">首页</a></p>
</li>
<li><p><a href="http://www.yankay.com/about/" target="_blank">关于</a></p>
</li>
</ul>
<h1 id="-http-www-yankay-com-"><a href="http://www.yankay.com/" target="_blank">我自然</a></h1>
<h2 id="-">颜开的博客</h2>
<h2 id="linux-">Linux大文件传输</h2>
<p>作者: <a href="http://www.yankay.com/author/admin/" title="查看 颜开 的所有文章" target="_blank">颜开</a> 日期: 2012 年 2 月 7 日  <a href="&quot;发表评论？&quot;">发表评论</a> (17) <a href="&quot;查看评论？&quot;">查看评论</a></p>
<p>我们经常需要在机器之间传输文件。比如备份，复制数据等等。这个是很常见，也是很简单的。用scp或者rsync就能很好的完成任务。但是如果文件很大，需要占用一些传输时间的时候，怎样又快又好地完成任务就很重要了。在我的测试用例中，一个最佳的方案比最差的方案，性能提高了10倍。</p>
<h3 id="-"><strong>复制文件</strong></h3>
<p>如果我们是复制一个<strong>未压缩</strong>的文件。这里走如下步骤：</p>
<ol>
<li>压缩数据</li>
<li>发送到另外一台机器上</li>
<li>数据解压缩</li>
<li>校验正确性
这样做会很有效率，数据压缩后可以更有效的利用带宽</li>
</ol>
<h3 id="-zip-scp-"><strong>使用ZIP+SCP</strong></h3>
<p>我们可以通过ZIP+SCP的组合实现这个功能。</p>
<p>gzip -c /home/yankay/data | ssh yankay01 &quot;gunzip -c - &gt; /home/yankay/data&quot;</p>
<p>这条命令是将/home/yankay/data经过GZIP压缩，通过ssh传输到yankay01的机器上。
data文件的大小是1.1GB,经过Zip压缩后是183MB，执行上面的命令需要45.6s。平均吞吐量为24.7MB/s</p>
<p>我们会发现Scp也有压缩功能，所以上面的语句可以写成
scp -C -c blowfish /home/yankay/data yankay01:/home/yankay/data</p>
<p>这样运行效果是相同的，不通之处在于我使用了blowfish算法作为Scp的密匙算法，使用这个算法可以比默认的情况快很多。单单对与scp,使用了blowfish 吞吐量是62MB/s,不使用只有46MB/s。</p>
<p>可是我执行上面一条命令的时候，发现还是需要45s。平均吞吐量还为24MB/s。没有丝毫的提升，可见瓶颈不在网络上。
那瓶颈在哪里呢？</p>
<h3 id="-"><strong>性能分析</strong></h3>
<p>我们先定义几个变量</p>
<ul>
<li>压缩工具的压缩比是 CompressRadio</li>
<li>压缩工具的压缩吞吐是CompressSpeed MB/s</li>
<li>网络传输的吞吐是 NetSpeed MB/s</li>
</ul>
<p>由于使用了管道，管道的性能取决于管道中最慢的部分的性能，所以整体的性能是：</p>
<p>speed=min(NetSpeed/CompressRadio,CompressSpeed)</p>
<p>当压缩吞吐较网络传输慢的时候，压缩是瓶颈；但网络较慢的时候，网络传输/吞吐 是瓶颈。</p>
<p>根据现有的测试数据(纯文本)，可以得到表格：
压缩比 吞吐量 千兆网卡(100MB/s)吞吐量 千兆网卡吞吐量,基于ssh(62MB/s) 百兆网卡(10MB/s)吞吐量 ZLIB 35.80% 9.6 9.6 9.6 9.6 LZO 54.40% 101.7 101.7 101.7 18.38235294 LIBLZF 54.60% 134.3 134.3 113.5531136 18.31501832 QUICKLZ 54.90% 183.4 182.1493625 112.9326047 18.21493625 FASTLZ 56.20% 134.4 134.4 110.3202847 17.79359431 SNAPPY 59.80% 189 167.2240803 103.6789298 16.72240803 NONE 100% 300 100 62 10</p>
<p>可以看出来。在千兆网卡下，使用QuickLZ作为压缩算法，可以达到最高的性能。如果使用SSH作为数据传输通道，则远远没有达到网卡可以达到的最佳性能。在百兆网卡的情况下，各个算法相近。对比下来QuickLZ是有优势的。</p>
<p>对于不同的数据和不同的机器，可以得出不同的最佳压缩算法。但有一点是肯定的，尽量把瓶颈压在网络上。对于较慢的网络环境，高压缩比的算法会比较有优势；相反对于较快的网络环境，低压缩比的算法会更好。</p>
<h3 id="-"><strong>结论</strong></h3>
<p>根据上面的分析结果，我们不能是用SSH作为网络传输通道，可以使用NC这个基本网络工具，提高性能。同时使用qpress作为压缩算法。
scp /usr/bin/qpress yankay01:/usr/bin/qpress ssh yankay01 &quot;nc -l 12345 | qpress -dio &gt; /home/yankay/data&quot; &amp; qpress -o /home/yankay/data |nc yankay01 12345</p>
<p>第一行是将gpress安装到远程机器上，第二行在远程机器上使用nc监听一个端口，第三行压缩并传送数据。</p>
<p>执行上面的命令需要2.8s。平均吞吐量为402MB/s,比使用Gzip+Scp快了16倍！！</p>
<p>根据上文的公式，和自己的数据，可以绘出上面的表格，就可以选择出最适合的压缩算法和传输方式。达到满意的效果。如果是一个长期运行的脚本的话，这么做是值得的。
Share the post &quot;Linux大文件传输&quot;</p>
<ul>
<li><a href="http://service.weibo.com/share/share.php?url=http%3A%2F%2Fwww.yankay.com%2Flinux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93%2F" title="Share this article on Weibo" target="_blank">Weibo</a>
<a href="http://www.yankay.com/category/%e6%8a%80%e6%9c%af/%e6%af%8f%e6%97%a5%e5%bf%83%e5%be%97/" title="查看 每日心得 中的全部文章" target="_blank">每日心得</a><a href="http://www.yankay.com/tag/linux/" target="_blank">Linux</a>, <a href="http://www.yankay.com/tag/%e4%bc%a0%e8%be%93/" target="_blank">传输</a>, <a href="http://www.yankay.com/tag/%e5%a4%a7%e6%96%87%e4%bb%b6/" target="_blank">大文件</a></li>
</ul>
<p><a href="http://www.yankay.com/%e5%86%85%e5%ad%98%e7%a9%b6%e7%ab%9f%e6%9c%89%e5%a4%9a%e5%bf%ab%ef%bc%9f/" target="_blank">← 内存究竟有多快？</a></p>
<p><a href="http://www.yankay.com/amazon-ebs%e6%9e%b6%e6%9e%84%e7%8c%9c%e6%83%b3/" target="_blank">Amazon EBS架构猜想 →</a></p>
<p><a href="&quot;发表评论？&quot;">发表评论？</a></p>
<h2 id="17-">17 条评论。</h2>
<ol>
<li><img src="" alt=""> xjj07 <a href="">2012 年 2 月 14 日 在 下午 3:50</a></li>
</ol>
<p>你说我当年那个网站还能找回来不？</p>
<p>有空再弄一下！
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=2764#respond" target="_blank">回复</a></p>
<ol>
<li><img src="" alt=""> zht <a href="">2012 年 2 月 21 日 在 上午 9:53</a></li>
</ol>
<p>校验正确性</p>
<p>好像没有考虑啊？ <img src="" alt=":lol:">
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=2791#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> 颜开 <a href="">2012 年 2 月 21 日 在 上午 10:15</a></li>
</ul>
<p>压缩已经内置了验证。
gzip是有验证的,其他几个没有仔细研究，应该也有。
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=2793#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> <a href="http://magicode.me/" target="_blank">renenglish</a> <a href="">2012 年 2 月 24 日 在 下午 12:10</a></li>
</ul>
<p>&quot;平均吞吐量为402MB/s&quot; 压缩速度跟网速度都没打到200M/s ，平均怎么到了402MB/s ?
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=2813#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> 颜开 <a href="">2012 年 2 月 28 日 在 下午 5:33</a></li>
</ul>
<p>我又重新测了一下还是402MB/s。是这样的，上面200M/s用的测试数据和下面1.1GB的文件不是一个文件。压缩比相差很大，所以达到了402MB/s。怪我没有说清楚，自己都记不清了。
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=2847#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> 阿干 <a href="">2013 年 1 月 8 日 在 下午 11:00</a></li>
</ul>
<p>请参考engineering.tumblr.com/post/7658008285/efficiently-copying-files-to-multiple-destinations
或者andrew.tumblr.com/post/2316602611
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=4526#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> 颜开 <a href="">2013 年 1 月 17 日 在 下午 1:13</a></li>
</ul>
<p>谢谢你
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=4553#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> <a href="http://blog.liuw.name/" target="_blank">liuw</a> <a href="">2013 年 1 月 9 日 在 上午 9:37</a></li>
</ul>
<p>1.1G的文件压缩到183M，这个说明文件冗余还是很大的。但是一般的二进制数据还会有这么好的效果吗？</p>
<p>另外有时候用scp还是有安全方面的考虑的吧，在公网上这样的方法可能要考虑过再使用了。</p>
<p>P.S 还是要大大赞一下钻研精神
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=4527#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> 小莫飞 <a href="">2013 年 1 月 9 日 在 下午 8:02</a></li>
</ul>
<p>请问性能运算公式是怎么看得？和表里的数据有对应关系吗
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=4529#respond" target="_blank">回复</a></p>
<ul>
<li><a href="http://www.xymyeah.com/1274.html" target="_blank">Linux大文件传输 | 互联网纪事</a> - pingback on 2013 年 1 月 10 日 在 下午 10:51</li>
<li><img src="" alt=""> erazy0 <a href="">2013 年 1 月 10 日 在 下午 11:20</a></li>
</ul>
<h1 id="-compressradio">压缩工具的压缩比是 CompressRadio</h1>
<p>Radio --&gt; Ratio
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=4533#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> shell <a href="">2013 年 1 月 11 日 在 下午 1:06</a></li>
</ul>
<p>猜测瓶颈在压缩算法跑满单核上。用mpstat测试一下？
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=4539#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> 深夜两点 <a href="">2013 年 1 月 18 日 在 下午 7:18</a></li>
</ul>
<p>我用下面的命令传数据是成功了，不过问题是在目标机器上，总是有俩tar进程，一个gzip进程，一个nc进程不结束。</p>
<p>cd /home/mengzang/zt;
ssh <a href="http://www.myhost.com/" target="_blank"><a href="http://www.myhost.com">http://www.myhost.com</a></a> &quot;nc -l 22345 | tar -zxf - -C /home/mengzang/zt/ggg&quot; &amp;
tar -zcf - 1.txt 2.txt d1 | nc <a href="http://www.myhost.com/" target="_blank"><a href="http://www.myhost.com">http://www.myhost.com</a></a> 22345
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=4559#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> <a href="http://www.huangkeye.com/" target="_blank">vfhky</a> <a href="">2013 年 3 月 5 日 在 下午 2:59</a></li>
</ul>
<p>博主真牛，不得不赞！
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=4823#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> bridge <a href="">2013 年 4 月 22 日 在 上午 11:31</a></li>
</ul>
<p>压缩是cpu换取传输时间
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=5770#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> <a href="http://blog1980.info/" target="_blank">lyman</a> <a href="">2013 年 5 月 3 日 在 下午 6:24</a></li>
</ul>
<p>nc 很裸很强大。但是如果要考虑断点续传的话（大文件嘛，呵呵），还是直接 rsync 比较省事
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=5907#respond" target="_blank">回复</a></p>
<ul>
<li><img src="" alt=""> 虎子 <a href="">2013 年 6 月 28 日 在 上午 11:31</a></li>
</ul>
<p>hello,请问gpress 这个是哪个软件包里面的工具呢
<a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/?replytocom=6492#respond" target="_blank">回复</a></p>
<h3 id="-">发表评论 <a href="">取消回复</a></h3>
<p>昵称</p>
<p>邮箱</p>
<p>网址</p>
<p><a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a> <a href=""><img src="" alt=""></a></p>
<p>注意 - 你可以用以下 HTML tags and attributes:</p>
<p><a href="" title=""> <abbr title=""> <acronym title=""> <b> <blockquote cite=""> <cite> <code> <del datetime=""> <em> <i> <q cite=""> <strike> <strong></p>
<h3 id="trackbacks-and-pingbacks-">Trackbacks and Pingbacks:</h3>
<ul>
<li><a href="http://www.xymyeah.com/1274.html" target="_blank">Linux大文件传输 | 互联网纪事</a> - Pingback on 2013/01/10/ 22:51
<a href="http://www.yankay.com/feed/" title="RSS 订阅" target="_blank">RSS 订阅</a> <a href="http://weibo.com/yankaycom" title="微博" target="_blank">微博</a></li>
</ul>
<h3 id="-">近期文章</h3>
<ul>
<li><a href="http://www.yankay.com/scala-tour-choiceness/" title="Scala Tour - 精选" target="_blank">Scala Tour - 精选</a></li>
<li><a href="http://www.yankay.com/nosql-anti-pattern-document/" title="NoSQL反模式 - 文档数据库篇" target="_blank">NoSQL反模式 - 文档数据库篇</a></li>
<li><a href="http://www.yankay.com/2012%e5%b9%b4%e5%ad%a6%e4%b9%a0%e5%b0%8f%e7%bb%93/" title="2012年学习小结" target="_blank">2012年学习小结</a></li>
<li><a href="http://www.yankay.com/go-clear-concurreny/" title="Go-简洁的并发" target="_blank">Go-简洁的并发</a></li>
<li><a href="http://www.yankay.com/google-spanner%e5%8e%9f%e7%90%86-%e5%85%a8%e7%90%83%e7%ba%a7%e7%9a%84%e5%88%86%e5%b8%83%e5%bc%8f%e6%95%b0%e6%8d%ae%e5%ba%93/" title="Google Spanner原理- 全球级的分布式数据库" target="_blank">Google Spanner原理- 全球级的分布式数据库</a></li>
<li><a href="http://www.yankay.com/google-dremel-rationale/" title="Google Dremel 原理 - 如何能3秒分析1PB" target="_blank">Google Dremel 原理 - 如何能3秒分析1PB</a></li>
<li><a href="http://www.yankay.com/java-fast-byte-comparison/" title="Java使用&quot;指针&quot;快速比较字节" target="_blank">Java使用&quot;指针&quot;快速比较字节</a></li>
<li><a href="http://www.yankay.com/hbase-slider/" title="HBase介绍PPT" target="_blank">HBase介绍PPT</a></li>
<li><a href="http://www.yankay.com/amazon-ebs%e6%9e%b6%e6%9e%84%e7%8c%9c%e6%83%b3/" title="Amazon EBS架构猜想" target="_blank">Amazon EBS架构猜想</a></li>
<li><a href="http://www.yankay.com/linux%e5%a4%a7%e6%96%87%e4%bb%b6%e4%bc%a0%e8%be%93/" title="Linux大文件传输" target="_blank">Linux大文件传输</a></li>
</ul>
<h3 id="-">标签</h3>
<p><a href="http://www.yankay.com/tag/android/" title="1 个话题" target="_blank">Android</a> <a href="http://www.yankay.com/tag/apache/" title="1 个话题" target="_blank">apache</a> <a href="http://www.yankay.com/tag/arch/" title="1 个话题" target="_blank">arch</a> <a href="http://www.yankay.com/tag/bigtable/" title="1 个话题" target="_blank">BigTable</a> <a href="http://www.yankay.com/tag/common-cloud/" title="1 个话题" target="_blank">Common Cloud</a> <a href="http://www.yankay.com/tag/eclipse/" title="2 个话题" target="_blank">eclipse</a> <a href="http://www.yankay.com/tag/facebook/" title="2 个话题" target="_blank">Facebook</a> <a href="http://www.yankay.com/tag/friendmap/" title="1 个话题" target="_blank">FriendMap</a> <a href="http://www.yankay.com/tag/gae/" title="3 个话题" target="_blank">Gae</a> <a href="http://www.yankay.com/tag/gaes/" title="5 个话题" target="_blank">GaeS</a> <a href="http://www.yankay.com/tag/gaevfs/" title="1 个话题" target="_blank">GaeVfs</a> <a href="http://www.yankay.com/tag/gdp/" title="1 个话题" target="_blank">GDP</a> <a href="http://www.yankay.com/tag/ggg/" title="1 个话题" target="_blank">GGG</a> <a href="http://www.yankay.com/tag/giant-global-graph/" title="1 个话题" target="_blank">Giant Global Graph</a> <a href="http://www.yankay.com/tag/google-reader/" title="1 个话题" target="_blank">Google Reader</a> <a href="http://www.yankay.com/tag/google-reader-play/" title="1 个话题" target="_blank">Google Reader Play</a> <a href="http://www.yankay.com/tag/hadoop/" title="2 个话题" target="_blank">Hadoop</a> <a href="http://www.yankay.com/tag/hbase/" title="2 个话题" target="_blank">Hbase</a> <a href="http://www.yankay.com/tag/html5/" title="2 个话题" target="_blank">HTML5</a> <a href="http://www.yankay.com/tag/java/" title="4 个话题" target="_blank">Java</a> <a href="http://www.yankay.com/tag/jpa2-0/" title="1 个话题" target="_blank">JPA2.0</a> <a href="http://www.yankay.com/tag/jsa4j/" title="2 个话题" target="_blank">Jsa4j</a> <a href="http://www.yankay.com/tag/latex/" title="2 个话题" target="_blank">latex</a> <a href="http://www.yankay.com/tag/linux/" title="2 个话题" target="_blank">Linux</a> <a href="http://www.yankay.com/tag/maven/" title="1 个话题" target="_blank">maven</a> <a href="http://www.yankay.com/tag/nosql/" title="5 个话题" target="_blank">NoSQL</a> <a href="http://www.yankay.com/tag/tortoisehg/" title="2 个话题" target="_blank">TortoiseHg</a> <a href="http://www.yankay.com/tag/ubuntu/" title="2 个话题" target="_blank">Ubuntu</a> <a href="http://www.yankay.com/tag/%e4%b8%ad%e6%96%87/" title="2 个话题" target="_blank">中文</a> <a href="http://www.yankay.com/tag/%e4%b8%ad%e7%a7%91%e6%9d%af/" title="1 个话题" target="_blank">中科杯</a> <a href="http://www.yankay.com/tag/%e4%b9%b1%e7%a0%81/" title="2 个话题" target="_blank">乱码</a> <a href="http://www.yankay.com/tag/%e4%bc%98%e5%8c%96/" title="2 个话题" target="_blank">优化</a> <a href="http://www.yankay.com/tag/%e5%8a%a8%e6%80%81%e8%a7%84%e5%88%92/" title="1 个话题" target="_blank">动态规划</a> <a href="http://www.yankay.com/tag/%e5%90%8c%e5%ad%a6/" title="1 个话题" target="_blank">同学</a> <a href="http://www.yankay.com/tag/%e5%9b%be%e4%b9%a6%e9%a6%86/" title="1 个话题" target="_blank">图书馆</a> <a href="http://www.yankay.com/tag/%e5%9c%a8%e6%b0%b4%e6%bb%a9/" title="1 个话题" target="_blank">在水滩</a> <a href="http://www.yankay.com/tag/%e6%95%b0%e6%8d%ae%e5%ba%93/" title="1 个话题" target="_blank">数据库</a> <a href="http://www.yankay.com/tag/%e6%96%87%e4%bb%b6/" title="1 个话题" target="_blank">文件</a> <a href="http://www.yankay.com/tag/%e6%a8%a1%e6%9d%bf/" title="1 个话题" target="_blank">模板</a> <a href="http://www.yankay.com/tag/%e6%b1%9f%e8%8b%8f%e6%9d%af/" title="1 个话题" target="_blank">江苏杯</a> <a href="http://www.yankay.com/tag/%e7%9f%a5%e8%af%86%e5%9b%be/" title="1 个话题" target="_blank">知识图</a> <a href="http://www.yankay.com/tag/%e7%ab%8b%e5%bf%97/" title="1 个话题" target="_blank">立志</a> <a href="http://www.yankay.com/tag/%e7%bb%b4%e5%9f%ba%e7%99%be%e7%a7%91/" title="1 个话题" target="_blank">维基百科</a> <a href="http://www.yankay.com/tag/%e8%a7%86%e9%a2%91/" title="1 个话题" target="_blank">视频</a> <a href="http://www.yankay.com/tag/%e9%85%92/" title="1 个话题" target="_blank">酒</a></p>
<h3 id="-">我的应用</h3>
<ul>
<li><a href="http://zh.scala-tour.com/" title="精彩的Scala之旅" target="_blank">Scala Tour</a></li>
<li><a href="http://weibagua.cloudfoundry.com/" target="_blank">趣味应用-微八卦</a></li>
</ul>
<h3 id="-">相关组织</h3>
<ul>
<li><a href="http://qing.weibo.com/emclabschina" title="EMC中国研究院" target="_blank">EMC中国研究院</a></li>
<li><p><a href="http://blog.nosqlfan.com/" target="_blank">nosqlfan</a></p>
<h3 id="-">友情链接</h3>
</li>
<li><p><a href="http://laynepeng.cloudfoundry.com/" target="_blank">Layne Peng的博客</a></p>
</li>
<li><a href="http://www.iiira.com/" target="_blank">爱陶</a></li>
<li><a href="http://larry-wang.com/" target="_blank">王小龙的博客</a></li>
<li><a href="http://loveharbor.net/" target="_blank">高晟</a>
版权所有 © 2013 我自然 | Powered by <a href="http://wordpress.org/" target="_blank">WordPress</a> and <a href="http://zww.me/" target="_blank">zBench</a>
↑ <a href="&quot;Back to top&quot;">回到顶部</a></li>
</ul>
<p></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span></span> | <span class="tags">Tagged <a href="/tags/linux/" class="label label-primary">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux--Linux大文件传输/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux--Linux大文件传输" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/114/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/112/">112</a></li><li><a class="page-number" href="/page/113/">113</a></li><li><a class="page-number" href="/page/114/">114</a></li><li class="active"><li><span class="page-number current">115</span></li><li><a class="page-number" href="/page/116/">116</a></li><li><a class="page-number" href="/page/117/">117</a></li><li><a class="page-number" href="/page/118/">118</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/163/">163</a></li><li><a class="page-number" href="/page/164/">164</a></li><li><a class="extend next" href="/page/116/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Site powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a>  update time: <em>2014-03-29 22:06:56</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
