
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 55 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency37-并发总结/">深入浅出 Java Concurrency (37)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency37-并发总结/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-37-">深入浅出 Java Concurrency (37): 并发总结</h1>
<p><a href="http://www.blogjava.net/xylz/archive/2011/12/29/365149.html" target="_blank">深入浅出 Java Concurrency (37): 并发总结 part 1 死锁与活跃度</a></p>
<h1 id="-">死锁与活跃度</h1>
<p>前面谈了很多并发的特性和工具，但是大部分都是和锁有关的。我们使用锁来保证线程安全，但是这也会引起一些问题。</p>
<ul>
<li>锁顺序死锁(lock-ordering deadlock)：多个线程试图通过不同的顺序获得多个相同的资源，则发生的循环锁依赖现象。</li>
<li>动态的锁顺序死锁（Dynamic Lock Order Deadlocks）：多个线程通过传递不同的锁造成的锁顺序死锁问题。</li>
<li>资源死锁（Resource Deadlocks）：线程间相互等待对方持有的锁，并且谁都不会释放自己持有的锁发生的死锁。也就是说当现场持有和等待的目标成为资源，就有可能发生此死锁。这和锁顺序死锁不一样的地方是，竞争的资源之间并没有严格先后顺序，仅仅是相互依赖而已。</li>
</ul>
<h2 id="-">锁顺序死锁</h2>
<p>最经典的锁顺序死锁就是LeftRightDeadLock.
<img src="" alt=""></p>
<p>public class LeftRightDeadLock {
    final Object left = new Object();
    final Object right = new Object();
    public void doLeftRight() {
        synchronized (left) {
            synchronized (right) {
                execute1();
            }
        }
    }
    public void doRightLeft() {
        synchronized (right) {
            synchronized (left) {
                execute2();
            }
        }
    }
    private void execute2() {
    }
    private void execute1() {
    }
}</p>
<p>这个例子很简单，当两个线程分别获取到left和right锁时，互相等待对方释放其对应的锁，很显然双方都陷入了绝境。</p>
<h2 id="-">动态的锁顺序死锁</h2>
<p>与锁顺序死锁不同的是动态的锁顺序死锁只是将静态的锁变成了动态锁。 一个比较生动的例子是这样的。</p>
<p>public void transferMoney(Account fromAccount,//
        Account toAccount,//
        int amount
        ) {
    synchronized (fromAccount) {
        synchronized (toAccount) {
            fromAccount.decr(amount);
            toAccount.add(amount);
        }
    }
}
当我们银行转账的时候，我们期望锁住双方的账户，这样保证是原子操作。 看起来很合理，可是如果双方同时在进行转账操作，那么就有可能发生死锁的可能性。</p>
<p>很显然，动态的锁顺序死锁的解决方案应该看起来和锁顺序死锁解决方案差不多。 但是一个比较特殊的解决方式是纠正这种顺序。 例如可以调整成这样：
Object lock = new Object();
public void transferMoney(Account fromAccount,//
        Account toAccount,//
        int amount
        ) {
    int order = fromAccount.name().compareTo(toAccount.name());
    Object lockFirst = order&gt;0?toAccount:fromAccount;
    Object lockSecond = order&gt;0?fromAccount:toAccount;
    if(order==0){
        synchronized(lock){
            synchronized(lockFirst){
                synchronized(lockSecond){
                    //do work
                }
            }
        }
    }else{
        synchronized(lockFirst){
            synchronized(lockSecond){
                //do work
            }
        }
    }
}</p>
<p>这个挺有意思的。比较两个账户的顺序，保证此两个账户之间的传递顺序总是按照某一种锁的顺序进行的， 即使多个线程同时发生，也会遵循一次操作完释放完锁才进行下一次操作的顺序，从而可以避免死锁的发生。</p>
<h2 id="-">资源死锁</h2>
<p>资源死锁比较容易理解，就是需要的资源远远大于已有的资源，这样就有可能线程间的资源竞争从而发生死锁。 一个简单的场景是，应用同时从两个连接池中获取资源，两个线程都在等待对方释放连接池的资源以便能够同时获取 到所需要的资源，从而发生死锁。</p>
<p>资源死锁除了这种资源之间的直接依赖死锁外，还有一种叫线程饥饿死锁（thread-starvation deadlock）。 严格意义上讲，这种死锁更像是活跃度问题。例如提交到线程池中的任务由于总是不能够抢到线程从而一直不被执行， 造成任务的“假死”状况。</p>
<p>除了上述几种问题外，还有协作对象间的死锁以及开发调用的问题。这个描述起来会比较困难，也不容易看出死锁来。</p>
<h1 id="-">避免和解决死锁</h1>
<p>通常发生死锁后程序难以自恢复。但也不是不能避免的。 有一些技巧和原则是可以降低死锁可能性的。</p>
<p>最简单的原则是尽可能的减少锁的范围。锁的范围越小，那么竞争的可能性也越小。 尽快释放锁也有助于避开锁顺序。如果一个线程每次最多只能够获取一个锁，那么就不会产生锁顺序死锁。尽管应用中比较困难，但是减少锁的边界有助于分析程序的设计和简化流程。 减少锁之间的依赖以及遵守获取锁的顺序是避免锁顺序死锁的有效途径。</p>
<p>另外尽可能的使用定时的锁有助于程序从死锁中自恢复。 例如对于上述顺序锁死锁中，使用定时锁很容易解决此问题。</p>
<p>public void doLeftRight() throws Exception {
    boolean over = false;
    while (!over) {
        if (left.tryLock(1, TimeUnit.SECONDS)) {
            try {
                if (right.tryLock(1, TimeUnit.SECONDS)) {
                    try {
                        execute1();
                    } finally {
                        right.unlock();
                        over = true;
                    }
                }
            } finally {
                left.unlock();
            }
        }
    }
}
public void doRightLeft() throws Exception {
    boolean over = false;
    while (!over) {
        if (right.tryLock(1, TimeUnit.SECONDS)) {
            try {
                if (left.tryLock(1, TimeUnit.SECONDS)) {
                    try {
                        execute2();
                    } finally {
                        left.unlock();
                        over = true;
                    }
                }
            } finally {
                right.unlock();
            }
        }
    }
}
看起来代码会比较复杂，但是这是避免死锁的有效方式。</p>
<h1 id="-">活跃度</h1>
<p>对于多线程来说，死锁是非常严重的系统问题，必须修正。除了死锁，遇到很多的就是活跃度问题了。 活跃度问题主要包括：饥饿，丢失信号，和活锁等。</p>
<h2 id="-">饥饿</h2>
<p>饥饿是指线程需要访问的资源被永久拒绝，以至于不能在继续进行。 比如说：某个权重比较低的线程可能一直不能够抢到CPU周期，从而一直不能够被执行。</p>
<p>也有一些场景是比较容易理解的。对于一个固定大小的连接池中，如果连接一直被用完，那么过多的任务可能由于一直无法抢占到连接从而不能够被执行。这也是饥饿的一种表现。</p>
<p>对于饥饿而言，就需要平衡资源的竞争，例如线程的优先级，任务的权重，执行的周期等等。总之，当空闲的资源较多的情况下，发生饥饿的可能性就越小。</p>
<h2 id="-">弱响应性</h2>
<p>弱响应是指，线程最终能够得到有效的执行，只是等待的响应时间较长。 最常见的莫过于GUI的“假死”了。很多时候GUI的响应只是为了等待后台数据的处理，如果线程协调不好，很有可能就会发生“失去响应”的现象。</p>
<p>另外，和饥饿很类似的情况。如果一个线程长时间独占一个锁，那么其它需要此锁的线程很有可能就会被迫等待。</p>
<h2 id="-">活锁</h2>
<p>活锁（Livelock）是指线程虽然没有被阻塞，但是由于某种条件不满足，一直尝试重试，却终是失败。</p>
<p>考虑一个场景，我们从队列中拿出一个任务来执行，如果任务执行失败，那么将任务重新加入队列，继续执行。假如任务总是执行失败，或者某种依赖的条件总是不满足，那么线程一直在繁忙却没有任何结果。</p>
<p>错误的循环引用和判断也有可能导致活锁。当某些条件总是不能满足的时候，可能陷入死循环的境地。</p>
<p>线程间的协同也有可能导致活锁。例如如果两个线程发生了某些条件的碰撞后重新执行，那么如果再次尝试后依然发生了碰撞，长此下去就有可能发生活锁。</p>
<p>解决活锁的一种方案是对重试机制引入一些随机性。例如如果检测到冲突，那么就暂停随机的一定时间进行重试。这回大大减少碰撞的可能性。</p>
<p>另外为了避免可能的死锁，适当加入一定的重试次数也是有效的解决办法。尽管这在业务上会引起一些复杂的逻辑处理。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/12/29/365149.html](http://www.blogjava.net/xylz/archive/2011/12/29/365149.html)">[http://www.blogjava.net/xylz/archive/2011/12/29/365149.html](http://www.blogjava.net/xylz/archive/2011/12/29/365149.html)</a> </p>
<h1 id="-">常见的并发场景</h1>
<h2 id="-">线程池</h2>
<p>并发最常见用于线程池，显然使用线程池可以有效的提高吞吐量。</p>
<p>最常见、比较复杂一个场景是Web容器的线程池。Web容器使用线程池同步或者异步处理HTTP请求，同时这也可以有效的复用HTTP连接，降低资源申请的开销。通常我们认为HTTP请求时非常昂贵的，并且也是比较耗费资源和性能的，所以线程池在这里就扮演了非常重要的角色。</p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2010/12/19/341098.html" target="_blank">线程池</a>的章节中非常详细的讨论了线程池的原理和使用，同时也提到了，线程池的配置和参数对性能的影响是巨大的。不尽如此，受限于资源（机器的性能、网络的带宽等等）、依赖的服务，客户端的响应速度等，线程池的威力也不会一直增长。达到了线程池的瓶颈后，性能和吞吐量都会大幅度降低。</p>
<p>一直增加机器的性能或者增大线程的个数，并不一定能有效的提高吞吐量。高并发的情况下，机器的负载会大幅提升，这时候机器的稳定性、服务的可靠性都会下降。</p>
<p>尽管如此，线程池依然是提高吞吐量的一个有效措施，配合合适的参数能够有效的充分利用资源，提高资源的利用率。</p>
<h2 id="-">任务队列</h2>
<p>除了线程池是比较发杂的并发场景外，<a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">任务队列</a>也是一个不错的并发工具。JDK内部有大量的队列（Queue),这些工具不仅能够方便使用，提高生产力，也能够进行组合适应于不同的场景。即使线程池内部，也是用了任务队列来处理任务的积压，平衡资源的消耗。</p>
<p>安全的任务队列能够有效的平衡机器的复杂，抵消由于峰值和波动带来的不稳定，有效提高服务的可靠性。同时任务队列的处理也有助于统计和分析服务的状况。</p>
<p>任务队列也可以在多个线程之间传递数据，有助于并行处理任务。例如经典的“生产者-消费者”模型就可以有效的提高多个线程的并行处理能力。在IO延时比较大的服务中尤其有效。 我最喜欢的一个案例是导数据是，一个线程负责往固定大小的任务队列中压入大量的数据，队列满了以后就暂停，另外几个线程负责从任务队列中获取数据并消费。这将串行的“生产-消费”，变成了并行的“生产-消费”。实践证明极大的节省任务处理时间。</p>
<h2 id="-">异步处理</h2>
<p>线程池也是异步处理的一种表现形式，除此之外，使用异步处理的目的也是为了提高服务的处理速度。 例如AOP的一个例子就是使用切面来记录日志，如果说我们要远程收集日志，显然不希望由于收集日志而影响服务本身。这时候就将日志收集的过程进行异步处理。</p>
<p>如今大量的开源组件都喜欢使用异步处理来提高IO的效率，某些不需要同步返回的操作使用异步处理后能够有效的提高吞吐量。</p>
<p>当然，异步也不总是令人满意的，也会有相应的问题。例如引入异步设计后的复杂性，线程中断后的处理机制，失败后的处理策略，产生的消息比消费的还快时怎么办，关闭程序时如何关闭异步处理逻辑等等。这都会增加系统的复杂性。</p>
<p>尽管大量的服务、业务使用异步来处理，但是很显然需要有保障机制能够保证异步处理的逻辑正确性。如果认为异步处理的任务不是特别重要，或者说主业务不能因为附属业务的逻辑出错而崩溃，那么使用异步处理是正确的选择。</p>
<h2 id="-">同步操作</h2>
<p>并发操作的同时还需要维护数据的一致性，或多或少的会涉及到同步操作。正确的使用原子操作，合理的使用独占锁和读写锁也是一个很大的挑战。</p>
<p>线程间的协调与通信，尤其是状态的同步都是比较困难的。我们看到线程池<a href="http://www.blogjava.net/xylz/archive/2011/01/18/343183.html" target="_blank">ThreadPoolExecutor</a>的实现为了解决各个线程的执行状态，引入的很多的同步操作。线程越来越多的情况下，同步的成本会越来越高，同时也有可能引入死锁的情况。</p>
<p>尽管如此，单个JVM内部的多线程同步还是比较容易控制的。JDK内部也提供了大量的工具来方便完成数据的同步。例如<a href="http://www.blogjava.net/xylz/archive/2010/07/05/325274.html" target="_blank">Lock</a>/<a href="http://www.blogjava.net/xylz/archive/2010/07/08/325540.html" target="_blank">Condition</a>/<a href="http://www.blogjava.net/xylz/archive/2010/07/09/325612.html" target="_blank">CountDownLatch</a>/<a href="http://www.blogjava.net/xylz/archive/2010/07/12/325913.html" target="_blank">CyclicBarrier</a>/<a href="http://www.blogjava.net/xylz/archive/2010/07/13/326021.html" target="_blank">Semaphore</a>/<a href="http://www.blogjava.net/xylz/archive/2010/11/22/338733.html" target="_blank">Exchanger</a>等等。</p>
<h2 id="-">分布式锁</h2>
<p>分布式的并发问题更难以处理，根据<a href="http://en.wikipedia.org/wiki/CAP_theorem" target="_blank">CAP</a>的原理，基本上没有一个至善至美的方案。 分布式资源协调使用分布式锁是一个不错的选择。<a href="http://blog.nosqlfan.com/html/1038.html" target="_blank">Google的分布式锁</a>（建立在BigTable之上），<a href="http://zookeeper.apache.org/doc/r3.3.2/zookeeperOver.html" target="_blank">Zookeeper的分布式锁</a>，甚至简单的利用<a href="http://memcached.org/" target="_blank">memcache</a>的add操作或者<a href="http://redis.io/" target="_blank">redis</a>的setnx操作建立伪分布式锁也可以解决类似的问题。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/12/29/367480.html](http://www.blogjava.net/xylz/archive/2011/12/29/367480.html)">[http://www.blogjava.net/xylz/archive/2011/12/29/367480.html](http://www.blogjava.net/xylz/archive/2011/12/29/367480.html)</a> </p>
<h1 id="-">常见的并发陷阱</h1>
<h2 id="volatile">volatile</h2>
<p>volatile只能强调数据的可见性，并不能保证原子操作和线程安全，因此volatile不是万能的。参考<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">指令重排序</a></p>
<p>volatile最常见于下面两种场景。</p>
<p>a. 循环检测机制
volatile boolean done = false;
<img src="" alt="">
    while( ! done ){
        dosomething();
    }</p>
<p>b. 单例模型 （<a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html%ef%bc%89" target="_blank"><a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html）">http://www.blogjava.net/xylz/archive/2009/12/18/306622.html）</a>
</a></p>
<p><a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html%ef%bc%89">public class DoubleLockSingleton {
    private static volatile DoubleLockSingleton instance = null;
    private DoubleLockSingleton() {
    }
    public static DoubleLockSingleton getInstance() {
        if (instance == null) {
            synchronized (DoubleLockSingleton.class) {
                if (instance == null) {
                    instance = new DoubleLockSingleton();
                }
            }
        }
        return instance;
    }
}</a></p>
<h2 id="synchronized-lock">synchronized/Lock</h2>
<p>看起来Lock有更好的性能以及更灵活的控制，是否完全可以替换synchronized？</p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2010/07/16/326246.html" target="_blank">锁的一些其它问题</a>中说过，synchronized的性能随着JDK版本的升级会越来越高，而Lock优化的空间受限于CPU的性能，很有限。另外JDK内部的工具（线程转储）对synchronized是有一些支持的（方便发现死锁等），而对Lock是没有任何支持的。</p>
<p>也就说简单的逻辑使用synchronized完全没有问题，随着机器的性能的提高，这点开销是可以忽略的。而且从代码结构上讲是更简单的。简单就是美。</p>
<p>对于复杂的逻辑，如果涉及到读写锁、条件变量、更高的吞吐量以及更灵活、动态的用法，那么就可以考虑使用Lock。当然这里尤其需要注意Lock的正确用法。
Lock lock = <img src="" alt="">
lock.lock();
try{
    //do something
}finally{
    lock.unlock();
}</p>
<p>一定要将Lock的释放放入finally块中，否则一旦发生异常或者逻辑跳转，很有可能会导致锁没有释放，从而发生死锁。而且这种死锁是难以排查的。</p>
<p>如果需要synchronized无法做到的尝试锁机制，或者说担心发生死锁无法自恢复，那么使用tryLock()是一个比较明智的选择的。
Lock lock = <img src="" alt="">
if(lock.tryLock()){
    try{
        //do something
    }finally{
        lock.unlock();
    }
}</p>
<p>甚至可以使用获取锁一段时间内超时的机制Lock.tryLock(long,TimeUnit)。 锁的使用可以参考前面文章的描述和建议。</p>
<h2 id="-">锁的边界</h2>
<p>一个流行的错误是这样的。
ConcurrentMap<String,String> map = new ConcurrentHashMap<String,String>();
if(!map.containsKey(key)){
    map.put(key,value);
}</p>
<p>看起来很合理的，对于一个线程安全的Map实现，要存取一个不重复的结果，先检测是否存在然后加入。 其实我们知道两个原子操作和在一起的指令序列不代表就是线程安全的。 割裂的多个原子操作放在一起在多线程的情况下就有可能发生错误。</p>
<p>实际上ConcurrentMap提供了putIfAbsent(K, V)的“原子操作”机制，这等价于下面的逻辑：
if(map.containsKey(key)){
    return map.get(key);
}else{
    return map.put(k,v);
}</p>
<p>除了putIfAbsent还有replace(K, V)以及replace(K, V, V)两种机制来完成组合的操作。</p>
<p>提到Map，这里有一篇谈<a href="http://www.blogjava.net/xylz/archive/2009/12/18/306602.html" target="_blank">HashMap读写并发</a>的问题。</p>
<h2 id="-">构造函数启动线程</h2>
<p>下面的实例是在构造函数中启动一个线程。
public class Runner{
   int x,y;
   Thread thread;
   public Runner(){
      this.x=1;
      this.y=2;
      this.thread=new MyThread();
      this.thread.start();
   }
}</p>
<p>这里可能存在的陷阱是如果此类被继承，那么启动的线程可能无法正确读取子类的初始化操作。</p>
<p>因此一个简单的原则是，禁止在构造函数中启动线程，可以考虑但是提供一个方法来启动线程。如果非要这么做，最好将类设置为final，禁止继承。</p>
<h2 id="-">丢失通知的问题</h2>
<p><a href="http://www.blogjava.net/xylz/archive/2011/09/05/326988.html" target="_blank">这篇文章</a>里面提到过notify丢失通知的问题。</p>
<p>对于wait/notify/notifyAll以及await/singal/singalAll，如果不确定到底是否能够正确的收到消息，担心丢失通知，简单一点就是总是通知所有。</p>
<p>如果担心只收到一次消息，使用循环一直监听是不错的选择。</p>
<p>非常主用性能的系统，可能就需要区分到底是通知单个还是通知所有的挂起者。</p>
<h2 id="-">线程数</h2>
<p>并不是线程数越多越好，在下一篇文章里面会具体了解下性能和可伸缩性。 简单的说，线程数多少没有一个固定的结论，受限于CPU的内核数，IO的性能以及依赖的服务等等。因此选择一个合适的线程数有助于提高吞吐量。</p>
<p>对于CPU密集型应用，线程数和CPU的内核数一致有助于提高吞吐量，所有CPU都很繁忙，效率就很高。 对于IO密集型应用，线程数受限于IO的性能，某些时候单线程可能比多线程效率更高。但通常情况下适当提高线程数，有利于提高网络IO的效率，因为我们总是认为网络IO的效率比较低。</p>
<p>对于线程池而言，选择合适的线程数以及任务队列是提高线程池效率的手段。
public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    long keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler)</p>
<p>对于线程池来说，如果任务总是有积压，那么可以适当提高corePoolSize大小；如果机器负载较低，那么可以适当提高maximumPoolSize的大小；任务队列不长的情况下减小keepAliveTime的时间有助于降低负载；另外任务队列的长度以及任务队列的<a href="http://www.blogjava.net/xylz/archive/2011/01/18/343183.html" target="_blank">拒绝策略</a>也会对任务的处理有一些影响。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/12/30/367592.html](http://www.blogjava.net/xylz/archive/2011/12/30/367592.html)">[http://www.blogjava.net/xylz/archive/2011/12/30/367592.html](http://www.blogjava.net/xylz/archive/2011/12/30/367592.html)</a> </p>
<h1 id="-">性能与伸缩性</h1>
<p>使用线程的一种说法是为了提高性能。多线程可以使程序充分利用闲置的资源，提高资源的利用率，同时能够并行处理任务，提高系统的响应性。 但是很显然，引入线程的同时也引入了系统的复杂性。另外系统的性能并不是总是随着线程数的增加而总是提高。</p>
<h2 id="-">性能与伸缩性</h2>
<p>性能的提升通常意味着可以用更少的资源做更多的事情。这里资源是包括我们常说的CPU周期、内存、网络带宽、磁盘IO、数据库、WEB服务等等。 引入多线程可以充分利用多核的优势，充分利用IO阻塞带来的延迟，也可以降低网络开销带来的影响，从而提高单位时间内的响应效率。</p>
<p>为了提高性能，需要有效的利用我们现有的处理资源，同时也要开拓新的可用资源。例如，对于CPU而言，理想状况下希望CPU能够满负荷工作。当然这里满负荷工作是指做有用的事情，而不是无谓的死循环或者等待。受限于CPU的计算能力，如果CPU达到了极限，那么很显然我们充分利用了计算能力。对于IO而言（内存、磁盘、网络等），如果达到了其对于的带宽，这些资源的利用率也就上去了。理想状况下所有资源的能力都被用完了，那么这个系统的性能达到了最大值。</p>
<p>为了衡量系统的性能，有一些指标用于定性、定量的分析。例如服务时间、等待时间、吞吐量、效率、可伸缩性、生成量等等。服务时间、等待时间等用于衡量系统的效率，即到底有多快。吞吐量、生成量等用于衡量系统的容量，即能够处理多少数据。除此之外，有效服务时间、中断时间等用于能力系统的可靠性和稳定性等。</p>
<p>可伸缩性的意思是指增加计算资源，吞吐量和生产量相应得到的改进。 从算法的角度讲，通常用复杂度来衡量其对应的性能。例如时间复杂度、空间复杂度等。</p>
<h2 id="amdahl-">Amdahl定律</h2>
<p>并行的任务增加资源显然能够提高性能，但是如果是串行的任务，增加资源并不一定能够得到合理的性能提升。 <a href="http://en.wikipedia.org/wiki/Amdahl%27s_law" target="_blank">Amdahl定律</a>描述的在一个系统中，增加处理器资源对系统行的提升比率。 假定在一个系统中，F是必须串行化执行的比重，N是处理器资源，那么随着N的增加最多增加的加速比：
<img src="" alt=""></p>
<p>理论上，当N趋近于无穷大时，加速比最大值无限趋近于1/F。 这意味着如果一个程序的串行化比重为50%，那么并行化后最大加速比为2倍。</p>
<p>加速比除了可以用于加速的比率外，也可以用于衡量CPU资源的利用率。如果每一个CPU的资源利用率为100%，那么CPU的资源每次翻倍时，加速比也应该翻倍。 事实上，在拥有10个处理器的系统中，程序如果有10%是串行化的，那么最多可以加速1/(0.1+(1-0.1)/10)=5.3倍，换句话说CPU的利用率只用5.3/10=53%。而如果处理器增加到100倍，那么加速比为9.2倍，也就是说CPU的利用率只有个9.3%。</p>
<p>显然增加CPU的数量并不能提高CPU的利用率。下图描述的是随着CPU的数量增加，不同串行化比重的系统的加速比。
<img src="" alt=""></p>
<p>很显然，串行比重越大，增加CPU资源的效果越不明显。</p>
<h2 id="-">性能提升</h2>
<p>性能的提升可以从以下几个方面入手。</p>
<h3 id="-">系统平台的资源利用率</h3>
<p>一个程序对系统平台的资源利用率是指某一个设备繁忙且服务于此程序的时间占所有时间的比率。从物理学的角度讲类似于有用功的比率。简单的说就是：资源利用率=有效繁忙时间/总耗费时间。</p>
<p>也就说尽可能的让设备做有用的功，同时榨取其最大值。无用的循环可能会导致CPU 100%的使用率，但不一定是有效的工作。有效性通常难以衡量，通常只能以主观来评估，或者通过被优化的程序的行为来判断是否提高了有效性。</p>
<h3 id="-">延迟</h3>
<p>延迟描述的是完成任务所耗费的时间。延迟有时候也成为响应时间。如果有多个并行的操作，那么延迟取决于耗费时间最大的任务。</p>
<h3 id="-">多处理</h3>
<p>多处理是指在单一系统上同时执行多个进程或者多个程序的能力。多处理能力的好处是可以提高吞吐量。多处理可以有效利用多核CPU的资源。</p>
<h3 id="-">多线程</h3>
<p>多线程描述的是同一个地址空间内同时执行多个线程的过程。这些线程都有不同的执行路径和不同的栈结构。我们说的并发性更多的是指针对线程。</p>
<h3 id="-">并发性</h3>
<p>同时执行多个程序或者任务称之为并发。单程序内的多任务处理或者多程序间的多任务处理都认为是并发。</p>
<h3 id="-">吞吐量</h3>
<p>吞吐量衡量系统在单位之间内可以完成的工作总量。对于硬件系统而言，吞吐量是物理介质的上限。在没有达到物理介质之前，提高系统的吞吐量也可以大幅度改进性能。同时吞吐量也是衡量性能的一个指标。</p>
<h3 id="-">瓶颈</h3>
<p>程序运行过程中性能最差的地方。通常而言，串行的IO、磁盘IO、内存单元分配、网络IO等都可能造成瓶颈。某些使用太频繁的算法也有可能成为瓶颈。</p>
<h3 id="-">可扩展性</h3>
<p>这里的可扩展性主要是指程序或系统通过增加可使用的资源而增加性能的能力。</p>
<h2 id="-">线程开销</h2>
<p>假设引入的多线程都用于计算，那么性能一定会有很大的提升么？ 其实引入多线程以后也会引入更多的开销。</p>
<h3 id="-">切换上下文</h3>
<p>如果可运行的线程数大于CPU的内核数，那么OS会根据一定的调度算法，强行切换正在运行的线程，从而使其它线程能够使用CPU周期。</p>
<p>切换线程会导致上下文切换。线程的调度会导致CPU需要在操作系统和进程间花费更多的时间片段，这样真正执行应用程序的时间就减少了。另外上下文切换也会导致缓存的频繁进出，对于一个刚被切换的线程来说，可能由于高速缓冲中没有数据而变得更慢，从而导致更多的IO开销。</p>
<h3 id="-">内存同步</h3>
<p>不同线程间要进行数据同步，synchronized以及volatile提供的可见性都会导致缓存失效。线程栈之间的数据要和主存进行同步，这些同步有一些小小的开销。如果线程间同时要进行数据同步，那么这些同步的线程可能都会受阻。</p>
<h3 id="-">阻塞</h3>
<p>当发生锁竞争时，失败的线程会导致阻塞。通常阻塞的线程可能在JVM内部进行自旋等待，或者被操作系统挂起。自旋等待可能会导致更多的CPU切片浪费，而操作系统挂起则会导致更多的上下文切换。</p>
<p>了解了性能的提升的几个方面，也了解性能的开销后，应用程序就要根据实际的场景进行取舍和评估。没有一劳永逸的优化方案，不断的进行小范围改进和调整是提高性能的有效手段。当前一些大的架构调整也会导致较大的性能的提升。</p>
<p>简单的原则是在保证逻辑正确的情况小，找到性能瓶颈，小步改进和优化。</p>
<h2 id="-">参考资料</h2>
<ul>
<li>Amdahl&#39;s law: <a href="http://en.wikipedia.org/wiki/Amdahl%27s_law" target="_blank"><a href="http://en.wikipedia.org/wiki/Amdahl%27s_law">http://en.wikipedia.org/wiki/Amdahl%27s_law</a></a></li>
<li>Gustafson&#39;s law: <a href="http://en.wikipedia.org/wiki/Gustafson%27s_law" target="_blank"><a href="http://en.wikipedia.org/wiki/Gustafson%27s_law">http://en.wikipedia.org/wiki/Gustafson%27s_law</a></a></li>
<li>Sun-Ni law: <a href="http://en.wikipedia.org/wiki/Sun-Ni_law" target="_blank"><a href="http://en.wikipedia.org/wiki/Sun-Ni_law">http://en.wikipedia.org/wiki/Sun-Ni_law</a></a></li>
<li>多核系统中三种典型锁竞争的加速比分析 <a href="http://blog.csdn.net/drzhouweiming/article/details/1800319" target="_blank"><a href="http://blog.csdn.net/drzhouweiming/article/details/1800319">http://blog.csdn.net/drzhouweiming/article/details/1800319</a></a></li>
<li>阿姆达尔定律和Gustafson定律的等价性 <a href="http://book.51cto.com/art/201004/197506.htm" target="_blank"><a href="http://book.51cto.com/art/201004/197506.htm">http://book.51cto.com/art/201004/197506.htm</a></a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/12/31/367641.html](http://www.blogjava.net/xylz/archive/2011/12/31/367641.html)">[http://www.blogjava.net/xylz/archive/2011/12/31/367641.html](http://www.blogjava.net/xylz/archive/2011/12/31/367641.html)</a> </li>
</ul>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency37-并发总结/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency37-并发总结" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency28-线程池/">深入浅出 Java Concurrency (28)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency28-线程池/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-28-">深入浅出 Java Concurrency (28): 线程池</h1>
<p><a href="http://www.blogjava.net/xylz/archive/2010/12/19/341098.html" target="_blank"> 简介</a></p>
<p>从这一节开始正式进入线程池的部分。其实整个体系已经拖了很长的时间，因此后面的章节会加快速度，甚至只是一个半成品或者简单化，以后有时间的慢慢补充、完善。</p>
<p>其实线程池是并发包里面很重要的一部分，在实际情况中也是使用很多的一个重要组件。</p>
<p>下图描述的是线程池API的一部分。广义上的完整线程池可能还包括Thread/Runnable、Timer/TimerTask等部分。这里只介绍主要的和高级的API以及架构和原理。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-part-1-_8E6F/ThreadPool2_2.png" target="_blank"><img src="&quot;ThreadPool2&quot;" alt="ThreadPool2"></a></p>
<p>大多数并发应用程序是围绕执行任务（Task）进行管理的。所谓任务就是抽象、离散的工作单元（unit of work）。把一个应用程序的工作（work）分离到任务中，可以简化程序的管理；这种分离还在不同事物间划分了自然的分界线，可以方便程序在出现错误时进行恢复；同时这种分离还可以为并行工作提供一个自然的结构，有利于提高程序的并发性。<a href="http://www.blogjava.net/xylz/archive/2010/12/19/341098.html#jcp" target="_blank">[1]</a></p>
<p>并发执行任务的一个很重要前提是拆分任务。把一个大的过程或者任务拆分成很多小的工作单元，每一个工作单元可能相关、也可能无关，这些单元在一定程度上可以充分利用CPU的特性并发的执行，从而提高并发性（性能、响应时间、吞吐量等）。</p>
<p>所谓的任务拆分就是确定每一个执行任务（工作单元）的边界。理想情况下独立的工作单元有最大的吞吐量，这些工作单元不依赖于其它工作单元的状态、结果或者其他资源等。因此将任务尽可能的拆分成一个个独立的工作单元有利于提高程序的并发性。</p>
<p>对于有依赖关系以及资源竞争的工作单元就涉及到任务的调度和负载均衡。工作单元的状态、结果或者其他资源等有关联的工作单元就需要有一个总体的调度者来协调资源和执行顺序。同样在有限的资源情况下，大量的任务也需要一个协调各个工作单元的调度者。这就涉及到任务执行的策略问题。</p>
<p>任务的执行策略包括4W3H部分：</p>
<ul>
<li>任务在什么（What）线程中执行</li>
<li>任务以什么（What）顺序执行（FIFO/LIFO/优先级等）</li>
<li>同时有多少个（How Many）任务并发执行</li>
<li>允许有多少个（How Many）个任务进入执行队列</li>
<li>系统过载时选择放弃哪一个（Which）任务，如何（How）通知应用程序这个动作</li>
<li>任务执行的开始、结束应该做什么（What）处理</li>
</ul>
<p>在后面的章节中会详细分写这些策略是如何实现的。我们先来简单回答些如何满足上面的条件。</p>
<ol>
<li>首先明确一定是在Java里面可以供使用者调用的启动线程类是Thread。因此Runnable或者Timer/TimerTask等都是要依赖Thread来启动的，因此在ThreadPool里面同样也是靠Thread来启动多线程的。</li>
<li>默认情况下Runnable接口执行完毕后是不能拿到执行结果的，因此在ThreadPool里就定义了一个Callable接口来处理执行结果。</li>
<li>为了异步阻塞的获取结果，Future可以帮助调用线程获取执行结果。</li>
<li>Executor解决了向线程池提交任务的入口问题，同时ScheduledExecutorService解决了如何进行重复调用任务的问题。</li>
<li>CompletionService解决了如何按照执行完毕的顺序获取结果的问题，这在某些情况下可以提高任务执行的并发，调用线程不必在长时间任务上等待过多时间。</li>
<li>显然线程的数量是有限的，而且也不宜过多，因此合适的任务队列是必不可少的，BlockingQueue的容量正好可以解决此问题。</li>
<li>固定任务容量就意味着在容量满了以后需要一定的策略来处理过多的任务（新任务），RejectedExecutionHandler正好解决此问题。</li>
<li>一定时间内阻塞就意味着有超时，因此TimeoutException就是为了描述这种现象。TimeUnit是为了描述超时时间方便的一个时间单元枚举类。</li>
<li>有上述问题就意味了配置一个合适的线程池是很复杂的，因此Executors默认的一些线程池配置可以减少这个操作。</li>
</ol>
<p>线程池的基本策略大致就这些，从下一节开始就从线程池的基本原理和执行方法开始描述。</p>
<p><a href="">[1] Java Concurrency in Practice</a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/12/19/341098.html](http://www.blogjava.net/xylz/archive/2010/12/19/341098.html)">[http://www.blogjava.net/xylz/archive/2010/12/19/341098.html](http://www.blogjava.net/xylz/archive/2010/12/19/341098.html)</a> <a href="http://www.blogjava.net/xylz/archive/2010/12/21/341281.html" target="_blank">Executor 以及Executors</a>
Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。</p>
<p>下面这张图完整描述了线程池的类体系结构。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-28--part-1-_1302E/Executor-class_2.png" target="_blank"><img src="&quot;Executor-class&quot;" alt="Executor-class"></a></p>
<p>首先Executor的execute方法只是执行一个Runnable的任务，当然了从某种角度上将最后的实现类也是在线程中启动此任务的。根据线程池的执行策略最后这个任务可能在新的线程中执行，或者线程池中的某个线程，甚至是调用者线程中执行（相当于直接运行Runnable的run方法）。这点在后面会详细说明。</p>
<p>ExecutorService在Executor的基础上增加了一些方法，其中有两个核心的方法：</p>
<ul>
<li>Future&lt;?&gt; submit(Runnable task)</li>
<li><T> Future<T> submit(Callable<T> task)</li>
</ul>
<p>这两个方法都是向线程池中提交任务，它们的区别在于Runnable在执行完毕后没有结果，Callable执行完毕后有一个结果。这在多个线程中传递状态和结果是非常有用的。另外他们的相同点在于都返回一个Future对象。Future对象可以阻塞线程直到运行完毕（获取结果，如果有的话），也可以取消任务执行，当然也能够检测任务是否被取消或者是否执行完毕。</p>
<p>在没有Future之前我们检测一个线程是否执行完毕通常使用Thread.join()或者用一个死循环加状态位来描述线程执行完毕。现在有了更好的方法能够阻塞线程，检测任务执行完毕甚至取消执行中或者未开始执行的任务。</p>
<p>ScheduledExecutorService描述的功能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。这包括延迟时间一次性执行、延迟时间周期性执行以及固定延迟时间周期性执行等。当然了继承ExecutorService的ScheduledExecutorService拥有ExecutorService的全部特性。</p>
<p>ThreadPoolExecutor是ExecutorService的默认实现，其中的配置、策略也是比较复杂的，在后面的章节中会有详细的分析。</p>
<p>ScheduledThreadPoolExecutor是继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现，在后面的章节中会有详细的分析。</p>
<p>这里需要稍微提一下的是CompletionService接口，它是用于描述顺序获取执行结果的一个线程池包装器。它依赖一个具体的线程池调度，但是能够根据任务的执行先后顺序得到执行结果，这在某些情况下可能提高并发效率。</p>
<p>要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。</p>
<ul>
<li><strong>newSingleThreadExecutor</strong>：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。</li>
<li><strong>newFixedThreadPool</strong>：创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。</li>
<li><strong>newCachedThreadPool</strong>：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。</li>
<li><strong>newScheduledThreadPool</strong>：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。</li>
<li><strong>newSingleThreadScheduledExecutor</strong>：创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。</li>
</ul>
<p>在详细讲解ThreadPoolExecutor的时候会具体讨论上述参数配置后的意义和原理。</p>
<p>线程池是一个复杂的任务调度工具，因此它涉及到任务、线程池等的生命周期问题，在下一节中来探讨下这个问题。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/12/21/341281.html](http://www.blogjava.net/xylz/archive/2010/12/21/341281.html)">[http://www.blogjava.net/xylz/archive/2010/12/21/341281.html](http://www.blogjava.net/xylz/archive/2010/12/21/341281.html)</a> <a href="http://www.blogjava.net/xylz/archive/2011/01/04/342316.html" target="_blank">Executor 生命周期</a></p>
<p>我们知道线程是有多种执行状态的，同样管理线程的线程池也有多种状态。JVM会在所有线程（非后台daemon线程）全部终止后才退出，为了节省资源和有效释放资源关闭一个线程池就显得很重要。有时候无法正确的关闭线程池，将会阻止JVM的结束。</p>
<p>线程池Executor是异步的执行任务，因此任何时刻不能够直接获取提交的任务的状态。这些任务有可能已经完成，也有可能正在执行或者还在排队等待执行。因此关闭线程池可能出现一下几种情况：</p>
<ul>
<li>平缓关闭：已经启动的任务全部执行完毕，同时不再接受新的任务</li>
<li>立即关闭：取消所有正在执行和未执行的任务</li>
</ul>
<p>另外关闭线程池后对于任务的状态应该有相应的反馈信息。</p>
<p>图1 描述了线程池的4种状态。</p>
<ul>
<li>线程池在构造前（new操作）是初始状态，一旦构造完成线程池就进入了执行状态RUNNING。严格意义上讲线程池构造完成后并没有线程被立即启动，只有进行“预启动”或者接收到任务的时候才会启动线程。这个会后面线程池的原理会详细分析。但是线程池是出于运行状态，随时准备接受任务来执行。</li>
<li>线程池运行中可以通过shutdown()和shutdownNow()来改变运行状态。shutdown()是一个平缓的关闭过程，线程池停止接受新的任务，同时等待已经提交的任务执行完毕，包括那些进入队列还没有开始的任务，这时候线程池处于SHUTDOWN状态；shutdownNow()是一个立即关闭过程，线程池停止接受新的任务，同时线程池取消所有执行的任务和已经进入队列但是还没有执行的任务，这时候线程池处于STOP状态。</li>
<li>一旦shutdown()或者shutdownNow()执行完毕，线程池就进入TERMINATED状态，此时线程池就结束了。</li>
<li>isTerminating()描述的是SHUTDOWN和STOP两种状态。</li>
<li>isShutdown()描述的是非RUNNING状态，也就是SHUTDOWN/STOP/TERMINATED三种状态。</li>
</ul>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-part-3-Executor-_12486/Executor-Lifecycle_4.png" target="_blank"><img src="&quot;Executor-Lifecycle&quot;" alt="Executor-Lifecycle"></a></p>
<p>图1</p>
<p>线程池的API如下：</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-part-3-Executor-_12486/ExecutorService-LifeCycle_2.png" target="_blank"><img src="&quot;ExecutorService-LifeCycle&quot;" alt="ExecutorService-LifeCycle"></a></p>
<p>图2</p>
<p>其中shutdownNow()会返回那些已经进入了队列但是还没有执行的任务列表。awaitTermination描述的是等待线程池关闭的时间，如果等待时间线程池还没有关闭将会抛出一个超时异常。</p>
<p>对于关闭线程池期间发生的任务提交情况就会触发一个拒绝执行的操作。这是java.util.concurrent.RejectedExecutionHandler描述的任务操作。下一个小结中将描述这些任务被拒绝后的操作。</p>
<p>总结下这个小节：</p>
<ol>
<li>线程池有运行、关闭、停止、结束四种状态，结束后就会释放所有资源</li>
<li>平缓关闭线程池使用shutdown()</li>
<li>立即关闭线程池使用shutdownNow()，同时得到未执行的任务列表</li>
<li>检测线程池是否正处于关闭中，使用isShutdown()</li>
<li>检测线程池是否已经关闭使用isTerminated()</li>
<li>定时或者永久等待线程池关闭结束使用awaitTermination()操作</li>
</ol>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2011/01/04/342316.html](http://www.blogjava.net/xylz/archive/2011/01/04/342316.html)">[http://www.blogjava.net/xylz/archive/2011/01/04/342316.html](http://www.blogjava.net/xylz/archive/2011/01/04/342316.html)</a></p>
<p><strong>线程池数据结构与线程构造方法</strong></p>
<p>由于已经看到了ThreadPoolExecutor的源码，因此很容易就看到了ThreadPoolExecutor线程池的数据结构。图1描述了这种数据结构。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-32--part-5-_72AF/ThreadPoolExecutor_2.png" target="_blank"><img src="&quot;ThreadPoolExecutor&quot;" alt="ThreadPoolExecutor"></a></p>
<p>图1 ThreadPoolExecutor 数据结构</p>
<p>其实，即使没有上述图形描述ThreadPoolExecutor的数据结构，我们根据线程池的要求也很能够猜测出其数据结构出来。</p>
<ul>
<li>线程池需要支持多个线程并发执行，因此有一个线程集合Collection<Thread>来执行线程任务；</li>
<li>涉及任务的异步执行，因此需要有一个集合来缓存任务队列Collection<Runnable>；</li>
<li>很显然在多个线程之间协调多个任务，那么就需要一个线程安全的任务集合，同时还需要支持阻塞、超时操作，那么BlockingQueue是必不可少的；</li>
<li>既然是线程池，出发点就是提高系统性能同时降低资源消耗，那么线程池的大小就有限制，因此需要有一个核心线程池大小（线程个数）和一个最大线程池大小（线程个数），有一个计数用来描述当前线程池大小；</li>
<li>如果是有限的线程池大小，那么长时间不使用的线程资源就应该销毁掉，这样就需要一个线程空闲时间的计数来描述线程何时被销毁；</li>
<li>前面描述过线程池也是有生命周期的，因此需要有一个状态来描述线程池当前的运行状态；</li>
<li>线程池的任务队列如果有边界，那么就需要有一个任务拒绝策略来处理过多的任务，同时在线程池的销毁阶段也需要有一个任务拒绝策略来处理新加入的任务；</li>
<li>上面种的线程池大小、线程空闲实际那、线程池运行状态等等状态改变都不是线程安全的，因此需要有一个全局的锁（mainLock）来协调这些竞争资源；</li>
<li>除了以上数据结构以外，ThreadPoolExecutor还有一些状态用来描述线程池的运行计数，例如线程池运行的任务数、曾经达到的最大线程数，主要用于调试和性能分析。</li>
</ul>
<p>对于ThreadPoolExecutor而言，一个线程就是一个Worker对象，它与一个线程绑定，当Worker执行完毕就是线程执行完毕，这个在后面详细讨论线程池中线程的运行方式。</p>
<p>既然是线程池，那么就首先研究下线程的构造方法。
public interface ThreadFactory {
    Thread newThread(Runnable r);
}</p>
<p>ThreadPoolExecutor使用一个线程工厂来构造线程。线程池都是提交一个任务Runnable，然后在某一个线程Thread中执行，ThreadFactory 负责如何创建一个新线程。</p>
<p>在J.U.C中有一个通用的线程工厂java.util.concurrent.Executors.DefaultThreadFactory，它的构造方式如下：
static class DefaultThreadFactory implements ThreadFactory {
    static final AtomicInteger poolNumber = new AtomicInteger(1);
    final ThreadGroup group;
    final AtomicInteger threadNumber = new AtomicInteger(1);
    final String namePrefix;
    DefaultThreadFactory() {
        SecurityManager s = System.getSecurityManager();
        group = (s != null)? s.getThreadGroup() :
                             Thread.currentThread().getThreadGroup();
        namePrefix = &quot;pool-&quot; +
                      poolNumber.getAndIncrement() +
                     &quot;-thread-&quot;;
    }
    public Thread newThread(Runnable r) {
        Thread t = new Thread(group, r,
                              namePrefix + threadNumber.getAndIncrement(),
                              0);
        if (t.isDaemon())
            t.setDaemon(false);
        if (t.getPriority() != Thread.NORM_PRIORITY)
            t.setPriority(Thread.NORM_PRIORITY);
        return t;
    }
}</p>
<p>在这个线程工厂中，同一个线程池的所有线程属于同一个线程组，也就是创建线程池的那个线程组，同时线程池的名称都是“pool-<poolNum>-thread-<threadNum>”，其中poolNum是线程池的数量序号，threadNum是此线程池中的线程数量序号。这样如果使用jstack的话很容易就看到了系统中线程池的数量和线程池中线程的数量。另外对于线程池中的所有线程默认都转换为非后台线程，这样主线程退出时不会直接退出JVM，而是等待线程池结束。还有一点就是默认将线程池中的所有线程都调为同一个级别，这样在操作系统角度来看所有系统都是公平的，不会导致竞争堆积。</p>
<p><strong>线程池中线程生命周期</strong></p>
<p>一个线程Worker被构造出来以后就开始处于运行状态。以下是一个线程执行的简版逻辑。
private final class Worker implements Runnable {
    private final ReentrantLock runLock = new ReentrantLock();
    private Runnable firstTask;
    Thread thread;
    Worker(Runnable firstTask) {
        this.firstTask = firstTask;
    }
    private void runTask(Runnable task) {
        final ReentrantLock runLock = this.runLock;
        runLock.lock();
        try {
           task.run();
        } finally {
            runLock.unlock();
        }
    }
    public void run() {
        try {
            Runnable task = firstTask;
            firstTask = null;
            while (task != null || (task = getTask()) != null) {
                runTask(task);
                task = null;
            }
        } finally {
            workerDone(this);
        }
    }
}</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-32--part-5-_72AF/ThreadPoolExecutor-Worker_2.png" target="_blank"><img src="&quot;ThreadPoolExecutor-Worker&quot;" alt="ThreadPoolExecutor-Worker"></a></p>
<p>当提交一个任务时，如果需要创建一个线程（何时需要在下一节中探讨）时，就调用线程工厂创建一个线程，同时将线程绑定到Worker工作队列中。需要说明的是，Worker队列构造的时候带着一个任务Runnable，因此Worker创建时总是绑定着一个待执行任务。换句话说，创建线程的前提是有必要创建线程（任务数已经超出了线程或者强制创建新的线程，至于为何强制创建新的线程后面章节会具体分析），不会无缘无故创建一堆空闲线程等着任务。这是节省资源的一种方式。</p>
<p>一旦线程池启动线程后（调用线程run()）方法，那么线程工作队列Worker就从第1个任务开始执行（这时候发现构造Worker时传递一个任务的好处了），一旦第1个任务执行完毕，就从线程池的任务队列中取出下一个任务进行执行。循环如此，直到线程池被关闭或者任务抛出了一个RuntimeException。</p>
<p>由此可见，线程池的基本原理其实也很简单，无非预先启动一些线程，线程进入死循环状态，每次从任务队列中获取一个任务进行执行，直到线程池被关闭。如果某个线程因为执行某个任务发生异常而终止，那么重新创建一个新的线程而已。如此反复。</p>
<p>其实，线程池原理看起来简单，但是复杂的是各种策略，例如何时该启动一个线程，何时该终止、挂起、唤醒一个线程，任务队列的阻塞与超时，线程池的生命周期以及任务拒绝策略等等。下一节将研究这些策略问题。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2011/01/18/343183.html](http://www.blogjava.net/xylz/archive/2011/01/18/343183.html)">[http://www.blogjava.net/xylz/archive/2011/01/18/343183.html](http://www.blogjava.net/xylz/archive/2011/01/18/343183.html)</a> </p>
<p><strong>线程池任务执行流程</strong></p>
<p>我们从一个API开始接触Executor是如何处理任务队列的。</p>
<p>java.util.concurrent.Executor.execute(Runnable)
Executes the given task sometime in the future. The task may execute in a new thread or in an existing pooled thread. If the task cannot be submitted for execution, either because this executor has been shutdown or because its capacity has been reached, the task is handled by the current RejectedExecutionHandler.</p>
<p>线程池中所有任务执行都依赖于此接口。这段话有以下几个意思：</p>
<ol>
<li>任务可能在将来某个时刻被执行，有可能不是立即执行。为什么这里有两个“可能”？继续往下面看。</li>
<li>任务可能在一个新的线程中执行或者线程池中存在的一个线程中执行。</li>
<li>任务无法被提交执行有以下两个原因：线程池已经关闭或者线程池已经达到了容量限制。</li>
<li>所有失败的任务都将被“当前”的任务拒绝策略RejectedExecutionHandler 处理。</li>
</ol>
<p>回答上面两个“可能“。任务可能被执行，那不可能的情况就是上面说的情况3；可能不是立即执行，是因为任务可能还在队列中排队，因此还在等待分配线程执行。了解完了字面上的问题，我们再来看具体的实现。
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) {
        if (runState == RUNNING &amp;&amp; workQueue.offer(command)) {
            if (runState != RUNNING || poolSize == 0)
                ensureQueuedTaskHandled(command);
        }
        else if (!addIfUnderMaximumPoolSize(command))
            reject(command); // is shutdown or saturated
    }
}</p>
<p>这一段代码看起来挺简单的，其实这就是线程池最重要的一部分，如果能够完全理解这一块，线程池还是挺容易的。整个执行流程是这样的：</p>
<ol>
<li>如果任务command为空，则抛出空指针异常，返回。否则进行2。</li>
<li>如果当前线程池大小 大于或等于 核心线程池大小，进行4。否则进行3。</li>
<li>创建一个新工作队列（线程，参考上一节），成功直接返回，失败进行4。</li>
<li>如果线程池正在运行并且任务加入线程池队列成功，进行5，否则进行7。</li>
<li>如果线程池已经关闭或者线程池大小为0，进行6，否则直接返回。</li>
<li>如果线程池已经关闭则执行拒绝策略返回，否则启动一个新线程来进行执行任务，返回。</li>
<li>如果线程池大小 不大于 最大线程池数量，则启动新线程来进行执行，否则进行拒绝策略，结束。</li>
</ol>
<p>文字描述步骤不够简单？下面图形详细表述了此过程。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-34--part-7--2_BFAE/Executor.execute_8.png" target="_blank"><img src="&quot;Executor.execute&quot;" alt="Executor.execute"></a></p>
<p>老实说这个图比上面步骤更难以理解，那么从何入手呢。</p>
<p>流程的入口很简单，我们就是要执行一个任务（Runnable command)，那么它的结束点在哪或者有哪几个？</p>
<p>根据左边这个图我们知道可能有以下几种出口：</p>
<p>（1）图中的P1、P7，我们根据这条路径可以看到，仅仅是将任务加入任务队列（offer(command)）了；</p>
<p>（2）图中的P3，这条路径不将任务加入任务队列，但是启动了一个新工作线程（Worker）进行扫尾操作，用户处理为空的任务队列；</p>
<p>（3）图中的P4，这条路径没有将任务加入任务队列，但是启动了一个新工作线程（Worker），并且工作现场的第一个任务就是当前任务；</p>
<p>（4）图中的P5、P6，这条路径没有将任务加入任务队列，也没有启动工作线程，仅仅是抛给了任务拒绝策略。P2是任务加入了任务队列却因为线程池已经关闭于是又从任务队列中删除，并且抛给了拒绝策略。</p>
<p>如果上面的解释还不清楚，可以去研究下面两段代码：
java.util.concurrent.ThreadPoolExecutor.addIfUnderCorePoolSize(Runnable)
java.util.concurrent.ThreadPoolExecutor.addIfUnderMaximumPoolSize(Runnable)
java.util.concurrent.ThreadPoolExecutor.ensureQueuedTaskHandled(Runnable)</p>
<p>那么什么时候一个任务被立即执行呢？</p>
<p>在线程池运行状态下，如果线程池大小 小于 核心线程池大小或者线程池已满（任务队列已满）并且线程池大小 小于 最大线程池大小（此时线程池大小 大于 核心线程池大小的），用程序描述为：
runState == RUNNING &amp;&amp; ( poolSize &lt; corePoolSize || poolSize &lt; maxnumPoolSize &amp;&amp; workQueue.isFull())</p>
<p>上面的条件就是一个任务能够被立即执行的条件。</p>
<p>有了execute的基础，我们看看ExecutorService中的几个submit方法的实现。
    public Future&lt;?&gt; submit(Runnable task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<Object> ftask = newTaskFor(task, null);
        execute(ftask);
        return ftask;
    }
    public <T> Future<T> submit(Runnable task, T result) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<T> ftask = newTaskFor(task, result);
        execute(ftask);
        return ftask;
    }
    public <T> Future<T> submit(Callable<T> task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<T> ftask = newTaskFor(task);
        execute(ftask);
        return ftask;
    }</p>
<p>很简单，不是么？对于一个线程池来说复杂的地方也就在execute方法的执行流程。在下一节中我们来讨论下如何获取任务的执行结果，也就是Future类的使用和原理。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2011/02/11/344091.html](http://www.blogjava.net/xylz/archive/2011/02/11/344091.html)">[http://www.blogjava.net/xylz/archive/2011/02/11/344091.html](http://www.blogjava.net/xylz/archive/2011/02/11/344091.html)</a> </p>
<p><strong>线程池任务执行结果</strong></p>
<p>这一节来探讨下线程池中任务执行的结果以及如何阻塞线程、取消任务等等。
1 package info.imxylz.study.concurrency.future;
2 
3 public class SleepForResultDemo implements Runnable {
4 
5     static boolean result = false;
6 
7     static void sleepWhile(long ms) {
8         try {
9             Thread.sleep(ms);
10         } catch (Exception e) {}
11     }
12 
13     @Override
14     public void run() {
15         //do work
16         System.out.println(&quot;Hello, sleep a while.&quot;);
17         sleepWhile(2000L);
18         result = true;
19     }
20 
21     public static void main(String[] args) {
22         SleepForResultDemo demo = new SleepForResultDemo();
23         Thread t = new Thread(demo);
24         t.start();
25         sleepWhile(3000L);
26         System.out.println(result);
27     }
28 
29 }
30 </p>
<p>在没有线程池的时代里面，使用Thread.sleep(long)去获取线程执行完毕的场景很多。显然这种方式很笨拙，他需要你事先知道任务可能的执行时间，并且还会阻塞主线程，不管任务有没有执行完毕。</p>
<p>1 package info.imxylz.study.concurrency.future;
2 
3 public class SleepLoopForResultDemo implements Runnable {
4 
5     boolean result = false;
6 
7     volatile boolean finished = false;
8 
9     static void sleepWhile(long ms) {
10         try {
11             Thread.sleep(ms);
12         } catch (Exception e) {}
13     }
14 
15     @Override
16     public void run() {
17         //do work
18         try {
19             System.out.println(&quot;Hello, sleep a while.&quot;);
20             sleepWhile(2000L);
21             result = true;
22         } finally {
23             finished = true;
24         }
25     }
26 
27     public static void main(String[] args) {
28         SleepLoopForResultDemo demo = new SleepLoopForResultDemo();
29         Thread t = new Thread(demo);
30         t.start();
31         while (!demo.finished) {
32             sleepWhile(10L);
33         }
34         System.out.println(demo.result);
35     }
36 
37 }
38 </p>
<p>使用volatile与while死循环的好处就是等待的时间可以稍微小一点，但是依然有CPU负载高并且阻塞主线程的问题。最简单的降低CPU负载的方式就是使用Thread.join().</p>
<pre><code>    SleepLoopForResultDemo demo = new SleepLoopForResultDemo();
    Thread t = new Thread(demo);
    t.start();
    t.join();
    System.out.println(demo.result);
</code></pre><p>显然这也是一种不错的方式，另外还有自己写锁使用wait/notify的方式。其实join()从本质上讲就是利用while和wait来实现的。</p>
<p>上面的方式中都存在一个问题，那就是会阻塞主线程并且任务不能被取消。为了解决这个问题，线程池中提供了一个Future接口。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-35--part-8--2_BFEA/ThreadPoolExecutor-Future_2.png" target="_blank"><img src="&quot;ThreadPoolExecutor-Future&quot;" alt="ThreadPoolExecutor-Future"></a></p>
<p>在Future接口中提供了5个方法。</p>
<ul>
<li>V get() throws InterruptedException, ExecutionException： 等待计算完成，然后获取其结果。</li>
<li>V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException。最多等待为使计算完成所给定的时间之后，获取其结果（如果结果可用）。</li>
<li>boolean cancel(boolean mayInterruptIfRunning)：试图取消对此任务的执行。</li>
<li>boolean isCancelled()：如果在任务正常完成前将其取消，则返回 true。</li>
<li>boolean isDone()：如果任务已完成，则返回 true。 可能由于正常终止、异常或取消而完成，在所有这些情况中，此方法都将返回 true。</li>
</ul>
<p>API看起来容易，来研究下异常吧。get()请求获取一个结果会阻塞当前进程，并且可能抛出以下三种异常：</p>
<ul>
<li>InterruptedException：执行任务的线程被中断则会抛出此异常，此时不能知道任务是否执行完毕，因此其结果是无用的，必须处理此异常。</li>
<li>ExecutionException：任务执行过程中(Runnable/#run()）方法可能抛出RuntimeException，如果提交的是一个java.util.concurrent.Callable<V>接口任务，那么java.util.concurrent.Callable.call()方法有可能抛出任意异常。</li>
<li>CancellationException：实际上get()方法还可能抛出一个CancellationException的RuntimeException，也就是任务被取消了但是依然去获取结果。</li>
</ul>
<p>对于get(long timeout, TimeUnit unit)而言，除了get()方法的异常外，由于有超时机制，因此还可能得到一个TimeoutException。</p>
<p>boolean cancel(boolean mayInterruptIfRunning)方法比较复杂，各种情况比较多：</p>
<ol>
<li>如果任务已经执行完毕，那么返回false。</li>
<li>如果任务已经取消，那么返回false。</li>
<li>循环直到设置任务为取消状态，对于未启动的任务将永远不再执行，对于正在运行的任务，将根据mayInterruptIfRunning是否中断其运行，如果不中断那么任务将继续运行直到结束。</li>
<li>此方法返回后任务要么处于运行结束状态，要么处于取消状态。isDone()将永远返回true，如果cancel()方法返回true，isCancelled()始终返回true。</li>
</ol>
<p>来看看Future接口的实现类java.util.concurrent.FutureTask<V>具体是如何操作的。</p>
<p>在FutureTask中使用了一个<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">AQS</a>数据结构来完成各种状态以及加锁、阻塞的实现。</p>
<p>在此AQS类java.util.concurrent.FutureTask.Sync中一个任务用4中状态：</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-35--part-8--2_BFEA/ThreadPoolExecutor-FutureTask-state_2.png" target="_blank"><img src="&quot;ThreadPoolExecutor-FutureTask-state&quot;" alt="ThreadPoolExecutor-FutureTask-state"></a></p>
<p>初始情况下任务状态state=0，任务执行(innerRun)后状态变为运行状态RUNNING(state=1)，执行完毕后变成运行结束状态RAN(state=2)。任务在初始状态或者执行状态被取消后就变为状态CANCELLED(state=4)。<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">AQS</a>最擅长无锁情况下处理几种简单的状态变更的。
        void innerRun() {
            if (!compareAndSetState(0, RUNNING))
                return;
            try {
                runner = Thread.currentThread();
                if (getState() == RUNNING) // recheck after setting thread
                    innerSet(callable.call());
                else
                    releaseShared(0); // cancel
            } catch (Throwable ex) {
                innerSetException(ex);
            }
        }</p>
<p>执行一个任务有四步：设置运行状态、设置当前线程（AQS需要）、执行任务(Runnable/#run或者Callable/#call）、设置执行结果。这里也可以看到，一个任务只能执行一次，因为执行完毕后它的状态不在为初始值0，要么为CANCELLED，要么为RAN。</p>
<p>取消一个任务(cancel)又是怎样进行的呢？对比下前面取消任务的描述是不是很简单，这里无非利用AQS的状态来改变任务的执行状态，最终达到放弃未启动或者正在执行的任务的目的。
boolean innerCancel(boolean mayInterruptIfRunning) {
    for (;;) {
        int s = getState();
        if (ranOrCancelled(s))
            return false;
        if (compareAndSetState(s, CANCELLED))
            break;
    }
    if (mayInterruptIfRunning) {
        Thread r = runner;
        if (r != null)
            r.interrupt();
    }
    releaseShared(0);
    done();
    return true;
}</p>
<p>到目前为止我们依然没有说明到底是如何阻塞获取一个结果的。下面四段代码描述了这个过程。</p>
<p>1     V innerGet() throws InterruptedException, ExecutionException {
2         acquireSharedInterruptibly(0);
3         if (getState() == CANCELLED)
4             throw new CancellationException();
5         if (exception != null)
6             throw new ExecutionException(exception);
7         return result;
8     }
9     //AQS/#acquireSharedInterruptibly
10     public final void acquireSharedInterruptibly(int arg) throws InterruptedException {
11         if (Thread.interrupted())
12             throw new InterruptedException();
13         if (tryAcquireShared(arg) &lt; 0)
14             doAcquireSharedInterruptibly(arg); //park current Thread for result
15     }
16     protected int tryAcquireShared(int ignore) {
17         return innerIsDone()? 1 : -1;
18     }
19 
20     boolean innerIsDone() {
21         return ranOrCancelled(getState()) &amp;&amp; runner == null;
22     }</p>
<p>当调用Future/#get()的时候尝试去获取一个共享变量。这就涉及到AQS的使用方式了。这里获取一个共享变量的状态是任务是否结束(innerIsDone())，也就是任务是否执行完毕或者被取消。如果不满足条件，那么在AQS中就会doAcquireSharedInterruptibly(arg)挂起当前线程，直到满足条件。AQS前面讲过，挂起线程使用的是LockSupport的park方式，因此性能消耗是很低的。</p>
<p>至于将Runnable接口转换成Callable接口，java.util.concurrent.Executors.callable(Runnable, T)也提供了一个简单实现。
    static final class RunnableAdapter<T> implements Callable<T> {
        final Runnable task;
        final T result;
        RunnableAdapter(Runnable  task, T result) {
            this.task = task;
            this.result = result;
        }
        public T call() {
            task.run();
            return result;
        }
    }</p>
<p><strong>延迟、周期性任务调度的实现</strong></p>
<p>java.util.concurrent.ScheduledThreadPoolExecutor是默认的延迟、周期性任务调度的实现。</p>
<p>有了整个线程池的实现，再回头来看延迟、周期性任务调度的实现应该就很简单了，因为所谓的延迟、周期性任务调度，无非添加一系列有序的任务队列，然后按照执行顺序的先后来处理整个任务队列。如果是周期性任务，那么在执行完毕的时候加入下一个时间点的任务即可。</p>
<p>由此可见，ScheduledThreadPoolExecutor和ThreadPoolExecutor的唯一区别在于任务是有序（按照执行时间顺序）的，并且需要到达时间点（临界点）才能执行，并不是任务队列中有任务就需要执行的。也就是说唯一不同的就是任务队列BlockingQueue<Runnable> workQueue不一样。ScheduledThreadPoolExecutor的任务队列是java.util.concurrent.ScheduledThreadPoolExecutor.DelayedWorkQueue，它是基于java.util.concurrent.DelayQueue<RunnableScheduledFuture>队列的实现。</p>
<p>DelayQueue是基于有序队列<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>实现的。<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a> 也叫优先级队列，按照自然顺序对元素进行排序，类似于TreeMap/Collections.sort一样。</p>
<p>同样是有序队列，DelayQueue和<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>区别在什么地方？</p>
<p>由于DelayQueue在获取元素时需要检测元素是否“可用”，也就是任务是否达到“临界点”（指定时间点），因此加入元素和移除元素会有一些额外的操作。</p>
<p>典型的，移除元素需要检测元素是否达到“临界点”，增加元素的时候如果有一个元素比“头元素”更早达到临界点，那么就需要通知任务队列。因此这需要一个条件变量final Condition available 。</p>
<p>移除元素（出队列）的过程是这样的：</p>
<ul>
<li>总是检测队列的头元素（顺序最小元素，也是最先达到临界点的元素）</li>
<li>检测头元素与当前时间的差，如果大于0，表示还未到底临界点，因此等待响应时间（使用条件变量available)</li>
<li>如果小于或者等于0，说明已经到底临界点或者已经过了临界点，那么就移除头元素，并且唤醒其它等待任务队列的线程。
  public E take() throws InterruptedException {<pre><code>  final ReentrantLock lock = this.lock;
  lock.lockInterruptibly();
  try {
      for (;;) {
          E first = q.peek();
          if (first == null) {
              available.await();
          } else {
              long delay =  first.getDelay(TimeUnit.NANOSECONDS);
              if (delay &gt; 0) {
                  long tl = available.awaitNanos(delay);
              } else {
                  E x = q.poll();
                  assert x != null;
                  if (q.size() != 0)
                      available.signalAll(); // wake up other takers
                  return x;
              }
          }
      }
  } finally {
      lock.unlock();
  }
</code></pre>  }</li>
</ul>
<p>同样加入元素也会有相应的条件变量操作。当前仅当队列为空或者要加入的元素比队列中的头元素还小的时候才需要唤醒“等待线程”去检测元素。因为头元素都没有唤醒那么比头元素更延迟的元素就更加不会唤醒。</p>
<pre><code>public boolean offer(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        E first = q.peek();
        q.offer(e);
        if (first == null || e.compareTo(first) &lt; 0)
            available.signalAll();
        return true;
    } finally {
        lock.unlock();
    }
}
</code></pre><p>有了任务队列后再来看Future在ScheduledThreadPoolExecutor中是如何操作的。</p>
<p>java.util.concurrent.ScheduledThreadPoolExecutor.ScheduledFutureTask<V>是继承java.util.concurrent.FutureTask<V>的，区别在于执行任务是否是周期性的。
        private void runPeriodic() {
            boolean ok = ScheduledFutureTask.super.runAndReset();
            boolean down = isShutdown();
            // Reschedule if not cancelled and not shutdown or policy allows
            if (ok &amp;&amp; (!down ||
                       (getContinueExistingPeriodicTasksAfterShutdownPolicy() &amp;&amp;
                        !isStopped()))) {
                long p = period;
                if (p &gt; 0)
                    time += p;
                else
                    time = now() - p;
                ScheduledThreadPoolExecutor.super.getQueue().add(this);
            }
            // This might have been the final executed delayed
            // task.  Wake up threads to check.
            else if (down)
                interruptIdleWorkers();
        }
        //<em>/</em>
         /<em> Overrides FutureTask version so as to reset/requeue if periodic.
         /</em>/
        public void run() {
            if (isPeriodic())
                runPeriodic();
            else
                ScheduledFutureTask.super.run();
        }
    }</p>
<p>如果不是周期性任务调度，那么就和java.util.concurrent.FutureTask.Sync的调度方式是一样的。如果是周期性任务（isPeriodic()）那么就稍微有所不同的。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-35--part-8--2_BFEA/ScheduledThreadPoolExecutor-ScheduledFutureTask_4.png" target="_blank"><img src="&quot;ScheduledThreadPoolExecutor-ScheduledFutureTask&quot;" alt="ScheduledThreadPoolExecutor-ScheduledFutureTask"></a></p>
<p>先从功能/结构上分析下。第一种情况假设提交的任务每次执行花费10s，间隔（delay/period)为20s，对于scheduleAtFixedRate而言，每次执行开始时间20s，对于scheduleWithFixedDelay来说每次执行开始时间30s。第二种情况假设提交的任务每次执行时间花费20s，间隔（delay/period)为10s，对于scheduleAtFixedRate而言，每次执行开始时间10s，对于scheduleWithFixedDelay来说每次执行开始时间30s。（具体分析可以参考<a href="http://www.blogjava.net/xylz/archive/2011/01/10/342738.html" target="_blank">这里</a>）</p>
<p>也就是说scheduleWithFixedDelay的执行开始时间为(delay+cost)，而对于scheduleAtFixedRate来说执行开始时间为max(period,cost)。</p>
<p>回头再来看上面源码runPeriodic()就很容易了。但特别要提醒的，如果任务的任何一个执行遇到异常，则后续执行都会被取消，这从runPeriodic()就能看出。要强调的第二点就是<strong>同一个周期性任务不会被同时执行</strong>。就比如说尽管上面第二种情况的scheduleAtFixedRate任务每隔10s执行到达一个时间点，但是由于每次执行时间花费为20s，因此每次执行间隔为20s，只不过执行的任务次数会多一点。但从本质上讲就是每隔20s执行一次，如果任务队列不取消的话。</p>
<p>为什么不会同时执行？</p>
<p>这是因为ScheduledFutureTask执行的时候会将任务从队列中移除来，执行完毕以后才会添加下一个同序列的任务，因此任务队列中其实最多只有同序列的任务的一份副本，所以永远不会同时执行（尽管要执行的时间在过去）。</p>
<p>ScheduledThreadPoolExecutor使用一个无界（容量无限，整数的最大值）的容器（DelayedWorkQueue队列），根据<a href="http://www.blogjava.net/xylz/archive/2011/02/11/344091.html" target="_blank">ThreadPoolExecutor</a>的原理，只要当容器满的时候才会启动一个大于corePoolSize的线程数。因此实际上ScheduledThreadPoolExecutor是一个固定线程大小的线程池，固定大小为corePoolSize，构造函数里面的Integer.MAX_VALUE其实是不生效的（尽管<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>使用数组实现有<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>大小限制，如果你的任务数超过了2147483647就会导致OutOfMemoryError，这个参考<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>的grow方法）。</p>
<p>再回头看scheduleAtFixedRate等方法就容易多了。无非就是往任务队列中添加一个未来某一时刻的ScheduledFutureTask任务，如果是scheduleAtFixedRate那么period/delay就是正数，如果是scheduleWithFixedDelay那么period/delay就是一个负数，如果是0那么就是一次性任务。直接调用父类<a href="http://www.blogjava.net/xylz/archive/2011/02/11/344091.html" target="_blank">ThreadPoolExecutor</a>的execute/submit等方法就相当于period/delay是0，并且initialDelay也是0。
    public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command,
                                                  long initialDelay,
                                                  long period,
                                                  TimeUnit unit) {
        if (command == null || unit == null)
            throw new NullPointerException();
        if (period &lt;= 0)
            throw new IllegalArgumentException();
        if (initialDelay &lt; 0) initialDelay = 0;
        long triggerTime = now() + unit.toNanos(initialDelay);
        RunnableScheduledFuture&lt;?&gt; t = decorateTask(command,
            new ScheduledFutureTask<Object>(command,
                                            null,
                                            triggerTime,
                                            unit.toNanos(period)));
        delayedExecute(t);
        return t;
    }</p>
<p>另外需要补充说明的一点，前面说过java.util.concurrent.FutureTask.Sync任务只能执行一次，那么在runPeriodic()里面怎么又将执行过的任务加入队列中呢？这是因为java.util.concurrent.FutureTask.Sync提供了一个innerRunAndReset()方法，此方法不仅执行任务还将任务的状态还原成0（初始状态）了，所以此任务就可以重复执行。这就是为什么runPeriodic()里面调用runAndRest()的缘故。</p>
<pre><code>    boolean innerRunAndReset() {
        if (!compareAndSetState(0, RUNNING))
            return false;
        try {
            runner = Thread.currentThread();
            if (getState() == RUNNING)
                callable.call(); // don&#39;t set result
            runner = null;
            return compareAndSetState(RUNNING, 0);
        } catch (Throwable ex) {
            innerSetException(ex);
            return false;
        }
    }
</code></pre><p><strong>后话</strong></p>
<p>整个并发实践原理和实现（源码）上的东西都讲完了，后面几个小节是一些总结和扫尾的工作，包括超时机制、异常处理等一些细节问题。也就是说大部分只需要搬出一些理论和最佳实践知识出来就好了，不会有大量费脑筋的算法分析和原理、思想探讨之类的。后面的章节也会加快一些进度。</p>
<p>老实说从刚开始的好奇到中间的兴奋，再到现在的彻悟，收获还是很多，个人觉得这是最认真、最努力也是自我最满意的一次技术研究和探讨，同时在这个过程中将很多技术细节都串联起来了，慢慢就有了那种技术相通的感觉。原来有了理论以后再去实践、再去分析问题、解决问题和那种纯解决问题得到的经验完全不一样。整个专辑下来不仅仅是并发包这一点点知识，设计到硬件、软件、操作系统、网络、安全、性能、算法、理论等等，总的来说这也算是一次比较成功的研究切入点，这比<a href="http://www.blogjava.net/xylz/archive/2009/12/22/306955.html" target="_blank">Guice</a>那次探讨要深入和持久的多。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/02/13/344207.html](http://www.blogjava.net/xylz/archive/2011/02/13/344207.html)">[http://www.blogjava.net/xylz/archive/2011/02/13/344207.html](http://www.blogjava.net/xylz/archive/2011/02/13/344207.html)</a> </p>
<p><a href="http://www.blogjava.net/xylz/archive/2011/07/12/354206.html" target="_blank">并发操作异常体系</a> </p>
<p>并发包引入的工具类很多方法都会抛出一定的异常，这些异常描述了任务在线程池中执行时发生的例外情况，而通常这些例外需要应用程序进行捕捉和处理。</p>
<p>例如在Future接口中有如下一个API：</p>
<p>java.util.concurrent.Future.get(long, TimeUnit) throws InterruptedException, ExecutionException, TimeoutException;</p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2011/02/13/344207.html" target="_blank">前面的章节</a>中描述了Future类的具体实现原理。这里不再讨论，但是比较好奇的抛出的三个异常。</p>
<p>这里有一篇文章（<a href="http://www.ibm.com/developerworks/cn/java/j-jtp05236.html" target="_blank">Java 理论与实践: 处理 InterruptedException</a>）描述了InterruptedException的来源和处理方式。简单的说就是线程在执行的过程中被自己或者别人中断了。这时候为了响应中断就需要处理当前的异常。</p>
<p>对于java.lang.Thread而言，InterruptedException也是一个很诡异的问题。</p>
<p>中断一个线程Thread.<strong>interrupt()</strong>时会触发下面一种情况：
如果线程在调用 Object 类的 wait()、wait(long) 或 wait(long, int) 方法，或者该类的 join()、join(long)、join(long, int)、sleep(long) 或 sleep(long, int) 方法过程中受阻，则其中断状态将被清除，它还将收到一个 InterruptedException。</p>
<p>检测一个线程的中断状态描述是这样的Thread.<strong>interrupted()：</strong></p>
<p>测试当前线程是否已经中断。线程的<em>中断状态</em> 由该方法清除。换句话说，如果连续两次调用该方法，则第二次调用将返回 false（在第一次调用已清除了其中断状态之后，且第二次调用检验完中断状态前，当前线程再次中断的情况除外）。 </p>
<p>也就是说如果检测到一个线程已经被中断了，那么线程的使用方（挂起、等待或者正在执行）都将应该得到一个中断异常，同时将会清除异常中断状态。</p>
<p>V innerGet(long nanosTimeout) throws InterruptedException, ExecutionException, TimeoutException {
    if (!tryAcquireSharedNanos(0, nanosTimeout))
        throw new TimeoutException();
    if (getState() == CANCELLED)
        throw new CancellationException();
    if (exception != null)
        throw new ExecutionException(exception);
    return result;
}</p>
<p>上面获取任务结果的方法实现中，将在获取锁的过程中得到一个中断异常。代码java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(int, long)描述了这种情况：
    public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    return tryAcquireShared(arg) &gt;= 0 ||
        doAcquireSharedNanos(arg, nanosTimeout);
    }</p>
<p>这里在获取锁的时候检测线程中断情况，如果被中断则清除中断位，同时抛出一个中断异常。为什么如此做？因为我们的线程在线程池中是被重复执行的，所以一旦线程被中断后并不会退出线程，而是设置中断位，等候任务队列自己处理线程，从而达到线程被重复利用的目的。有兴趣的可以参考代码java.util.concurrent.ThreadPoolExecutor.Worker.runTask(Runnable)。这里在关闭线程池时就会导致中断所有线程。</p>
<p>除了InterruptedException 异常我们还发现了一个全新的异常java.util.concurrent.TimeoutException，此异常是用来描述任务执行时间超过了期望等待时间，也许是一直没有获取到锁，也许是还没有执行完成。</p>
<p>在innerGet代码片段中我们看到，如果线程在指定的时间无法获取到锁，那么就会得到一个超时异常。这个很好理解，比如如果执行一个非常耗时的网络任务，我们不希望任务一直等待从而占用大量的资源，可能在一定时间后就会希望取消此操作。此时超时异常很好的描述了这种需求。</p>
<p>与此同时，如果取消了一个任务，那么再次从任务中获取执行结果，那么将会得到一个任务被取消的异常java.util.concurrent.CancellationException。</p>
<p>除了上述异常外，还将得到一个java.util.concurrent.ExecutionException异常，</p>
<p>这是因为我们的提交的任务java.util.concurrent.Callable在call()方法中允许抛出任何异常，另外常规的线程执行也可能抛出一个RuntimeException，所以这里简单包装了下所有异常，当作执行过程中发生的异常ExecutionException抛出。</p>
<p>以上就是整个异常体系，所有并发操作的异常都可以归结于上述几类。</p>
<p>很多情况下处理时间长度都是用<strong>java.util.concurrent.TimeUnit</strong>，这是一个枚举类型，用来描述时间长度。其中内置了一些长度的单位。其中包括纳秒、微秒、毫秒、秒、分、时、天。例如超时操作5秒，可以使用</p>
<p>Future.get(5,TimeUnit.SECONDS) 或者 Future.get(5000L,TimeUnit.MILLISECONDS)</p>
<p>当然一种单位的时间转换成另一种单位的时间也是非常方便的。另外还有线程的sleep/join以及对象的wait操作的便捷操作。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/07/12/354206.html](http://www.blogjava.net/xylz/archive/2011/07/12/354206.html)">[http://www.blogjava.net/xylz/archive/2011/07/12/354206.html](http://www.blogjava.net/xylz/archive/2011/07/12/354206.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency28-线程池/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency28-线程池" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--java多线程学习-javautilconcurrent详解/">java多线程学习</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--java多线程学习-javautilconcurrent详解/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="java-java-util-concurrent-">java多线程学习-java.util.concurrent详解</h1>
<h3 id="-latch-barrier-http-janeky-iteye-com-blog-769965-"><a href="http://janeky.iteye.com/blog/769965" target="_blank">Latch/Barrier</a></h3>
<p>   Java1.5提供了一个非常高效实用的多线程包：java.util.concurrent, 提供了大量高级工具，可以帮助开发者编写高效、易维护、结构清晰的Java多线程程序。从这篇blog起，我将跟大家一起共同学习这些新的Java多线程构件 </p>
<ol>
<li><p>CountDownLatch 
 我们先来学习一下JDK1.5 API中关于这个类的详细介绍： 
“一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 用给定的计数 初始化 CountDownLatch。由于调用了 countDown() 方法，所以在当前计数到达零之前，await 方法会一直受阻塞。之后，会释放所有等待的线程，await 的所有后续调用都将立即返回。这种现象只出现一次——计数无法被重置。如果需要重置计数，请考虑使用 CyclicBarrier。” 
 这就是说，CountDownLatch可以用来管理一组相关的线程执行，只需在主线程中调用CountDownLatch 的await方法（一直阻塞），让各个线程调用countDown方法。当所有的线程都只需完countDown了，await也顺利返回，不再阻塞了。在这样情况下尤其适用：将一个任务分成若干线程执行，等到所有线程执行完，再进行汇总处理。 
 下面我举一个非常简单的例子。假设我们要打印1-100，最后再输出“Ok“。1-100的打印顺序不要求统一，只需保证“Ok“是在最后出现即可。 
 解决方案：我们定义一个CountDownLatch，然后开10个线程分别打印（n-1）/<em>10+1至（n-1）/</em>10+10。主线程中调用await方法等待所有线程的执行完毕，每个线程执行完毕后都调用countDown方法。最后再await返回后打印“Ok”。 
具体代码如下（本代码参考了JDK示例代码）： 
Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
</li>
<li><p>import java.util.concurrent.CountDownLatch;  </p>
</li>
<li>//<em>/</em> </li>
<li>/* 示例：CountDownLatch的使用举例 </li>
<li>/* Mail: ken@iamcoding.com </li>
<li>/* @author janeky </li>
<li>/*/  </li>
<li>public class TestCountDownLatch {  </li>
<li>private static final int N = 10;  </li>
<li></li>
<li>public static void main(String[] args) throws InterruptedException {  </li>
<li>CountDownLatch doneSignal = new CountDownLatch(N);  </li>
<li>CountDownLatch startSignal = new CountDownLatch(1);//开始执行信号  </li>
<li></li>
<li>for (int i = 1; i &lt;= N; i++) {  </li>
<li>new Thread(new Worker(i, doneSignal, startSignal)).start();//线程启动了  </li>
<li>}  </li>
<li>System.out.println(&quot;begin------------&quot;);  </li>
<li>startSignal.countDown();//开始执行啦  </li>
<li>doneSignal.await();//等待所有的线程执行完毕  </li>
<li>System.out.println(&quot;Ok&quot;);  </li>
<li></li>
<li>}  </li>
<li></li>
<li>static class Worker implements Runnable {  </li>
<li>private final CountDownLatch doneSignal;  </li>
<li>private final CountDownLatch startSignal;  </li>
<li>private int beginIndex;  </li>
<li></li>
<li>Worker(int beginIndex, CountDownLatch doneSignal,  </li>
<li>CountDownLatch startSignal) {  </li>
<li>this.startSignal = startSignal;  </li>
<li>this.beginIndex = beginIndex;  </li>
<li>this.doneSignal = doneSignal;  </li>
<li>}  </li>
<li></li>
<li>public void run() {  </li>
<li>try {  </li>
<li>startSignal.await(); //等待开始执行信号的发布  </li>
<li>beginIndex = (beginIndex - 1) /* 10 + 1;  </li>
<li>for (int i = beginIndex; i &lt;= beginIndex + 10; i++) {  </li>
<li>System.out.println(i);  </li>
<li>}  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>} finally {  </li>
<li>doneSignal.countDown();  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li>}<br> 总结：CounDownLatch对于管理一组相关线程非常有用。上述示例代码中就形象地描述了两种使用情况。第一种是计算器为1，代表了两种状态，开关。第二种是计数器为N，代表等待N个操作完成。今后我们在编写多线程程序时，可以使用这个构件来管理一组独立线程的执行。 </li>
<li><p>CyclicBarrier 
 我们先来学习一下JDK1.5 API中关于这个类的详细介绍： 
 “一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 
 CyclicBarrier 支持一个可选的 Runnable 命令，在一组线程中的最后一个线程到达之后（但在释放所有线程之前），该命令只在每个屏障点运行一次。若在继续所有参与线程之前更新共享状态，此屏障操作 很有用。 
 我们在学习CountDownLatch的时候就提到了CyclicBarrier。两者究竟有什么联系呢？引用[JCIP]中的描述“The key difference is that with a barrier, all the threads must come together at a barrier point at the same time in order to proceed. Latches are for waiting for events; barriers are for waiting for other threads。CyclicBarrier等待所有的线程一起完成后再执行某个动作。这个功能CountDownLatch也同样可以实现。但是CountDownLatch更多时候是在等待某个事件的发生。在CyclicBarrier中，所有的线程调用await方法，等待其他线程都执行完。 
 举一个很简单的例子，今天晚上我们哥们4个去Happy。就互相通知了一下：晚上八点准时到xx酒吧门前集合，不见不散！。有个哥们住的近，早早就到了。有的事务繁忙，刚好踩点到了。无论怎样，先来的都不能独自行动，只能等待所有人 
代码如下（参考了网上给的一些教程） 
Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
</li>
<li><p>import java.util.Random;  </p>
</li>
<li>import java.util.concurrent.BrokenBarrierException;  </li>
<li>import java.util.concurrent.CyclicBarrier;  </li>
<li>import java.util.concurrent.ExecutorService;  </li>
<li>import java.util.concurrent.Executors;  </li>
<li></li>
<li>public class TestCyclicBarrier {  </li>
<li></li>
<li>public static void main(String[] args) {  </li>
<li></li>
<li>ExecutorService exec = Executors.newCachedThreadPool();       </li>
<li>final Random random=new Random();  </li>
<li></li>
<li>final CyclicBarrier barrier=new CyclicBarrier(4,new Runnable(){  </li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>System.out.println(&quot;大家都到齐了，开始happy去&quot;);  </li>
<li>}});  </li>
<li></li>
<li>for(int i=0;i&lt;4;i++){  </li>
<li>exec.execute(new Runnable(){  </li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>try {  </li>
<li>Thread.sleep(random.nextInt(1000));  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>System.out.println(Thread.currentThread().getName()+&quot;到了，其他哥们呢&quot;);  </li>
<li>try {  </li>
<li>barrier.await();//等待其他哥们  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>} catch (BrokenBarrierException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}});  </li>
<li>}  </li>
<li>exec.shutdown();  </li>
<li>}  </li>
<li></li>
<li><p>}<br> 关于await方法要特别注意一下，它有可能在阻塞的过程中由于某些原因被中断 
 总结：CyclicBarrier就是一个栅栏，等待所有线程到达后再执行相关的操作。barrier 在释放等待线程后可以重用。 </p>
</li>
<li><p>Semaphore 
 我们先来学习一下JDK1.5 API中关于这个类的详细介绍： 
“一个计数信号量。从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。” 
 我们一般用它来控制某个对象的线程访问对象 
 例如，对于某个容器，我们规定，最多只能容纳n个线程同时操作 
使用信号量来模拟实现 
具体代码如下（参考 [JCIP]） 
Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
</li>
<li><p>import java.util.Collections;  </p>
</li>
<li>import java.util.HashSet;  </li>
<li>import java.util.Set;  </li>
<li>import java.util.concurrent.ExecutorService;  </li>
<li>import java.util.concurrent.Executors;  </li>
<li>import java.util.concurrent.Semaphore;  </li>
<li></li>
<li>public class TestSemaphore {  </li>
<li></li>
<li>public static void main(String[] args) {  </li>
<li>ExecutorService exec = Executors.newCachedThreadPool();  </li>
<li>TestSemaphore t = new TestSemaphore();  </li>
<li>final BoundedHashSet<String> set = t.getSet();  </li>
<li></li>
<li>for (int i = 0; i &lt; 3; i++) {//三个线程同时操作add  </li>
<li>exec.execute(new Runnable() {  </li>
<li>public void run() {  </li>
<li>try {  </li>
<li>set.add(Thread.currentThread().getName());  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}  </li>
<li>});  </li>
<li>}  </li>
<li></li>
<li>for (int j = 0; j &lt; 3; j++) {//三个线程同时操作remove  </li>
<li>exec.execute(new Runnable() {  </li>
<li>public void run() {  </li>
<li>set.remove(Thread.currentThread().getName());  </li>
<li>}  </li>
<li>});  </li>
<li>}  </li>
<li>exec.shutdown();  </li>
<li>}  </li>
<li></li>
<li>public BoundedHashSet<String> getSet() {  </li>
<li>return new BoundedHashSet<String>(2);//定义一个边界约束为2的线程  </li>
<li>}  </li>
<li></li>
<li>class BoundedHashSet<T> {  </li>
<li>private final Set<T> set;  </li>
<li>private final Semaphore semaphore;  </li>
<li></li>
<li>public BoundedHashSet(int bound) {  </li>
<li>this.set = Collections.synchronizedSet(new HashSet<T>());  </li>
<li>this.semaphore = new Semaphore(bound, true);  </li>
<li>}  </li>
<li></li>
<li>public void add(T o) throws InterruptedException {  </li>
<li>semaphore.acquire();//信号量控制可访问的线程数目  </li>
<li>set.add(o);  </li>
<li>System.out.printf(&quot;add:%s%n&quot;,o);  </li>
<li>}  </li>
<li></li>
<li>public void remove(T o) {  </li>
<li>if (set.remove(o))  </li>
<li>semaphore.release();//释放掉信号量  </li>
<li>System.out.printf(&quot;remove:%s%n&quot;,o);  </li>
<li>}  </li>
<li>}  </li>
<li><p>}<br> 总结：Semaphore通常用于对象池的控制 
4．FutureTask 
 我们先来学习一下JDK1.5 API中关于这个类的详细介绍： 
 “取消的异步计算。利用开始和取消计算的方法、查询计算是否完成的方法和获取计算结果的方法，此类提供了对 Future 的基本实现。仅在计算完成时才能获取结果；如果计算尚未完成，则阻塞 get 方法。一旦计算完成，就不能再重新开始或取消计算。 
可使用 FutureTask 包装 Callable 或 Runnable 对象。因为 FutureTask 实现了 Runnable，所以可将 FutureTask 提交给 Executor 执行。 
除了作为一个独立的类外，此类还提供了 protected 功能，这在创建自定义任务类时可能很有用。 “ 
 应用举例：我们的算法中有一个很耗时的操作，在编程的是，我们希望将它独立成一个模块，调用的时候当做它是立刻返回的，并且可以随时取消的 
具体代码如下（参考 [JCIP]） 
Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
</li>
<li><p>import java.util.concurrent.Callable;  </p>
</li>
<li>import java.util.concurrent.ExecutionException;  </li>
<li>import java.util.concurrent.ExecutorService;  </li>
<li>import java.util.concurrent.Executors;  </li>
<li>import java.util.concurrent.FutureTask;  </li>
<li></li>
<li>public class TestFutureTask {  </li>
<li></li>
<li>public static void main(String[] args) {  </li>
<li>ExecutorService exec=Executors.newCachedThreadPool();  </li>
<li></li>
<li>FutureTask<String> task=new FutureTask<String>(new Callable<String>(){//FutrueTask的构造参数是一个Callable接口  </li>
<li>@Override  </li>
<li>public String call() throws Exception {  </li>
<li>return Thread.currentThread().getName();//这里可以是一个异步操作  </li>
<li>}});  </li>
<li></li>
<li>try {  </li>
<li>exec.execute(task);//FutureTask实际上也是一个线程  </li>
<li>String result=task.get();//取得异步计算的结果，如果没有返回，就会一直阻塞等待  </li>
<li>System.out.printf(&quot;get:%s%n&quot;,result);  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>} catch (ExecutionException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>}<br> 总结：FutureTask其实就是新建了一个线程单独执行，使得线程有一个返回值，方便程序的编写 </li>
<li><p>Exchanger 
 我们先来学习一下JDK1.5 API中关于这个类的详细介绍： 
 “可以在pair中对元素进行配对和交换的线程的同步点。每个线程将条目上的某个方法呈现给 exchange 方法，与伙伴线程进行匹配，并且在返回时接收其伙伴的对象。Exchanger 可能被视为 SynchronousQueue 的双向形式。Exchanger 可能在应用程序（比如遗传算法和管道设计）中很有用。 “ 
 应用举例：有两个缓存区，两个线程分别向两个缓存区fill和take，当且仅当一个满了，两个缓存区交换 
 代码如下（参考了网上给的示例   <a href="http://hi.baidu.com/webidea/blog/item/2995e731e53ad5a55fdf0e7d.html）" target="_blank">http://hi.baidu.com/webidea/blog/item/2995e731e53ad5a55fdf0e7d.html）</a> 
Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
</li>
<li><p>import java.util.ArrayList;  </p>
</li>
<li>import java.util.concurrent.Exchanger;  </li>
<li></li>
<li>public class TestExchanger {  </li>
<li></li>
<li>public static void main(String[] args) {  </li>
<li>final Exchanger<ArrayList<Integer>&gt; exchanger = new Exchanger<ArrayList<Integer>&gt;();  </li>
<li>final ArrayList<Integer> buff1 = new ArrayList<Integer>(10);  </li>
<li>final ArrayList<Integer> buff2 = new ArrayList<Integer>(10);  </li>
<li></li>
<li>new Thread(new Runnable() {  </li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>ArrayList<Integer> buff = buff1;  </li>
<li>try {  </li>
<li>while (true) {  </li>
<li>if (buff.size() &gt;= 10) {  </li>
<li>buff = exchanger.exchange(buff);//开始跟另外一个线程交互数据  </li>
<li>System.out.println(&quot;exchange buff1&quot;);  </li>
<li>buff.clear();  </li>
<li>}  </li>
<li>buff.add((int)(Math.random()/*100));  </li>
<li>Thread.sleep((long)(Math.random()/*1000));  </li>
<li>}  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}  </li>
<li>}).start();  </li>
<li></li>
<li>new Thread(new Runnable(){  </li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>ArrayList<Integer> buff=buff2;  </li>
<li>while(true){  </li>
<li>try {  </li>
<li>for(Integer i:buff){  </li>
<li>System.out.println(i);  </li>
<li>}  </li>
<li>Thread.sleep(1000);  </li>
<li>buff=exchanger.exchange(buff);//开始跟另外一个线程交换数据  </li>
<li>System.out.println(&quot;exchange buff2&quot;);  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}  </li>
<li>}}).start();  </li>
<li>}  </li>
<li><p>}<br> 总结：Exchanger在特定的使用场景比较有用（两个伙伴线程之间的数据交互） </p>
</li>
<li><p>ScheduledThreadPoolExecutor 
 我们先来学习一下JDK1.5 API中关于这个类的详细介绍： 
 &quot;可另行安排在给定的延迟后运行命令，或者定期执行命令。需要多个辅助线程时，或者要求 ThreadPoolExecutor 具有额外的灵活性或功能时，此类要优于 Timer。 
 一旦启用已延迟的任务就执行它，但是有关何时启用，启用后何时执行则没有任何实时保证。按照提交的先进先出 (FIFO) 顺序来启用那些被安排在同一执行时间的任务。 
 虽然此类继承自 ThreadPoolExecutor，但是几个继承的调整方法对此类并无作用。特别是，因为它作为一个使用 corePoolSize 线程和一个无界队列的固定大小的池，所以调整 maximumPoolSize 没有什么效果。&quot; 
 在JDK1.5之前，我们关于定时/周期操作都是通过Timer来实现的。但是Timer有以下几种危险[JCIP] 
a. Timer是基于绝对时间的。容易受系统时钟的影响。 
b. Timer只新建了一个线程来执行所有的TimeTask。所有TimeTask可能会相关影响 
c. Timer不会捕获TimerTask的异常，只是简单地停止。这样势必会影响其他TimeTask的执行。 
 如果你是使用JDK1.5以上版本，建议用ScheduledThreadPoolExecutor代替Timer。它基本上解决了上述问题。它采用相对时间，用线程池来执行TimerTask，会出来TimerTask异常。 
 下面通过一个简单的实例来阐述ScheduledThreadPoolExecutor的使用。 </p>
<p> 我们定期让定时器抛异常 
 我们定期从控制台打印系统时间 
代码如下（参考了网上的一些代码，在此表示感谢） 
Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
</li>
<li><p>import java.util.concurrent.ScheduledThreadPoolExecutor;  </p>
</li>
<li>import java.util.concurrent.TimeUnit;  </li>
<li></li>
<li></li>
<li>public class TestScheduledThreadPoolExecutor {  </li>
<li></li>
<li>public static void main(String[] args) {  </li>
<li>ScheduledThreadPoolExecutor exec=new ScheduledThreadPoolExecutor(1);  </li>
<li></li>
<li>exec.scheduleAtFixedRate(new Runnable(){//每隔一段时间就触发异常  </li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>throw new RuntimeException();  </li>
<li>}}, 1000, 5000, TimeUnit.MILLISECONDS);  </li>
<li></li>
<li>exec.scheduleAtFixedRate(new Runnable(){//每隔一段时间打印系统时间，证明两者是互不影响的  </li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>System.out.println(System.nanoTime());  </li>
<li>}}, 1000, 2000, TimeUnit.MILLISECONDS);  </li>
<li>}  </li>
<li></li>
<li>}<br>总结：是时候把你的定时器换成 ScheduledThreadPoolExecutor了 </li>
</ol>
<p>7.BlockingQueue 
    “支持两个附加操作的 Queue，这两个操作是：获取元素时等待队列变为非空，以及存储元素时等待空间变得可用。“ 
    这里我们主要讨论BlockingQueue的最典型实现：LinkedBlockingQueue 和ArrayBlockingQueue。两者的不同是底层的数据结构不够，一个是链表，另外一个是数组。 </p>
<pre><code>后面将要单独解释其他类型的BlockingQueue和SynchronousQueue 
BlockingQueue的经典用途是 生产者-消费者模式 
代码如下： 
</code></pre><p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
<ol>
<li>import java.util.Random;  </li>
<li>import java.util.concurrent.BlockingQueue;  </li>
<li>import java.util.concurrent.LinkedBlockingQueue;  </li>
<li></li>
<li>public class TestBlockingQueue {  </li>
<li></li>
<li>public static void main(String[] args) {  </li>
<li>final BlockingQueue<Integer> queue=new LinkedBlockingQueue<Integer>(3);  </li>
<li>final Random random=new Random();  </li>
<li></li>
<li>class Producer implements Runnable{  </li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>while(true){  </li>
<li>try {  </li>
<li>int i=random.nextInt(100);  </li>
<li>queue.put(i);//当队列达到容量时候，会自动阻塞的  </li>
<li>if(queue.size()==3)  </li>
<li>{  </li>
<li>System.out.println(&quot;full&quot;);  </li>
<li>}  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>class Consumer implements Runnable{  </li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>while(true){  </li>
<li>try {  </li>
<li>queue.take();//当队列为空时，也会自动阻塞  </li>
<li>Thread.sleep(1000);  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>new Thread(new Producer()).start();  </li>
<li>new Thread(new Consumer()).start();  </li>
<li>}  </li>
<li></li>
<li>}<br> 总结：BlockingQueue使用时候特别注意take 和 put </li>
<li><p>DelayQueue 
我们先来学习一下JDK1.5 API中关于这个类的详细介绍： 
 “它是包含Delayed 元素的一个无界阻塞队列，只有在延迟期满时才能从中提取元素。该队列的头部 是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部，并且 poll 将返回 null。当一个元素的 getDelay(TimeUnit.NANOSECONDS) 方法返回一个小于等于 0 的值时，将发生到期。即使无法使用 take 或 poll 移除未到期的元素，也不会将这些元素作为正常元素对待。例如，size 方法同时返回到期和未到期元素的计数。此队列不允许使用 null 元素。” 
 在现实生活中，很多DelayQueue的例子。就拿上海的SB会来说明，很多国家地区的开馆时间不同。你很早就来到园区，然后急急忙忙地跑到一些心仪的馆区，发现有些还没开，你吃了闭门羹。 
 仔细研究DelayQueue，你会发现它其实就是一个PriorityQueue的封装（按照delay时间排序），里面的元素都实现了Delayed接口，相关操作需要判断延时时间是否到了。 
 在实际应用中，有人拿它来管理跟实际相关的缓存、session等 
下面我就通过 “上海SB会的例子来阐述DelayQueue的用法” 
代码如下： 
Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
</li>
<li><p>import java.util.Random;  </p>
</li>
<li>import java.util.concurrent.DelayQueue;  </li>
<li>import java.util.concurrent.Delayed;  </li>
<li>import java.util.concurrent.TimeUnit;  </li>
<li></li>
<li>public class TestDelayQueue {  </li>
<li></li>
<li>private class Stadium implements Delayed  </li>
<li>{  </li>
<li>long trigger;  </li>
<li></li>
<li>public Stadium(long i){  </li>
<li>trigger=System.currentTimeMillis()+i;  </li>
<li>}  </li>
<li></li>
<li>@Override  </li>
<li>public long getDelay(TimeUnit arg0) {  </li>
<li>long n=trigger-System.currentTimeMillis();  </li>
<li>return n;  </li>
<li>}  </li>
<li></li>
<li>@Override  </li>
<li>public int compareTo(Delayed arg0) {  </li>
<li>return (int)(this.getDelay(TimeUnit.MILLISECONDS)-arg0.getDelay(TimeUnit.MILLISECONDS));  </li>
<li>}  </li>
<li></li>
<li>public long getTriggerTime(){  </li>
<li>return trigger;  </li>
<li>}  </li>
<li></li>
<li>}  </li>
<li>public static void main(String[] args)throws Exception {  </li>
<li>Random random=new Random();  </li>
<li>DelayQueue<Stadium> queue=new DelayQueue<Stadium>();  </li>
<li>TestDelayQueue t=new TestDelayQueue();  </li>
<li></li>
<li>for(int i=0;i&lt;5;i++){  </li>
<li>queue.add(t.new Stadium(random.nextInt(30000)));  </li>
<li>}  </li>
<li>Thread.sleep(2000);  </li>
<li></li>
<li>while(true){  </li>
<li>Stadium s=queue.take();//延时时间未到就一直等待  </li>
<li>if(s!=null){  </li>
<li>System.out.println(System.currentTimeMillis()-s.getTriggerTime());//基本上是等于0  </li>
<li>}  </li>
<li>if(queue.size()==0)  </li>
<li>break;  </li>
<li>}  </li>
<li>}  </li>
<li>}<br> 总结：适用于需要延时操作的队列管理 </li>
<li><p>SynchronousQueue 
 我们先来学习一下JDK1.5 API中关于这个类的详细介绍： 
 “一种阻塞队列，其中每个插入操作必须等待另一个线程的对应移除操作 ，反之亦然。同步队列没有任何内部容量，甚至连一个队列的容量都没有。不能在同步队列上进行 peek，因为仅在试图要移除元素时，该元素才存在；除非另一个线程试图移除某个元素，否则也不能（使用任何方法）插入元素；也不能迭代队列，因为其中没有元素可用于迭代。队列的头 是尝试添加到队列中的首个已排队插入线程的元素；如果没有这样的已排队线程，则没有可用于移除的元素并且 poll() 将会返回 null。对于其他 Collection 方法（例如 contains），SynchronousQueue 作为一个空 collection。此队列不允许 null 元素。 
 同步队列类似于 CSP 和 Ada 中使用的 rendezvous 信道。它非常适合于传递性设计，在这种设计中，在一个线程中运行的对象要将某些信息、事件或任务传递给在另一个线程中运行的对象，它就必须与该对象同步。 “ 
 看起来很有意思吧。队列竟然是没有内部容量的。这个队列其实是BlockingQueue的一种实现。每个插入操作必须等待另一个线程的对应移除操作，反之亦然。它给我们提供了在线程之间交换单一元素的极轻量级方法 
应用举例：我们要在多个线程中传递一个变量。 
代码如下（其实就是生产者消费者模式） 
Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
</li>
<li><p>import java.util.Arrays;  </p>
</li>
<li>import java.util.List;  </li>
<li>import java.util.concurrent.BlockingQueue;  </li>
<li>import java.util.concurrent.SynchronousQueue;  </li>
<li></li>
<li>public class TestSynchronousQueue {  </li>
<li></li>
<li>class Producer implements Runnable {  </li>
<li>private BlockingQueue<String> queue;  </li>
<li>List<String> objects = Arrays.asList(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;);  </li>
<li></li>
<li>public Producer(BlockingQueue<String> q) {  </li>
<li>this.queue = q;  </li>
<li>}  </li>
<li></li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>try {  </li>
<li>for (String s : objects) {  </li>
<li>queue.put(s);// 产生数据放入队列中  </li>
<li>System.out.printf(&quot;put:%s%n&quot;,s);  </li>
<li>}  </li>
<li>queue.put(&quot;Done&quot;);// 已完成的标志  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>class Consumer implements Runnable {  </li>
<li>private BlockingQueue<String> queue;  </li>
<li></li>
<li>public Consumer(BlockingQueue<String> q) {  </li>
<li>this.queue = q;  </li>
<li>}  </li>
<li></li>
<li>@Override  </li>
<li>public void run() {  </li>
<li>String obj = null;  </li>
<li>try {  </li>
<li>while (!((obj = queue.take()).equals(&quot;Done&quot;))) {  </li>
<li>System.out.println(obj);//从队列中读取对象  </li>
<li>Thread.sleep(3000);     //故意sleep，证明Producer是put不进去的  </li>
<li>}  </li>
<li>} catch (InterruptedException e) {  </li>
<li>e.printStackTrace();  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>public static void main(String[] args) {  </li>
<li>BlockingQueue<String> q=new SynchronousQueue<String>();  </li>
<li>TestSynchronousQueue t=new TestSynchronousQueue();  </li>
<li>new Thread(t.new Producer(q)).start();  </li>
<li>new Thread(t.new Consumer(q)).start();  </li>
<li>}  </li>
<li></li>
<li>}<br>总结：SynchronousQueue主要用于单个元素在多线程之间的传递 </li>
</ol>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--java多线程学习-javautilconcurrent详解/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--java多线程学习-javautilconcurrent详解" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-内存--缓存算法/">缓存算法</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-内存--缓存算法/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-">缓存算法</h1>
<p><strong>缓存算法</strong></p>
<p>没有人能说清哪种缓存算法由于其他的缓存算法。（以下的几种缓存算法，有的我也理解不好，如果感兴趣，你可以Google一下 ）</p>
<p><strong>Least Frequently Used（LFU）</strong>：</p>
<p>大家好，我是 LFU，我会计算为每个缓存对象计算他们被使用的频率。我会把最不常用的缓存对象踢走。</p>
<p><strong>Least Recently User（LRU）</strong>：</p>
<p>我是LRU缓存算法，我把最近最少使用的缓存对象给踢走。</p>
<p>我总是需要去了解在什么时候，用了哪个缓存对象。如果有人想要了解我为什么总能把最近最少使用的对象踢掉，是非常困难的。</p>
<p>浏览器就是使用了我（LRU）作为缓存算法。新的对象会被放在缓存的顶部，当缓存达到了容量极限，我会把底部的对象踢走，而技巧就是：我会把最新被访问的缓存对象，放到缓存池的顶部。</p>
<p>所以，经常被读取的缓存对象就会一直呆在缓存池中。有两种方法可以实现我，array 或者是 linked list。</p>
<p>我的速度很快，我也可以被数据访问模式适配。我有一个大家庭，他们都可以完善我，甚至做的比我更好（我确实有时会嫉妒，但是没关系）。我家庭的一些成员包括LRU2 和 2Q，他们就是为了完善 LRU 而存在的。</p>
<p><strong>Least Recently Used 2（LRU2）</strong>：</p>
<p>我是 Least Recently Used 2，有人叫我最近最少使用twice，我更喜欢这个叫法。我会把被两次访问过的对象放入缓存池，当缓存池满了之后，我会把有两次最少使用的缓存对象踢走。 因为需要跟踪对象2次，访问负载就会随着缓存池的增加而增加。如果把我用在大容量的缓存池中，就会有问题。另外，我还需要跟踪那么不在缓存的对象，因为他 们还没有被第二次读取。我比LRU好，而且是 adoptive to access 模式 。</p>
<p><strong>Two Queues（2Q）</strong>：</p>
<p>我是 Two Queues；我把被访问的数据放到LRU的缓存中，如果这个对象再一次被访问，我就把他转移到第二个、更大的LRU缓存。</p>
<p>我踢走缓存对象是为了保持第一个缓存池是第二个缓存池的1/3。当缓存的访问负载是固定的时候，把 LRU 换成 LRU2，就比增加缓存的容量更好。这种机制使得我比 LRU2 更好，我也是 LRU 家族中的一员，而且是 adoptive to access 模式 。</p>
<p><strong>Adaptive Replacement Cache（ARC）</strong>：</p>
<p>我是 ARC，有人说我是介于 LRU 和 LFU 之间，为了提高效果，我是由2个 LRU 组成，第一个，也就是 L1，包含的条目是最近只被使用过一次的，而第二个 LRU，也就是 L2，包含的是最近被使用过两次的条目。因此， L1 放的是新的对象，而 L2 放的是常用的对象。所以，别人才会认为我是介于 LRU 和 LFU 之间的，不过没关系，我不介意。</p>
<p>我被认为是性能最好的缓存算法之一，能够自调，并且是低负载的。我也保存着历史对象，这样，我就可以记住那些被移除的对象，同时，也让我可以看到被移除的对象是否可以留下，取而代之的是踢走别的对象。我的记忆力很差，但是我很快，适用性也强。</p>
<p><strong>Most Recently Used（MRU）</strong>：</p>
<p>我是 MRU，和 LRU 是对应的。我会移除最近最多被使用的对象，你一定会问我为什么。好吧，让我告诉你，当一次访问过来的时候，有些事情是无法预测的，并且在缓存系统中找出最少最近使用的对象是一项时间复杂度非常高的运算，这就是为什么我是最好的选择。</p>
<p>我是数据库内存缓存中是多么的常见！每当一次缓存记录的使用，我会把它放到栈的顶端。当栈满了的时候，你猜怎么着？我会把栈顶的对象给换成新进来的对象！</p>
<p><strong>First in First out（FIFO）</strong>：</p>
<p>我是先进先出，我是一个低负载的算法，并且对缓存对象的管理要求不高。我通过一个队列去跟踪所有的缓存对象，最近最常用的缓存对象放在后面，而更早的缓存对象放在前面，当缓存容量满时，排在前面的缓存对象会被踢走，然后把新的缓存对象加进去。我很快，但是我并不适用。</p>
<p><strong>Second Chance</strong>：</p>
<p>大家好，我是 second chance，我是通过FIFO修改而来的，被大家叫做 second chance 缓存算法，我比 FIFO 好的地方是我改善了 FIFO 的成本。我是 FIFO 一样也是在观察队列的前端，但是很FIFO的立刻踢出不同，我会检查即将要被踢出的对象有没有之前被使用过的标志（1一个bit表示），没有没有被使用 过，我就把他踢出；否则，我会把这个标志位清除，然后把这个缓存对象当做新增缓存对象加入队列。你可以想象就这就像一个环队列。当我再一次在队头碰到这个 对象时，由于他已经没有这个标志位了，所以我立刻就把他踢开了。我在速度上比FIFO快。</p>
<p><strong>CLock</strong></p>
<p>我是Clock，一个更好的FIFO，也比 second chance更好。因为我不会像second chance那样把有标志的缓存对象放到队列的尾部，但是也可以达到second chance的效果。</p>
<p>我持有一个装有缓存对象的环形列表，头指针指向列表中最老的缓存对象。当缓存miss发生并且没有新的缓存空间时，我会问问指针指向的缓存对象的标 志位去决定我应该怎么做。如果标志是0，我会直接用新的缓存对象替代这个缓存对象；如果标志位是1，我会把头指针递增，然后重复这个过程，知道新的缓存对 象能够被放入。我比second chance更快。</p>
<p><strong>Simple time-based</strong>：</p>
<p>我是 simple time-based 缓存算法，我通过绝对的时间周期去失效那些缓存对象。对于新增的对象，我会保存特定的时间。我很快，但是我并不适用。</p>
<p><strong>Extended time-based expiration</strong>：</p>
<p>我是 extended time-based expiration 缓存算法，我是通过相对时间去失效缓存对象的；对于新增的缓存对象，我会保存特定的时间，比如是每5分钟，每天的12点。</p>
<p><strong>Sliding time-based expiration</strong>：</p>
<p>我是 sliding time-based expiration，与前面不同的是，被我管理的缓存对象的生命起点是在这个缓存的最后被访问时间算起的。我很快，但是我也不太适用。</p>
<p>好了！听了那么多缓存算法的自我介绍，其他的缓存算法还考虑到了下面几点：</p>
<p>成本。如果缓存对象有不同的成本，应该把那些难以获得的对象保存下来。
容量。如果缓存对象有不同的大小，应该把那些大的缓存对象清除，这样就可以让更多的小缓存对象进来了。
时间。一些缓存还保存着缓存的过期时间。电脑会失效他们，因为他们已经过期了。
根据缓存对象的大小而不管其他的缓存算法可能是有必要的。</p>
<p><strong>Random Cache</strong>：</p>
<p>我是随机缓存，我随意的替换缓存实体，没人敢抱怨。你可以说那个被替换的实体很倒霉。通过这些行为，我随意的去处缓存实体。我比FIFO机制好，在某些情况下，我甚至比 LRU 好，但是，通常LRU都会比我好。</p>
<p>看看缓存元素（缓存实体）
public class CacheElement {</p>
<p>private Object objectValue;</p>
<p>private Object objectKey;</p>
<p>private int index;</p>
<p>private int hitCount;</p>
<p>// getters and setters</p>
<p>}</p>
<p>这个缓存实体拥有缓存的key和value，这个实体的数据结构会被以下所有缓存算法用到。</p>
<p>缓存算法的公用代码
public final synchronized void addElement(Object key,Object value) {</p>
<p>int index;
Object obj;</p>
<p>// get the entry from the table
obj = table.get(key);</p>
<p>// If we have the entry already in our table
then get it and replace only its value.
if (obj != null) {
CacheElement element;</p>
<p>element = (CacheElement) obj;
element.setObjectValue(value);
element.setObjectKey(key);</p>
<p>return;
}
}</p>
<p>上面的代码会被所有的缓存算法实现用到。这段代码是用来检查缓存元素是否在缓存中了，如果是，我们就替换它，但是如果我们找不到这个key对应的缓存，我们会怎么做呢？那我们就来深入的看看会发生什么吧！</p>
<p>现场访问</p>
<p>今天的专题很特殊，因为我们有特殊的客人，事实上他们是我们想要听的与会者，但是首先，先介绍一下我们的客人：Random Cache，FIFO Cache。让我们从 Random Cache开始。</p>
<p>看看随机缓存的实现
public final synchronized void addElement(Object key,Object value) {</p>
<p>int index;
Object obj;</p>
<p>obj = table.get(key);</p>
<p>if (obj != null) {
CacheElement element;</p>
<p>// Just replace the value.
element = (CacheElement) obj;
element.setObjectValue(value);
element.setObjectKey(key);</p>
<p>return;
}</p>
<p>// If we haven’t
filled the cache yet, put it at the end.
if (!isFull()) {
index = numEntries;
++numEntries;
} else {
// Otherwise, replace a random entry.
index = (int) (cache.length /* random.nextFloat());
table.remove(cache[index].getObjectKey());
}</p>
<p>cache[index].setObjectValue(value);
cache[index].setObjectKey(key);
table.put(key, cache[index]);
}</p>
<p>看看FIFO缓存算法的实现</p>
<p>public final synchronized void addElement(Object
key,Object value) {
int index;
Object obj;</p>
<p>obj = table.get(key);</p>
<p>if (obj != null) {
CacheElement element;</p>
<p>// Just replace the value.
element = (CacheElement) obj;
element.setObjectValue(value);
element.setObjectKey(key);</p>
<p>return;
}</p>
<p>// If we haven’t filled the cache yet, put it at the end.
if (!isFull()) {
index = numEntries;
++numEntries;
} else {
// Otherwise, replace the current pointer, entry with the new one
index = current;
// in order to make Circular FIFO
if (++current &gt;= cache.length)
current = 0;</p>
<p>table.remove(cache[index].getObjectKey());
}</p>
<p>cache[index].setObjectValue(value);
cache[index].setObjectKey(key);
table.put(key, cache[index]);
}</p>
<p>看看LFU缓存算法的实现</p>
<p>public synchronized Object getElement(Object key) {</p>
<p>Object obj;</p>
<p>obj = table.get(key);</p>
<p>if (obj != null) {
CacheElement element = (CacheElement) obj;
element.setHitCount(element.getHitCount() + 1);
return element.getObjectValue();
}
return null;</p>
<p>}</p>
<p>public final synchronized void addElement(Object key, Object value) {</p>
<p>Object obj;</p>
<p>obj = table.get(key);</p>
<p>if (obj != null) {
CacheElement element;</p>
<p>// Just replace the value.
element = (CacheElement) obj;
element.setObjectValue(value);
element.setObjectKey(key);</p>
<p>return;
}</p>
<p>if (!isFull()) {</p>
<p>index = numEntries;
++numEntries;
} else {
CacheElement element = removeLfuElement();
index = element.getIndex();
table.remove(element.getObjectKey());
}</p>
<p>cache[index].setObjectValue(value);
cache[index].setObjectKey(key);
cache[index].setIndex(index);
table.put(key, cache[index]);
}</p>
<p>public CacheElement removeLfuElement() {</p>
<p>CacheElement[] elements = getElementsFromTable();
CacheElement leastElement = leastHit(elements);
return leastElement;
}</p>
<p>public static CacheElement leastHit(CacheElement[] elements) {</p>
<p>CacheElement lowestElement = null;
for (int i = 0; i &lt; elements.length; i++) {
CacheElement element = elements[i];
if (lowestElement == null) {
lowestElement = element;</p>
<p>} else {
if (element.getHitCount() &lt; lowestElement.getHitCount()) { lowestElement = element; }</p>
<p>}</p>
<p>}</p>
<p>return lowestElement;</p>
<p>}</p>
<p>最重点的代码，就应该是 leastHit 这个方法，这段代码就是把 hitCount 最低的元素找出来，然后删除，给新进的缓存元素留位置。 看看LRU缓存算法实现</p>
<p>private void moveToFront(int index) {</p>
<p>int nextIndex, prevIndex;</p>
<p>if(head != index) {</p>
<p>nextIndex = next[index];</p>
<p>prevIndex = prev[index]; // Only the head has a prev entry that is an invalid index so // we don’t check. next[prevIndex] = nextIndex; // Make sure index is valid. If it isn’t, we’re at the tail // and don’t set prev[next]. if(nextIndex &gt;= 0)
prev[nextIndex] = prevIndex;
else
tail = prevIndex;</p>
<p>prev[index] = -1;
next[index] = head;
prev[head] = index;
head = index;
}
}</p>
<p>public final synchronized void addElement(Object key, Object value) {
int index;
Object obj;</p>
<p>obj = table.get(key);</p>
<p>if(obj != null) {
CacheElement entry;</p>
<p>// Just replace the value, but move it to the front.
entry = (CacheElement)obj;
entry.setObjectValue(value);
entry.setObjectKey(key);</p>
<p>moveToFront(entry.getIndex());</p>
<p>return;
}</p>
<p>// If we haven’t filled the cache yet, place in next available spot
// and move to front.
if(!isFull()) {
if(_numEntries &gt; 0) {
prev[_numEntries] = tail;
next[_numEntries] = -1;
moveToFront(numEntries);
}
++numEntries;
} else {
// We replace the tail of the list.
table.remove(cache[tail].getObjectKey());
moveToFront(tail);
}</p>
<p>cache[head].setObjectValue(value);
cache[head].setObjectKey(key);
table.put(key, cache[head]);
}</p>
<p>这段代码的逻辑如 LRU算法 的描述一样，把再次用到的缓存提取到最前面，而每次删除的都是最后面的元素。</p>
<p>结论</p>
<p>我们已经看到 LFU缓存算法 和 LRU缓存算法的实现方式，至于如何实现，采用数组还是 LinkedHashMap，都由你决定，不够我一般是小的缓存容量用数组，大的用LinkedHashMap。
来源： <a href="[http://www.yiihsia.com/2011/01/%e7%bc%93%e5%ad%98%e7%ae%97%e6%b3%95/](http://www.yiihsia.com/2011/01/%e7%bc%93%e5%ad%98%e7%ae%97%e6%b3%95/)">[http://www.yiihsia.com/2011/01/%e7%bc%93%e5%ad%98%e7%ae%97%e6%b3%95/](http://www.yiihsia.com/2011/01/%e7%bc%93%e5%ad%98%e7%ae%97%e6%b3%95/)</a> 
Intro to Caching,Caching algorithms and caching frameworks part 2</p>
<p>Introduction:
In this part we are going to show how to implement some of the famous replacement algorithms as we mentioned in <a href="http://www.jtraining.com/blogs/intro-to-caching-caching-algorithms-and-caching-frameworks.html" target="_blank">part 1</a>, the code in this article is just for demonstration purpose which means you will have to do some extra effort if you want to make use of it in your application (if you are going to build your own implementation and wont use any caching frameworks)</p>
<p>The Leftover policy:</p>
<p>After programmer 1 read the article he proceeded to review the comments on this article, one of these comments were talking about leftover policy, which is named “Random Cache”</p>
<p>Random Cache:</p>
<p>I am random cache, I replace any cache entry I want, I just do that and no one can complain about that, you can say the unlucky entry, by doing this I remove any overhead of tracking references or so, am better than FIFO policy, in some cases I perform even better than LRU but in general LRU is better than me.</p>
<p>It is comment time:</p>
<p>While programmer 1 was reading the rest of the comments, he found very interesting comment about implementation of some of the famous replacement policies, actually it was a link to the commenter site which has the actual implementation so programmer 1 clicked the link and here what he got:</p>
<p>Meet the Cache Element:
public class CacheElement {
private Object objectValue;
private Object objectKey;
private int index;
private int
hitCount;
.
. // getters and setters
.
}</p>
<p>This is the cache entry which will use to hold the key and the value; this will be used in all the cache algorithms implementation</p>
<p>Common Code for All Caches:
public final synchronized void addElement(Object key,Object value) {
int index;
Object obj;
// get the entry from the table
obj = table.get(key);
// If we have the entry already in our table
then get it and replace only its value.
if (obj != null) {
CacheElement
element;
element = (CacheElement) obj;
element.setObjectValue(value);
element.setObjectKey(key);
return;
}
}</p>
<p>The above code will be common for all our implementation; it is about checking if the cacheElemnet already exists in our cache, if so then we just need to place its value and we don’t need to make anything else but what if we didn’t find it ? Then we will have to dig deeper and see what will happen below.</p>
<p>The Talk Show:</p>
<p>Today’s episode is a special episode , we have special guests , they are in fact compotators we are going to hear what everyone has to say but first lets introduce our guests:</p>
<p>Random Cache, FIFO Cache</p>
<p>Let’s start with the Random Cache.</p>
<p>Meet Random Cache implementation:
public final synchronized void addElement(Object key,Object value) {
int index;
Object obj;
obj = table.get(key);
if (obj
!= null) {
CacheElement element;
// Just replace the value.
element = (CacheElement) obj;
element.setObjectValue(value);
element.setObjectKey(key);
return;
}
// If we haven&#39;t
filled the cache yet, put it at the end.
if (!isFull()) {
index =
numEntries;
++numEntries;
} else {
// Otherwise, replace a random
entry.
index = (int) (cache.length /* random.nextFloat());
table.remove(cache[index].getObjectKey());
}
cache[index].setObjectValue(value);
cache[index].setObjectKey(key);
table.put(key, cache[index]);
}</p>
<p>Analyzing Random Cache Code (Talk show):</p>
<p>In today’s show the Random Cache is going to explain the code line by line and here we go.
I will go straight to the main point; if I am not full then I will place the new entry that the client requested at the end of the cache (in case there is a cache miss).</p>
<p>I do this by getting the number of entries that resides in the cache and assign it to index (which will be the index of the current entry the client is adding) after that I increment the number of entries.
if (!isFull()) {
index = numEntries;
++numEntries;
}</p>
<p>If I don’t have enough room for the current entry, I will have to kick out a random entry (totally random, bribing isn’t allowed).</p>
<p>In order to get the random entry, I will use the random util. shipped with java to generate a random index and ask the cache to remove the entry that its index equal to the generated index.
else {
// Otherwise, replace a random entry.
index = (int) (cache.length /* random.nextFloat());
table.remove(cache[index].getObjectKey());
}</p>
<p>At the end I just place the entry -either the cache was full or no- in the cache.</p>
<p>cache[index].setObjectValue(value);
cache[index].setObjectKey(key);
table.put(key, cache[index]);</p>
<p>Magnifying the Code:</p>
<p>It is said that when you look at stuff from a near view it is better to understand it, so that’s why we have a magnifying glass and we are going to magnify the code to get more near to it (and maybe understand it more).</p>
<p>Cache entries in the same voice: hi ho, hi ho, into cache we go.</p>
<p>New cache entry: excuse me; I have a question! (Asking a singing old cache entry near to him)</p>
<p>Old cache entry: go ahead.</p>
<p>New cache entry: I am new here and I don’t understand my role exactly, how will the algorithm handle us?</p>
<p>Old cache entry: cache! (Instead of man!), you remind me of myself when I was new (1st time I was added to the cache), I used to ask questions like that, let me show you what will happen.
<img src="" alt=""></p>
<p>Meet FIFO Cache Implementation:</p>
<p>public final synchronized void addElement(Object
key,Object value) {
int index;
Object obj;
obj = table.get(key);
if (obj != null) {
CacheElement element;
// Just replace the
value.
element = (CacheElement) obj;
element.setObjectValue(value);
element.setObjectKey(key);
return;
}
// If we haven&#39;t
filled the cache yet, put it at the end.
if (!isFull()) {
index =
numEntries;
++numEntries;
} else {
// Otherwise, replace the current
pointer, entry with the new one
index = current;
// in order to make
Circular FIFO
if (++current &gt;= cache.length)
current = 0;
table.remove(cache[index].getObjectKey());
}
cache[index].setObjectValue(value);
cache[index].setObjectKey(key);
table.put(key, cache[index]);
}</p>
<p>Analyzing FIFO Cache Code (Talk show):</p>
<p>After Random Cache, audience went crazy for random cache, which made FIFO a little bit jealous so FIFO started talking and said:</p>
<p>When there is no more rooms for the new cache entry , I will have to kick out the entry at the front (the one came first) as I work in a circular queue like manner, by default the current position is at the beginning of the queue(points to the beginning of the queue).</p>
<p>I assign current value to index (index of the current entry) and then check to see if the incremented current greater than or equals to the cache length(coz I want to reset current –pointer- position to the beginning of the queue) ,if so then I will set current to zero again ,after that I just kick the entry at the index position (Which is the first entry in the queue now) and place the new entry.
else {
// Otherwise, replace the current pointer,
which takes care of
// FIFO in a circular fashion.
index = current;
if (++current &gt;= cache.length)
current = 0;
table.remove(cache[index].getObjectKey());
}
cache[index].setObjectValue(value);
cache[index].setObjectKey(key);
table.put(key, cache[index]);</p>
<p>Magnifying the Code:</p>
<p>Back to our magnifying glass we can observe the following actions happening to our entries</p>
<p><img src="" alt="">Conclusion:</p>
<p>As we have seen in this article how to implement the FIFO replacement policy and also Random replacement policy, in the upcoming articles we will try to take our magnifying glass and magnify LFU, LRU replacement policy, till then stay tuned ;)</p>
<p>来源： <a href="[http://www.jtraining.com/component/content/article/35-jtraining-blog/137.html](http://www.jtraining.com/component/content/article/35-jtraining-blog/137.html)">[http://www.jtraining.com/component/content/article/35-jtraining-blog/137.html](http://www.jtraining.com/component/content/article/35-jtraining-blog/137.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/内存/">内存</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/内存/" class="label label-info">内存</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-内存--缓存算法/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-内存--缓存算法" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-内存--深入理解Java内存模型（七）——总结/">深入理解Java内存模型（七）——总结</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-内存--深入理解Java内存模型（七）——总结/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-">深入理解Java内存模型（七）——总结</h1>
<h3 id="-">分享到</h3>
<ul>
<li><a href="">一键分享</a></li>
<li><a href="">QQ空间</a></li>
<li><a href="">新浪微博</a></li>
<li><a href="">百度搜藏</a></li>
<li><a href="">人人网</a></li>
<li><a href="">腾讯微博</a></li>
<li><a href="">百度相册</a></li>
<li><a href="">开心网</a></li>
<li><a href="">腾讯朋友</a></li>
<li><a href="">百度贴吧</a></li>
<li><a href="">豆瓣网</a></li>
<li><a href="">搜狐微博</a></li>
<li><a href="">百度新首页</a></li>
<li><a href="">QQ好友</a></li>
<li><a href="">和讯微博</a></li>
<li><a href="">更多...</a></li>
</ul>
<p><a href="">百度分享</a></p>
<ul>
<li><a href="http://www.infoq.com/cn/aboutus" title="关于我们" target="_blank">关于我们</a></li>
<li><p><a href="http://www.infoq.com/cn/contribute" title="让大家在InfoQ上听见你的声音" target="_blank">让大家在InfoQ上听见你的声音</a></p>
</li>
<li><p>欢迎关注我们的：</p>
</li>
<li><a href="http://e.weibo.com/infoqchina" target="_blank"><img src="" alt=""></a></li>
<li><a href="http://www.infoq.com/cn/news/2013/02/infoq-wechat" target="_blank"><img src="" alt=""></a></li>
<li><a href="http://www.infoq.com/cn/rss/rss.action?token=AjlwmaWcwi5ejkcT6GcRk1pCqJ4K7ocs" target="_blank"><img src="" alt=""></a></li>
</ul>
<p>促进软件开发领域知识与创新的传播</p>
<p><a href="&quot;Login&quot;">登录</a>
<a href="http://www.infoq.com/cn/" target="_blank"><img src="" alt=""></a></p>
<ul>
<li><a href="http://www.infoq.com/" target="_blank">En</a> |</li>
<li><a href="&quot;InfoQ China&quot;">中文</a> |</li>
<li><a href="http://www.infoq.com/jp/" target="_blank">日本</a> |</li>
<li><a href="http://www.infoq.com/fr/" target="_blank">Fr</a> |</li>
<li><a href="http://www.infoq.com/br/" target="_blank">Br</a></li>
</ul>
<p>164,153 六月 独立访问用户</p>
<ul>
<li><p><a href="http://www.infoq.com/cn/development/" title="Development" target="_blank">语言 &amp; 开发</a></p>
</li>
<li><p><a href="http://www.infoq.com/cn/java/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="Java" target="_blank">Java</a></p>
</li>
<li><a href="http://www.infoq.com/cn/dotnet/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title=".Net" target="_blank">.Net</a></li>
<li><a href="http://www.infoq.com/cn/cloud-computing/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="云计算" target="_blank">云计算</a></li>
<li><a href="http://www.infoq.com/cn/mobile/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="移动" target="_blank">移动</a></li>
<li><a href="http://www.infoq.com/cn/HTML5Topic/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="HTML 5" target="_blank">HTML 5</a></li>
<li><a href="http://www.infoq.com/cn/javascript/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="JavaScript" target="_blank">JavaScript</a></li>
<li><a href="http://www.infoq.com/cn/ruby/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="Ruby" target="_blank">Ruby</a></li>
<li><a href="http://www.infoq.com/cn/dsl/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="DSLs" target="_blank">DSLs</a></li>
<li><a href="http://www.infoq.com/cn/python/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="Python" target="_blank">Python</a></li>
<li><a href="http://www.infoq.com/cn/Topic_PHP/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="PHP" target="_blank">PHP</a></li>
<li><a href="http://www.infoq.com/cn/PaaS/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="PaaS" target="_blank">PaaS</a></li>
</ul>
<h2 id="-">特别专题语言 &amp; 开发</h2>
<h3 id="-juergen-fesslmeier-javascript-http-www-infoq-com-cn-interviews-end-to-end-javascript-"><a href="http://www.infoq.com/cn/interviews/end-to-end-javascript" target="_blank">Juergen Fesslmeier谈端到端的JavaScript开发</a></h3>
<p><img src="" alt=""> Juergen谈论了使用JavaScript进行端对端开发的好处和开发团队可能遇见的挑战。他还谈到了Wakanda Studio以及如何仅用JavaScript通过它来开发复杂的应用程序。
<a href="http://www.infoq.com/cn/development/" target="_blank">浏览所有<strong>语言 &amp; 开发</strong></a></p>
<ul>
<li><p><a href="http://www.infoq.com/cn/architecture-design/" title="Architecture &amp; Design" target="_blank">架构 &amp; 设计</a></p>
</li>
<li><p><a href="http://www.infoq.com/cn/Modeling/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="建模" target="_blank">建模</a></p>
</li>
<li><a href="http://www.infoq.com/cn/performance-scalability/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="性能和可伸缩性" target="_blank">性能和可伸缩性</a></li>
<li><a href="http://www.infoq.com/cn/domain-driven-design/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="领域驱动设计" target="_blank">领域驱动设计</a></li>
<li><a href="http://www.infoq.com/cn/AOP/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="AOP" target="_blank">AOP</a></li>
<li><a href="http://www.infoq.com/cn/DesignPattern/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="设计模式" target="_blank">设计模式</a></li>
<li><a href="http://www.infoq.com/cn/Security/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="安全" target="_blank">安全</a></li>
<li><a href="http://www.infoq.com/cn/cloud-computing/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="云计算" target="_blank">云计算</a></li>
<li><a href="http://www.infoq.com/cn/soa_platforms/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="SOA" target="_blank">SOA</a></li>
</ul>
<h2 id="-">特别专题架构 &amp; 设计</h2>
<h3 id="-http-www-infoq-com-cn-articles-design-pattern-automation-"><a href="http://www.infoq.com/cn/articles/Design-Pattern-Automation" target="_blank">设计模式自动化</a></h3>
<p><img src="" alt=""> 尽管维护每行代码的成本如此高昂，但我们仍然每天都在编写着大量的样板代码。如果我们有更智能的编译器，那其中很大一部分是可以避免的。实际上，多数模板代码只是重复地实现那些我们已理解透彻的设计模式，只要我们教会编译器一些技巧，有一些设计模式完全是可以自动实现的。
<a href="http://www.infoq.com/cn/architecture-design/" target="_blank">浏览所有<strong>架构 &amp; 设计</strong></a></p>
<ul>
<li><p><a href="http://www.infoq.com/cn/process-practices/" title="Process &amp; Practices" target="_blank">过程 &amp; 实践</a></p>
</li>
<li><p><a href="http://www.infoq.com/cn/agile/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="Agile" target="_blank">Agile</a></p>
</li>
<li><a href="http://www.infoq.com/cn/Leadership/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="领导能力" target="_blank">领导能力</a></li>
<li><a href="http://www.infoq.com/cn/team-collaboration/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="团队协作" target="_blank">团队协作</a></li>
<li><a href="http://www.infoq.com/cn/agile_techniques/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="敏捷技术" target="_blank">敏捷技术</a></li>
<li><a href="http://www.infoq.com/cn/methodologies/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="方法论" target="_blank">方法论</a></li>
<li><a href="http://www.infoq.com/cn/continuous_integration/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="持续集成" target="_blank">持续集成</a></li>
<li><a href="http://www.infoq.com/cn/lean/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="精益" target="_blank">精益</a></li>
<li><a href="http://www.infoq.com/cn/cust_requirements/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="客户及需求" target="_blank">客户及需求</a></li>
</ul>
<h2 id="-">特别专题过程 &amp; 实践</h2>
<h3 id="-alm-http-www-infoq-com-cn-articles-integrated-alm-"><a href="http://www.infoq.com/cn/articles/Integrated-ALM" target="_blank">成功的根本—集成的ALM工具</a></h3>
<p><img src="" alt=""> 典型的软件交付项目会无数次地去获取需求，并在多个地方描述测试，但它们却与某一特定的构建里的具体内容并不相符合，因此项目往往需要大量分析来获知谁在做什么以及为什么做。Dave West深入研究造成该问题的原因，并致力研究一个整体的、集成的ALM方法。
<a href="http://www.infoq.com/cn/process-practices/" target="_blank">浏览所有<strong>过程 &amp; 实践</strong></a></p>
<ul>
<li><p><a href="http://www.infoq.com/cn/operations-infrastructure/" title="Operations &amp; Infrastructure" target="_blank">运维 &amp; 基础架构</a></p>
</li>
<li><p><a href="http://www.infoq.com/cn/performance-scalability/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="性能和可伸缩性" target="_blank">性能和可伸缩性</a></p>
</li>
<li><a href="http://www.infoq.com/cn/bigdata/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="大数据" target="_blank">大数据</a></li>
<li><a href="http://www.infoq.com/cn/devops/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="DevOps" target="_blank">DevOps</a></li>
<li><a href="http://www.infoq.com/cn/cloud-computing/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="云计算" target="_blank">云计算</a></li>
<li><a href="http://www.infoq.com/cn/virtualization/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="虚拟化" target="_blank">虚拟化</a></li>
<li><a href="http://www.infoq.com/cn/NoSQL/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="NoSQL" target="_blank">NoSQL</a></li>
<li><a href="http://www.infoq.com/cn/ApplicationServers/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="应用服务器" target="_blank">应用服务器</a></li>
<li><a href="http://www.infoq.com/cn/operations/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="运维" target="_blank">运维</a></li>
</ul>
<h2 id="-">特别专题运维 &amp; 基础架构</h2>
<h3 id="-http-www-infoq-com-cn-articles-atdd-by-example-book-"><a href="http://www.infoq.com/cn/articles/atdd-by-example-book" target="_blank">书评：验收测试驱动开发实践指南</a></h3>
<p><img src="" alt=""> 《验收测试驱动开发实践指南》一书的目的是作为一个介绍性使用指南指导那些从零开始的团队成功执行和应用验收测试驱动开发（ATDD）。尽管该书在指出及总结了成功敏捷测试人员应该掌握的多个测试相关实践上做了有效的工作，但该书最终并没有为它的各层读者提供他们所需要的信息。By Manuel Pais
<a href="http://www.infoq.com/cn/operations-infrastructure/" target="_blank">浏览所有<strong>运维 &amp; 基础架构</strong></a></p>
<ul>
<li><p><a href="http://www.infoq.com/cn/enterprise-architect/" title="Enterprise Architecture" target="_blank">企业架构</a></p>
</li>
<li><p><a href="http://www.infoq.com/cn/enterprise-architecture/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="企业架构" target="_blank">企业架构</a></p>
</li>
<li><a href="http://www.infoq.com/cn/bpm/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="业务流程建模" target="_blank">业务流程建模</a></li>
<li><a href="http://www.infoq.com/cn/business_it_alignment/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="业务/IT整合" target="_blank">业务/IT整合</a></li>
<li><a href="http://www.infoq.com/cn/EAI/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="Integration (EAI)" target="_blank">Integration (EAI)</a></li>
<li><a href="http://www.infoq.com/cn/Governance/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="治理" target="_blank">治理</a></li>
<li><a href="http://www.infoq.com/cn/web20/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="Web 2.0" target="_blank">Web 2.0</a></li>
<li><a href="http://www.infoq.com/cn/soa/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="SOA" target="_blank">SOA</a></li>
</ul>
<h2 id="-">特别专题企业架构</h2>
<h3 id="-http-www-infoq-com-cn-articles-designing-a-world-at-your-fingertips-mobile-user-interfaces-"><a href="http://www.infoq.com/cn/articles/designing-a-world-at-your-fingertips-mobile-user-interfaces" target="_blank">设计指尖上的世界：移动用户界面一瞥</a></h3>
<p><img src="" alt=""> 对任何成功的移动应用来说，用户界面（UI）是至关重要的组成部分。在这篇文章中，Forrest Skull展示了他与人机交互（HCI）研究者们进行的访谈与讨论，他们探讨了移动设备UI方面的原则，以及其它一些正在研究的领域，包括多设备、隐私、安全和语音。这篇文章还描述了开发移动设备用户界面过程中会面临的挑战。
<a href="http://www.infoq.com/cn/enterprise-architect/" target="_blank">浏览所有<strong>企业架构</strong></a>
<a href="http://www.qconshanghai.com/" title="New York 2013"><strong>QCon上海2013</strong>
11月1-3日
上海光大会展中心</a></p>
<ul>
<li><a href="http://www.infoq.com/cn/mobile/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="移动" target="_blank">移动</a></li>
<li><a href="http://www.infoq.com/cn/html-5/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="HTML 5" target="_blank">HTML 5</a></li>
<li><a href="http://www.infoq.com/cn/nodejs/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="Node.js" target="_blank">Node.js</a></li>
<li><a href="http://www.infoq.com/cn/cloud-computing/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="云计算" target="_blank">云计算</a></li>
<li><a href="http://www.infoq.com/cn/bigdata/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="大数据" target="_blank">大数据</a></li>
<li><a href="http://www.infoq.com/cn/operations/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="运维" target="_blank">运维</a></li>
<li><a href="http://www.infoq.com/cn/architect/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="架构师" target="_blank">架构师</a></li>
<li><a href="http://www.infoq.com/cn/baidu_cloud/?utm_source=infoq&amp;utm_medium=header_graybar&amp;utm_campaign=topic_clk" title="百度云" target="_blank">百度云</a>
<a href="http://www.infoq.com/cn/topics" target="_blank">全部话题</a></li>
</ul>
<p><a href="http://www.infoq.com/news/2013/04/infoq-redesign" target="_blank">New UI</a>
您目前处于： <a href="http://www.infoq.com/cn" title="InfoQ首页" target="_blank">InfoQ首页</a> <a href="http://www.infoq.com/cn/articles" title="文章" target="_blank">文章</a> 深入理解Java内存模型（七）——总结</p>
<h1 id="-java-">深入理解Java内存模型（七）——总结</h1>
<p>作者 <a href="http://www.infoq.com/cn/author/%E7%A8%8B%E6%99%93%E6%98%8E" target="_blank">程晓明</a> 发布于 三月 15, 2013 <em>|</em> <a href="">4 评论</a></p>
<ul>
<li><a href="&quot;分享到新浪微博&quot;">新浪微博</a> <a href="&quot;分享到腾讯微博&quot;">腾讯微博</a> <a href="&quot;分享到豆瓣网&quot;">豆瓣网</a> <a href="&quot;分享到Twitter&quot;">Twitter</a> <a href="&quot;分享到Facebook&quot;">Facebook</a> <a href="&quot;分享到linkedin&quot;">linkedin</a> <a href="&quot;分享到邮件分享&quot;">邮件分享</a> 更多 <a href="&quot;累计分享23次&quot;">23</a></li>
<li><a href="">稍后阅读</a></li>
<li><a href="http://www.infoq.com/cn/showbookmarks.action" target="_blank">我的阅读清单</a><h2 id="-">处理器内存模型</h2>
</li>
</ul>
<p>顺序一致性内存模型是一个理论参考模型，JMM和处理器内存模型在设计时通常会把顺序一致性内存模型作为参照。JMM和处理器内存模型在设计时会对顺序一致性模型做一些放松，因为如果完全按照顺序一致性模型来实现处理器和JMM，那么很多的处理器和编译器优化都要被禁止，这对执行性能将会有很大的影响。</p>
<p>根据对不同类型读/写操作组合的执行顺序的放松，可以把常见处理器的内存模型划分为下面几种类型：</p>
<ol>
<li>放松程序中写-读操作的顺序，由此产生了total store ordering内存模型（简称为TSO）。</li>
<li>在前面1的基础上，继续放松程序中写-写操作的顺序，由此产生了partial store order 内存模型（简称为PSO）。</li>
<li>在前面1和2的基础上，继续放松程序中读-写和读-读操作的顺序，由此产生了relaxed memory order内存模型（简称为RMO）和PowerPC内存模型。</li>
</ol>
<p>注意，这里处理器对读/写操作的放松，是以两个操作之间不存在数据依赖性为前提的（因为处理器要遵守as-if-serial语义，处理器不会对存在数据依赖性的两个内存操作做重排序）。</p>
<p>下面的表格展示了常见处理器内存模型的细节特征：
内存模型名称</p>
<p>对应的处理器
相关厂商内容</p>
<h3 id="-javaone-spring-java-ee-6-http-www-infoq-com-infoq-url-action-i-3379-t-f-"><a href="http://www.infoq.com/infoq/url.action?i=3379&amp;t=f" target="_blank">JavaOne上海：迁移Spring应用到Java EE 6</a></h3>
<h3 id="-javaone-http-www-infoq-com-infoq-url-action-i-3380-t-f-"><a href="http://www.infoq.com/infoq/url.action?i=3380&amp;t=f" target="_blank">JavaOne上海：淘宝的鹰眼分布式日志系统</a></h3>
<h3 id="-qcon-2013-http-www-infoq-com-cn-vendorcontent-show-action-vcr-2272-utm_source-infoq-utm_medium-vcr-utm_campaign-vcr_articles_click-"><a href="http://www.infoq.com/cn/vendorcontent/show.action?vcr=2272&amp;utm_source=infoq&amp;utm_medium=VCR&amp;utm_campaign=vcr_articles_click" target="_blank">豆瓣工程副总裁段念确认参与QCon上海2013，担任团队文化专题出品人</a></h3>
<h3 id="-html5-builder-web-http-www-infoq-com-cn-vendorcontent-show-action-vcr-2308-utm_source-infoq-utm_medium-vcr-utm_campaign-vcr_articles_click-"><a href="http://www.infoq.com/cn/vendorcontent/show.action?vcr=2308&amp;utm_source=infoq&amp;utm_medium=VCR&amp;utm_campaign=vcr_articles_click" target="_blank">白皮书下载：用HTML5 Builder构建单一代码库的Web/移动应用</a></h3>
<h3 id="-qcon-20-80-http-www-infoq-com-cn-vendorcontent-show-action-vcr-2311-utm_source-infoq-utm_medium-vcr-utm_campaign-vcr_articles_click-"><a href="http://www.infoq.com/cn/vendorcontent/show.action?vcr=2311&amp;utm_source=infoq&amp;utm_medium=VCR&amp;utm_campaign=vcr_articles_click" target="_blank">首届QCon上海20个专题确认，80余场分享，全面征集演讲主题</a></h3>
<p>相关赞助商
<a href="http://www.infoq.com/infoq/url.action?i=3367&amp;t=f" target="_blank"><img src="" alt=""></a></p>
<p>JavaOne大会独家社区合作，<a href="http://www.infoq.com/infoq/url.action?i=3511&amp;t=f" target="_blank">InfoQ用户享75折购票</a>。 
Store-Load 重排序</p>
<p>Store-Store重排序</p>
<p>Load-Load 和Load-Store重排序</p>
<p>可以更早读取到其它处理器的写</p>
<p>可以更早读取到当前处理器的写 TSO</p>
<p>sparc-TSO</p>
<p>X64</p>
<p>Y</p>
<p>Y PSO</p>
<p>sparc-PSO</p>
<p>Y</p>
<p>Y</p>
<p>Y RMO</p>
<p>ia64</p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>Y PowerPC</p>
<p>PowerPC</p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>Y</p>
<p>在这个表格中，我们可以看到所有处理器内存模型都允许写-读重排序，原因在第一章以说明过：它们都使用了写缓存区，写缓存区可能导致写-读操作重排序。同时，我们可以看到这些处理器内存模型都允许更早读到当前处理器的写，原因同样是因为写缓存区：由于写缓存区仅对当前处理器可见，这个特性导致当前处理器可以比其他处理器先看到临时保存在自己的写缓存区中的写。</p>
<p>上面表格中的各种处理器内存模型，从上到下，模型由强变弱。越是追求性能的处理器，内存模型设计的会越弱。因为这些处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。</p>
<p>由于常见的处理器内存模型比JMM要弱，java编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。同时，由于各种处理器内存模型的强弱并不相同，为了在不同的处理器平台向程序员展示一个一致的内存模型，JMM在不同的处理器中需要插入的内存屏障的数量和种类也不相同。下图展示了JMM在不同处理器内存模型中需要插入的内存屏障的示意图：</p>
<p><img src="" alt=""></p>
<p>如上图所示，JMM屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为java程序员呈现了一个一致的内存模型。</p>
<h2 id="jmm-">JMM，处理器内存模型与顺序一致性内存模型之间的关系</h2>
<p>JMM是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。下面是语言内存模型，处理器内存模型和顺序一致性内存模型的强弱对比示意图：</p>
<p><img src="" alt=""></p>
<p>从上图我们可以看出：常见的4种处理器内存模型比常用的3中语言内存模型要弱，处理器内存模型和语言内存模型都比顺序一致性内存模型要弱。同处理器内存模型一样，越是追求执行性能的语言，内存模型设计的会越弱。</p>
<h2 id="jmm-">JMM的设计</h2>
<p>从JMM设计者的角度来说，在设计JMM时，需要考虑两个关键因素：</p>
<ul>
<li>程序员对内存模型的使用。程序员希望内存模型易于理解，易于编程。程序员希望基于一个强内存模型来编写代码。</li>
<li>编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。</li>
</ul>
<p>由于这两个因素互相矛盾，所以JSR-133专家组在设计JMM时的核心目标就是找到一个好的平衡点：一方面要为程序员提供足够强的内存可见性保证；另一方面，对编译器和处理器的限制要尽可能的放松。下面让我们看看JSR-133是如何实现这一目标的。</p>
<p>为了具体说明，请看前面提到过的计算圆面积的示例代码：
double pi = 3.14; //A double r = 1.0; //B double area = pi /<em> r /</em> r; //C</p>
<p>上面计算圆的面积的示例代码存在三个happens- before关系：</p>
<ol>
<li>A happens- before B；</li>
<li>B happens- before C；</li>
<li>A happens- before C；</li>
</ol>
<p>由于A happens- before B，happens- before的定义会要求：A操作执行的结果要对B可见，且A操作的执行顺序排在B操作之前。 但是从程序语义的角度来说，对A和B做重排序即不会改变程序的执行结果，也还能提高程序的执行性能（允许这种重排序减少了对编译器和处理器优化的束缚）。也就是说，上面这3个happens- before关系中，虽然2和3是必需要的，但1是不必要的。因此，JMM把happens- before要求禁止的重排序分为了下面两类：</p>
<ul>
<li>会改变程序执行结果的重排序。</li>
<li>不会改变程序执行结果的重排序。</li>
</ul>
<p>JMM对这两种不同性质的重排序，采取了不同的策略：</p>
<ul>
<li>对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序。</li>
<li>对于不会改变程序执行结果的重排序，JMM对编译器和处理器不作要求（JMM允许这种重排序）。</li>
</ul>
<p>下面是JMM的设计示意图：</p>
<p><img src="" alt=""></p>
<p>从上图可以看出两点：</p>
<ul>
<li>JMM向程序员提供的happens- before规则能满足程序员的需求。JMM的happens- before规则不但简单易懂，而且也向程序员提供了足够强的内存可见性保证（有些内存可见性保证其实并不一定真实存在，比如上面的A happens- before B）。</li>
<li>JMM对编译器和处理器的束缚已经尽可能的少。从上面的分析我们可以看出，JMM其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。比如，如果编译器经过细致的分析后，认定一个锁只会被单个线程访问，那么这个锁可以被消除。再比如，如果编译器经过细致的分析后，认定一个volatile变量仅仅只会被单个线程访问，那么编译器可以把这个volatile变量当作一个普通变量来对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。</li>
</ul>
<h2 id="jmm-">JMM的内存可见性保证</h2>
<p>Java程序的内存可见性保证按程序类型可以分为下列三类：</p>
<ol>
<li>单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。</li>
<li>正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是JMM关注的重点，JMM通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。</li>
<li>未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）。</li>
</ol>
<p>下图展示了这三类程序在JMM中与在顺序一致性内存模型中的执行结果的异同：</p>
<p><img src="" alt=""></p>
<p>只要多线程程序是正确同步的，JMM保证该程序在任意的处理器平台上的执行结果，与该程序在顺序一致性内存模型中的执行结果一致。</p>
<h2 id="jsr-133-">JSR-133对旧内存模型的修补</h2>
<p>JSR-133对JDK5之前的旧内存模型的修补主要有两个：</p>
<ul>
<li>增强volatile的内存语义。旧内存模型允许volatile变量与普通变量重排序。JSR-133严格限制volatile变量与普通变量的重排序，使volatile的写-读和锁的释放-获取具有相同的内存语义。</li>
<li>增强final的内存语义。在旧内存模型中，多次读取同一个final变量的值可能会不相同。为此，JSR-133为final增加了两个重排序规则。现在，final具有了初始化安全性。</li>
</ul>
<h2 id="-">参考文献</h2>
<ol>
<li><a href="http://www.amazon.com/Computer-Architecture-Fourth-Quantitative-Approach/dp/0123704901/ref=sr_1_10/102-0116773-7214567?ie=UTF8&amp;s=books&amp;qid=1188797467&amp;sr=1-10" target="_blank">Computer Architecture: A Quantitative Approach, 4th Edition</a></li>
<li><a href="http://www.hpl.hp.com/techreports/Compaq-DEC/WRL-95-7.pdf" target="_blank">Shared memory consistency models: A tutorial</a></li>
<li><a href="http://www.intel.com/content/dam/www/public/us/en/documents/manuals/itanium-architecture-software-developer-rev-2-3-vol-2-manual.pdf" target="_blank">Intel® Itanium® Architecture Software Developer’s Manual Volume 2: System Architecture</a></li>
<li><a href="http://www.amazon.com/Concurrent-Programming-Windows-Joe-Duffy/dp/032143482X/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1262571776&amp;sr=1-1" target="_blank">Concurrent Programming on Windows</a></li>
<li><a href="http://www.cs.umd.edu/users/pugh/java/memoryModel/jsr-133-faq.html" target="_blank">JSR 133 (Java Memory Model) FAQ</a></li>
<li><a href="http://gee.cs.oswego.edu/dl/jmm/cookbook.html" target="_blank">The JSR-133 Cookbook for Compiler Writers</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-jtp03304/index.html" target="_blank">Java theory and practice: Fixing the Java Memory Model, Part 2</a></li>
</ol>
<h2 id="-">关于作者</h2>
<p><strong>程晓明</strong>，Java软件工程师，国家认证的系统分析师、信息项目管理师。专注于并发编程，就职于富士通南大。个人邮箱：<a href="mailto:asst2003@163.com">asst2003@163.com</a>。</p>
<ul>
<li><a href="">Sections</a></li>
<li><a href="http://www.infoq.com/cn/architecture-design" target="_blank"><strong>架构 &amp; 设计</strong></a></li>
<li><a href="http://www.infoq.com/cn/development" target="_blank"><strong>语言 &amp; 开发</strong></a></li>
<li><a href="">Topics</a></li>
<li><a href="http://www.infoq.com/cn/Multi-threading" target="_blank">多线程</a></li>
<li><a href="http://www.infoq.com/cn/memory-model" target="_blank">内存模型</a></li>
<li><a href="http://www.infoq.com/cn/concurrency" target="_blank">并发</a></li>
<li><a href="http://www.infoq.com/cn/java" target="_blank">Java</a></li>
<li><a href="http://www.infoq.com/cn/special-column" target="_blank">专栏</a></li>
</ul>
<p>相关内容</p>
<h3 id="-java-final-http-www-infoq-com-cn-articles-java-memory-model-6-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-6?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（六）——final</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-5-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-5?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（五）——锁</a></h3>
<h3 id="-java-volatile-http-www-infoq-com-cn-articles-java-memory-model-4-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-4?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（四）——volatile</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-3-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-3?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（三）——顺序一致性</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-2-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-2?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（二）——重排序</a></h3>
<h2 id="-">您好，陌生人！</h2>
<p>您需要 <a href="http://www.infoq.com/reginit.action" target="_blank">注册一个InfoQ账号</a> 或者 <a href="">登录</a> 才能进行评论。在您完成注册后还需要进行一些设置。</p>
<h2 id="-infoq-">获得来自InfoQ的更多体验。 <a href=""></a></h2>
<h3 id="-">告诉我们您的想法</h3>
<p>允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p
当有人回复此评论时请E-mail通知我</p>
<p>社区评论  <a href="">Watch Thread</a></p>
<p><a href=""><strong>看完后有两点疑问，请教一下：</strong>  by Z CS Posted 21/03/2013 07:37</a>
<a href=""><strong>Re: 看完后有两点疑问，请教一下：</strong>  by 程 晓明 Posted 23/03/2013 12:50</a></p>
<p><a href=""><strong>编译器什么时候插入内存屏障？</strong>  by 黄 春 Posted 10/04/2013 12:49</a>
<a href=""><strong>Re: 编译器什么时候插入内存屏障？</strong>  by 程 晓明 Posted 14/04/2013 11:01</a>
<a href=""></a></p>
<p><strong>看完后有两点疑问，请教一下：</strong>  21/03/2013 07:37 by Z CS</p>
<ol>
<li>文中所写的 “未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）。”，JSR-133 真的做到这样了么? 那 么 long和double的 读写 的非原子性是怎么回事啊？是不是矛盾啊？</li>
<li>关于本文中最后“JSR-133为final增加了两个重排序规则。现在，final具有了初始化安全性。”，这句话，是不是也还要加上那个 前提“保证final引用不从构造函数内逸出”，final才能具有“初始化安全性”啊？</li>
</ol>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a></li>
</ul>
<p><a href=""></a></p>
<p><strong>Re: 看完后有两点疑问，请教一下：</strong>  23/03/2013 12:50 by 程 晓明</p>
<p>谢谢您的关注。
/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>
问题1
最小安全性与64位数据的非原子性读/写并不矛盾。
它们是两个不同的概念，它们“发生”的时间点也不同。
最小安全性保证对象默认初始化之后（设置成员域为0，null或false），才会被任意线程使用。
最小安全性“发生”在对象被任意线程使用之前。
64位数据的非原子性读/写“发生”在对象被多个线程使用的过程中（读/写共享变量）。
当发生《本文三》末尾的那种问题时（处理器B看到仅仅被处理器A“写了一半“的无效值），
这里虽然处理器B读取到一个被写了一半的无效值，但这个值任然是处理器A写入的，只不过处理器A还没有写完而已。
最小安全性保证线程读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）。
但最小安全性并不保证线程读取到的共享变量的值，一定是某个线程写完后的值。
最小安全性保证线程读取到的值不会无中生有的冒出来，但并不保证线程读取到的值一定是正确的。
/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/<em>/</em>/*
问题2
是的，你的理解是对的。
这句话也要加上那个前提：“保证final引用不从构造函数内逸出”，final才能具有“初始化安全性”。</p>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a>
<a href=""></a></li>
</ul>
<p><strong>编译器什么时候插入内存屏障？</strong>  10/04/2013 12:49 by 黄 春</p>
<p>厚积薄发之做。 明白了很多不解的地方。 这里有个问题想问下。 文中说“java编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序”。 这里有个问题请教。
插入内存屏障， 是在编译成字节码的时候完成， 还是在JIT执行的时候重新调整指令生成的？ 或者JIT只生产本地代码， 跟插入内存屏障之类的没关系？</p>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a></li>
</ul>
<p><a href=""></a></p>
<p><strong>Re: 编译器什么时候插入内存屏障？</strong>  14/04/2013 11:01 by 程 晓明</p>
<p>Doug Lea在《The JSR-133 Cookbook for Compiler Writers》中，并没有明确指定插入内存屏障的时机。
个人估计，应该是取决于具体的JVM实现。</p>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a></li>
</ul>
<p><a href="">关闭</a></p>
<h3 id="-by"><em>**</em> by</h3>
<p>发布于</p>
<ul>
<li><a href="">查看</a></li>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a>
<a href="">关闭</a>  主题   您的回复 <a href="">引用原消息</a></li>
</ul>
<p>允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p
当有人回复此评论时请E-mail通知我</p>
<p><a href="">关闭</a>  主题  您的回复</p>
<p>允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p
当有人回复此评论时请E-mail通知我
<a href="">关闭</a></p>
<ul>
<li>热点内容</li>
<li><a href="">本周</a></li>
<li><a href="">本月</a></li>
<li><a href="">近6个月</a><h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
</li>
</ul>
<h3 id="-thoughtworks-2013-5-http-www-infoq-com-cn-articles-thoughtworks-technology-radar-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/thoughtWorks-technology-radar?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">ThoughtWorks技术雷达（2013年5月）</a></h3>
<h3 id="-1-5-http-www-infoq-com-cn-articles-iqiyi-cloud-push-practices-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/iqiyi-cloud-push-practices?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">让1.5亿移动端用户第一时间获取消息</a></h3>
<h3 id="-thoughtworks-ceo-http-www-infoq-com-cn-news-2013-06-tw-guoxiao-on-talents-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/tw-guoxiao-on-talents?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">ThoughtWorks全球CEO郭晓谈软件人才的招聘与培养</a></h3>
<h3 id="-http-www-infoq-com-cn-news-2013-06-10-sins-for-scalability-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/10-sins-for-scalability?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">影响可扩展性的十宗罪</a></h3>
<h3 id="-6-http-www-infoq-com-cn-minibooks-architect-jun-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jun-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（6月刊）</a></h3>
<h3 id="-http-www-infoq-com-cn-articles-function-switch-realize-better-continuous-implementations-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/function-switch-realize-better-continuous-implementations?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">使用功能开关更好地实现持续部署</a></h3>
<h3 id="-eclipse-github-http-www-infoq-com-cn-news-2013-06-eclipse-github-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/eclipse-github?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Eclipse迁移到GitHub</a></h3>
<h3 id="-newegg-com-http-www-infoq-com-cn-presentations-newegg-big-data-practice-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/presentations/newegg-big-data-practice?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Newegg.com大数据实践</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-software-sys-architect-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/software-sys-architect?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">软件系统架构：使用视点和视角与利益相关者合作</a></h3>
<h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
<h3 id="-6-http-www-infoq-com-cn-minibooks-architect-jun-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jun-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（6月刊）</a></h3>
<h3 id="-rest-http-www-infoq-com-cn-news-2013-06-rest-drawbacks-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/rest-drawbacks?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">REST的缺点是什么？</a></h3>
<h3 id="-google-web-ui-polymer-http-www-infoq-com-cn-news-2013-06-webcomponents-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/webcomponents?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Google 发布新一代Web UI库Polymer</a></h3>
<h3 id="-http-www-infoq-com-cn-news-2013-06-dianping-xinnet-hacked-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/dianping-xinnet-hacked?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">大众点评网域名劫持事件概述</a></h3>
<h3 id="-node-js-grunt-js-http-www-infoq-com-cn-articles-gruntjs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/GruntJs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">基于Node.js的自动化构建工具Grunt.js</a></h3>
<h3 id="-node-js-node-js-http-www-infoq-com-cn-articles-what-is-nodejs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/what-is-nodejs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（一）：什么是Node.js</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-i-m-wrights-hard-code-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/i-m-wrights-hard-code?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">代码之殇·第二版</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-software-sys-architect-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/software-sys-architect?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">软件系统架构：使用视点和视角与利益相关者合作</a></h3>
<h3 id="-18-java-http-www-infoq-com-cn-news-2013-06-zhuhong-on-java-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/zhuhong-on-java?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">大家谈18岁的Java——朱鸿：开过跑车后再去开大巴车总是有点不爽的</a></h3>
<h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-1-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/java-memory-model-1?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入理解Java内存模型（一）——基础</a></h3>
<h3 id="-node-js-node-js-http-www-infoq-com-cn-articles-what-is-nodejs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/what-is-nodejs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（一）：什么是Node.js</a></h3>
<h3 id="-node-js-node-js-npm-http-www-infoq-com-cn-articles-nodejs-npm-install-config-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/nodejs-npm-install-config?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（二）：Node.js&amp;NPM的安装与配置</a></h3>
<h3 id="-3-http-www-infoq-com-cn-minibooks-architect-mar-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-mar-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（3月刊）</a></h3>
<h3 id="-1-http-www-infoq-com-cn-minibooks-architect-jan-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jan-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（1月刊）</a></h3>
<h3 id="-4-http-www-infoq-com-cn-minibooks-architect-apr-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-apr-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（4月刊）</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-threadpool-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/java-threadPool?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">聊聊并发（三）——JAVA线程池的分析和使用</a></h3>
<h3 id="-2-http-www-infoq-com-cn-minibooks-architect-feb-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-feb-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（2月刊）</a></h3>
<h3 id="-12306-github-http-www-infoq-com-cn-news-2013-01-12306-plugin-ddos-github-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/01/12306-plugin-ddos-github?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">12306订票助手插件拖垮GitHub事件原因始末</a></h3>
<h2 id="-">深度内容</h2>
<ul>
<li><a href="">全部</a></li>
<li><a href="">文章</a></li>
<li><a href="">演讲</a></li>
<li><a href="">访谈</a></li>
<li><a href="">迷你书</a><h2 id="-juergen-fesslmeier-javascript-http-www-infoq-com-cn-interviews-end-to-end-javascript-juergen-fesslmeier-javascript-"><a href="http://www.infoq.com/cn/interviews/end-to-end-javascript" title="Juergen Fesslmeier谈端到端的JavaScript开发" target="_blank">Juergen Fesslmeier谈端到端的JavaScript开发</a></h2>
</li>
</ul>
<p><a href="http://www.infoq.com/cn/author/Juergen-Fesslmeier" title="Juergen Fesslmeier" target="_blank">Juergen Fesslmeier</a> 七月 02, 2013</p>
<p><a href="http://www.infoq.com/cn/interviews/end-to-end-javascript" title="Juergen Fesslmeier谈端到端的JavaScript开发" target="_blank"><img src="" alt=""></a></p>
<h2 id="-http-www-infoq-com-cn-articles-design-pattern-automation-"><a href="http://www.infoq.com/cn/articles/Design-Pattern-Automation" title="设计模式自动化" target="_blank">设计模式自动化</a></h2>
<p><a href="http://www.infoq.com/cn/author/Gael-Fraiteur-and-Yan-Cui" title="Gael Fraiteur and Yan Cui" target="_blank">Gael Fraiteur and Yan Cui</a> 七月 01, 2013</p>
<p><a href="http://www.infoq.com/cn/articles/Design-Pattern-Automation" title="设计模式自动化" target="_blank"><img src="" alt=""></a></p>
<h2 id="-http-www-infoq-com-cn-articles-designing-a-world-at-your-fingertips-mobile-user-interfaces-"><a href="http://www.infoq.com/cn/articles/designing-a-world-at-your-fingertips-mobile-user-interfaces" title="设计指尖上的世界：移动用户界面一瞥" target="_blank">设计指尖上的世界：移动用户界面一瞥</a></h2>
<p><a href="http://www.infoq.com/cn/author/Forrest-Shull" title="Forrest Shull" target="_blank">Forrest Shull</a> 六月 28, 2013</p>
<p><a href="http://www.infoq.com/cn/articles/designing-a-world-at-your-fingertips-mobile-user-interfaces" title="设计指尖上的世界：移动用户界面一瞥" target="_blank"><img src="" alt=""></a></p>
<h2 id="-alm-http-www-infoq-com-cn-articles-integrated-alm-alm-"><a href="http://www.infoq.com/cn/articles/Integrated-ALM" title="成功的根本—集成的ALM工具" target="_blank">成功的根本—集成的ALM工具</a></h2>
<p><a href="http://www.infoq.com/cn/author/Dave-West" title="Dave West" target="_blank">Dave West</a> 六月 28, 2013</p>
<p><a href="http://www.infoq.com/cn/articles/Integrated-ALM" title="成功的根本—集成的ALM工具" target="_blank"><img src="" alt=""></a></p>
<h2 id="-http-www-infoq-com-cn-articles-atdd-by-example-book-"><a href="http://www.infoq.com/cn/articles/atdd-by-example-book" title="书评：验收测试驱动开发实践指南" target="_blank">书评：验收测试驱动开发实践指南</a></h2>
<p><a href="http://www.infoq.com/cn/author/Manuel-Pais" title="Manuel Pais" target="_blank">Manuel Pais</a> 六月 26, 2013</p>
<p><a href="http://www.infoq.com/cn/articles/atdd-by-example-book" title="书评：验收测试驱动开发实践指南" target="_blank"><img src="" alt=""></a></p>
<h2 id="-web-http-www-infoq-com-cn-presentations-across-device-web-web-"><a href="http://www.infoq.com/cn/presentations/across-device-web" title="跨终端的web" target="_blank">跨终端的web</a></h2>
<p><a href="http://www.infoq.com/cn/author/%E8%88%92%E6%96%87%E4%BA%AE" title="舒文亮" target="_blank">舒文亮</a> 六月 26, 2013</p>
<p><a href="http://www.infoq.com/cn/presentations/across-device-web" title="跨终端的web" target="_blank"><img src="" alt=""></a></p>
<ul>
<li><a href="">更早的 &gt;</a></li>
</ul>
<p>赞助商链接</p>
<h3 id="infoq-">InfoQ每周精要</h3>
<p>通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。
<a href="http://www.infoq.com/cn/newsletter_sample.html" target="_blank"><img src="" alt=""></a></p>
<p>语言 &amp; 开发</p>
<p><a href="http://www.infoq.com/cn/interviews/end-to-end-javascript" title="Juergen Fesslmeier谈端到端的JavaScript开发" target="_blank">Juergen Fesslmeier谈端到端的JavaScript开发</a></p>
<p><a href="http://www.infoq.com/cn/news/2013/07/mobilecloud-tfs" title="MobileCloud for TFS支持测试Windows Phone,Android,iOS及BlackBerry应用" target="_blank">MobileCloud for TFS支持测试Windows Phone,Android,iOS及BlackBerry应用</a></p>
<p><a href="http://www.infoq.com/cn/news/2013/07/baidu-salon39-summary" title="百度技术沙龙第39期回顾：前端快速开发实践（含资料下载）" target="_blank">百度技术沙龙第39期回顾：前端快速开发实践（含资料下载）</a></p>
<p>架构 &amp; 设计</p>
<p><a href="http://www.infoq.com/cn/news/2013/07/Native-Performance" title="内存与本机代码的性能" target="_blank">内存与本机代码的性能</a></p>
<p><a href="http://www.infoq.com/cn/articles/Design-Pattern-Automation" title="设计模式自动化" target="_blank">设计模式自动化</a></p>
<p><a href="http://www.infoq.com/cn/news/2013/07/WinRT-Devices" title="连接设备编程" target="_blank">连接设备编程</a>
过程 &amp; 实践</p>
<p><a href="http://www.infoq.com/cn/articles/Integrated-ALM" title="成功的根本—集成的ALM工具" target="_blank">成功的根本—集成的ALM工具</a></p>
<p><a href="http://www.infoq.com/cn/news/2013/06/tw-guoxiao-on-talents" title="ThoughtWorks全球CEO郭晓谈软件人才的招聘与培养" target="_blank">ThoughtWorks全球CEO郭晓谈软件人才的招聘与培养</a></p>
<p><a href="http://www.infoq.com/cn/articles/atdd-by-example-book" title="书评：验收测试驱动开发实践指南" target="_blank">书评：验收测试驱动开发实践指南</a></p>
<p>运维 &amp; 基础架构</p>
<p><a href="http://www.infoq.com/cn/news/2013/06/devops-in-traditional-enterprise" title="在传统企业中引入DevOps" target="_blank">在传统企业中引入DevOps</a></p>
<p><a href="http://www.infoq.com/cn/news/2013/06/dod-ams-day1-s-is-for-security" title="安全性——“DevOpS”中的S" target="_blank">安全性——“DevOpS”中的S</a></p>
<p><a href="http://www.infoq.com/cn/articles/atdd-by-example-book" title="书评：验收测试驱动开发实践指南" target="_blank">书评：验收测试驱动开发实践指南</a>
企业架构</p>
<p><a href="http://www.infoq.com/cn/articles/designing-a-world-at-your-fingertips-mobile-user-interfaces" title="设计指尖上的世界：移动用户界面一瞥" target="_blank">设计指尖上的世界：移动用户界面一瞥</a></p>
<p><a href="http://www.infoq.com/cn/news/2013/06/stratos-2" title="Stratos 2.0已发布，支持所有运行时环境和30个IaaS" target="_blank">Stratos 2.0已发布，支持所有运行时环境和30个IaaS</a></p>
<p><a href="http://www.infoq.com/cn/articles/iqiyi-cloud-push-practices" title="让1.5亿移动端用户第一时间获取消息" target="_blank">让1.5亿移动端用户第一时间获取消息</a></p>
<ul>
<li><a href="http://www.infoq.com/cn/" title="首页" target="_blank">首页</a></li>
<li><a href="http://www.infoq.com/cn/topics" title="全部话题" target="_blank">全部话题</a></li>
<li><a href="http://www.qconferences.com/" title="QCon全球软件开发大会" target="_blank">QCon全球软件开发大会</a></li>
<li><a href="http://www.infoq.com/cn/aboutus" title="关于我们" target="_blank">关于我们</a></li>
<li><a href="http://www.infoq.com/cn/contribute" title="让大家在InfoQ上听见你的声音" target="_blank">让大家在InfoQ上听见你的声音</a></li>
<li><a href="http://www.infoq.com/cn/reginit.action" title="创建账号" target="_blank">创建账号</a></li>
<li><p><a href="&quot;登录&quot;">登录</a></p>
</li>
<li><p><strong>会议</strong></p>
</li>
<li><a href="http://www.qconshanghai.com/" title="技术大会：QCon上海2013，11月1-3日 " target="_blank">QCon全球软件开发大会（上海站）2013，11月1-3日</a><h3 id="infoq-">InfoQ每周精要</h3>
</li>
</ul>
<p>通过个性化定制的新闻邮件、RSS Feeds和InfoQ业界邮件通知，保持您对感兴趣的社区内容的时刻关注。</p>
<p><a href="http://www.infoq.com/cn/newsletter_sample.html" target="_blank"><img src="" alt=""></a></p>
<ul>
<li><a href="http://www.infoq.com/cn/rss/rss.action?token=AjlwmaWcwi5ejkcT6GcRk1pCqJ4K7ocs" target="_blank">属于您的个性化RSS</a></li>
<li><a href="http://weibo.com/infoqchina" target="_blank">新浪微博</a></li>
<li><a href="http://www.facebook.com/InfoQ" target="_blank">社区新闻和热点</a></li>
</ul>
<p>特别专题</p>
<ul>
<li><a href="http://www.infoq.com/cn/chinaitevents" target="_blank"><strong>技术社区活动日历</strong></a></li>
<li><a href="http://www.infoq.com/cn/zones/baidu-salon/" target="_blank"><strong>百度技术沙龙</strong></a></li>
<li><a href="http://www.infoq.com/cn/scrum/" target="_blank"><strong>Scrum开发</strong></a></li>
<li><a href="http://www.infoq.com/cn/architect/" target="_blank"><strong>月刊：《架构师》</strong></a></li>
<li><a href="http://www.infoq.com/cn/qclub/" target="_blank"><strong>线下活动：QClub</strong></a>
定制您感兴趣的技术领域</li>
</ul>
<p>语言 &amp; 开发 架构 &amp; 设计 过程 &amp; 实践 运维 &amp; 基础架构 企业架构
提供反馈</p>
<p><a href="mailto:feedback@cn.infoq.com">feedback@cn.infoq.com</a>
 错误报告</p>
<p><a href="mailto:bugs@cn.infoq.com">bugs@cn.infoq.com</a>
 商务合作</p>
<p><a href="mailto:sales@cn.infoq.com">sales@cn.infoq.com</a>
 内容合作</p>
<p><a href="mailto:editors@cn.infoq.com">editors@cn.infoq.com</a>
 InfoQ.com及所有内容，版权所有 © 2006-2013 C4Media Inc. InfoQ.com 服务器由 <a href="http://www.contegix.com/" target="_blank">Contegix</a>提供, 我们最信赖的ISP合作伙伴。
<a href="http://www.infoq.com/cn/privacypolicy" target="_blank">隐私政策</a></p>
<p><a href="">Close</a>  E-mail  密码</p>
<p><a href="http://www.infoq.com/cn/social/googleLogin.action?fl=login" title="使用Google账号登录" target="_blank">使用Google账号登录</a>  <a href="http://www.infoq.com/cn/social/liveLogin.action?fl=login" title="使用Microsoft账号登录" target="_blank">使用Microsoft账号登录</a>
<a href="">忘记密码？</a>
   InfoQ账号使用的E-mail  发送邮件</p>
<p><a href="">重新登录</a>
重新发送激活信息  重新发送</p>
<p><a href="">重新登录</a>
<a href="http://www.infoq.com/cn/reginit.action" target="_blank">没有用户名？</a></p>
<p><a href="http://www.infoq.com/cn/reginit.action" target="_blank">点击注册</a></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/内存/">内存</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/内存/" class="label label-info">内存</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-内存--深入理解Java内存模型（七）——总结/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-内存--深入理解Java内存模型（七）——总结" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/54/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/52/">52</a></li><li><a class="page-number" href="/page/53/">53</a></li><li><a class="page-number" href="/page/54/">54</a></li><li class="active"><li><span class="page-number current">55</span></li><li><a class="page-number" href="/page/56/">56</a></li><li><a class="page-number" href="/page/57/">57</a></li><li><a class="page-number" href="/page/58/">58</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/161/">161</a></li><li><a class="page-number" href="/page/162/">162</a></li><li><a class="extend next" href="/page/56/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Site powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a>  update time: <em>2014-04-07 19:25:39</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
