
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 109 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux--用JAVA通过LDAP修改AD用户密码注意事项-一事无成-ITeye技术网站/">用JAVA通过LDAP修改AD用户密码注意事项 </a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux--用JAVA通过LDAP修改AD用户密码注意事项-一事无成-ITeye技术网站/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-ldap-ad-iteye-">用JAVA通过LDAP修改AD用户密码注意事项 - 一事无成 - ITeye技术网站</h1>
<p><a href="http://www.iteye.com/" target="_blank">首页</a> <a href="http://www.iteye.com/news" target="_blank">资讯</a> <a href="http://www.iteye.com/magazines" target="_blank">精华</a> <a href="http://www.iteye.com/forums" target="_blank">论坛</a> <a href="http://www.iteye.com/ask" target="_blank">问答</a> <a href="http://www.iteye.com/blogs" target="_blank">博客</a> <a href="http://www.iteye.com/blogs/subjects" target="_blank">专栏</a> <a href="http://www.iteye.com/groups" target="_blank">群组</a> <a href="http://lxs647.iteye.com/blog/1245948#" target="_blank">更多 ▼</a></p>
<p><a href="http://job.iteye.com/iteye" target="_blank">招聘</a> <a href="http://www.iteye.com/search" target="_blank">搜索</a></p>
<p><a href="http://lxs647.iteye.com/login" title="登录" target="_blank">您还未登录 !</a> <a href="http://lxs647.iteye.com/login" target="_blank">登录</a> <a href="http://lxs647.iteye.com/signup" target="_blank">注册</a></p>
<h1 id="-lxs647-http-lxs647-iteye-com-"><a href="http://lxs647.iteye.com/" target="_blank">lxs647</a></h1>
<ul>
<li><a href="http://lxs647.iteye.com/" target="_blank"><strong>博客</strong></a></li>
<li><a href="http://lxs647.iteye.com/weibo" target="_blank">微博</a></li>
<li><a href="http://lxs647.iteye.com/album" target="_blank">相册</a></li>
<li><a href="http://lxs647.iteye.com/link" target="_blank">收藏</a></li>
<li><a href="http://lxs647.iteye.com/blog/guest_book" target="_blank">留言</a></li>
<li><a href="http://lxs647.iteye.com/blog/profile" target="_blank">关于我</a></li>
</ul>
<h3 id="-vi-vim-"><a href="">vi / vim 删除以及其它命令</a> **</h3>
<p>删除一行：dd</p>
<p>删除一个单词/光标之后的单词剩余部分：dw</p>
<p>删除当前字符：x</p>
<p>光标之后的该行部分：d$</p>
<p>文本删除</p>
<p>dd 删除一行</p>
<p>d$ 删除以当前字符开始的一行字符</p>
<p>ndd 删除以当前行开始的n行</p>
<p>dw 删除以当前字符开始的一个字</p>
<p>ndw 删除以当前字符开始的n个字</p>
<p>D 与d$同义</p>
<p>d) 删除到下一句的开始</p>
<p>d} 删除到下一段的开始</p>
<p>d回车 删除2行</p>
<p>ndw 或 ndW 删除光标处开始及其后的 n-1 个字符。
d0 删至行首。
d$ 删至行尾。
ndd 删除当前行及其后 n-1 行。
x 或 X 删除一个字符。
Ctrl+u 删除输入方式下所输入的文本。
^R 恢复u的操作
J 把下一行合并到当前行尾
V 选择一行
^V 按下^V后即可进行矩形的选择了
aw 选择单词
iw 内部单词(无空格)
as 选择句子
is 选择句子(无空格)
ap 选择段落
ip 选择段落(无空格)
D 删除到行尾
x,y 删除与复制包含高亮区
dl 删除当前字符（与x命令功能相同）
d0 删除到某一行的开始位置
d^ 删除到某一行的第一个字符位置（不包括空格或TAB字符）
dw 删除到某个单词的结尾位置
d3w 删除到第三个单词的结尾位置
db 删除到某个单词的开始位置
dW 删除到某个以空格作为分隔符的单词的结尾位置
dB 删除到某个以空格作为分隔符的单词的开始位置
d7B 删除到前面7个以空格作为分隔符的单词的开始位置
d） 删除到某个语句的结尾位置
d4） 删除到第四个语句的结尾位置
d（ 删除到某个语句的开始位置
d） 删除到某个段落的结尾位置
d{ 删除到某个段落的开始位置
d7{ 删除到当前段落起始位置之前的第7个段落位置
dd 删除当前行
d/text 删除从文本中出现“text”中所指定字样的位置，
一直向前直到下一个该字样所出现的位置（但不包括该字样）之间的内容
dfc 删除从文本中出现字符“c”的位置，一直向前直到下一个该字符所出现的位置（包括该字符）之间的内容
dtc 删除当前行直到下一个字符“c”所出现位置之间的内容
D 删除到某一行的结尾
d$ 删除到某一行的结尾
5dd 删除从当前行所开始的5行内容
dL 删除直到屏幕上最后一行的内容
dH 删除直到屏幕上第一行的内容
dG 删除直到工作缓存区结尾的内容
d1G 删除直到工作缓存区开始的内容</p>
<h2 id="-vi-">在Vi 中移动光标</h2>
<p>k 上 h l 左 右 j 下 ^ 移动到该行第一个非空格的字符处 w 向前移动一个单词，将符号或标点当作单词处理 W 向前移动一个单词，不把符号或标点当作单词处理 b 向后移动一个单词，把符号或标点当作单词处理 B 向后移动一个单词，不把符号或标点当作单词处理 ( 光标移至句首 ) 光标移至句尾 { 光标移至段落开头 } 光标移至段落结尾 H 光标移至屏幕顶行 M 光标移至屏幕中间行 L 光标移至屏幕最后行 0 到行首 $ 到行尾 gg 到页首 G 到页末 行号+G 跳转到指定行 n+ 光标下移n行 n- 光标上移n行 Ctrl+g 查询当前行信息和当前文件信息 fx 向右跳到本行字符x处（x可以是任何字符） Fx 向左跳到本行字符x处（x可以是任何字符） tx 和fx相同，区别是跳到字符x前 Tx 和Fx相同，区别是跳到字符x后 C-b 向上滚动一屏 C-f 向下滚动一屏 C-u 向上滚动半屏 C-d 向下滚动半屏 C-y 向上滚动一行 C-e 向下滚动一行 nz 将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部。</p>
<h2 id="-vi-">进入和退出Vi命令</h2>
<p>vi filename 打开或新建文件，并将光标置于第一行首 vi +n filename 打开文件，并将光标置于第n行首 vi + filename 打开文件，并将光标置于最后一行首 vi +/pattern filename 打开文件，并将光标置于第一个与pattern匹配的串处 vi -r filename 在上次正用vi编辑时发生系统崩溃，恢复filename vi filename ... filename 打开多个文件，依次进行编辑 ZZ 退出vi并保存 :q! 退出vi，不保存 :wq 退出vi并保存</p>
<h2 id="-">重复操作</h2>
<p>. 重复上一次操作</p>
<h2 id="-">自动补齐</h2>
<p>C-n 匹配下一个关键字 C-p 匹配上一个关键字</p>
<h2 id="-">插入</h2>
<p>o 在光标下方新开一行并将光标置于新行行首，进入插入模式。 O 同上，在光标上方。 a 在光标之后进入插入模式。 A 同上，在光标之前。 R 进入替换模式，直到按下Esc set xxx 设置XXX选项。</p>
<h2 id="-">行合并</h2>
<p>J 把下面一行合并到本行后面</p>
<h2 id="vi-">Vi中查找及替换命令</h2>
<p>/pattern 从光标开始处向文件尾搜索pattern ?pattern 从光标开始处向文件首搜索pattern n 在同一方向重复上一次搜索命令 N 在反方向上重复上一次搜索命令 % 查找配对的括号 :s/p1/p2/g 将当前行中所有p1均用p2替代，若要每个替换都向用户询问则应该用gc选项 :n1,n2s/p1/p2/g 将第n1至n2行中所有p1均用p2替代 :g/p1/s//p2/g 将文件中所有p1均用p2替换 ./*[]^%~$ 在Vi中具有特殊含义，若需要查找则应该加上转义字符&quot;\&quot;</p>
<h3 id="-">查找的一些选项</h3>
<h3 id="-">设置高亮</h3>
<p>:set hlsearch 设置高亮 :set nohlsearch 关闭高亮 :nohlsearch 关闭当前已经设置的高亮</p>
<h3 id="-">增量查找</h3>
<p>:set incsearch 设置增量查找 :set noincsearch 关闭增量查找</p>
<h2 id="-vi-">在Vi中删除</h2>
<p>x 删除当前光标下的字符 dw 删除光标之后的单词剩余部分。 d$ 删除光标之后的该行剩余部分。 dd 删除当前行。 c 功能和d相同，区别在于完成删除操作后进入INSERT MODE cc 也是删除当前行，然后进入INSERT MODE</p>
<h2 id="-">更改字符</h2>
<p>rx 将当前光标下的字符更改为x（x为任意字符） ~ 更改当前光标下的字符的大小写</p>
<h2 id="-">键盘宏操作</h2>
<p>qcharacter 开始录制宏，character为a到z的任意字符 q 终止录制宏 @character 调用先前录制的宏</p>
<h2 id="-">恢复误操作</h2>
<p>u 撤销最后执行的命令 U 修正之前对该行的操作 Ctrl+R Redo</p>
<h2 id="-vi-frame">在Vi中操作Frame</h2>
<p>c-w c-n 增加frame c-w c-c 减少frame c-w c-w 切换frame c-w c-r 交换两个frame</p>
<h2 id="vim-">VIM中的块操作</h2>
<p>Vim支持多达26个剪贴板
选块 先用v，C-v，V选择一块，然后用y复制，再用p粘贴。 yy 复制当前整行 nyy 复制当前行开始的n行内容 ?nyy 将光标当前行及其下n行的内容保存到寄存器?中，其中?为一个字母，n为一个数字 ?nyw 将光标当前行及其下n个词保存到寄存器?中，其中?为一个字母，n为一个数字 ?nyl 将光标当前行及其下n个字符保存到寄存器?中，其中?为一个字母，n为一个数字 ?p 将寄存器?中的内容粘贴到光标位置之后。如果?是用yy复制的完整行， 则粘贴在光标所在行下面。这里?可以是一个字母，也可以是一个数字 ?P 将寄存器a中的内容粘贴到光标位置之前。如果?是用yy复制的完整行， 则粘贴在光标所在行上面。这里?可以是一个字母，也可以是一个数字 ay[motion] ay$ 复制光标位置到行末并保存在寄存器a中 ayft 复制光标位置到当前行第一个字母t并保存在寄存器a中</p>
<p>以上指令皆可去掉a工作，则y,p对未命名寄存器工作（所有d,c,x,y的对象都被保存在这里）。</p>
<h3 id="-">剪切/复制/粘贴</h3>
<p>所有删除的内容自动被保存，可以用p键粘贴</p>
<h2 id="vi-">Vi的选项设置</h2>
<p>all 列出所有选项设置情况 term 设置终端类型 ignorance 在搜索中忽略大小写 list 显示制表位(Ctrl+I)和行尾标志($) number 显示行号 report 显示由面向行的命令修改过的数目 terse 显示简短的警告信息 warn 在转到别的文件时若没保存当前文件则显示NO write信息 nomagic 允许在搜索模式中，使用前面不带“\”的特殊字符 nowrapscan 禁止vi在搜索到达文件两端时，又从另一端开始 mesg 允许vi显示其他用户用write写到自己终端上的信息</p>
<h2 id="tips">tips</h2>
<p>对代码自动格式化 gg=G</p>
<p>在vi/vim中，跳到文件首尾快捷键:</p>
<p>文件开始:shift + g</p>
<p>文件结束:g g</p>
<p>from:<a href="http://dsec.pku.edu.cn/~jinlong/vi/Vi.html" target="_blank"><a href="http://dsec.pku.edu.cn/~jinlong/vi/Vi.html">http://dsec.pku.edu.cn/~jinlong/vi/Vi.html</a></a></p>
<p>from:<a href="http://www.caole.net/diary/vim.html#sec-1" target="_blank"><a href="http://www.caole.net/diary/vim.html/#sec-1">http://www.caole.net/diary/vim.html/#sec-1</a></a>
分享到： <a href="&quot;分享到新浪微博&quot;"><img src="" alt=""></a> <a href="&quot;分享到腾讯微博&quot;"><img src="" alt=""></a></p>
<p><a href="http://lxs647.iteye.com/blog/1246871" title="linux 中的ln命令" target="_blank">linux 中的ln命令</a> | <a href="http://lxs647.iteye.com/blog/1244965" title="Flex 中很幽灵的一个bug(2)" target="_blank">Flex 中很幽灵的一个bug(2)</a></p>
<ul>
<li>2011-11-09 12:11</li>
<li>浏览 8572</li>
<li><a href="http://lxs647.iteye.com/blog/1245948#comments" target="_blank">评论(0)</a></li>
<li>分类:<a href="http://www.iteye.com/blogs/category/os" target="_blank">操作系统</a></li>
<li><a href="http://www.iteye.com/wiki/blog/1245948" target="_blank">相关推荐</a></li>
</ul>
<h3 id="-">评论</h3>
<p><a href=""></a></p>
<h3 id="-">发表评论</h3>
<p><a href="http://lxs647.iteye.com/login" target="_blank"><img src="" alt=""></a><a href="http://lxs647.iteye.com/login" target="_blank">您还没有登录,请您登录后再发表评论</a></p>
<p><a href="http://lxs647.iteye.com/" target="_blank"><img src="&quot;lxs647的博客: &quot;" alt="lxs647的博客"></a></p>
<p>lxs647</p>
<ul>
<li>浏览: 70685 次</li>
<li>性别: <img src="&quot;男&quot;" alt="Icon_minigender_1"></li>
<li>来自: 北京</li>
<li><img src="" alt=""><h3 id="-http-lxs647-iteye-com-blog-user_visits-">最近访客 <a href="http://lxs647.iteye.com/blog/user_visits" target="_blank">更多访客&gt;&gt;</a></h3>
</li>
</ul>
<p><a href="http://michael-roshen.iteye.com/" target="_blank"><img src="&quot;michael_roshen的博客: Mr.C&quot;" alt="michael_roshen的博客"></a></p>
<p><a href="http://michael-roshen.iteye.com/" title="michael_roshen" target="_blank">michael_roshen</a></p>
<p><a href="http://yaoyao19851023.iteye.com/" target="_blank"><img src="&quot;yaoyao19851023的博客: &quot;" alt="yaoyao19851023的博客"></a></p>
<p><a href="http://yaoyao19851023.iteye.com/" title="yaoyao19851023" target="_blank">yaoyao19851023</a>
<a href="http://oneis1-gma.iteye.com/" target="_blank"><img src="&quot;oneis1_gma的博客: &quot;" alt="oneis1_gma的博客"></a></p>
<p><a href="http://oneis1-gma.iteye.com/" title="oneis1_gma" target="_blank">oneis1_gma</a></p>
<p><a href="http://liuhongyansn.iteye.com/" target="_blank"><img src="&quot;liuhongyansn的博客: &quot;" alt="liuhongyansn的博客"></a></p>
<p><a href="http://liuhongyansn.iteye.com/" title="liuhongyansn" target="_blank">liuhongyansn</a></p>
<h3 id="-">文章分类</h3>
<ul>
<li><p><a href="http://lxs647.iteye.com/" target="_blank">全部博客 (126)</a></p>
<h3 id="-">社区版块</h3>
</li>
<li><p><a href="http://lxs647.iteye.com/blog/news" target="_blank">我的资讯</a> (0)</p>
</li>
<li><a href="http://lxs647.iteye.com/blog/post" target="_blank">我的论坛</a> (246)</li>
<li><a href="http://lxs647.iteye.com/blog/answered_problems" target="_blank">我的问答</a> (2)</li>
</ul>
<h3 id="-">存档分类</h3>
<ul>
<li><a href="http://lxs647.iteye.com/blog/monthblog/2012-10" target="_blank">2012-10</a> (3)</li>
<li><a href="http://lxs647.iteye.com/blog/monthblog/2012-01" target="_blank">2012-01</a> (2)</li>
<li><a href="http://lxs647.iteye.com/blog/monthblog/2011-12" target="_blank">2011-12</a> (1)</li>
<li><p><a href="http://lxs647.iteye.com/blog/monthblog_more" target="_blank">更多存档...</a></p>
<h3 id="-">最新评论</h3>
</li>
<li><p><a href="http://douknow.iteye.com/" title="douknow" target="_blank">douknow</a>： 多谢lz,搞定
<a href="http://lxs647.iteye.com/blog/1274975#bc2285287" target="_blank">Project configuration is not up-to-date with pom.xml</a></p>
</li>
<li><a href="http://shuimuqinghua77.iteye.com/" title="水木清华77" target="_blank">水木清华77</a>： 多谢楼主
<a href="http://lxs647.iteye.com/blog/1274975#bc2268270" target="_blank">Project configuration is not up-to-date with pom.xml</a></li>
<li><a href="http://elan1986.iteye.com/" title="elan1986" target="_blank">elan1986</a>： ...
<a href="http://lxs647.iteye.com/blog/1274975#bc2266806" target="_blank">Project configuration is not up-to-date with pom.xml</a></li>
<li><a href="http://easense2009.iteye.com/" title="easense2009" target="_blank">easense2009</a>： 多谢楼主，今天也遇到同样的问题，用楼主的方法问题解决，than ...
<a href="http://lxs647.iteye.com/blog/1274975#bc2248132" target="_blank">Project configuration is not up-to-date with pom.xml</a></li>
<li><a href="http://hailinhe1986-163-com.iteye.com/" title="hehailin1986_163.com" target="_blank">hehailin1986_163.com</a>： 你好，我试了一下，貌似不支持中文目录的，有好方法么？
<a href="http://lxs647.iteye.com/blog/1179043#bc2224452" target="_blank">Adobe AIR:压缩Zip/创建zip文件</a>
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2012 ITeye.com. All rights reserved. [ 京ICP证110151号 京公网安备110105010620 ]
<img src="" alt=""></li>
</ul>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span></span> | <span class="tags">Tagged <a href="/tags/linux/" class="label label-primary">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux--用JAVA通过LDAP修改AD用户密码注意事项-一事无成-ITeye技术网站/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux--用JAVA通过LDAP修改AD用户密码注意事项-一事无成-ITeye技术网站" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux-android--adb命令详解/">adb命令详解</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux-android--adb命令详解/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="adb-">adb命令详解</h1>
<p>ADB全称Android Debug Bridge, 是android sdk里的一个工具, 用这个工具可以直接操作管理android模拟器或者真实的andriod设备(如G1手机).
它的主要功能有:
    /<em> 运行设备的shell(命令行)
    /</em> 管理模拟器或设备的端口映射
    /<em> 计算机和设备之间上传/下载文件
    /</em> 将本地apk软件安装至模拟器或android设备
ADB是一个 客户端-服务器端 程序, 其中客户端是你用来操作的电脑, 服务器端是android设备..
先说安装方法, 电脑上需要安装客户端. 客户端包含在sdk里. 设备上不需要安装, 只需要在手机上打开选项settings-applications-development-USB debugging.
对于Mac和Linux用户, 下载好的sdk解压后, 可以放~或者任意目录. 然后修改~/.bash_profile文件, 设置运行环境指向sdk的tools目录.
具体是打开~/.bash_profile文件(如果没有此文件也可以自行添加), 在里面加入一行:
export PATH=${PATH}:&lt;你的sdk目录&gt;/tools
然后就可以使用adb命令了.
嫌安装麻烦的同学其实也可以省去上面安装步骤, 直接输入完整路径来使用命令。
对于windows xp用户, 需要先安装usb驱动 android_usb_windows.zip, 然后如果你只打算使用adb而不想下载整个sdk的话, 可以下载这个单独的adb工具包 adb_win.zip 下载后解压, 把里面 adb.exe 和 AdbWinApi.dll 两个文件放到系统盘的 windows/system32 文件夹里就可以了
现在说下ADB常用的几个命令
查看设备
    /<em> adb devices
这个命令是查看当前连接的设备, 连接到计算机的android设备或者模拟器将会列出显示
安装软件
    /</em> adb install <apk文件路径>
这个命令将指定的apk文件安装到设备上.
卸载软件
    /<em> adb uninstall &lt;软件名&gt;
    /</em> adb uninstall -k &lt;软件名&gt;
如果加 -k 参数,为卸载软件但是保留配置和缓存文件.
登录设备shell
    /<em> adb shell
    /</em> adb shell <command命令>
这个命令将登录设备的shell.
后面加<command命令>将是直接运行设备命令, 相当于执行远程命令
从电脑上发送文件到设备
    /<em> adb push &lt;本地路径&gt; &lt;远程路径&gt;
用push命令可以把本机电脑上的文件或者文件夹复制到设备(手机)
从设备上下载文件到电脑
    /</em> adb pull &lt;远程路径&gt; &lt;本地路径&gt;
用pull命令可以把设备(手机)上的文件或者文件夹复制到本机电脑
显示帮助信息
    /* adb help
这个命令将显示帮助信息
这里还有一个英文版的：
在DOS下输入以下命令基本可以完成刷机任务,一些常用命令解释如下:
    adb devices - 列出连接到电脑的ADB设备(也就是手机),一般显示出手机P/N码.如果没有显示出来则手机与电脑没有连接上.
    adb install <packagename.apk> – 安装手机软件到手机中,如:adb install qq2009.apk.
    adb remount – 重新打开手机写模式(刷机模式).
    adb push <localfile> <location on your phone> - 传送文件到手机中,如:adb push recovery.img /sdcard/recovery.img,将本地目录中的recovery.img文件传送手机的SD卡中并取同样的文件名.
    adb pull <location on your phone> <localfile> - 传送手机的文件到本地目录(和上命令相反).
    adb shell <command> - 让手机执行命令,<command>就是手机执行的命令.如: adb shell flash_image recovery /sd-card/recovery-RAv1.0G.img,执行将recovery-RAv1.0G.img写入到recovery 区中.
我们刷recovery时一般按下顺序执行:
    adb shell mount -a
    adb push recovery-RAv1.0G.img /system/recovery.img
    adb push recovery-RAv1.0G.img /sdcard/recovery-RAv1.0G.img
    adb shell flash_image recovery /sdcard/recovery-RAv1.0G.img reboot
其它的自己灵活运用了.
ADB命令详解:
Android Debug Bridge version 1.0.20
-d 　- directs command to the only connected USB device　returns an error if more than one USB device is　present.
-e  　- directs command to the only running emulator.returns an error if more than one emulator is running.
-s <serial number>            – directs command to the USB device or emulator withthe given serial number
-p <product name or path>     – simple product name like ‘sooner’, or　a relative/absolute path to a product　out directory like ‘out/target/product/sooner’.
If -p is not specified, the ANDROID_PRODUCT_OUT　environment variable is used, which must　be an absolute path.
devices 　 – list all connected devices
device commands:
adb push <local> <remote>    – copy file/dir to device
adb pull <remote> <local>    – copy file/dir from device
adb sync [ <directory> ]     – copy host-&gt;device only if changed　(see ‘adb help all’)
adb shell                    – run remote shell interactively
adb shell <command>          – run remote shell command
adb emu <command>            – run emulator console command
adb logcat [ <filter-spec> ] – View device log
adb forward <local> <remote> – forward socket connections
forward specs are one of:
    tcp:<port>
    localabstract:<unix domain socket name>
    localreserved:<unix domain socket name>
    localfilesystem:<unix domain socket name>
    dev:<character device name>
    jdwp:<process pid> (remote only)
adb jdwp　 – list PIDs of processes hosting a JDWP transport
adb install [-l] [-r] <file> – push this package file to the device and install it
(‘-l’ means forward-lock the app)
(‘-r’ means reinstall the app, keeping its data)
adb uninstall [-k] <package> – remove this app package from the device
(‘-k’ means keep the data and cache directories)
adb bugreport                – return all information from the device　that should be included in a bug report.
adb help                     – show this help message
adb version                  – show version num
DATAOPTS:
(no option)                   – don’t touch the data partition
-w                           – wipe the data partition
-d                           – flash the data partition
scripting:
adb wait-for-device          – block until device is online
adb start-server             – ensure that there is a server running
adb kill-server              – kill the server if it is running
adb get-state                – prints: offline | bootloader | device
adb get-serialno             – prints: <serial-number>
adb status-window            – continuously print device status for a specified device
adb remount                  – remounts the /system partition on the device re
ad-write
adb root                     – restarts adb with root permissions
networking:
adb ppp <tty> [parameters]   – Run PPP over USB.
Note: you should not automatically start a PDP connection.</p>
<p><tty> refers to the tty for PPP stream. Eg. dev:/dev/omap_csmi_tty1
[parameters] – Eg. defaultroute debug dump local notty usepeerdns
adb sync notes: adb sync [ <directory> ]</p>
<p><localdir> can be interpreted in several ways:</p>
<ul>
<li>If <directory> is not specified, both /system and /data partitions will be updated.</li>
<li>If it is “system” or “data”, only the corresponding partition　is updated.</li>
</ul>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span><span class="breadcrumb"><li><a href="/categories/linux/">linux</a></li><li><a href="/categories/linux/android/">android</a></li></span></span> | <span class="tags">Tagged <a href="/tags/android/" class="label label-primary">android</a><a href="/tags/linux/" class="label label-success">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux-android--adb命令详解/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux-android--adb命令详解" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux-android--通过网络使用adb/">通过网络使用adb</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux-android--通过网络使用adb/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-adb">通过网络使用adb</h1>
<p>在adb的说明文档中提到：</p>
<pre><code>“An ADB transport models a connection between the ADB server and one device
or emulator. There are currently two kinds of transports:
   - USB transports, for physical devices through USB
   - Local transports, for emulators running on the host, connected to
     the server through TCP”

大意是说，在物理设备上，adb是通过USB连接到设备上的，而在模拟器上，adb是通过TCP协议连接到设备上的。实际上在物理设备上，也可以让adb 通过TCP协议来连接设备（当然前提条件是你的设备要有网口）。首先看一下下面这段源代码，出自system/core/adb/adb.c，第921 行：
</code></pre><p>   //<em> for the device, start the usb transport if the
        /</em>/<em> android usb device exists and &quot;service.adb.tcp&quot;
        /</em>/<em> is not set, otherwise start the network transport.
        /</em>/
    property_get(&quot;service.adb.tcp.port&quot;, value, &quot;0&quot;);
    if (sscanf(value, &quot;%d&quot;, &amp;port) == 1 &amp;&amp; port &gt; 0) {
        // listen on TCP port specified by service.adb.tcp.port property
        local_init(port);
    } else if (access(&quot;/dev/android_adb&quot;, F_OK) == 0) {
        // listen on USB
        usb_init();
    } else {
        // listen on default port
        local_init(ADB_LOCAL_TRANSPORT_PORT);
    }</p>
<pre><code>分析上述代码可以发现，在adbd启动时首先检查是否设置了service.adb.tcp.port，如果设置了，就是使用TCP作为连接方式；如果没 设置，就去检查是否有adb的USB设备（dev/android_adb)，如果有就用USB作为连接方式；如果没有USB设备，则还是用TCP作为连 接方式。

因此只需要在启动adbd之前设置service.adb.tcp.port，就可以让adbd选则TCP模式，也就可以通过网络来连接adb了。这需要修改init.rc文件。如果不想修改，也可以在系统启动之后，在控制台上执行下列命令：

/#stop adbd

/#set service.adb.tcp.port 5555

/#start adbd

这样就可以在主机上通过下列命令来连接设备了：

adb connetc &lt;ip-of-device&gt;:5555
</code></pre>
      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span><span class="breadcrumb"><li><a href="/categories/linux/">linux</a></li><li><a href="/categories/linux/android/">android</a></li></span></span> | <span class="tags">Tagged <a href="/tags/android/" class="label label-primary">android</a><a href="/tags/linux/" class="label label-success">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux-android--通过网络使用adb/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux-android--通过网络使用adb" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux-android--linux下adb工具的安装/">linux下adb工具的安装</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux-android--linux下adb工具的安装/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="linux-adb-">linux下adb工具的安装</h1>
<p>第一步：启动开发板，进入android系统后，在linux终端输入lsusb命令查询USB总线上的设备，比如我这里查询结果如下：</p>
<p>我这里是:
Bus 007 Device 009: ID 18d1:4e12</p>
<p>第二步：下载最新的android SDK并解压到某目录，下载地址：
<a href="http://developer.android.com/sdk/index.html" target="_blank"><a href="http://developer.android.com/sdk/index.html">http://developer.android.com/sdk/index.html</a></a>
截至目前最新的SDK为android-sdk_r12-linux_x86.tgz
解压出来的名称为android-sdk-linux_x86
进入下面目录：
cd android-sdk-linux_x86/tools/
./android update adb</p>
<p>第三步：创建一个新的udev规则的文件，在/etc/udev/rules.d路径下，新建名为imx-android.rules的文件，编辑内容如下：
vim /etc/udev/rules.d/50-android.rules</p>
<p>文件里添加如下配置参数:</p>
<p>/#Acer      0502</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;0502&quot;, MODE=&quot;0666&quot;</p>
<p>/#Dell     413c</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;413c&quot;, MODE=&quot;0666&quot;</p>
<p>/#Foxconn     0489</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;0489&quot;, MODE=&quot;0666&quot;</p>
<p>/#Garmin-Asus     091E</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;091e&quot;, MODE=&quot;0666&quot;</p>
<p>/#HTC     0bb4</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;0bb4&quot;, MODE=&quot;0666&quot;</p>
<p>/#Huawei     12d1</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;12d1&quot;, MODE=&quot;0666&quot;</p>
<p>/#Kyocera     0482</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;0482&quot;, MODE=&quot;0666&quot;</p>
<p>/#LG     1004</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;1004&quot;, MODE=&quot;0666&quot;</p>
<p>/#Motorola     22b8</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;22b8&quot;, MODE=&quot;0666&quot;</p>
<p>/#Nvidia     0955</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;0955&quot;, MODE=&quot;0666&quot;</p>
<p>/#Pantech     10A9</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;10A9&quot;, MODE=&quot;0666&quot;</p>
<p>/#Samsung     04e8</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;04e8&quot;, MODE=&quot;0666&quot;</p>
<p>/#Sharp     04dd</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;04dd&quot;, MODE=&quot;0666&quot;</p>
<p>/#Sony Ericsson     0fce</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;0fce&quot;, MODE=&quot;0666&quot;</p>
<p>/#ZTE     19D2</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;19D2&quot;, MODE=&quot;0666</p>
<p>/#MEIZU     18d1</p>
<p>SUBSYSTEM==&quot;usb&quot;, SYSFS{idVendor}==&quot;18d1&quot;, MODE=&quot;0666</p>
<p>但是这上面的ID，并不能包括所有。
解决办法是你可以使用lsusb命令查看你的USB ID</p>
<p>第四步：在/etc/profile中声明adb的路径:</p>
<p>export PATH=/usr/local/android-sdk-linux/platform-tools:$PATH</p>
<p>第五步：重启ADB
adb kill-server
adb start-server</p>
<p>第六步：使用adb devices命令查找设备：</p>
<p>[root@redhat6 platform-tools]/# adb devices</p>
<p>List of devices attached</p>
<p>353BCHHRB44F    device</p>
<p>至此，安装成功。</p>
<p>你可以进去设备了，用adb shell，可以操作你到android了。</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span><span class="breadcrumb"><li><a href="/categories/linux/">linux</a></li><li><a href="/categories/linux/android/">android</a></li></span></span> | <span class="tags">Tagged <a href="/tags/android/" class="label label-primary">android</a><a href="/tags/linux/" class="label label-success">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux-android--linux下adb工具的安装/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux-android--linux下adb工具的安装" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--hdfs_design/">hdfs_design</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--hdfs_design/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hdfs_design">hdfs_design</h1>
<p>HDFS Architecture
by Dhruba Borthakur
Table of contents
1 2
Introduction .......................................................................................................................3 Assumptions and Goals .....................................................................................................3
2.1 2.2 2.3 2.4 2.5 2.6
Hardware Failure .......................................................................................................... 3 Streaming Data Access .................................................................................................3 Large Data Sets .............................................................................................................3 Simple Coherency Model ............................................................................................. 4 “Moving Computation is Cheaper than Moving Data” ................................................4 Portability Across Heterogeneous Hardware and Software Platforms .........................4
3 4 5
NameNode and DataNodes ...............................................................................................4 The File System Namespace ............................................................................................. 5 Data Replication ................................................................................................................6
5.1 5.2 5.3
Replica Placement: The First Baby Steps .................................................................... 7 Replica Selection .......................................................................................................... 8 Safemode ...................................................................................................................... 8
6 7 8
The Persistence of File System Metadata ......................................................................... 8 The Communication Protocols ......................................................................................... 9 Robustness ........................................................................................................................ 9
8.1 8.2 8.3 8.4 8.5
Data Disk Failure, Heartbeats and Re-Replication .....................................................10 Cluster Rebalancing ....................................................................................................10 Data Integrity ..............................................................................................................10 Metadata Disk Failure ................................................................................................ 10 Snapshots ....................................................................................................................11
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
9
Data Organization ........................................................................................................... 11
9.1 9.2 9.3
Data Blocks ................................................................................................................ 11 Staging ........................................................................................................................11 Replication Pipelining ................................................................................................ 12 FS Shell .....................................................................................................................12 DFSAdmin ................................................................................................................ 13 Browser Interface ......................................................................................................13 File Deletes and Undeletes ....................................................................................... 13 Decrease Replication Factor ..................................................................................... 14
10
Accessibility .................................................................................................................. 12
10.1 10.2 10.3 11
Space Reclamation ........................................................................................................ 13
11.1 11.2 12
References ..................................................................................................................... 14
Page 2
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture</p>
<ol>
<li>Introduction
The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. It has many similarities with existing distributed file systems. However, the differences from other distributed file systems are significant. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets. HDFS relaxes a few POSIX requirements to enable streaming access to file system data. HDFS was originally built as infrastructure for the Apache Nutch web search engine project. HDFS is part of the Apache Hadoop Core project. The project URL is <a href="http://hadoop.apache.org/core/" target="_blank">http://hadoop.apache.org/core/</a>.</li>
<li>Assumptions and Goals
2.1. Hardware Failure
Hardware failure is the norm rather than the exception. An HDFS instance may consist of hundreds or thousands of server machines, each storing part of the file system’s data. The fact that there are a huge number of components and that each component has a non-trivial probability of failure means that some component of HDFS is always non-functional. Therefore, detection of faults and quick, automatic recovery from them is a core architectural goal of HDFS.
2.2. Streaming Data Access
Applications that run on HDFS need streaming access to their data sets. They are not general purpose applications that typically run on general purpose file systems. HDFS is designed more for batch processing rather than interactive use by users. The emphasis is on high throughput of data access rather than low latency of data access. POSIX imposes many hard requirements that are not needed for applications that are targeted for HDFS. POSIX semantics in a few key areas has been traded to increase data throughput rates.
2.3. Large Data Sets
Applications that run on HDFS have large data sets. A typical file in HDFS is gigabytes to terabytes in size. Thus, HDFS is tuned to support large files. It should provide high aggregate data bandwidth and scale to hundreds of nodes in a single cluster. It should support tens of millions of files in a single instance.
Page 3
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
2.4. Simple Coherency Model
HDFS applications need a write-once-read-many access model for files. A file once created, written, and closed need not be changed. This assumption simplifies data coherency issues and enables high throughput data access. A Map/Reduce application or a web crawler application fits perfectly with this model. There is a plan to support appending-writes to files in the future.
2.5. “Moving Computation is Cheaper than Moving Data”
A computation requested by an application is much more efficient if it is executed near the data it operates on. This is especially true when the size of the data set is huge. This minimizes network congestion and increases the overall throughput of the system. The assumption is that it is often better to migrate the computation closer to where the data is located rather than moving the data to where the application is running. HDFS provides interfaces for applications to move themselves closer to where the data is located.
2.6. Portability Across Heterogeneous Hardware and Software Platforms
HDFS has been designed to be easily portable from one platform to another. This facilitates widespread adoption of HDFS as a platform of choice for a large set of applications.</li>
<li>NameNode and DataNodes
HDFS has a master/slave architecture. An HDFS cluster consists of a single NameNode, a master server that manages the file system namespace and regulates access to files by clients. In addition, there are a number of DataNodes, usually one per node in the cluster, which manage storage attached to the nodes that they run on. HDFS exposes a file system namespace and allows user data to be stored in files. Internally, a file is split into one or more blocks and these blocks are stored in a set of DataNodes. The NameNode executes file system namespace operations like opening, closing, and renaming files and directories. It also determines the mapping of blocks to DataNodes. The DataNodes are responsible for serving read and write requests from the file system’s clients. The DataNodes also perform block creation, deletion, and replication upon instruction from the NameNode.
Page 4
Copyright © 2008 The Apache Software Foundation. All rights reserved.
<img src="" alt=""> HDFS Architecture
The NameNode and DataNode are pieces of software designed to run on commodity machines. These machines typically run a GNU/Linux operating system (OS). HDFS is built using the Java language; any machine that supports Java can run the NameNode or the DataNode software. Usage of the highly portable Java language means that HDFS can be deployed on a wide range of machines. A typical deployment has a dedicated machine that runs only the NameNode software. Each of the other machines in the cluster runs one instance of the DataNode software. The architecture does not preclude running multiple DataNodes on the same machine but in a real deployment that is rarely the case. The existence of a single NameNode in a cluster greatly simplifies the architecture of the system. The NameNode is the arbitrator and repository for all HDFS metadata. The system is designed in such a way that user data never flows through the NameNode.</li>
<li>The File System Namespace
HDFS supports a traditional hierarchical file organization. A user or an application can create directories and store files inside these directories. The file system namespace hierarchy is
Page 5
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
similar to most other existing file systems; one can create and remove files, move a file from one directory to another, or rename a file. HDFS does not yet implement user quotas or access permissions. HDFS does not support hard links or soft links. However, the HDFS architecture does not preclude implementing these features. The NameNode maintains the file system namespace. Any change to the file system namespace or its properties is recorded by the NameNode. An application can specify the number of replicas of a file that should be maintained by HDFS. The number of copies of a file is called the replication factor of that file. This information is stored by the NameNode.</li>
<li>Data Replication
HDFS is designed to reliably store very large files across machines in a large cluster. It stores each file as a sequence of blocks; all blocks in a file except the last block are the same size. The blocks of a file are replicated for fault tolerance. The block size and replication factor are configurable per file. An application can specify the number of replicas of a file. The replication factor can be specified at file creation time and can be changed later. Files in HDFS are write-once and have strictly one writer at any time. The NameNode makes all decisions regarding replication of blocks. It periodically receives a Heartbeat and a Blockreport from each of the DataNodes in the cluster. Receipt of a Heartbeat implies that the DataNode is functioning properly. A Blockreport contains a list of all blocks on a DataNode.
Page 6
Copyright © 2008 The Apache Software Foundation. All rights reserved.
<img src="" alt=""> HDFS Architecture
5.1. Replica Placement: The First Baby Steps
The placement of replicas is critical to HDFS reliability and performance. Optimizing replica placement distinguishes HDFS from most other distributed file systems. This is a feature that needs lots of tuning and experience. The purpose of a rack-aware replica placement policy is to improve data reliability, availability, and network bandwidth utilization. The current implementation for the replica placement policy is a first effort in this direction. The short-term goals of implementing this policy are to validate it on production systems, learn more about its behavior, and build a foundation to test and research more sophisticated policies. Large HDFS instances run on a cluster of computers that commonly spread across many racks. Communication between two nodes in different racks has to go through switches. In most cases, network bandwidth between machines in the same rack is greater than network bandwidth between machines in different racks. The NameNode determines the rack id each DataNode belongs to via the process outlined in Rack Awareness. A simple but non-optimal policy is to place replicas on unique racks. This prevents losing data when an entire rack fails and allows use of bandwidth from multiple
Page 7
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
racks when reading data. This policy evenly distributes replicas in the cluster which makes it easy to balance load on component failure. However, this policy increases the cost of writes because a write needs to transfer blocks to multiple racks. For the common case, when the replication factor is three, HDFS’s placement policy is to put one replica on one node in the local rack, another on a different node in the local rack, and the last on a different node in a different rack. This policy cuts the inter-rack write traffic which generally improves write performance. The chance of rack failure is far less than that of node failure; this policy does not impact data reliability and availability guarantees. However, it does reduce the aggregate network bandwidth used when reading data since a block is placed in only two unique racks rather than three. With this policy, the replicas of a file do not evenly distribute across the racks. One third of replicas are on one node, two thirds of replicas are on one rack, and the other third are evenly distributed across the remaining racks. This policy improves write performance without compromising data reliability or read performance. The current, default replica placement policy described here is a work in progress.
5.2. Replica Selection
To minimize global bandwidth consumption and read latency, HDFS tries to satisfy a read request from a replica that is closest to the reader. If there exists a replica on the same rack as the reader node, then that replica is preferred to satisfy the read request. If angg/ HDFS cluster spans multiple data centers, then a replica that is resident in the local data center is preferred over any remote replica.
5.3. Safemode
On startup, the NameNode enters a special state called Safemode. Replication of data blocks does not occur when the NameNode is in the Safemode state. The NameNode receives Heartbeat and Blockreport messages from the DataNodes. A Blockreport contains the list of data blocks that a DataNode is hosting. Each block has a specified minimum number of replicas. A block is considered safely replicated when the minimum number of replicas of that data block has checked in with the NameNode. After a configurable percentage of safely replicated data blocks checks in with the NameNode (plus an additional 30 seconds), the NameNode exits the Safemode state. It then determines the list of data blocks (if any) that still have fewer than the specified number of replicas. The NameNode then replicates these blocks to other DataNodes.</li>
<li>The Persistence of File System Metadata
Page 8
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
The HDFS namespace is stored by the NameNode. The NameNode uses a transaction log called the EditLog to persistently record every change that occurs to file system metadata. For example, creating a new file in HDFS causes the NameNode to insert a record into the EditLog indicating this. Similarly, changing the replication factor of a file causes a new record to be inserted into the EditLog. The NameNode uses a file in its local host OS file system to store the EditLog. The entire file system namespace, including the mapping of blocks to files and file system properties, is stored in a file called the FsImage. The FsImage is stored as a file in the NameNode’s local file system too. The NameNode keeps an image of the entire file system namespace and file Blockmap in memory. This key metadata item is designed to be compact, such that a NameNode with 4 GB of RAM is plenty to support a huge number of files and directories. When the NameNode starts up, it reads the FsImage and EditLog from disk, applies all the transactions from the EditLog to the in-memory representation of the FsImage, and flushes out this new version into a new FsImage on disk. It can then truncate the old EditLog because its transactions have been applied to the persistent FsImage. This process is called a checkpoint. In the current implementation, a checkpoint only occurs when the NameNode starts up. Work is in progress to support periodic checkpointing in the near future. The DataNode stores HDFS data in files in its local file system. The DataNode has no knowledge about HDFS files. It stores each block of HDFS data in a separate file in its local file system. The DataNode does not create all files in the same directory. Instead, it uses a heuristic to determine the optimal number of files per directory and creates subdirectories appropriately. It is not optimal to create all local files in the same directory because the local file system might not be able to efficiently support a huge number of files in a single directory. When a DataNode starts up, it scans through its local file system, generates a list of all HDFS data blocks that correspond to each of these local files and sends this report to the NameNode: this is the Blockreport.</li>
<li>The Communication Protocols
All HDFS communication protocols are layered on top of the TCP/IP protocol. A client establishes a connection to a configurable TCP port on the NameNode machine. It talks the ClientProtocol with the NameNode. The DataNodes talk to the NameNode using the DataNode Protocol. A Remote Procedure Call (RPC) abstraction wraps both the Client Protocol and the DataNode Protocol. By design, the NameNode never initiates any RPCs. Instead, it only responds to RPC requests issued by DataNodes or clients.</li>
<li>Robustness
The primary objective of HDFS is to store data reliably even in the presence of failures. The
Page 9
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
three common types of failures are NameNode failures, DataNode failures and network partitions.
8.1. Data Disk Failure, Heartbeats and Re-Replication
Each DataNode sends a Heartbeat message to the NameNode periodically. A network partition can cause a subset of DataNodes to lose connectivity with the NameNode. The NameNode detects this condition by the absence of a Heartbeat message. The NameNode marks DataNodes without recent Heartbeats as dead and does not forward any new IO requests to them. Any data that was registered to a dead DataNode is not available to HDFS any more. DataNode death may cause the replication factor of some blocks to fall below their specified value. The NameNode constantly tracks which blocks need to be replicated and initiates replication whenever necessary. The necessity for re-replication may arise due to many reasons: a DataNode may become unavailable, a replica may become corrupted, a hard disk on a DataNode may fail, or the replication factor of a file may be increased.
8.2. Cluster Rebalancing
The HDFS architecture is compatible with data rebalancing schemes. A scheme might automatically move data from one DataNode to another if the free space on a DataNode falls below a certain threshold. In the event of a sudden high demand for a particular file, a scheme might dynamically create additional replicas and rebalance other data in the cluster. These types of data rebalancing schemes are not yet implemented.
8.3. Data Integrity
It is possible that a block of data fetched from a DataNode arrives corrupted. This corruption can occur because of faults in a storage device, network faults, or buggy software. The HDFS client software implements checksum checking on the contents of HDFS files. When a client creates an HDFS file, it computes a checksum of each block of the file and stores these checksums in a separate hidden file in the same HDFS namespace. When a client retrieves file contents it verifies that the data it received from each DataNode matches the checksum stored in the associated checksum file. If not, then the client can opt to retrieve that block from another DataNode that has a replica of that block.
8.4. Metadata Disk Failure
The FsImage and the EditLog are central data structures of HDFS. A corruption of these files can cause the HDFS instance to be non-functional. For this reason, the NameNode can be configured to support maintaining multiple copies of the FsImage and EditLog. Any update
Page 10
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
to either the FsImage or EditLog causes each of the FsImages and EditLogs to get updated synchronously. This synchronous updating of multiple copies of the FsImage and EditLog may degrade the rate of namespace transactions per second that a NameNode can support. However, this degradation is acceptable because even though HDFS applications are very data intensive in nature, they are not metadata intensive. When a NameNode restarts, it selects the latest consistent FsImage and EditLog to use. The NameNode machine is a single point of failure for an HDFS cluster. If the NameNode machine fails, manual intervention is necessary. Currently, automatic restart and failover of the NameNode software to another machine is not supported.
8.5. Snapshots
Snapshots support storing a copy of data at a particular instant of time. One usage of the snapshot feature may be to roll back a corrupted HDFS instance to a previously known good point in time. HDFS does not currently support snapshots but will in a future release.</li>
<li>Data Organization
9.1. Data Blocks
HDFS is designed to support very large files. Applications that are compatible with HDFS are those that deal with large data sets. These applications write their data only once but they read it one or more times and require these reads to be satisfied at streaming speeds. HDFS supports write-once-read-many semantics on files. A typical block size used by HDFS is 64 MB. Thus, an HDFS file is chopped up into 64 MB chunks, and if possible, each chunk will reside on a different DataNode.
9.2. Staging
A client request to create a file does not reach the NameNode immediately. In fact, initially the HDFS client caches the file data into a temporary local file. Application writes are transparently redirected to this temporary local file. When the local file accumulates data worth over one HDFS block size, the client contacts the NameNode. The NameNode inserts the file name into the file system hierarchy and allocates a data block for it. The NameNode responds to the client request with the identity of the DataNode and the destination data block. Then the client flushes the block of data from the local temporary file to the specified DataNode. When a file is closed, the remaining un-flushed data in the temporary local file is transferred to the DataNode. The client then tells the NameNode that the file is closed. At this point, the NameNode commits the file creation operation into a persistent store. If the
Page 11
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
NameNode dies before the file is closed, the file is lost. The above approach has been adopted after careful consideration of target applications that run on HDFS. These applications need streaming writes to files. If a client writes to a remote file directly without any client side buffering, the network speed and the congestion in the network impacts throughput considerably. This approach is not without precedent. Earlier distributed file systems, e.g. AFS, have used client side caching to improve performance. A POSIX requirement has been relaxed to achieve higher performance of data uploads.
9.3. Replication Pipelining
When a client is writing data to an HDFS file, its data is first written to a local file as explained in the previous section. Suppose the HDFS file has a replication factor of three. When the local file accumulates a full block of user data, the client retrieves a list of DataNodes from the NameNode. This list contains the DataNodes that will host a replica of that block. The client then flushes the data block to the first DataNode. The first DataNode starts receiving the data in small portions (4 KB), writes each portion to its local repository and transfers that portion to the second DataNode in the list. The second DataNode, in turn starts receiving each portion of the data block, writes that portion to its repository and then flushes that portion to the third DataNode. Finally, the third DataNode writes the data to its local repository. Thus, a DataNode can be receiving data from the previous one in the pipeline and at the same time forwarding data to the next one in the pipeline. Thus, the data is pipelined from one DataNode to the next.</li>
<li>Accessibility
HDFS can be accessed from applications in many different ways. Natively, HDFS provides a FileSystem Java API for applications to use. A C language wrapper for this Java API is also available. In addition, an HTTP browser can also be used to browse the files of an HDFS instance. Work is in progress to expose HDFS through the WebDAV protocol.
10.1. FS Shell
HDFS allows user data to be organized in the form of files and directories. It provides a commandline interface called FS shell that lets a user interact with the data in HDFS. The syntax of this command set is similar to other shells (e.g. bash, csh) that users are already familiar with. Here are some sample action/command pairs:
Action Create a directory named /foodir Command bin/hadoop dfs -mkdir /foodir
Page 12
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
Remove a directory named /foodir View the contents of a file named /foodir/myfile.txt
bin/hadoop dfs -rmr /foodir bin/hadoop dfs -cat /foodir/myfile.txt
FS shell is targeted for applications that need a scripting language to interact with the stored data.
10.2. DFSAdmin
The DFSAdmin command set is used for administering an HDFS cluster. These are commands that are used only by an HDFS administrator. Here are some sample action/command pairs:
Action Put the cluster in Safemode Generate a list of DataNodes Recommission or decommission DataNode(s) Command bin/hadoop dfsadmin -safemode enter bin/hadoop dfsadmin -report bin/hadoop dfsadmin -refreshNodes
10.3. Browser Interface
A typical HDFS install configures a web server to expose the HDFS namespace through a configurable TCP port. This allows a user to navigate the HDFS namespace and view the contents of its files using a web browser.</li>
<li>Space Reclamation
11.1. File Deletes and Undeletes
When a file is deleted by a user or an application, it is not immediately removed from HDFS. Instead, HDFS first renames it to a file in the /trash directory. The file can be restored quickly as long as it remains in /trash. A file remains in /trash for a configurable amount of time. After the expiry of its life in /trash, the NameNode deletes the file from the HDFS namespace. The deletion of a file causes the blocks associated with the file to be freed. Note that there could be an appreciable time delay between the time a file is deleted by a user and the time of the corresponding increase in free space in HDFS. A user can Undelete a file after deleting it as long as it remains in the /trash directory. If a user wants to undelete a file that he/she has deleted, he/she can navigate the /trash directory and retrieve the file. The /trash directory contains only the latest copy of the file
Page 13
Copyright © 2008 The Apache Software Foundation. All rights reserved.
HDFS Architecture
that was deleted. The /trash directory is just like any other directory with one special feature: HDFS applies specified policies to automatically delete files from this directory. The current default policy is to delete files from /trash that are more than 6 hours old. In the future, this policy will be configurable through a well defined interface.
11.2. Decrease Replication Factor
When the replication factor of a file is reduced, the NameNode selects excess replicas that can be deleted. The next Heartbeat transfers this information to the DataNode. The DataNode then removes the corresponding blocks and the corresponding free space appears in the cluster. Once again, there might be a time delay between the completion of the setReplication API call and the appearance of free space in the cluster.</li>
<li>References
Hadoop JavaDoc API. HDFS source code: <a href="http://hadoop.apache.org/core/version_control.html" target="_blank">http://hadoop.apache.org/core/version_control.html</a>
Page 14
Copyright © 2008 The Apache Software Foundation. All rights reserved.</li>
</ol>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--hdfs_design/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--hdfs_design" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/108/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/106/">106</a></li><li><a class="page-number" href="/page/107/">107</a></li><li><a class="page-number" href="/page/108/">108</a></li><li class="active"><li><span class="page-number current">109</span></li><li><a class="page-number" href="/page/110/">110</a></li><li><a class="page-number" href="/page/111/">111</a></li><li><a class="page-number" href="/page/112/">112</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/161/">161</a></li><li><a class="page-number" href="/page/162/">162</a></li><li><a class="extend next" href="/page/110/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Site powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a>  update time: <em>2014-04-07 19:25:39</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
