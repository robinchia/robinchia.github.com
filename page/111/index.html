
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 111 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--HDFS写入和读取流程/">HDFS写入和读取流程</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--HDFS写入和读取流程/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hdfs-">HDFS写入和读取流程</h1>
<p>您还未登录！|<a href="https://passport.csdn.net/account/login" target="_blank">登录</a>|<a href="https://passport.csdn.net/account/register" target="_blank">注册</a>|<a href="https://passport.csdn.net/help/faq" target="_blank">帮助</a></p>
<ul>
<li><a href="http://www.csdn.net/" target="_blank">首页</a></li>
<li><a href="http://news.csdn.net/" target="_blank">业界</a></li>
<li><a href="http://mobile.csdn.net/" target="_blank">移动</a></li>
<li><a href="http://cloud.csdn.net/" target="_blank">云计算</a></li>
<li><a href="http://sd.csdn.net/" target="_blank">研发</a></li>
<li><a href="http://bbs.csdn.net/" target="_blank">论坛</a></li>
<li><a href="http://blog.csdn.net/" target="_blank">博客</a></li>
<li><a href="http://download.csdn.net/" target="_blank">下载</a></li>
<li><h2 id="-"><a href="">更多</a></h2>
</li>
</ul>
<h1 id="-guisu-http-blog-csdn-net-hguisu-"><a href="http://blog.csdn.net/hguisu" target="_blank">guisu，程序人生。</a></h1>
<h2 id="-a-clever-person-solves-a-problem-a-wise-person-avoids-it-">能干的人解决问题。智慧的人绕开问题(A clever person solves a problem. A wise person avoids it)</h2>
<ul>
<li><a href="http://blog.csdn.net/hguisu?viewmode=contents" target="_blank"><img src="" alt="">目录视图</a></li>
<li><a href="http://blog.csdn.net/hguisu?viewmode=list" target="_blank"><img src="" alt="">摘要视图</a></li>
<li><a href="http://blog.csdn.net/hguisu/rss/list" target="_blank"><img src="" alt="">订阅</a>
<a href="http://blog.csdn.net/blogdevteam/article/details/11889881" target="_blank">2014年1月微软MVP申请开始啦！</a>      <a href="http://bbs.csdn.net/topics/390594487" target="_blank">CSDN社区中秋晒福利活动正式开始啦！</a>        <a href="http://www.csdn.net/article/2013-09-17/2816962" target="_blank">专访钟声：Java程序员，上班那点事儿</a>      <a href="http://blog.csdn.net/adali/article/details/9813651" target="_blank">独一无二的职位：开源社区经理</a>      <a href="http://blog.csdn.net/blogdevteam/article/details/11975399" target="_blank">“说说家乡的互联网”主题有奖征文</a></li>
</ul>
<h3 id="-hdfs-"><a href="">HDFS写入和读取流程</a></h3>
<p>分类： <a href="http://blog.csdn.net/hguisu/article/category/1072794" target="_blank">云计算hadoop</a>  2012-02-14 23:50 8282人阅读 <a href="">评论</a>(17) <a href="&quot;收藏&quot;">收藏</a> <a href="&quot;举报&quot;">举报</a>
<a href="http://blog.csdn.net/tag/details.html?tag=%e5%ad%98%e5%82%a8" target="_blank">存储</a><a href="http://blog.csdn.net/tag/details.html?tag=hadoop" target="_blank">hadoop</a><a href="http://blog.csdn.net/tag/details.html?tag=image" target="_blank">image</a><a href="http://blog.csdn.net/tag/details.html?tag=system" target="_blank">system</a><a href="http://blog.csdn.net/tag/details.html?tag=mysql" target="_blank">mysql</a></p>
<p>目录<a href="&quot;系统根据文章中H1到H6标签自动生成文章目录&quot;">(?)</a><a href="&quot;展开&quot;">[+]</a></p>
<ol>
<li><a href="">一HDFS</a></li>
<li><a href="">二HDFS的体系结构</a></li>
<li><p><a href="">三读写流程</a></p>
</li>
<li><p><a href="">GFS论文提到的文件读取简单流程</a></p>
</li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href=""></a></li>
<li><a href="">详细流程</a></li>
<li><a href=""></a></li>
<li><p><a href="">GFS论文提到的写入文件简单流程</a></p>
</li>
<li><p><a href="">详细流程</a></p>
</li>
<li><a href=""></a><h2 id="-hdfs"><a href=""></a>一、HDFS</h2>
</li>
</ol>
<p>HDFS全称是Hadoop Distributed System。HDFS是为以流的方式存取大文件而设计的。适用于几百MB，GB以及TB，并写一次读多次的场合。而对于低延时数据访问、大量小文件、同时写和任意的文件修改，则并不是十分适合。</p>
<p>目前HDFS支持的使用接口除了Java的还有，Thrift、C、FUSE、WebDAV、HTTP等。HDFS是以block-sized chunk组织其文件内容的，默认的block大小为64MB，对于不足64MB的文件，其会占用一个block，但实际上不用占用实际硬盘上的64MB，这可以说是HDFS是在文件系统之上架设的一个中间层。之所以将默认的block大小设置为64MB这么大，是因为block-sized对于文件定位很有帮助，同时大文件更使传输的时间远大于文件寻找的时间，这样可以最大化地减少文件定位的时间在整个文件获取总时间中的比例 。</p>
<h2 id="-hdfs-"><a href=""></a>二、HDFS的体系结构</h2>
<p>构成HDFS主要是Namenode（master）和一系列的Datanode（workers）。Namenode是管理HDFS的目录树和相关的文件元数据，这些信息是以&quot;namespace image&quot;和&quot;edit log&quot;两个文件形式存放在本地磁盘，但是这些文件是在HDFS每次重启的时候重新构造出来的。Datanode则是存取文件实际内容的节点，Datanodes会定时地将block的列表汇报给Namenode。</p>
<p>由于Namenode是元数据存放的节点，如果Namenode挂了那么HDFS就没法正常运行，因此一般使用将元数据持久存储在本地或远程的机器上，或者使用secondary namenode来定期同步Namenode的元数据信息，secondary namenode有点类似于MySQL的Master/Salves中的Slave，&quot;edit log&quot;就类似&quot;bin log&quot;。如果Namenode出现了故障，一般会将原Namenode中持久化的元数据拷贝到secondary namenode中，使secondary namenode作为新的Namenode运行起来。</p>
<pre><code>                        ![]()
</code></pre><h2 id="-"><a href=""></a>三、读写流程</h2>
<h3 id="-gfs-"><a href=""></a>GFS论文提到的文件读取简单流程：</h3>
<h3 id="-"><a href=""></a></h3>
<h3 id="-"><a href=""></a>                <img src="" alt=""></h3>
<h3 id="-"><a href=""></a><em>**</em></h3>
<h3 id="-reading-data-from-hdfs-http-blog-endlesscode-com-wp-content-uploads-2010-06-reading-data-from-hdfs-png-reading-data-from-hdfs-"><a href=""></a><strong>详细流程：</strong><img src="http://blog.endlesscode.com/wp-content/uploads/2010/06/reading-data-from-hdfs.png" alt="reading data from hdfs" title="reading data from hdfs"></h3>
<p>文件读取的过程如下：</p>
<ol>
<li>使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求；</li>
<li>Namenode会视情况返回文件的部分或者全部block列表，对于每个block，Namenode都会返回有该block拷贝的DataNode地址；</li>
<li>客户端开发库Client会选取离客户端最接近的DataNode来读取block；如果客户端本身就是DataNode,那么将从本地直接获取数据.</li>
<li>读取完当前block的数据后，关闭与当前的DataNode连接，并为读取下一个block寻找最佳的DataNode；</li>
<li>当读完列表的block后，且文件读取还没有结束，客户端开发库会继续向Namenode获取下一批的block列表。</li>
<li>读取完一个block都会进行checksum验证，如果读取datanode时出现错误，客户端会通知Namenode，然后再从下一个拥有该block拷贝的datanode继续读。</li>
</ol>
<h3 id="-"><a href=""></a></h3>
<h3 id="-gfs-"><a href=""></a>GFS论文提到的写入文件简单流程：</h3>
<pre><code>                                 ![]()             
</code></pre><h2 id="-writing-data-to-hdfs-http-blog-endlesscode-com-wp-content-uploads-2010-06-writing-data-to-hdfs-png-writing-data-to-hdfs-"><a href=""></a>详细流程：<img src="http://blog.endlesscode.com/wp-content/uploads/2010/06/writing-data-to-hdfs.png" alt="writing data to hdfs" title="writing data to hdfs"></h2>
<p>写入文件的过程比读取较为复杂：</p>
<ol>
<li>使用HDFS提供的客户端开发库Client，向远程的Namenode发起RPC请求；</li>
<li>Namenode会检查要创建的文件是否已经存在，创建者是否有权限进行操作，成功则会为文件<strong>创建一个记录</strong>，否则会让客户端抛出异常；</li>
<li>当客户端开始写入文件的时候，开发库会将文件切分成多个packets，并在内部以数据队列&quot;data queue&quot;的形式管理这些packets，并向Namenode申请新的blocks，获取用来存储replicas的合适的datanodes列表，列表的大小根据在Namenode中对replication的设置而定。</li>
<li>开始以pipeline（管道）的形式将packet写入所有的replicas中。开发库把packet以流的方式写入第一个datanode，该datanode把该packet存储之后，再将其传递给在此pipeline中的下一个datanode，直到最后一个datanode，这种写数据的方式呈流水线的形式。</li>
<li>最后一个datanode成功存储之后会返回一个ack packet，在pipeline里传递至客户端，在客户端的开发库内部维护着&quot;ack queue&quot;，成功收到datanode返回的ack packet后会从&quot;ack queue&quot;移除相应的packet。</li>
<li>如果传输过程中，有某个datanode出现了故障，那么当前的pipeline会被关闭，出现故障的datanode会从当前的pipeline中移除，剩余的block会继续剩下的datanode中继续以pipeline的形式传输，同时Namenode会分配一个新的datanode，保持replicas设定的数量。</li>
</ol>
<h2 id="-"><a href=""></a></h2>
<p>分享到： <a href="&quot;分享到新浪微博&quot;"></a><a href="&quot;分享到腾讯微博&quot;"></a></p>
<ol>
<li>上一篇：<a href="http://blog.csdn.net/hguisu/article/details/7256833" target="_blank">Hadoop Hive sql语法详解</a></li>
<li>下一篇：<a href="http://blog.csdn.net/hguisu/article/details/7261145" target="_blank">Hadoop HDFS分布式文件系统设计要点与架构</a></li>
</ol>
<p>顶 3 踩 1
查看评论<a href=""></a></p>
<p>3楼 <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-04-09 11:25发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>在写数据的过程中，一个文件被分割成很多blocks，这些block是按顺序一个个操作的，还是并发的进行传输的？Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-04-09 12:45发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：写数据的是以流的方式传输，即管道的方式，一个一个block顺序传输。而不是像树形拓扑结构那样分散传输。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-04-17 18:03发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：您好，很感谢您回答我，但是我仍有点疑惑，hdfs中的文件大小区分为：chunk&lt;packet&lt;block,在每个packet的传输到多个DN（datanode）的过程中是以pipeline方式，但是当其中一个block在以这种方式传输时，其他的block是要等待还是并发的进行呢？谢谢！Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-04-20 16:23发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：管道方式，即是队列方式传输。只能一个block传完了，接着传下个block。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-04-30 18:18发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：你好！如果这样，那hdfs的并发写实如何体现的呢？Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-05-02 09:29发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：hdfs没有并发写入。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-05-03 23:39发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：这样的话，那hadoop是比较适合大数据的处理了，对于文件的写的速度并没有多大的提高了?Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-05-04 09:40发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：hadoop本来就是通往云服务的捷径，为处理超大数据集而准备。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-05-07 10:57发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：这样hadoop的主要优势是在map/reduce那一块，而其文件系统有什么样的优势呢（在文件的读写方面，和其他的文件系统）？Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-05-07 11:50发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复huangbo1988911：hdfs可以存储超大数据，而map/reduce要处理的数据存储在hdfs上，即MR分布式运算。Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-05-09 22:35发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu： 那多个文件同时向hdfs写入是如何进行的呢？Re: <a href="http://blog.csdn.net/huangbo1988911" target="_blank">huangbo1988911</a> 2012-05-09 00:39发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/huangbo1988911" target="_blank"><img src="" alt=""></a>回复hguisu：恩，hdfs相对于其他的文件系统，除了更适合存储大数据以外，而且有很强的容错能力，但是对数据的读写等，没有并发性，只是采用了管道的方式，这可能是它的一个小缺点吧。2楼 <a href="http://blog.csdn.net/CD_xiaoxin" target="_blank">CD_xiaoxin</a> 2012-03-19 09:44发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/CD_xiaoxin" target="_blank"><img src="" alt=""></a>很详细 很有帮助 谢谢1楼 <a href="http://blog.csdn.net/lin_FS" target="_blank">lin_FS</a> 2012-03-16 10:01发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/lin_FS" target="_blank"><img src="" alt=""></a>client端的那个queue是在内存中，还是写在临时文件里了？Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-03-19 09:43发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复lin_FS：client分割数据成一个个block（packet）这些数据都不在内存中，你可以想象，如果一个数据是100G，它你那个放进内存吗？Re: <a href="http://blog.csdn.net/lin_FS" target="_blank">lin_FS</a> 2012-03-21 17:26发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/lin_FS" target="_blank"><img src="" alt=""></a>在client端， 多个block（packet）组成一个队列，然后可以想象把文件（100G）分成若干个packet，如果队列满了就根本写不进去数据了，根本不会出现你想象的那种情况。我想了解的是，这个队列在内存中还是以文件的形式，呵呵Re: <a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a> 2012-03-31 18:47发表 <a href="&quot;回复&quot;">[回复]</a>  <a href="&quot;引用&quot;">[引用]</a> <a href="&quot;举报&quot;">[举报]</a><a href="http://blog.csdn.net/hguisu" target="_blank"><img src="" alt=""></a>回复lin_FS：这个队列肯定是文件的形式存在的。
您还没有登录,请<a href="">[登录]</a>或<a href="http://passport.csdn.net/account/register?from=http%3A%2F%2Fblog.csdn.net%2Fhguisu%2Farticle%2Fdetails%2F7259716" target="_blank">[注册]</a></p>
<p>/* 以上用户言论只代表其个人观点，不代表CSDN网站的观点或立场<a href=""></a><a href=""></a></p>
<p><a href="">hguisu</a>
<a href="&quot;回到顶部&quot;"><img src="" alt="TOP"></a></p>
<p>个人资料</p>
<p><a href="http://my.csdn.net/hguisu" target="_blank"><img src="&quot;访问我的空间&quot;" alt=""></a>
<a href="http://my.csdn.net/hguisu" target="_blank">真实的归宿</a></p>
<p><a href="&quot;[加关注]&quot;"></a> <a href="&quot;[发私信]&quot;"></a>
<a href="http://medal.blog.csdn.net/allmedal.aspx" target="_blank"><img src="" alt=""></a></p>
<ul>
<li>访问：481035次</li>
<li>积分：6666分</li>
<li><p>排名：第614名</p>
</li>
<li><p>原创：190篇</p>
</li>
<li>转载：1篇</li>
<li>译文：0篇</li>
<li>评论：313条</li>
</ul>
<p>文章分类</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/category/1253451" target="_blank">操作系统</a>(5)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/796967" target="_blank">Linux</a>(17)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/796963" target="_blank">MySQL</a>(12)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/796962" target="_blank">PHP</a>(41)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1104862" target="_blank">PHP内核</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/796968" target="_blank">技术人生</a>(7)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1054628" target="_blank">数据结构与算法</a>(27)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1072794" target="_blank">云计算hadoop</a>(20)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1075597" target="_blank">网络知识</a>(7)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1080443" target="_blank">c/c++</a>(22)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1099674" target="_blank">memcache</a>(5)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1111071" target="_blank">HipHop</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1112019" target="_blank">计算机原理</a>(4)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1114530" target="_blank">Java</a>(7)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1122753" target="_blank">socket网络编程</a>(5)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1133340" target="_blank">设计模式</a>(26)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1151353" target="_blank">AOP</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1152364" target="_blank">重构</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1173389" target="_blank">重构与模式</a>(1)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1209788" target="_blank">大数据处理</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1230933" target="_blank">搜索引擎Search Engine</a>(15)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1302430" target="_blank">HTML5</a>(1)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1309674" target="_blank">Android</a>(1)</li>
<li><a href="http://blog.csdn.net/hguisu/article/category/1422000" target="_blank">webserver</a>(3)</li>
<li><p><a href="http://blog.csdn.net/hguisu/article/category/1429288" target="_blank">NOSQL</a>(6)
文章存档</p>
</li>
<li><p><a href="http://blog.csdn.net/hguisu/article/month/2013/09" target="_blank">2013年09月</a>(2)</p>
</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/08" target="_blank">2013年08月</a>(1)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/07" target="_blank">2013年07月</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/06" target="_blank">2013年06月</a>(3)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/05" target="_blank">2013年05月</a>(3)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/03" target="_blank">2013年03月</a>(3)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/02" target="_blank">2013年02月</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2013/01" target="_blank">2013年01月</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/12" target="_blank">2012年12月</a>(4)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/11" target="_blank">2012年11月</a>(3)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/10" target="_blank">2012年10月</a>(2)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/09" target="_blank">2012年09月</a>(15)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/08" target="_blank">2012年08月</a>(6)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/07" target="_blank">2012年07月</a>(8)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/06" target="_blank">2012年06月</a>(14)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/05" target="_blank">2012年05月</a>(29)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/04" target="_blank">2012年04月</a>(26)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/03" target="_blank">2012年03月</a>(27)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2012/02" target="_blank">2012年02月</a>(18)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2011/12" target="_blank">2011年12月</a>(7)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2011/01" target="_blank">2011年01月</a>(8)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2010/07" target="_blank">2010年07月</a>(6)</li>
<li><a href="http://blog.csdn.net/hguisu/article/month/2007/12" target="_blank">2007年12月</a>(2)</li>
</ul>
<p>展开</p>
<p>阅读排行</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7237395" title="Hadoop集群配置（最全面总结）" target="_blank">Hadoop集群配置（最全面总结）</a>(23024)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7527842" title="设计模式（五）适配器模式Adapter（结构型）" target="_blank">设计模式（五）适配器模式Adapter（结构型）</a>(21421)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244413" title="hbase安装配置（整合到hadoop）" target="_blank">hbase安装配置（整合到hadoop）</a>(20780)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390" title="socket阻塞与非阻塞，同步与异步、I/O模型" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a>(12788)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7282050" title="Hadoop Hive与Hbase整合" target="_blank">Hadoop Hive与Hbase整合</a>(11869)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7558249" title="设计模式 ( 十八 ) 策略模式Strategy（对象行为型）" target="_blank">设计模式 ( 十八 ) 策略模式Strategy（对象行为型）</a>(11737)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7786014" title="B-树和B+树的应用：数据搜索和数据库索引" target="_blank">B-树和B+树的应用：数据搜索和数据库索引</a>(11507)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/5731880" title="Mysql 多表联合查询效率分析及优化" target="_blank">Mysql 多表联合查询效率分析及优化</a>(10454)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244991" title="谷歌三大核心技术（三）Google BigTable中文版" target="_blank">谷歌三大核心技术（三）Google BigTable中文版</a>(9958)</li>
<li><p><a href="&quot;HDFS写入和读取流程&quot;">HDFS写入和读取流程</a>(8282)
评论排行</p>
</li>
<li><p><a href="http://blog.csdn.net/hguisu/article/details/7558249" title="设计模式 ( 十八 ) 策略模式Strategy（对象行为型）" target="_blank">设计模式 ( 十八 ) 策略模式Strategy（对象行为型）</a>(33)</p>
</li>
<li><a href="&quot;HDFS写入和读取流程&quot;">HDFS写入和读取流程</a>(17)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7529194" title="设计模式（六）桥连模式Bridge（结构型）" target="_blank">设计模式（六）桥连模式Bridge（结构型）</a>(14)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7505909" title="设计模式（一）工厂模式Factory（创建型）" target="_blank">设计模式（一）工厂模式Factory（创建型）</a>(13)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7880288" title="海量数据处理算法—Bit-Map" target="_blank">海量数据处理算法—Bit-Map</a>(13)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7237395" title="Hadoop集群配置（最全面总结）" target="_blank">Hadoop集群配置（最全面总结）</a>(13)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7448528" title="PHP SOCKET编程" target="_blank">PHP SOCKET编程</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390" title="socket阻塞与非阻塞，同步与异步、I/O模型" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a>(11)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7282050" title="Hadoop Hive与Hbase整合" target="_blank">Hadoop Hive与Hbase整合</a>(10)</li>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244413" title="hbase安装配置（整合到hadoop）" target="_blank">hbase安装配置（整合到hadoop）</a>(10)</li>
</ul>
<p>推荐文章
最新评论</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390#comments" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a></li>
</ul>
<p><a href="http://blog.csdn.net/ctqctq99" target="_blank">ctqctq99</a>: 他的意思可能是阻塞IO和非阻塞IO的区别就在于：应用程序的调用是否立即返回！这句话说反了。应该是非阻...</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7408047#comments" target="_blank">硬盘的读写原理</a></li>
</ul>
<p><a href="http://blog.csdn.net/m1013923728" target="_blank">m1013923728</a>: 写的通俗易懂！</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7470695#comments" target="_blank">C语言中的宏定义</a></li>
</ul>
<p><a href="http://blog.csdn.net/ouwen3536" target="_blank">ouwen3536</a>: 很半，转起！</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7470695#comments" target="_blank">C语言中的宏定义</a></li>
</ul>
<p><a href="http://blog.csdn.net/zhangyongbluesky" target="_blank">zhangyongbluesky</a>: good</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244413#comments" target="_blank">hbase安装配置（整合到hadoop）</a></li>
</ul>
<p><a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a>: @u012171806:conf/hbase-site.xml你应该看官方文档的快速入门。安装的东西...</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7244413#comments" target="_blank">hbase安装配置（整合到hadoop）</a></li>
</ul>
<p><a href="http://blog.csdn.net/u012171806" target="_blank">JAVA_小陈</a>: 我把hbase下载了，你上面说的需要配置一个xml文件，请问配置在什么地方呢？然后启动的时候是在什么...</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7408047#comments" target="_blank">硬盘的读写原理</a></li>
</ul>
<p><a href="http://blog.csdn.net/mxhlee" target="_blank">mxhlee</a>: 好东西啊！！！（实际是斜切向运动）这句话让我纠结了很长时间、我自己就感觉是这运动 但是没有一个介绍...</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390#comments" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a></li>
</ul>
<p><a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a>: @liaokailin:并没有反。实际就是这样的。</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390#comments" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a></li>
</ul>
<p><a href="http://blog.csdn.net/hguisu" target="_blank">真实的归宿</a>: @liaokailin:实际就是这样的。</p>
<ul>
<li><a href="http://blog.csdn.net/hguisu/article/details/7453390#comments" target="_blank">socket阻塞与非阻塞，同步与异步、I/O模型</a></li>
</ul>
<p><a href="http://blog.csdn.net/liaokailin" target="_blank">廖凯林</a>: 同步IO和异步IO的区别就在于：数据拷贝的时候进程是否阻塞！阻塞IO和非阻塞IO的区别就在于：应用程...</p>
<p><a href="http://www.csdn.net/company/about.html" target="_blank">公司简介</a>|<a href="http://www.csdn.net/company/recruit.html" target="_blank">招贤纳士</a>|<a href="http://www.csdn.net/company/marketing.html" target="_blank">广告服务</a>|<a href="http://www.csdn.net/company/account.html" target="_blank">银行汇款帐号</a>|<a href="http://www.csdn.net/company/contact.html" target="_blank">联系方式</a>|<a href="http://www.csdn.net/company/statement.html" target="_blank">版权声明</a>|<a href="http://www.csdn.net/company/layer.html" target="_blank">法律顾问</a>|<a href="mailto:webmaster@csdn.net">问题报告</a><a href="http://wpa.qq.com/msgrd?v=3&amp;uin=2355263776&amp;site=qq&amp;menu=yes" target="_blank">QQ客服</a> <a href="http://e.weibo.com/csdnsupport/profile" target="_blank">微博客服</a> <a href="http://bbs.csdn.net/forums/Service" target="_blank">论坛反馈</a> <a href="mailto:webmaster@csdn.net">联系邮箱：webmaster@csdn.net</a> 服务热线：400-600-2320京 ICP 证 070598 号北京创新乐知信息技术有限公司 版权所有世纪乐知(北京)网络技术有限公司 提供技术支持江苏乐知网络技术有限公司 提供商务支持Copyright © 1999-2012, CSDN.NET, All Rights Reserved <a href="http://www.hd315.gov.cn/beian/view.asp?bianhao=010202001032100010" target="_blank"><img src="" alt="GongshangLogo"></a>
<img src="http://counter.csdn.net/pv.aspx?id=24" alt=""></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--HDFS写入和读取流程/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--HDFS写入和读取流程" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--Hadoop121编译Eclipse插件/">Hadoop 1.2.1编译Eclipse插件</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--Hadoop121编译Eclipse插件/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hadoop-1-2-1-eclipse-">Hadoop 1.2.1编译Eclipse插件</h1>
<h2 id="-src-contrib-eclipse-plugin-build-xml">/src/contrib/eclipse-plugin/build.xml</h2>
<h3 id="1-ivy-download-">1）取消ivy-download：</h3>
<p><a href="http://static.oschina.net/uploads/space/2013/0520/194613_IBLw_256028.png" target="_blank"><img src="" alt=""></a></p>
<h3 id="2-plugin-jar-">2）添加将要打包到plugin中的第三方jar包列表：</h3>
<p>01</p>
<!-- Override jar target to specify manifest -->


<p>02</p>
<p>&lt;</p>
<p>target</p>
<p>name</p>
<p>=</p>
<p>&quot;jar&quot;</p>
<p>depends</p>
<p>=</p>
<p>&quot;compile&quot;</p>
<p>unless</p>
<p>=</p>
<p>&quot;skip.contrib&quot;</p>
<p>&gt;
03</p>
<p>&lt;</p>
<p>mkdir</p>
<p>dir</p>
<p>=</p>
<p>&quot;${build.dir}/lib&quot;</p>
<p>/&gt; </p>
<p>04</p>
<p>05</p>
<!-- 自定义的修改内容：begin -->


<p>06</p>
<!--
07

<copy file="${hadoop.root}/build/hadoop-core-${version}.jar"

08



tofile="${build.dir}/lib/hadoop-core.jar" verbose="true"/>
09

<copy file="${hadoop.root}/build/ivy/lib/Hadoop/common/commons-cli-${commons-cli.version}.jar" 

10



todir="${build.dir}/lib" verbose="true"/> 
11

-->


<p>12</p>
<p>&lt;</p>
<p>copy</p>
<p>file</p>
<p>=</p>
<p>&quot;${hadoop.root}/hadoop-core-${version}.jar&quot;</p>
<p>tofile</p>
<p>=</p>
<p>&quot;${build.dir}/lib/hadoop-core.jar&quot;</p>
<p>verbose</p>
<p>=</p>
<p>&quot;true&quot;</p>
<p>/&gt;
13</p>
<p>&lt;</p>
<p>copy</p>
<p>file</p>
<p>=</p>
<p>&quot;${hadoop.root}/lib/commons-cli-1.2.jar&quot;</p>
<p>todir</p>
<p>=</p>
<p>&quot;${build.dir}/lib&quot;</p>
<p>verbose</p>
<p>=</p>
<p>&quot;true&quot;</p>
<p>/&gt; </p>
<p>14</p>
<p>&lt;</p>
<p>copy</p>
<p>file</p>
<p>=</p>
<p>&quot;${hadoop.root}/lib/commons-configuration-1.6.jar&quot;</p>
<p>todir</p>
<p>=</p>
<p>&quot;${build.dir}/lib&quot;</p>
<p>verbose</p>
<p>=</p>
<p>&quot;true&quot;</p>
<p>/&gt; 
15</p>
<p>&lt;</p>
<p>copy</p>
<p>file</p>
<p>=</p>
<p>&quot;${hadoop.root}/lib/commons-httpclient-3.0.1.jar&quot;</p>
<p>todir</p>
<p>=</p>
<p>&quot;${build.dir}/lib&quot;</p>
<p>verbose</p>
<p>=</p>
<p>&quot;true&quot;</p>
<p>/&gt; </p>
<p>16</p>
<p>&lt;</p>
<p>copy</p>
<p>file</p>
<p>=</p>
<p>&quot;${hadoop.root}/lib/commons-lang-2.4.jar&quot;</p>
<p>todir</p>
<p>=</p>
<p>&quot;${build.dir}/lib&quot;</p>
<p>verbose</p>
<p>=</p>
<p>&quot;true&quot;</p>
<p>/&gt;<br>17</p>
<p>&lt;</p>
<p>copy</p>
<p>file</p>
<p>=</p>
<p>&quot;${hadoop.root}/lib/jackson-core-asl-1.8.8.jar&quot;</p>
<p>todir</p>
<p>=</p>
<p>&quot;${build.dir}/lib&quot;</p>
<p>verbose</p>
<p>=</p>
<p>&quot;true&quot;</p>
<p>/&gt;</p>
<p>18</p>
<p>&lt;</p>
<p>copy</p>
<p>file</p>
<p>=</p>
<p>&quot;${hadoop.root}/lib/jackson-mapper-asl-1.8.8.jar&quot;</p>
<p>todir</p>
<p>=</p>
<p>&quot;${build.dir}/lib&quot;</p>
<p>verbose</p>
<p>=</p>
<p>&quot;true&quot;</p>
<p>/&gt;<br>19</p>
<!-- 自定义的修改内容：end -->


<p>20</p>
<p>&lt;</p>
<p>jar
21</p>
<p>jarfile</p>
<p>=</p>
<p>&quot;${build.dir}/hadoop-${name}-${version}.jar&quot;</p>
<p>22</p>
<p>manifest</p>
<p>=</p>
<p>&quot;${root}/META-INF/MANIFEST.MF&quot;</p>
<blockquote>
<p>23</p>
</blockquote>
<p>&lt;</p>
<p>fileset</p>
<p>dir</p>
<p>=</p>
<p>&quot;${build.dir}&quot;</p>
<p>includes</p>
<p>=</p>
<p>&quot;classes/ lib/&quot;</p>
<p>/&gt; </p>
<p>24</p>
<p>&lt;</p>
<p>fileset</p>
<p>dir</p>
<p>=</p>
<p>&quot;${root}&quot;</p>
<p>includes</p>
<p>=</p>
<p>&quot;resources/ plugin.xml&quot;</p>
<p>/&gt; 
25</p>
<p>&lt;/</p>
<p>jar</p>
<blockquote>
</blockquote>
<p>26</p>
<p>&lt;/</p>
<p>target</p>
<blockquote>
<p>&lt;</p>
</blockquote>
<p>span</p>
<p>style</p>
<p>=</p>
<p>&quot;font-size:10pt;line-height:1.5;font-family:&#39;sans serif&#39;, tahoma, verdana, helvetica;&quot;</p>
<blockquote>
<p> &lt;/</p>
</blockquote>
<p>span</p>
<p>&gt;</p>
<p><a href="http://static.oschina.net/uploads/space/2013/0520/194752_bBaX_256028.png" target="_blank"><img src="" alt=""></a> </p>
<h2 id="3-hadoop-src-contrib-build-contrib-xml-">3.%hadoop%/src/contrib/build-contrib.xml ：</h2>
<h3 id="1-hadoop-version-eclipse-eclipse-home-">1）添加hadoop的version和eclipse的eclipse.home属性：</h3>
<p>1</p>
<p>&lt;?</p>
<p>xml</p>
<p>version</p>
<p>=</p>
<p>&quot;1.0&quot;</p>
<p>?&gt;</p>
<p>2</p>
<!-- Imported by contrib//*/build.xml files to share generic targets. -->
3

&lt;

project


name

=

&quot;hadoopbuildcontrib&quot;


xmlns:ivy

=

&quot;antlib:org.apache.ivy.ant&quot;

&gt;

4

&lt;

property


name

=

&quot;name&quot;


value

=

&quot;${ant.project.name}&quot;

/&gt;
5

&lt;

property


name

=

&quot;root&quot;


value

=

&quot;${basedir}&quot;

/&gt;

6

&lt;

property


name

=

&quot;hadoop.root&quot;


location

=

&quot;${root}/../../../&quot;

/&gt;
7

<!-- hadoop版本、eclipse安装路径 -->

<p>8</p>
<p>&lt;</p>
<p>property</p>
<p>name</p>
<p>=</p>
<p>&quot;version&quot;</p>
<p>value</p>
<p>=</p>
<p>&quot;1.1.2&quot;</p>
<p>/&gt;
9</p>
<p>&lt;</p>
<p>property</p>
<p>name</p>
<p>=</p>
<p>&quot;eclipse.home&quot;</p>
<p>location</p>
<p>=</p>
<p>&quot;%eclipse%&quot;</p>
<p>/&gt;</p>
<p><a href="http://static.oschina.net/uploads/space/2013/0520/194838_mpUD_256028.png" target="_blank"><img src="" alt=""></a>  </p>
<h3 id="2-ivy-download-">2）取消ivy-download：</h3>
<p><a href="http://static.oschina.net/uploads/space/2013/0520/194859_Cc5J_256028.png" target="_blank"><img src="" alt=""></a> 
来源： <a href="[http://my.oschina.net/vigiles/blog/132238](http://my.oschina.net/vigiles/blog/132238)">[http://my.oschina.net/vigiles/blog/132238](http://my.oschina.net/vigiles/blog/132238)</a></p>
<p>配置/${hadoop-home}/src/contrib/eclipse-plugins/build.xml</p>
<p>找到</p>
<path id=”classpath”>

<p>然后添加</p>
<fileset dir=”${hadoop.root}/”>
      <include name=”/*.jar”/>
</fileset>

<p><strong>这一步很重要，如果不添加的话会出现找不到相应的程序包，错误如下（给出部分）</strong> ：</p>
<p>[javac]      Counters.Group group = counters.getGroup(groupName);
    [javac]              ^
    [javac] /home/summerdg/hadoop_src/hadoop-1.2.1/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/server/HadoopJob.java:305: 错误: 程序包Counters不存在
    [javac]      for (Counters.Counter counter : group) {
    [javac]                    ^
    [javac] /home/summerdg/hadoop_src/hadoop-1.2.1/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/dfs/DFSFile.java:74: 错误: 找不到符号
    [javac]      FileStatus fs = getDFS().getFileStatus(path);
    [javac]      ^
    [javac]  符号:  类 FileStatus
    [javac]  位置: 类 DFSFile
    [javac] 注: 某些输入文件使用或覆盖了已过时的 API。
    [javac] 注: 有关详细信息, 请使用 -Xlint:deprecation 重新编译。
    [javac] 注: 某些输入文件使用了未经检查或不安全的操作。
    [javac] 注: 有关详细信息, 请使用 -Xlint:unchecked 重新编译。
    [javac] 100 个错误</p>
<p>当然，出现这个错误还有个原因，就是你已经设置了这句，但你依然出现这个错误，那就是你eclipse版本的问题了。</p>
<p>找到
来源： <a href="[http://www.kankanews.com/ICkengine/archives/63441.shtml](http://www.kankanews.com/ICkengine/archives/63441.shtml)">[http://www.kankanews.com/ICkengine/archives/63441.shtml](http://www.kankanews.com/ICkengine/archives/63441.shtml)</a> </p>
<h2 id="4-hadoop_home-build-xml-">4.编辑%HADOOP_HOME%/build.xml：</h2>
<h3 id="1-hadoop-">1）修改hadoop版本号：</h3>
<p><a href="http://static.oschina.net/uploads/space/2013/0520/194950_g5cw_256028.png" target="_blank"><img src="" alt=""></a></p>
<h3 id="2-ivy-download-">2）取消ivy-download：</h3>
<p><a href="http://static.oschina.net/uploads/space/2013/0520/195011_l8BK_256028.png" target="_blank"><img src="" alt=""></a> </p>
<h2 id="5-hadoop-src-contrib-eclipse-plugin-meta-inf-manifest-mf-">5.修改%hadoop%/src/contrib/eclipse-plugin/META-INF/MANIFEST.MF：</h2>
<p>修改${HADOOP_HOME}/src/contrib/eclipse-plugin/META-INF/MANIFEST.MF的Bundle-ClassPath：
1</p>
<p>Bundle-ClassPath: classes/,</p>
<p>2</p>
<p>lib/hadoop-core.jar,
3</p>
<p>lib/commons-cli-1.2.jar,</p>
<p>4</p>
<p>lib/commons-configuration-1.6.jar,
5</p>
<p>lib/commons-httpclient-3.0.1.jar,</p>
<p>6</p>
<p>lib/commons-lang-2.4.jar,
7</p>
<p>lib/jackson-core-asl-1.8.8.jar,</p>
<p>8</p>
<p>lib/jackson-mapper-asl-1.8.8.jar</p>
<p><a href="http://static.oschina.net/uploads/space/2013/0520/195106_mqwV_256028.png" target="_blank"><img src="" alt=""></a> </p>
<h2 id="-build-contrib-eclipse-plugin-ant-jar-">进入到 /build/contrib/eclipse-plugin/执行 ant jar ：</h2>
<p>01</p>
<p>hep@hep-ubuntu:~$ </p>
<p>cd</p>
<p>~/hadoop/src/contrib/eclipse-plugin</p>
<p>02</p>
<p>hep@hep-ubuntu:~/hadoop/src/contrib/eclipse-plugin$ ant jar
03</p>
<p>Buildfile: /home/hep/hadoop/src/contrib/eclipse-plugin/build.xml</p>
<p>04</p>
<p>05</p>
<p>check-contrib:</p>
<p>06</p>
<p>07</p>
<p>init:</p>
<p>08</p>
<p>[</p>
<p>echo</p>
<p>] contrib: eclipse-plugin
09</p>
<p>10</p>
<p>init-contrib:
11</p>
<p>12</p>
<p>ivy-probe-antlib:
13</p>
<p>14</p>
<p>ivy-init-antlib:
15</p>
<p>16</p>
<p>ivy-init:
17</p>
<p>[ivy:configure] :: Ivy 2.1.0 - 20090925235825 :: <a href="http://ant.apache.org/ivy/" target="_blank">http://ant.apache.org/ivy/</a> ::</p>
<p>18</p>
<p>[ivy:configure] :: loading settings :: </p>
<p>file</p>
<p>= /home/hep/hadoop/ivy/ivysettings.xml
19</p>
<p>20</p>
<p>ivy-resolve-common:
21</p>
<p>[ivy:resolve] :: resolving dependencies :: org.apache.hadoop</p>
<p>/#eclipse-plugin;working@hep-ubuntu</p>
<p>22</p>
<p>[ivy:resolve]   confs: [common]
23</p>
<p>[ivy:resolve]   found commons-logging</p>
<p>/#commons-logging;1.0.4 in maven2</p>
<p>24</p>
<p>[ivy:resolve]   found log4j</p>
<p>/#log4j;1.2.15 in maven2
25</p>
<p>[ivy:resolve] :: resolution report :: resolve 171ms :: artifacts dl 4ms</p>
<p>26</p>
<hr>
<p>27</p>
<p>|                  |            modules            ||   artifacts   |</p>
<p>28</p>
<p>|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
29</p>
<hr>
<p>30</p>
<p>|      common      |   2   |   0   |   0   |   0   ||   2   |   0   |
31</p>
<hr>
<p>32</p>
<p>33</p>
<p>ivy-retrieve-common:</p>
<p>34</p>
<p>[ivy:retrieve] :: retrieving :: org.apache.hadoop</p>
<p>/#eclipse-plugin [sync]
35</p>
<p>[ivy:retrieve]  confs: [common]</p>
<p>36</p>
<p>[ivy:retrieve]  0 artifacts copied, 2 already retrieved (0kB/6ms)
37</p>
<p>[ivy:cachepath] DEPRECATED: </p>
<p>&#39;ivy.conf.file&#39;</p>
<p>is deprecated, use </p>
<p>&#39;ivy.settings.file&#39;</p>
<p>instead</p>
<p>38</p>
<p>[ivy:cachepath] :: loading settings :: </p>
<p>file</p>
<p>= /home/hep/hadoop/ivy/ivysettings.xml
39</p>
<p>40</p>
<p>compile:
41</p>
<p>[</p>
<p>echo</p>
<p>] contrib: eclipse-plugin</p>
<p>42</p>
<p>[javac] /home/hep/hadoop/src/contrib/eclipse-plugin/build.xml:61: warning: </p>
<p>&#39;includeantruntime&#39;</p>
<p>was not </p>
<p>set</p>
<p>, defaulting to build.sysclasspath=last; </p>
<p>set</p>
<p>to </p>
<p>false</p>
<p>for</p>
<p>repeatable builds
43</p>
<p>44</p>
<p>jar:
45</p>
<p>[</p>
<p>mkdir</p>
<p>] Created </p>
<p>dir</p>
<p>: /home/hep/hadoop/build/contrib/eclipse-plugin/lib</p>
<p>46</p>
<p>[copy] Copying 1 </p>
<p>file</p>
<p>to /home/hep/hadoop/build/contrib/eclipse-plugin/lib
47</p>
<p>[copy] Copying /home/hep/hadoop/hadoop-core-1.1.2.jar to /home/hep/hadoop/build/contrib/eclipse-plugin/lib/hadoop-core.jar</p>
<p>48</p>
<p>[copy] Copying 1 </p>
<p>file</p>
<p>to /home/hep/hadoop/build/contrib/eclipse-plugin/lib
49</p>
<p>[copy] Copying /home/hep/hadoop/lib/commons-cli-1.2.jar to /home/hep/hadoop/build/contrib/eclipse-plugin/lib/commons-cli-1.2.jar</p>
<p>50</p>
<p>[copy] Copying 1 </p>
<p>file</p>
<p>to /home/hep/hadoop/build/contrib/eclipse-plugin/lib
51</p>
<p>[copy] Copying /home/hep/hadoop/lib/commons-configuration-1.6.jar to /home/hep/hadoop/build/contrib/eclipse-plugin/lib/commons-configuration-1.6.jar</p>
<p>52</p>
<p>[copy] Copying 1 </p>
<p>file</p>
<p>to /home/hep/hadoop/build/contrib/eclipse-plugin/lib
53</p>
<p>[copy] Copying /home/hep/hadoop/lib/commons-httpclient-3.0.1.jar to /home/hep/hadoop/build/contrib/eclipse-plugin/lib/commons-httpclient-3.0.1.jar</p>
<p>54</p>
<p>[copy] Copying 1 </p>
<p>file</p>
<p>to /home/hep/hadoop/build/contrib/eclipse-plugin/lib
55</p>
<p>[copy] Copying /home/hep/hadoop/lib/commons-lang-2.4.jar to /home/hep/hadoop/build/contrib/eclipse-plugin/lib/commons-lang-2.4.jar</p>
<p>56</p>
<p>[copy] Copying 1 </p>
<p>file</p>
<p>to /home/hep/hadoop/build/contrib/eclipse-plugin/lib
57</p>
<p>[copy] Copying /home/hep/hadoop/lib/jackson-core-asl-1.8.8.jar to /home/hep/hadoop/build/contrib/eclipse-plugin/lib/jackson-core-asl-1.8.8.jar</p>
<p>58</p>
<p>[copy] Copying 1 </p>
<p>file</p>
<p>to /home/hep/hadoop/build/contrib/eclipse-plugin/lib
59</p>
<p>[copy] Copying /home/hep/hadoop/lib/jackson-mapper-asl-1.8.8.jar to /home/hep/hadoop/build/contrib/eclipse-plugin/lib/jackson-mapper-asl-1.8.8.jar</p>
<p>60</p>
<p>[jar] Building jar: /home/hep/hadoop/build/contrib/eclipse-plugin/hadoop-eclipse-plugin-1.1.2.jar
61</p>
<p>62</p>
<p>BUILD SUCCESSFUL
63</p>
<p>Total </p>
<p>time</p>
<p>: 3 seconds</p>
<p>生成的插件jar就在本目录中。</p>
<p>把编译好的插件放入 $eclipse_home/dropins/hadoop/plugins/ (mkdir -p 创建)</p>
<p>启动eclipse 新建mapreduce project， 配置好map/reduce location, 就可以看到hdfs中的文件了</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--Hadoop121编译Eclipse插件/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--Hadoop121编译Eclipse插件" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--HadoopSummit2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了/">Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--HadoopSummit2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hadoop-summit-2013-hadoop-">Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了</h1>
<p>原文出处： <a href="http://blog.sina.com.cn/s/blog_53a5366c0101dp0q.html" target="_blank">钱五哥の共享空间</a></p>
<p>今天参加了3个keynotes，42个session中的8个，和一大堆厂商讨论技术，真是信息大爆炸的一天。</p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c4e020b68545d6amp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p>Hadoop从诞生到今年已经有7个年头，今年出现了很多新的变化：</p>
<p>1、Hadoop被公认是一套行业大数据标准开源软件，在分布式环境下提供了海量数据的处理能力（Gartner）。几乎所有主流厂商都围绕Hadoop开发工具、开源软件、商业化工具和技术服务。今年大型IT公司，如EMC、Microsoft、Intel、Teradata、Cisco都明显增加了Hadoop方面的投入，Teradata还公开展示了一个一体机；另一方面创业型Hadoop公司层出不穷，这次看到的几个是Sqrrl、Wandisco、GridGain、InMobi等等，都推出了开源的或者商用的软件。</p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c4e020b79dcc7bamp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p>2、Hadoop生态系统丰富多彩，但是核心已经被Cloudera、HortonWorks牢牢掌控，基本上没有撼动之可能。今年Hortonworks的宣传是100% open source，Cloudera只好干着急，谁叫他不开放Cloudera Enterprise Manager的源代码呢？Hortonworks介绍Ambari的时候，会场至少5个Cloudera的工程师在仔细聆听，有个小伙不停地在iPad上面速记，竞争可见一斑，个人估计，Cloudera早晚将Enterprise Manager开源。Hortonworks目前Ambari的committer是20+，Contributor 50+，后一个数字可能有些水，但是第一个是没有问题的。目前每天有update，1.25版本比1.0x版本明显好用了。其他大小厂商的生存之道就是搞插件，如Wandisco、vmware、mellanox、GridGain，而且插件均是不用修改内核的外挂 – 这些厂商是没有能力动内核的，持续投入可能会有一些作用，如vmware，但是一线hadoop厂商是绝不会松手的。</p>
<p>3、Hadoop 2.0转型基本上无可阻挡。Hortonworks的VPArun在介绍Tez的时候，给出了很多有趣的ppt，主旨就是一个：MapReduce已经是昨日黄花，Yarn将是未来并行计算的基础设施。我自己还没有使用Yarn，但是Hortonworks已经围绕Yarn开发了很多工具，尤其是Tez，这个玩意可以提升查询计划的执行时间，PIG和Hive将被改写并重装上阵。Hortonworks虽然没有搞出来Impala，但是从更底层的技术上包围Impala，两个老大的布局和较量始终没有停止。</p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c4e020b9af392eamp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c4e020bac324d8amp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p>4、SQL over Hadoop是一个重要的技术趋势。去年Hadoop World时，MPP还吹嘘自己如何牛X。但是Google发布了Dremel和PowerDrill，EMC搞出来HAWQ，Cloudera搞出来Impala之后，所有的MPP都开始反思自己的技术路线。和Parccel技术人员（感觉是售前）讨论了一下，她找出一张卡片说Parccel速度是Hive的100X，领先Impala10年。我感觉这个说话很快就会失灵，首先是Hive的优化一直没有停止，Hortonworks搞出来Tez、Stinger（与Facebook合作）。虽然MPP领先Hadoop很多年，根据80：20原则，如果hadoopSQL只做用户需要的20%特性，那么这个差距最多2年，2年内，hadoopSQL将在部分领域超越MPP。MPP企业的出路就是学习HAWQ。列存储也是推陈出新，近期主要是ORC（MS和Hortonworks合作）、Parquet（Twitter和Cloudera合作），有木有看出来两个巨头PK的身影？有木有看到抱团PK？这些技术在测试中均显示出很大的优势</p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c4e020bc314b2bamp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c4e020bd3a31e7amp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c4e020be5d05c3amp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p>5、IT和开源单位合作广泛。这个不仅仅存在IT厂商和开源之间，实际上开源之间也在密切合作。不太清楚合作的内部信息，但是基本上有两种模式：产品/软件交叉集成（含管理系统集成）；合作开发和推广。在技术方面就要求软件有很好的架构，提供开放的接口，这一点Ambari的设计和俺对HT的要求一模一样，可以俺未能如愿，而Amabri已经开发了好几个版本。</p>
<p>6、技术上看，大数据和云的整合也是一个选项（注意，不是趋势，而是选项）。今年新增了OpenStack相关议题，一些集成商和厂商也提出了云上Hadoop的适用场景。这个并不是适用于所有人，但是部分用户可以因此获益。Netflix是一个典型的例子，他们的实例都在AWS上面，显然他们的hadoop是基于虚拟机的，和一个Netflix小伙子（日本人）交流，他们大约有2000个虚拟实例，基于EMR，并开发了Gennie管理系统。</p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c4e020bf6e8c61amp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p>要睡觉了，4小时后还有一场信息大爆炸！贴一张在宾馆小院乘凉，看到的小松鼠吧，也就距离我5米不到，真要赞一声美帝的环境！</p>
<p><a href="http://cdn2.jobbole.com/2013/06/53a5366c07cd01360d282amp.jpg" title="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" target="_blank"><img src="&quot;Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了&quot;" alt="Hadoop Summit 2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了"></a></p>
<p>相关信息：</p>
<ol>
<li><a href="http://blog.sina.com.cn/s/blog_53a5366c0101doch.html" title="http://blog.sina.com.cn/s/blog_53a5366c0101doch.html" target="_blank">Hadoop Summit 2013 Day1：BOF&amp;Meetup</a>
<img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"><img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"><img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"><img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"><img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"> (<strong>*1</strong> 个评分，平均: <strong>5.00*</strong>)</li>
</ol>
<p><img src="&quot;Loading ...&quot;" alt="Loading ..."> Loading ...</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--HadoopSummit2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--HadoopSummit2013见闻：看完基本了解整个Hadoop生态圈格局和趋势了" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux-redhat--centoslibxml2/">centos libxml2</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux-redhat--centoslibxml2/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="centos-libxml2">centos libxml2</h1>
<h2 id="introduction-to-libx-ml2">Introduction to libx‍ml2</h2>
<p>The libxml2 package contains          libraries and utilities used for parsing XML files.</p>
<p>This package is known to build and work properly using an LFS-7.4          platform.</p>
<h3 id="package-information">Package Information</h3>
<ul>
<li>Download (HTTP): <a href="http://xmlsoft.org/sources/libxml2-2.9.1.tar.gz" target="_blank"><a href="http://xmlsoft.org/sources/libxml2-2.9.1.tar.gz">http://xmlsoft.org/sources/libxml2-2.9.1.tar.gz</a></a></li>
<li>Download (FTP): <a href="ftp://xmlsoft.org/libxml2/libxml2-2.9.1.tar.gz">ftp://xmlsoft.org/libxml2/libxml2-2.9.1.tar.gz</a></li>
<li>Download MD5 sum: 9c0cfef285d5c4a5c80d00904ddab380</li>
<li>Download size: 5.0 MB</li>
<li>Estimated disk space required: 100 MB</li>
<li>Estimated build time: 0.6 SBU</li>
</ul>
<h3 id="additional-downloads">Additional Downloads</h3>
<ul>
<li>Optional Testsuite: <a href="http://www.w3.org/XML/Test/xmlts20130923.tar.gz" target="_blank"><a href="http://www.w3.org/XML/Test/xmlts20130923.tar.gz">http://www.w3.org/XML/Test/xmlts20130923.tar.gz</a></a>                - This enables <strong>make                check</strong> to do complete testing.</li>
</ul>
<h3 id="libxml2-dependencies">libxml2 Dependencies</h3>
<h3 id="recommended">Recommended</h3>
<p><a href="http://www.linuxfromscratch.org/blfs/view/svn/general/python2.html" title="Python-2.7.6" target="_blank">Python-2.7.6</a> (to build and install a          Python library module,          additionally it is required to run the full suite of tests)</p>
<p><img src="http://www.linuxfromscratch.org/blfs/view/svn/images/note.png" alt="[Note]">          </p>
<h3 id="note">Note</h3>
<p>Some packages which utilize libxml2 (such as GNOME Doc Utils) need the Python module installed to function properly            and some packages (such as MesaLib) will not build properly if            the Python module is not            available.</p>
<p>User Notes: <a href="http://wiki.linuxfromscratch.org/blfs/wiki/libxml2" target="_blank"><a href="http://wiki.linuxfromscratch.org/blfs/wiki/libxml2">http://wiki.linuxfromscratch.org/blfs/wiki/libxml2</a></a>        </p>
<h2 id="installation-of-libxml2">Installation of libxml2</h2>
<p>If you downloaded the testsuite, issue the following command:
tar xf ../xmlts20130923.tar.gz</p>
<p>Install libxml2 by running the          following commands:
./configure --prefix=/usr --disable-static --with-history &amp;&amp; make</p>
<p>To test the results, issue: <strong>make          check</strong>.</p>
<p>Now, as the</p>
<p>root
user:
make install</p>
<h2 id="command-explanations">Command Explanations</h2>
<p><em>
--disable-static
</em>: This          switch prevents installation of static versions of the libraries.</p>
<p>--with-history
: This switch enables          Readline support when running          <strong>xmlcatalog</strong> or          <strong>xmllint</strong> in shell          mode.</p>
<h2 id="contents">Contents</h2>
<p><strong>Installed Programs:</strong>              xml2-config, xmlcatalog and              xmllint            </p>
<p><strong>Installed Libraries:</strong>              libxml2.so and optionally, the              libxml2mod.so Python              module            </p>
<p><strong>Installed Directories:</strong>              /usr/include/libxml2,              /usr/share/doc/libxml2-2.9.1,              /usr/share/doc/libxml2-python-2.9.1 and              /usr/share/gtk-doc/html/libxml2            </p>
<h3 id="short-descriptions">Short Descriptions</h3>
<p><a href=""></a><strong>xml2-config</strong>                  </p>
<p>determines the compile and linker flags that should be                    used to compile and link programs that use</p>
<p>libxml2
.<a href=""></a><strong>xmlcatalog</strong>                  </p>
<p>is used to monitor and manipulate XML and SGML catalogs.<a href=""></a><strong>xmllint</strong>                  </p>
<p>parses XML files and outputs reports (based upon options)                    to detect errors in XML coding.<a href=""></a></p>
<p>libxml2.so</p>
<p>provides functions for programs to parse files that use                    the XML format.                   </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span><span class="breadcrumb"><li><a href="/categories/linux/">linux</a></li><li><a href="/categories/linux/redhat/">redhat</a></li></span></span> | <span class="tags">Tagged <a href="/tags/linux/" class="label label-primary">linux</a><a href="/tags/redhat/" class="label label-success">redhat</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux-redhat--centoslibxml2/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux-redhat--centoslibxml2" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--Hadoop在CentOS下的单机配置/">Hadoop在CentOS下的单机配置</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--Hadoop在CentOS下的单机配置/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hadoop-centos-">Hadoop在CentOS下的单机配置</h1>
<p>前言的前言</p>
<p>如果你做某件从未接触过的事的时候很纠结很曲折，那么为你自己高兴吧，你能学到很多东西！</p>
<p>以下的东西都是贴图，所以你们只有手敲了。我也不清楚这个东西是不是应该花很多时间去做，有得有失，某些付出不知道到底值多少。据/<em>/</em>说一下午都能配出来，谁叫我傻呢，谁叫我蠢呢，不过该走的路咱还是踏实点走吧，不去跟人比。所以现在我把细节写出来，供大家参考，让你能在两小时内完成。希望它能帮助你学习，而不是让你变得更依赖。如有不对的地方请指正，我也是初学者。谢谢！</p>
<p>前言</p>
<p>做事总有个原因吧，那么我们为什么安装单机的<a href="http://www.linuxidc.com/topicnews.aspx?tid=13" title="Hadoop" target="_blank">Hadoop</a>呢？因为官网上有安装单机hadoop，因为某权威网站有<a href="http://www.linuxidc.com/topicnews.aspx?tid=2" title="Ubuntu" target="_blank">Ubuntu</a>下安装单机hadoop，但是没有一个网站有<a href="http://www.linuxidc.com/topicnews.aspx?tid=14" title="CentOS" target="_blank">CentOS</a>下单机安装，所以我现在CentOS下面单机配置hadoop。</p>
<p>其实单机hadoop的安装没有什么实质的用处，主要用于初学者熟悉指令，以及对hadoop配置有个大致了解，以便于安装分布式。</p>
<p>首先，我们来理清思路。</p>
<p>目的：安装hadoop</p>
<p>Hadoop是需要在java环境下面运行，所以，首先要保证你的系统下面装有JDK。那么步骤是：配置SSH——安装JDK——安装hadoop（当然你愿意先安装它也完全没问题）——配置java的环境变量（需要知道java的安装路径）——配置namenode下面3个配置文件——格式化hadoop——启动hadoop。</p>
<p>我们用一般用户登录，然后切换到root下面，因为权限的问题，这样相比下会更安全点，注意linux下面尽量不要用root登录。</p>
<p>开始了</p>
<p>所需软件</p>
<p>CentOS、Java、Hadoop安装软件。本人用的版本为Linux Cent OS 5.5、jdk1.6.0_13、hadoop-0.20.2.tar.gz。</p>
<p>我们要提醒一下，linux下面很注意权限问题。我们应该以一般用户登录，然后切换至root用户才能使用某些命令，并能使系统处于相对安全的状态。</p>
<p>所以做如下处理，来切换到root用户。
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<ol>
<li>SSH无密码验证配置（更建议放到最后一步进行，为非核心步骤，只是方便而已）</li>
</ol>
<p>Hadoop 需要使用SSH 协议。</p>
<p>namenode 将使用SSH 协议启动 namenode和datanode 进程，配置 SSH localhost无密码验证。</p>
<p>(1)生成密钥对
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>前面是为了切换到root下面</p>
<p>通过以上命令将在/root/.ssh/ 目录下生成id_rsa私钥和id_rsa.pub公钥。</p>
<p>（2）进入/root/.ssh目录在namenode节点下做如下配置：
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>可以用键入ssh localhost命令来看已经连接，会有这样的显示</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>注意最后一行！跟第一行比较，发现我们用ssh进入到localhost了！但已不需要输入密码了。（这样说你们也一定不知道，如果把这个放到最后一步做就会更懂。）</p>
<p>本人认为这样设置会发现后面操作不会让你老是输入密码，并非核心步骤，大家可以试试先配置其它的，再到这一步，就明白为什么了。
来源： <a href="[http://www.linuxidc.com/Linux/2011-07/37992.htm](http://www.linuxidc.com/Linux/2011-07/37992.htm)">[http://www.linuxidc.com/Linux/2011-07/37992.htm](http://www.linuxidc.com/Linux/2011-07/37992.htm)</a> </p>
<ol>
<li>安装JDK</li>
</ol>
<p>(1)下载JDK</p>
<p>建议到sun的官网上下载,地址如下：<a href="https://cds.sun.com/is-bin/INTERSHOP.enfinity/WFS/CDS-CDS_Developer-Site/en_US/-/USD/ViewFilteredProducts-SingleVariationTypeFilter" target="_blank"><a href="https://cds.sun.com/is-bin/INTERSHOP.enfinity/WFS/CDS-CDS_Developer-Site/en_US/-/USD/ViewFilteredProducts-SingleVariationTypeFilter">https://cds.sun.com/is-bin/INTERSHOP.enfinity/WFS/CDS-CDS_Developer-Site/en_US/-/USD/ViewFilteredProducts-SingleVariationTypeFilter</a></a></p>
<p>选择jdk-6u24-linux-i586.bin</p>
<p>(2)安装JDK</p>
<p>我把它装在/opt里面,所以切换到/opt下面。在命令行输入如下指令来执行JDK文件:</p>
<p><img src="" alt=""></p>
<p>权限有问题！我们看看它的权限
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>没有可执行的x标志，那么我们可以通过命令改变。如下操作：</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>看到没，变成绿色的了。有人是把所有者、组、其他用户对该文件的权限都设置为可执行，不过我在这就只让它能被所有者执行就行了。（该文件可能不管紧要，其他重要的文件，我认为不能像他们那样设置。）</p>
<p>现在我们再执行它
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>没有问题了吧，在开始解包了。</p>
<p>(1)Java环境变量配置</p>
<p>输入vim /etc/profile，添加如下的内容（在此我建议所有的都编辑都用vim取代vi，因为它有颜色变化，有语法问题的话很容易发现。）
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>保存好退出后，我们需要改变一下改文件的权限，并执行一下该文件使配置生效。（注：大家一定要小心版本和路径啊，）</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>配置完后执行java –version</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>显示java的版本</p>
<p>来源： <a href="[http://www.linuxidc.com/Linux/2011-07/37992p2.htm](http://www.linuxidc.com/Linux/2011-07/37992p2.htm)">[http://www.linuxidc.com/Linux/2011-07/37992p2.htm](http://www.linuxidc.com/Linux/2011-07/37992p2.htm)</a> </p>
<ol>
<li>安装<a href="http://www.linuxidc.com/topicnews.aspx?tid=13" title="Hadoop" target="_blank">Hadoop</a></li>
</ol>
<p>（1）下载hadoop</p>
<p>到如下网址下载hadoop，存到/opt中,当然也可以手动点击下载。
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>（2）解压hadoop到/opt/hadoop下面，当然没有现成的opt/hadoop这个目录，所以要新建。</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>然后解压到/opt/hadoop下</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>3.1   进入/opt/hadoop/hadoop-0.20.2/conf，配置Hadoop配置文件。</p>
<p>（1）配置java环境：修改hadoop-env.sh文件
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>在最后加上这样的内容</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>(2)配置Namenode的三个配置文件core-site.xml, hdfs-site.xml, mapred-site.xml。对应于/src/core/core-default.xml，但不能直接修改它，（hadoop启动时先读取src下面的core/core-default.xml,hdfs/hdfs-default.xml,apred/mapred-default.xml，里面缺失的变量由conf下面的三个-site文件提供）</p>
<p>这部分的配置建议参考官方网站（建议大家多上官网），如下：<a href="http://hadoop.apache.org/common/docs/current/single_node_setup.html" target="_blank"><a href="http://hadoop.apache.org/common/docs/current/single_node_setup.html">http://hadoop.apache.org/common/docs/current/single_node_setup.html</a></a></p>
<p>(2.1)配置core
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>（2.2）配置hdfs</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>（2.3）配置mapred</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>来源： <a href="[http://www.linuxidc.com/Linux/2011-07/37992p3.htm](http://www.linuxidc.com/Linux/2011-07/37992p3.htm)">[http://www.linuxidc.com/Linux/2011-07/37992p3.htm](http://www.linuxidc.com/Linux/2011-07/37992p3.htm)</a></p>
<p>4、启动<a href="http://www.linuxidc.com/topicnews.aspx?tid=13" title="Hadoop" target="_blank">Hadoop</a></p>
<p>(1)格式化namenode，（注意看清路径哦）
<img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>(2) 启动Hadoop守护进程</p>
<p><img src="" alt="Hadoop在CentOS下的单机配置"></p>
<p>这就表示你配置成功了，上面的一个都不能少</p>
<p>这时候你就可以点击进入下面的网站了。</p>
<p>NameNode - <a href="http://localhost:50070/" target="_blank">http://localhost:50070/</a></p>
<p>JobTracker - <a href="http://localhost:50030/" target="_blank">http://localhost:50030/</a></p>
<p>good luck</p>
<p>其实刚刚接触一个东西可能会觉得不好弄，一旦你弄好了以后就会很顺手。那时候你会告诉自己，这个东西装起来怎么这么白痴啊！赶紧开始下一个工作！加油！
来源： <a href="[http://www.linuxidc.com/Linux/2011-07/37992p4.htm](http://www.linuxidc.com/Linux/2011-07/37992p4.htm)">[http://www.linuxidc.com/Linux/2011-07/37992p4.htm](http://www.linuxidc.com/Linux/2011-07/37992p4.htm)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--Hadoop在CentOS下的单机配置/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--Hadoop在CentOS下的单机配置" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/110/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/108/">108</a></li><li><a class="page-number" href="/page/109/">109</a></li><li><a class="page-number" href="/page/110/">110</a></li><li class="active"><li><span class="page-number current">111</span></li><li><a class="page-number" href="/page/112/">112</a></li><li><a class="page-number" href="/page/113/">113</a></li><li><a class="page-number" href="/page/114/">114</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/161/">161</a></li><li><a class="page-number" href="/page/162/">162</a></li><li><a class="extend next" href="/page/112/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Site powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a>  update time: <em>2014-04-07 18:24:57</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
