
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 105 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-log4j--Log4j写入数据库详解-ziruobing的专栏-CSDN博客/">Log4j写入数据库详解 </a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:37.000Z"> <a href="/2014/02/02/2014-02-02-log4j--Log4j写入数据库详解-ziruobing的专栏-CSDN博客/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="log4j-ziruobing-csdn-">Log4j写入数据库详解 - ziruobing的专栏 - CSDN博客</h1>
<p>您还未登录！|<a href="http://passport.csdn.net/UserLogin.aspx" target="_blank">登录</a>|<a href="http://passport.csdn.net/CSDNUserRegister.aspx" target="_blank">注册</a>|<a href="http://passport.csdn.net/help/faq" target="_blank">帮助</a></p>
<ul>
<li><a href="http://www.csdn.net/" target="_blank">CSDN首页</a></li>
<li><a href="http://news.csdn.net/" target="_blank">资讯</a></li>
<li><a href="http://bbs.csdn.net/" target="_blank">论坛</a></li>
<li><a href="http://blog.csdn.net/" target="_blank">博客</a></li>
<li><a href="http://download.csdn.net/" target="_blank">下载</a></li>
<li><a href="http://so.csdn.net/" target="_blank">搜索</a></li>
<li><h2 id="-"><a href="">更多</a></h2>
</li>
<li><p><a href="http://cto.csdn.net/" target="_blank">CTO俱乐部</a></p>
</li>
<li><a href="http://student.csdn.net/" target="_blank">学生大本营</a></li>
<li><a href="http://edu.csdn.net/" target="_blank">培训充电</a></li>
<li><a href="http://mobile.csdn.net/" target="_blank">移动开发</a></li>
<li><a href="http://sd.csdn.net/" target="_blank">软件研发</a></li>
<li><a href="http://cloud.csdn.net/" target="_blank">云计算</a></li>
<li><a href="http://www.programmer.com.cn/" target="_blank">程序员</a></li>
<li><a href="http://tup.csdn.net/" target="_blank">TUP</a></li>
</ul>
<h1 id="-ziruobing-http-blog-csdn-net-ziruobing-"><a href="http://blog.csdn.net/ziruobing" target="_blank">ziruobing的专栏</a></h1>
<h2 id="-">黑暗中漫舞</h2>
<ul>
<li><a href="http://hi.csdn.net/space-notice.html" target="_blank">条新通知</a></li>
<li><a href="http://passport.csdn.net/UserLogin.aspx?from=http%3A%2F%2Fblog.csdn.net%2Fziruobing%2Farchive%2F2009%2F02%2F22%2F3919501.aspx" target="_blank">登录</a></li>
<li><a href="http://passport.csdn.net/CSDNUserRegister.aspx" target="_blank">注册</a></li>
<li><a href="http://hi.csdn.net/" target="_blank">欢迎</a></li>
<li><a href="http://writeblog.csdn.net/Signout.aspx" target="_blank">退出</a></li>
<li><a href="http://blog.csdn.net/" target="_blank">我的博客</a></li>
<li><a href="http://writeblog.csdn.net/configure.aspx" target="_blank">配置</a></li>
<li><a href="http://writeblog.csdn.net/PostEdit.aspx" target="_blank">写文章</a></li>
<li><a href="http://writeblog.csdn.net/PostList.aspx" target="_blank">文章管理</a></li>
<li><a href="http://blog.csdn.net/" target="_blank">博客首页</a></li>
</ul>
<p>*</p>
<ul>
<li><p>全站 当前博客
*</p>
</li>
<li><p><a href="http://hi.csdn.net/ziruobing" target="_blank">空间</a></p>
</li>
<li><a href="http://blog.csdn.net/ziruobing" target="_blank">博客</a></li>
<li><a href="http://hi.csdn.net/!s/friend/list/ziruobing" target="_blank">好友</a></li>
<li><a href="http://hi.csdn.net/!s/album/list/ziruobing" target="_blank">相册</a></li>
<li><a href="http://hi.csdn.net/!s/wall/to/ziruobing" target="_blank">留言</a>
用户操作 <a href="http://hi.csdn.net/!s/wall/to/ziruobing" target="_blank">[留言]</a>  <a href="http://hi.csdn.net/!s/msg/to/ziruobing" target="_blank">[发消息]</a>  <a href="http://hi.csdn.net/!s/friend/add/ziruobing" target="_blank">[加为好友]</a>  ziruobingID：<a href="http://hi.csdn.net/ziruobing" target="_blank">ziruobing</a><a href="http://hi.csdn.net/ziruobing" target="_blank"><img src="" alt="ziruobing"></a>共<em>5086</em>次访问，排名<em>2万外</em>ziruobing的文章原创 7 篇翻译 0 篇转载 4 篇评论 8 篇  订阅我的博客 <a href="http://feeds.feedsky.com/csdn.net/ziruobing" target="_blank"><img src="" alt="XML聚合"></a>   <a href="http://feeds.feedsky.com/csdn.net/ziruobing" target="_blank"><img src="" alt="FeedSky"></a> <a href="http://www.xianguo.com/subscribe.php?url=http://feeds.feedsky.com/csdn.net/ziruobing" target="_blank"><img src="" alt="订阅到鲜果"></a> <a href="http://fusion.google.com/add?feedurl=http://feeds.feedsky.com/csdn.net/ziruobing" target="_blank"><img src="" alt="订阅到Google"></a> <a href="http://www.zhuaxia.com/add_channel.php?url=http://feeds.feedsky.com/csdn.net/ziruobing" target="_blank"><img src="" alt="订阅到抓虾"></a>  <a href="http://writeblog.csdn.net/configure.aspx" target="_blank">[编辑]</a>ziruobing的公告 <a href="http://writeblog.csdn.net/EditCategories.aspx?catID=1" target="_blank">[编辑]</a>文章分类 * <a href="http://blog.csdn.net/ziruobing/category/517642.aspx/rss" target="_blank"><img src="" alt="(RSS)"></a><a href="http://blog.csdn.net/ziruobing/category/517642.aspx" title="数据库" target="_blank">database</a></li>
<li><a href="http://blog.csdn.net/ziruobing/category/515395.aspx/rss" target="_blank"><img src="" alt="(RSS)"></a><a href="http://blog.csdn.net/ziruobing/category/515395.aspx" title="java" target="_blank">java</a></li>
<li><a href="http://blog.csdn.net/ziruobing/category/515969.aspx/rss" target="_blank"><img src="" alt="(RSS)"></a><a href="http://blog.csdn.net/ziruobing/category/515969.aspx" target="_blank">其它</a> 存档 * <a href="http://blog.csdn.net/ziruobing/archive/2009/09.aspx" target="_blank">2009年09月(1)</a></li>
<li><a href="http://blog.csdn.net/ziruobing/archive/2009/06.aspx" target="_blank">2009年06月(1)</a></li>
<li><a href="http://blog.csdn.net/ziruobing/archive/2009/03.aspx" target="_blank">2009年03月(2)</a></li>
<li><a href="http://blog.csdn.net/ziruobing/archive/2009/02.aspx" target="_blank">2009年02月(7)</a></li>
</ul>
<h3 id="-">公告：</h3>
<ul>
<li><a href="http://topic.csdn.net/u/20110519/09/63bafb67-8580-4f4f-a8a6-0e8469459875.html" target="_blank">CSDN社区招聘.Net开发工程师、运营专员，UI设计师</a>
<a href="http://forum.csdn.net/SList/blogSupport" target="_blank">[意见反馈]</a><a href="http://blog.csdn.net/blogdevteam" target="_blank">[官方博客]</a></li>
</ul>
<h1 id="-log4j-"><img src="" alt="原创">  Log4j写入数据库详解 <a href="&quot;收藏到我的网摘中，并分享给我的朋友&quot;">收藏</a></h1>
<p> log4j是一个优秀的开源日志记录项目，我们不仅可以对输出的日志的格式自定义，还可以自己定义日志输出的目的地，比如：屏幕，文本文件，数据库，甚至能通过socket输出。本节主要讲述如何将日志信息输入到数据库（可以插入任何数据库，在此主要以MSSQL为例进行详解）。
用log4j将日志写入数据库主要用到是log4j包下的JDBCAppender类，它提供了将日志信息异步写入数据的功能，我们可以直接使用这个类将我们的日志信息写入数据库；也可以扩展JDBCAppender类，就是将JDBCAppender类作为基类。下面将通过一个实例来讲解log4j是如何将日志信息写入数据库的。
我们的需求：我们在软件开发的过程中需要将调试信息、操作信息等记录下来，以便后面的审计，这些日志信息包括用户ID、用户姓名、操作类、路径、方法、操作时间、日志信息。
设计思想：我们采用JDBCAppender类直接将日志信息插入数据库，所有只需要在配置文件配置此类就可以;要获得用户信息需要用过滤器来实现；（假如不需要用户的信息，就不需要设计过滤器，其实大部分情况下都是需要这些用户信息，尤其是在web应用开发中）在日志信息中获得用户信息，就的通过过滤器的request或session对象，从session中拿到用户信息怎样传到log4j呢，log4j为我们提供了MDC（MDC是log4j种非常有用类，它们用于存储应用程序的上下文信息（context infomation），从而便于在log中使用这些上下文信息。MDC内部使用了类似map的机制来存储信息，上下文信息也是每个线程独立地储存，所不同的是信息都是以它们的key值存储在”map”中。相对应的方法，</p>
<p>MDC.put(key, value); MDC.remove(key); MDC.get(key);</p>
<p>在配置PatternLayout的时候使用：%x{key}来输出对应的value）。有了MDC，我们可以在过滤器中先获得用户信息，再用MDC.Put（“key”）方法，log在执行sql语句时通过%x{key}来输出对应的value。</p>
<p>实现步骤：
1、在你的项目中要确保有log4j和commons-logging这两个jar文件；
2、设置要你要插入日志信息的表结构</p>
<ol>
<li>if exists (select /* from dbo.sysobjects where id = object_id(N&#39;[dbo].[WDZLOG]&#39;) and OBJECTPROPERTY(id, N&#39;IsUserTable&#39;) = 1)  </li>
<li>drop table [dbo].[WDZLOG]  </li>
<li>GO  </li>
<li></li>
<li>CREATE TABLE [dbo].[WDZLOG] (  </li>
<li>[WDZLOGID] [int] IDENTITY (1, 1) NOT NULL ,  </li>
<li>[LogName] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL ,//用户ID  </li>
<li>[UserName] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL ,//用户姓名  </li>
<li>[Class] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL ,//类名  </li>
<li>[Mothod] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL //,方法名  </li>
<li>[CreateTime] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL ,//产生时间  </li>
<li>[LogLevel] [varchar] (20) COLLATE Chinese_PRC_CI_AS NULL ,//日志级别  </li>
<li>[MSG] [varchar] (555) COLLATE Chinese_PRC_CI_AS NULL //日志信息  </li>
<li>) ON [PRIMARY]  </li>
<li>GO<br>if exists (select /* from dbo.sysobjects where id = object_id(N&#39;[dbo].[WDZLOG]&#39;) and OBJECTPROPERTY(id, N&#39;IsUserTable&#39;) = 1) drop table [dbo].[WDZLOG] GO CREATE TABLE [dbo].[WDZLOG] ( [WDZLOGID] [int] IDENTITY (1, 1) NOT NULL , [LogName] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL ,//用户ID [UserName] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL ,//用户姓名 [Class] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL ,//类名 [Mothod] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL //,方法名 [CreateTime] [varchar] (255) COLLATE Chinese_PRC_CI_AS NULL ,//产生时间 [LogLevel] [varchar] (20) COLLATE Chinese_PRC_CI_AS NULL ,//日志级别 [MSG] [varchar] (555) COLLATE Chinese_PRC_CI_AS NULL //日志信息 ) ON [PRIMARY] GO</li>
</ol>
<p>3、配置文件（摘自我们的项目）后面将对此配置文件进行详细讲解，它也log4j的核心部分。</p>
<ol>
<li>log4j.properties  </li>
<li>log4j.rootLogger=INFO,stdout  </li>
<li></li>
<li>log4j.logger.org.springframework.web.servlet=INFO,db  </li>
<li></li>
<li>log4j.logger.org.springframework.beans.factory.xml=INFO  </li>
<li>log4j.logger.com.neam.stum.user=INFO,db  </li>
<li></li>
<li>log4j.appender.stdout=org.apache.log4j.ConsoleAppender  </li>
<li>log4j.appender.stdout.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %p [%c] - - &lt;%m&gt;%n  </li>
<li></li>
<li>log4j.appender.logfile=org.apache.log4j.DailyRollingFileAppender  </li>
<li>log4j.appender.logfile.File=${webapp.root}/WEB-INF/logs/exppower.log  </li>
<li>log4j.appender.logfile.DatePattern=.yyyy-MM-dd  </li>
<li>log4j.appender.logfile.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] wang- &lt;%m&gt;%n  </li>
<li></li>
<li>/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#  </li>
<li></li>
<li>/# JDBC Appender  </li>
<li></li>
<li>/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#  </li>
<li></li>
<li></li>
<li>/#log4j.logger.business=INFO,db  </li>
<li>/#log4j.appender.db=com.neam.commons.MyJDBCAppender  </li>
<li>log4j.appender.db=JDBCExtAppender  </li>
<li></li>
<li>log4j.appender.db.BufferSize=10  </li>
<li></li>
<li>log4j.appender.db.sqlname=log  </li>
<li></li>
<li>log4j.appender.db.driver=net.sourceforge.jtds.jdbc.Driver  </li>
<li></li>
<li>log4j.appender.db.URL=jdbc:jtds:SqlServer://localhost:1433;DatabaseName=pubs  </li>
<li></li>
<li>log4j.appender.db.user=sa  </li>
<li></li>
<li>log4j.appender.db.password=sa  </li>
<li></li>
<li>log4j.appender.db.sql=insert into WDZLOG (LogName,UserName,Class,Mothod,createTime,LogLevel,MSG) values (&#39;%X{userId}&#39;,&#39;%X{userName}&#39;,&#39;%C&#39;,&#39;%M&#39;,&#39;%d{yyyy-MM-dd HH:mm:ss}&#39;,&#39;%p&#39;,&#39;%m&#39;)  </li>
<li></li>
<li>log4j.appender.db.layout=org.apache.log4j.PatternLayout<br>log4j.properties log4j.rootLogger=INFO,stdout log4j.logger.org.springframework.web.servlet=INFO,db log4j.logger.org.springframework.beans.factory.xml=INFO log4j.logger.com.neam.stum.user=INFO,db log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %p [%c] - - &lt;%m&gt;%n log4j.appender.logfile=org.apache.log4j.DailyRollingFileAppender log4j.appender.logfile.File=${webapp.root}/WEB-INF/logs/exppower.log log4j.appender.logfile.DatePattern=.yyyy-MM-dd log4j.appender.logfile.layout=org.apache.log4j.PatternLayout log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] wang- &lt;%m&gt;%n /#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/# /# JDBC Appender /#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/# /#log4j.logger.business=INFO,db /#log4j.appender.db=com.neam.commons.MyJDBCAppender log4j.appender.db=JDBCExtAppender log4j.appender.db.BufferSize=10 log4j.appender.db.sqlname=log log4j.appender.db.driver=net.sourceforge.jtds.jdbc.Driver log4j.appender.db.URL=jdbc:jtds:SqlServer://localhost:1433;DatabaseName=pubs log4j.appender.db.user=sa log4j.appender.db.password=sa log4j.appender.db.sql=insert into WDZLOG (LogName,UserName,Class,Mothod,createTime,LogLevel,MSG) values (&#39;%X{userId}&#39;,&#39;%X{userName}&#39;,&#39;%C&#39;,&#39;%M&#39;,&#39;%d{yyyy-MM-dd HH:mm:ss}&#39;,&#39;%p&#39;,&#39;%m&#39;) log4j.appender.db.layout=org.apache.log4j.PatternLayout</li>
</ol>
<p>4、编写过滤器（ResFilter.java）</p>
<ol>
<li>import java.io.IOException;  </li>
<li>import javax.servlet.Filter;  </li>
<li>import javax.servlet.FilterChain;  </li>
<li>import javax.servlet.FilterConfig;  </li>
<li>import javax.servlet.ServletException;  </li>
<li>import javax.servlet.ServletRequest;  </li>
<li>import javax.servlet.ServletResponse;  </li>
<li>import javax.servlet.http.HttpServletRequest;  </li>
<li>import javax.servlet.http.HttpSession;  </li>
<li></li>
<li>import org.apache.log4j.Logger;  </li>
<li>import org.apache.log4j.MDC;  </li>
<li></li>
<li>import com.neam.domain.User;  </li>
<li></li>
<li>public class ResFilter implements Filter{  </li>
<li></li>
<li></li>
<li>private final static double DEFAULT_USERID= Math.random()/*100000.0;    </li>
<li></li>
<li>public void destroy() {  </li>
<li>}  </li>
<li></li>
<li>public void doFilter(ServletRequest request, ServletResponse response,  </li>
<li>FilterChain chain) throws IOException, ServletException {  </li>
<li>HttpServletRequest req=(HttpServletRequest)request;  </li>
<li>HttpSession session= req.getSession();  </li>
<li>if (session==null){  </li>
<li>MDC.put(&quot;userId&quot;,DEFAULT_USERID);    </li>
<li>}  </li>
<li>else{  </li>
<li>User customer=(User)session.getAttribute(&quot;user&quot;);  </li>
<li>if (customer==null){  </li>
<li>MDC.put(&quot;userId&quot;,DEFAULT_USERID);  </li>
<li>MDC.put(&quot;userName&quot;,DEFAULT_USERID);  </li>
<li>}  </li>
<li>else  </li>
<li>{  </li>
<li>MDC.put(&quot;userId&quot;,customer.getName());  </li>
<li>MDC.put(&quot;userName&quot;,customer.getName());  </li>
<li>}  </li>
<li>}  </li>
<li>//logger.info(&quot;test for MDC.&quot;);  </li>
<li></li>
<li>chain.doFilter(request, response);  </li>
<li>}  </li>
<li>public void init(FilterConfig Config) throws ServletException {  </li>
<li>//     this.filterConfig = Config;  </li>
<li>//     String ccc = Config.getServletContext().getInitParameter(&quot;cherset&quot;);  </li>
<li>//     this.targetEncoding = Config.getInitParameter(&quot;cherset&quot;);  </li>
<li></li>
<li>}  </li>
<li>}<br>import java.io.IOException; import javax.servlet.Filter; import javax.servlet.FilterChain; import javax.servlet.FilterConfig; import javax.servlet.ServletException; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletRequest; import javax.servlet.http.HttpSession; import org.apache.log4j.Logger; import org.apache.log4j.MDC; import com.neam.domain.User; public class ResFilter implements Filter{ private final static double DEFAULT_USERID= Math.random()/*100000.0; public void destroy() { } public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { HttpServletRequest req=(HttpServletRequest)request; HttpSession session= req.getSession(); if (session==null){ MDC.put(&quot;userId&quot;,DEFAULT_USERID); } else{ User customer=(User)session.getAttribute(&quot;user&quot;); if (customer==null){ MDC.put(&quot;userId&quot;,DEFAULT_USERID); MDC.put(&quot;userName&quot;,DEFAULT_USERID); } else { MDC.put(&quot;userId&quot;,customer.getName()); MDC.put(&quot;userName&quot;,customer.getName()); } } //logger.info(&quot;test for MDC.&quot;); chain.doFilter(request, response); } public void init(FilterConfig Config) throws ServletException { // this.filterConfig = Config; // String ccc = Config.getServletContext().getInitParameter(&quot;cherset&quot;); // this.targetEncoding = Config.getInitParameter(&quot;cherset&quot;); } }</li>
</ol>
<p>5、在需要写入日志的地方引入</p>
<ol>
<li>private Log logger = LogFactory.getLog(this.getClass());  </li>
<li></li>
<li>在具体方法中就可以写入日志  </li>
<li>logger.info(&quot;&quot;);  </li>
<li>logger.debug(&quot;&quot;);  </li>
<li>logger.warn(&quot;&quot;);  </li>
<li>logger.error(&quot;&quot;);<br>private Log logger = LogFactory.getLog(this.getClass()); 在具体方法中就可以写入日志 logger.info(&quot;&quot;); logger.debug(&quot;&quot;); logger.warn(&quot;&quot;); logger.error(&quot;&quot;);</li>
</ol>
<p><strong>配置文件详解：
</strong>log4j.properties
log4j.properties
log4j.rootLogger=INFO,stdout</p>
<p>//<strong>配置根Logger，</strong>其语法为：
log4j.rootLogger = [ level ] , appenderName1, appenderName2, …
level : 是日志记录的优先级，分为OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者您定义的级别。Log4j建议只使用四个级别，优先级从高到低分别是ERROR、WARN、INFO、DEBUG。通过在这里定义的级别，您可以控制到应用程序中相应级别的日志信息的开关。比如在这里定义了INFO级别，则应用程序中所有DEBUG级别的日志信息将不被打印出来。
appenderName:就是指定日志信息输出到哪个地方。您可以同时指定多个输出目的地。
例如：log4j.rootLogger＝info,A1,B2,C3 配置了3个输出地方我们可以设置让A1在控制台输出；B2生产日志文件；C3让日志信息插入数据库中。
本例中是将所有的日志信息在控制台打印出来。
log4j.logger.org.springframework.web.servlet=INFO,db
//设置将spring下包的某些类的日志信息写入数据库中，并且在控制台上打印出来。（是通过log4j.rootLogger=INFO,stdout来体现的）db是将日志信息写入数据库中
log4j.logger.org.springframework.beans.factory.xml=INFO
//本实例中为了让某些包下的日志信息能写入数据库
log4j.logger.com.neam.stum.user=INFO,db
//设置自己某个模块下的日志信息既在控制台上打印而且往数据库中保存
//下面是配置在控制台上打印日志信息，在这里就不再仔细描述了
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %p [%c] - - &lt;%m&gt;%n
//下面是配置将日志信息写入文件中，在这里也就不再仔细描述了
log4j.appender.logfile=org.apache.log4j.DailyRollingFileAppender
log4j.appender.logfile.File=${webapp.root}/WEB-INF/logs/exppower.log
log4j.appender.logfile.DatePattern=.yyyy-MM-dd
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] wang- &lt;%m&gt;%n
/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#
/# JDBC Appender
/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#/#
/#log4j.appender.db=com.neam.commons.MyJDBCAppender
//下面是配置将日志信息插入数据库，
log4j.appender.db=org.apache.log4j.jdbc.JDBCAppender
//配置输出目标为数据库（假如要将日志在控制台输出，配置为log4j.appender. stdout =org.apache.log4j.ConsoleAppender；将日志写入文件，配置为log4j.appender.logfile=org.apache.log4j.DailyRollingFileAppender
这样的配置在许多地方都要有，需要可查有关资料）,当然你也可以自己扩展org.apache.log4j.jdbc.JDBCAppender这个类，只需要在这里配置就可以了例如我们配置我自己扩展的MyJDBCAppender，配置为/#log4j.appender.db=com.neam.commons.MyJDBCAppender
log4j.appender.db.BufferSize=10
//设置缓存大小，就是当有10条日志信息是才忘数据库插一次
log4j.appender.db.driver=net.sourceforge.jtds.jdbc.Driver
//设置要将日志插入到数据库的驱动<br>log4j.appender.db.URL=jdbc:jtds:SqlServer://localhost:1433;DatabaseName=pubs
log4j.appender.db.user=sa
log4j.appender.db.password=sa
log4j.appender.db.sql=insert into WDZLOG (LogName,UserName,Class,Mothod,createTime,LogLevel,MSG) values (&#39;%X{userId}&#39;,&#39;%X{userName}&#39;,&#39;%C&#39;,&#39;%M&#39;,&#39;%d{yyyy-MM-dd HH:mm:ss}&#39;,&#39;%p&#39;,&#39;%m&#39;)
//设置要插入日志信息的格式和内容，%X{userId}是置取MDC中的key值，因为我们在过滤器中是将用户id和用户姓名放入MDC中，所有在这里可以用%X{userId}和%X{userName}取出用户的ID和用户姓名；&#39;%C&#39;表示日志信息是来自于那个类；%M表示日志信息来自于那个方法中；%d{yyyy-MM-dd HH:mm:ss}表示日志信息产生的时间，{yyyy-MM-dd HH:mm:ss}表示一种时间格式，你也可以直接写成%d；%p表示日志信息的级别（debug info warn error）；
%m表示你写入的日志信息
log4j.appender.db.layout=org.apache.log4j.PatternLayout</p>
<p>发表于 @ 2009年02月22日　01:05:00 | <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#FeedBack" title="评论" target="_blank">评论( 5  )</a>| <a href="http://writeblog.csdn.net/PostEdit.aspx?entryId=3919501" title="编辑" target="_blank">编辑</a>| <a href="mailto:webmaster@csdn.net?subject=Article%20Report!!!&amp;body=Author:ziruobing%0D%0AURL:http://blog.csdn.net/ArticleContent.aspx?UserName=ziruobing&amp;Entryid=3919501">举报</a>| <a href="&quot;收藏到我的网摘中，并分享给我的朋友&quot;">收藏</a></p>
<h3 id="-http-blog-csdn-net-ziruobing-archive-2009-02-20-3914902-aspx-hibernate-jdbc-jta-http-blog-csdn-net-ziruobing-archive-2009-02-26-3938601-aspx-"><a href="http://blog.csdn.net/ziruobing/archive/2009/02/20/3914902.aspx" target="_blank">旧一篇:正则表达式入门</a> | <a href="http://blog.csdn.net/ziruobing/archive/2009/02/26/3938601.aspx" target="_blank">新一篇:Hibernate的两种事务管理jdbc 和jta方式</a></h3>
<p>-</p>
<p><a href="http://blog.csdn.net/" target="_blank">查看最新精华文章 请访问博客首页</a>相关文章 <a href="http://blog.csdn.net/cosio/archive/2005/11/05/523334.aspx" target="_blank">SQL计算表达式</a><a href="http://blog.csdn.net/bugchen888/archive/2005/11/24/536069.aspx" target="_blank">用SQL向/*.txt中追加文本</a><a href="http://blog.csdn.net/frankchenyj/archive/2007/11/19/1892075.aspx" target="_blank">儲存過程萬能分頁</a><a href="http://blog.csdn.net/zhaowei001/archive/2008/01/03/2021036.aspx" target="_blank">利用SQL移动硬盘文件</a><a href="http://blog.csdn.net/taikeqi/archive/2008/11/05/3220018.aspx" target="_blank">改变SQLServer 数据库所有对象的所有者成dbo</a><a href="http://blog.csdn.net/dahaizisheng/archive/2009/09/23/4579491.aspx" target="_blank">log4j把日志写入数据库详解</a> <a href=""></a></p>
<p><a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#1154556" title="permalink: Re:� Log4j写入数据库详解" target="_blank"></a><a href="http://hi.csdn.net/wofile">wofile</a> 发表于Wed Sep 30 2009 12:13:26 GMT+0800 (China Standard Time)  IP:<a href="mailto:webmaster@csdn.net?subject=Comment%20Report!!!&amp;body=Author:wofile%20URL:http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx">举报</a><a href="">回复</a><a href="">删除</a><img src="" alt="">tai hao le .... xie xie a ~~~<a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#1179457" title="permalink: Re:Log4j写入数据库详解" target="_blank"></a><a href="http://hi.csdn.net/luchangbin_66">luchangbin_66</a> 发表于Thu Nov 19 2009 10:53:29 GMT+0800 (China Standard Time)  IP:<a href="mailto:webmaster@csdn.net?subject=Comment%20Report!!!&amp;body=Author:luchangbin_66%20URL:http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx">举报</a><a href="">回复</a><a href="">删除</a><img src="" alt="">Filter在web.xml中过滤那些。。。。。<a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#1185590" title="permalink: Re:� Log4j写入数据库详解" target="_blank"></a><a href="http://hi.csdn.net/liang_gdong">liang_gdong</a> 发表于Mon Nov 30 2009 16:06:18 GMT+0800 (China Standard Time)  IP:<a href="mailto:webmaster@csdn.net?subject=Comment%20Report!!!&amp;body=Author:liang_gdong%20URL:http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx">举报</a><a href="">回复</a><a href="">删除</a><img src="" alt="">好东西，支持<a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#1211462" title="permalink: Log4j写入数据库详解" target="_blank"></a><a href="http://hi.csdn.net/mwj0103">mwj0103</a> 发表于Wed Jan 06 2010 13:24:41 GMT+0800 (China Standard Time)  IP:<a href="mailto:webmaster@csdn.net?subject=Comment%20Report!!!&amp;body=Author:mwj0103%20URL:http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx">举报</a><a href="">回复</a><a href="">删除</a><img src="" alt=""><img src="" alt="">太让人感动了！~<a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#1219539" title="permalink: Log4j写入数据库详解" target="_blank"></a><a href="http://hi.csdn.net/iceyrain">iceyrain</a> 发表于Tue Jan 12 2010 10:22:37 GMT+0800 (China Standard Time)  IP:<a href="mailto:webmaster@csdn.net?subject=Comment%20Report!!!&amp;body=Author:iceyrain%20URL:http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx">举报</a><a href="">回复</a><a href="">删除</a><img src="" alt="">很牛， 受教了 谢谢</p>
<ul>
<li><p>发表评论</p>
</li>
<li><p>表 情：</p>
</li>
<li><p><a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;顶&quot;" alt="顶"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;砸&quot;" alt="砸"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;棒&quot;" alt="棒"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;大笑&quot;" alt="大笑"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;愤怒&quot;" alt="愤怒"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;大哭&quot;" alt="大哭"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;疑问&quot;" alt="疑问"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;汗&quot;" alt="汗"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;呕吐&quot;" alt="呕吐"></a> <a href="http://blog.csdn.net/ziruobing/archive/2009/02/22/3919501.aspx#" target="_blank"><img src="&quot;送花&quot;" alt="送花"></a></p>
</li>
<li><p>评论内容：
*</p>
</li>
<li>用 户 名：</li>
<li><p><a href="">登录</a> <a href="http://passport.csdn.net/CSDNUserRegister.aspx" target="_blank">注册</a>  匿名评论 匿名用户</p>
</li>
<li><p>验 证 码：</p>
</li>
<li><p><a href=""><img src="" alt="验证码"></a> <a href="">重新获得验证码</a></p>
</li>
<li><p>*</p>
</li>
</ul>
<h3 id="-">专区推荐内容</h3>
<ul>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298921" title="哥是传奇—组团参赛心得" target="_blank">哥是传奇—组团参赛心得</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298920" title="【教程】Windows平台下MeeGo v1.2 SDK的安装" target="_blank">【教程】Windows平台下MeeGo v1.2 SDK的安装</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298814" title="MeeGo 1.2 正式版发布" target="_blank">MeeGo 1.2 正式版发布</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298657" title="在生命走到尽头前用脚贡献了最后一个代码补丁" target="_blank">在生命走到尽头前用脚贡献了最后一个代码补丁</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298656" title="浅谈QT中窗口刷新事件" target="_blank">浅谈QT中窗口刷新事件</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298655" title="赢笔记本电脑，提升管理软件新水平！" target="_blank">赢笔记本电脑，提升管理软件新水平！</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298548" title="【教程】安装MeeGO和Windows 7双系统的方法" target="_blank">【教程】安装MeeGO和Windows 7双系统的方法</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298449" title="分享我的个人初赛体会" target="_blank">分享我的个人初赛体会</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298309" title="【免费】参与移动应用投票赢手机话费" target="_blank">【免费】参与移动应用投票赢手机话费</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298307" title="Nokia宣布Qt 5计划" target="_blank">Nokia宣布Qt 5计划</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298138" title="立即加入IBM dW，万千技术尽网罗" target="_blank">立即加入IBM dW，万千技术尽网罗</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298040" title="Linux 上简单的MeeGo 开发 QT 程序" target="_blank">Linux 上简单的MeeGo 开发 QT 程序</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=298039" title="软件产品性能优化注意事项" target="_blank">软件产品性能优化注意事项</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=297526" title="用C#实现HTTP协议下的多线程文件传输" target="_blank">用C/#实现HTTP协议下的多线程文件传输</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=297525" title="【实战】搭建Meego Tablet开发测试平台" target="_blank">【实战】搭建Meego Tablet开发测试平台</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=297421" title="AppUp Center为更多程序员创造机会" target="_blank">AppUp Center为更多程序员创造机会</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=297420" title="【源码分享】一个多线程下载文件的程序" target="_blank">【源码分享】一个多线程下载文件的程序</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=297204" title="轻松漫画聊快速构建网站" target="_blank">轻松漫画聊快速构建网站</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296905" title="如何创建一个简单的Qt应用程序" target="_blank">如何创建一个简单的Qt应用程序</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296820" title="【赢取旧金山之旅】2011线程挑战赛" target="_blank">【赢取旧金山之旅】2011线程挑战赛</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296709" title="【图】爱上NOOK COLOR的5个理由" target="_blank">【图】爱上NOOK COLOR的5个理由</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296610" title="IPAD&amp;NOOK COLOR屏幕对比多图" target="_blank">IPAD&amp;NOOK COLOR屏幕对比多图</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296533" title="【教程】AppUp 进阶基础篇" target="_blank">【教程】AppUp 进阶基础篇</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296502" title="Nokia CEO：下一步会与谁合作？" target="_blank">Nokia CEO：下一步会与谁合作？</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296501" title="点评三星Smart TV智能电视" target="_blank">点评三星Smart TV智能电视</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296407" title="太震撼了！首次参加IDF有感" target="_blank">太震撼了！首次参加IDF有感</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296334" title="【教程】基于VC色温图效果实现" target="_blank">【教程】基于VC色温图效果实现</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296333" title="【教程】游戏技巧特效处理" target="_blank">【教程】游戏技巧特效处理</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296243" title="Firefox 4在meego上成功安装" target="_blank">Firefox 4在meego上成功安装</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296239" title="IDF2011：多图详解MeeGo 3月后正式发布" target="_blank">IDF2011：多图详解MeeGo 3月后正式发布</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296238" title="PayPal助力移动支付应用" target="_blank">PayPal助力移动支付应用</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296079" title="Android应用换电视，前30名有效！" target="_blank">Android应用换电视，前30名有效！</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296068" title="【教程】笔记本安装MeeGo" target="_blank">【教程】笔记本安装MeeGo</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296067" title="微软BI解决方案开发简介" target="_blank">微软BI解决方案开发简介</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296064" title="下载Windows Phone 中文培训包" target="_blank">下载Windows Phone 中文培训包</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296060" title="下载 Windows Phone 开发工具" target="_blank">下载 Windows Phone 开发工具</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=296059" title="全新Windows Phone 开发中心" target="_blank">全新Windows Phone 开发中心</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=295728" title="VS2010 SharePoint 入门" target="_blank">VS2010 SharePoint 入门</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=295726" title="【免费下载】WebMatrix建站工具" target="_blank">【免费下载】WebMatrix建站工具</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=295725" title="AIX 专区有奖话题讨论" target="_blank">AIX 专区有奖话题讨论</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=295724" title="4.21日Adobe企业RIA开发者研讨会" target="_blank">4.21日Adobe企业RIA开发者研讨会</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=295713" title="MeeGo中文社区全新呈现" target="_blank">MeeGo中文社区全新呈现</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=299402" title="羡慕嫉妒恨！MeeGO平板到手" target="_blank">羡慕嫉妒恨！MeeGO平板到手</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=299401" title="MeeGo SDK 1.2 for Linux 初窥" target="_blank">MeeGo SDK 1.2 for Linux 初窥</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=299243" title="2011台北国际电脑展开幕（5.31-6.4）" target="_blank">2011台北国际电脑展开幕（5.31-6.4）</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=299235" title="关于QT编程入门的那些事" target="_blank">关于QT编程入门的那些事</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=299234" title="相见 ——“人生若只如初见”" target="_blank">相见 ——“人生若只如初见”</a></li>
<li><a href="http://articles.csdn.net/plus/view.php?aid=299094" title="游戏远程代码注入和动态连接库的使用" target="_blank">游戏远程代码注入和动态连接库的使用</a>
&lt;&lt; &gt;&gt;</li>
</ul>
<h3 id="-http-special-csdn-net-zhaopin-index-html-">热门招聘职位 【<a href="http://special.csdn.net/zhaopin/index.html" target="_blank">更多</a>】</h3>
<ul>
<li><a href="http://g.csdn.net/5185888" target="_blank">【傲盾软件】高薪诚聘C、C++、JAVA、cavium/linux工程师</a></li>
<li><a href="http://g.csdn.net/5185906" target="_blank">【道达天际】高薪诚聘：渗透测试、网络安全、逆向技术分析 专业人才</a></li>
<li><a href="http://g.csdn.net/5185702" target="_blank">诚聘高级软件工程师，架构师，待遇从优</a></li>
<li><a href="http://g.csdn.net/5185637" target="_blank">【山重融资】诚聘软件开发工程师、网络管理工程师</a></li>
<li><a href="http://g.csdn.net/5185599" target="_blank">【卓坤信息】诚聘MFC高级客户端、网页设计师、PHP开发等</a></li>
<li><a href="http://g.csdn.net/5185494" target="_blank">爱福康诚招：C++ / Directshow 软件工程师</a></li>
<li><a href="http://g.csdn.net/5185490" target="_blank">【天健集团】诚聘架构师，高级软件开发工程师（.NET、PB、J2EE）,实施人员</a></li>
<li><a href="http://g.csdn.net/5184976" target="_blank">爱唱数码诚聘 研发经理&amp;程序员</a></li>
<li><a href="http://g.csdn.net/5184945" target="_blank">【北京联银通科技有限制公司】高薪诚聘技术经理、高级工程师等职位</a></li>
<li><a href="http://g.csdn.net/5184844" target="_blank">【安博教育】诚聘软件开发、架构师、技术总监等技术人才</a></li>
<li><a href="http://g.csdn.net/5162966" target="_blank">【Autodesk】欧特克软件(中国)诚聘软件开发,测试,研究员</a></li>
<li><a href="http://g.csdn.net/5185477" target="_blank">【北京平川嘉恒】团队Leader及客户端/服务器端研发工程师</a></li>
<li><a href="http://g.csdn.net/5183628" target="_blank">【欢网科技】诚聘系统架构师、需求分析师、开发工程师</a></li>
<li><a href="http://g.csdn.net/5183513" target="_blank">【酷狗音乐】诚聘VC、服务端开发工程师等职位</a></li>
<li><a href="http://g.csdn.net/5182525" target="_blank">【法国电信】诚聘研发类人才</a></li>
<li><a href="http://g.csdn.net/5183220" target="_blank">【飞漫公司】诚聘C/C++研发工程师、软件测试等！</a></li>
<li><a href="http://g.csdn.net/5182403" target="_blank">【上海电科智能】高新诚聘JAVA和C/#等软件工程师</a></li>
<li><a href="http://g.csdn.net/5182398" target="_blank">【仙掌软件】高新诚聘java、android、iPhone软件工程师等职位，期待您的加入！</a></li>
<li><a href="http://g.csdn.net/5181583" target="_blank">【完美世界】（原完美时空）诚聘各类游戏领域人才</a></li>
<li><a href="http://g.csdn.net/5180531" target="_blank">【亿阳信通】诚邀您的加盟！</a></li>
<li><a href="http://g.csdn.net/5182687" target="_blank">【Amazon】亚马逊诚聘技术专家！</a></li>
<li><a href="http://g.csdn.net/5180413" target="_blank">【航天信息股份有限公司】诚聘系统架构，需求分析、JAVA开发、C/C++开发研发岗位热招中</a></li>
<li><a href="http://g.csdn.net/5180371" target="_blank">【杭州引力】高薪诚聘ios开发人员</a></li>
<li><a href="http://g.csdn.net/5178940" target="_blank">【 CSDN】高薪诚聘：java、运营、就业、商务策划经理、网站编辑！</a></li>
<li><a href="http://g.csdn.net/5185888" target="_blank">【傲盾软件】高薪诚聘C、C++、JAVA、cavium/linux工程师</a></li>
<li><a href="http://g.csdn.net/5185906" target="_blank">【道达天际】高薪诚聘：渗透测试、网络安全、逆向技术分析 专业人才</a></li>
<li><a href="http://g.csdn.net/5185702" target="_blank">诚聘高级软件工程师，架构师，待遇从优</a></li>
<li><a href="http://g.csdn.net/5185637" target="_blank">【山重融资】诚聘软件开发工程师、网络管理工程师</a></li>
<li><a href="http://g.csdn.net/5185599" target="_blank">【卓坤信息】诚聘MFC高级客户端、网页设计师、PHP开发等</a></li>
<li><a href="http://g.csdn.net/5185494" target="_blank">爱福康诚招：C++ / Directshow 软件工程师</a></li>
<li><a href="http://g.csdn.net/5185490" target="_blank">【天健集团】诚聘架构师，高级软件开发工程师（.NET、PB、J2EE）,实施人员</a></li>
<li><a href="http://g.csdn.net/5184976" target="_blank">爱唱数码诚聘 研发经理&amp;程序员</a></li>
<li><a href="http://g.csdn.net/5184945" target="_blank">【北京联银通科技有限制公司】高薪诚聘技术经理、高级工程师等职位</a></li>
<li><a href="http://g.csdn.net/5184844" target="_blank">【安博教育】诚聘软件开发、架构师、技术总监等技术人才</a></li>
<li><a href="http://g.csdn.net/5162966" target="_blank">【Autodesk】欧特克软件(中国)诚聘软件开发,测试,研究员</a></li>
<li><a href="http://g.csdn.net/5185477" target="_blank">【北京平川嘉恒】团队Leader及客户端/服务器端研发工程师</a></li>
<li><a href="http://g.csdn.net/5183628" target="_blank">【欢网科技】诚聘系统架构师、需求分析师、开发工程师</a></li>
<li><a href="http://g.csdn.net/5183513" target="_blank">【酷狗音乐】诚聘VC、服务端开发工程师等职位</a></li>
<li><a href="http://g.csdn.net/5182525" target="_blank">【法国电信】诚聘研发类人才</a></li>
<li><a href="http://g.csdn.net/5183220" target="_blank">【飞漫公司】诚聘C/C++研发工程师、软件测试等！</a></li>
<li><a href="http://g.csdn.net/5182403" target="_blank">【上海电科智能】高新诚聘JAVA和C/#等软件工程师</a></li>
<li><a href="http://g.csdn.net/5182398" target="_blank">【仙掌软件】高新诚聘java、android、iPhone软件工程师等职位，期待您的加入！</a></li>
<li><a href="http://g.csdn.net/5181583" target="_blank">【完美世界】（原完美时空）诚聘各类游戏领域人才</a></li>
<li><a href="http://g.csdn.net/5180531" target="_blank">【亿阳信通】诚邀您的加盟！</a></li>
<li><a href="http://g.csdn.net/5182687" target="_blank">【Amazon】亚马逊诚聘技术专家！</a></li>
<li><a href="http://g.csdn.net/5180413" target="_blank">【航天信息股份有限公司】诚聘系统架构，需求分析、JAVA开发、C/C++开发研发岗位热招中</a></li>
<li><a href="http://g.csdn.net/5180371" target="_blank">【杭州引力】高薪诚聘ios开发人员</a></li>
<li><a href="http://g.csdn.net/5178940" target="_blank">【 CSDN】高薪诚聘：java、运营、就业、商务策划经理、网站编辑！</a>
<img src="" alt="">
<a href="http://www.csdn.net/company/about.html" target="_blank">公司简介</a>|<a href="http://www.csdn.net/company/recruit.html" target="_blank">招贤纳士</a>|<a href="http://www.csdn.net/company/marketing.html" target="_blank">广告服务</a>|<a href="http://www.csdn.net/company/account.html" target="_blank">银行汇款帐号</a>|<a href="http://www.csdn.net/company/contact.html" target="_blank">联系方式</a>|<a href="http://www.csdn.net/company/statement.html" target="_blank">版权声明</a>|<a href="http://www.csdn.net/company/layer.html" target="_blank">法律顾问</a>|<a href="mailto:webmaster@csdn.net">问题报告</a>北京创新乐知信息技术有限公司 版权所有, 京 ICP 证 070598 号世纪乐知(北京)网络技术有限公司 提供技术支持江苏乐知网络技术有限公司 提供商务支持<img src="" alt=""> Email:webmaster@csdn.netCopyright © 1999-2011, CSDN.NET, All Rights Reserved<a href="http://www.hd315.gov.cn/beian/view.asp?bianhao=010202001032100010" target="_blank"><img src="" alt="GongshangLogo"></a> <img src="" alt=""> <img src="" alt=""></li>
</ul>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/log4j/">log4j</a></li></span></span> | <span class="tags">Tagged <a href="/tags/log4j/" class="label label-primary">log4j</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:37"datetime="2014-03-07 09:54:37"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-log4j--Log4j写入数据库详解-ziruobing的专栏-CSDN博客/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-log4j--Log4j写入数据库详解-ziruobing的专栏-CSDN博客" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-log4j--log4jproperties参数-蓝色贝壳-ITeye技术网站/">log4j.properties参数 </a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:37.000Z"> <a href="/2014/02/02/2014-02-02-log4j--log4jproperties参数-蓝色贝壳-ITeye技术网站/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="log4j-properties-iteye-">log4j.properties参数 - 蓝色贝壳 - ITeye技术网站</h1>
<p><a href="http://www.iteye.com/" target="_blank">首页</a> <a href="http://www.iteye.com/news" target="_blank">新闻</a> <a href="http://www.iteye.com/forums" target="_blank">论坛</a> <a href="http://www.iteye.com/ask" target="_blank">问答</a> <a href="http://www.iteye.com/blogs" target="_blank">博客</a> <a href="http://www.iteye.com/job" target="_blank">招聘</a> <a href="http://ff861.iteye.com/blog/459983#" target="_blank">更多 ▼</a></p>
<p><a href="http://www.iteye.com/groups" target="_blank">群组</a> <a href="http://www.iteye.com/search" target="_blank">搜索</a></p>
<p><a href="http://ff861.iteye.com/login" title="登录" target="_blank">您还未登录 !</a> <a href="http://www.iteye.com/all" target="_blank">我的应用</a> <a href="http://ff861.iteye.com/login" target="_blank">登录</a> <a href="http://ff861.iteye.com/signup" target="_blank">注册</a></p>
<h1 id="-http-ff861-iteye-com-"><a href="http://ff861.iteye.com/" target="_blank">蓝色贝壳</a></h1>
<p>永久域名 <a href="http://ff861.iteye.com/" target="_blank"><a href="http://ff861.iteye.com">http://ff861.iteye.com</a></a></p>
<p><a href="http://ff861.iteye.com/blog/505750" title="java中判断字符串是否为数字的方法 " target="_blank">java中判断字符串是否为数字的方法</a> | <a href="http://ff861.iteye.com/blog/447203" title="根据wsdl地址或文件生成webservice客户端" target="_blank">根据wsdl地址或文件生成webservice客户端</a></p>
<p>2009-09-01</p>
<h3 id="-log4j-properties-"><a href="">log4j.properties参数</a></h3>
<p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"><img src="" alt=""></a></p>
<ol>
<li>log4j.rootLogger=DEBUG,CONSOLE,DATABASE,FILE  </li>
<li>log4j.addivity.org.apache=true  </li>
<li></li>
<li>/# 应用于控制台  </li>
<li>log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender  </li>
<li>log4j.appender.CONSOLE.Threshold=INFO  </li>
<li>log4j.appender.CONSOLE.Target=System.out  </li>
<li>log4j.appender.CONSOLE.Encoding=GBK  </li>
<li>log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.CONSOLE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n  </li>
<li></li>
<li>/# 用于数据库  </li>
<li>/#log4j.appender.DATABASE=org.apache.log4j.jdbc.JDBCAppender  </li>
<li>/#log4j.appender.DATABASE.URL=jdbc:mysql://localhost:3306/ww  </li>
<li>/#log4j.appender.DATABASE.driver=com.mysql.jdbc.Driver  </li>
<li>/#log4j.appender.DATABASE.user=root  </li>
<li>/#log4j.appender.DATABASE.password=123  </li>
<li>/#log4j.appender.CONSOLE.Threshold=WARN  </li>
<li>/#log4j.appender.DATABASE.sql=INSERT INTO LOG4J(stamp,thread, infolevel,class,messages) VALUES (&#39;%d{yyyy-MM-dd HH:mm:ss}&#39;, &#39;%t&#39;, &#39;%p&#39;, &#39;%l&#39;, &#39;%m&#39;)  </li>
<li>/# INSERT INTO LOG4J (Message) VALUES (&#39;[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n&#39;)  </li>
<li>/# 写入数据库中的表LOG4J的Message字段中，内容％d（日期）%c: 日志信息所在地（类名）%p: 日志信息级别%m: 产生的日志具体信息 %n: 输出日志信息换行  </li>
<li>/#log4j.appender.DATABASE.layout=org.apache.log4j.PatternLayout  </li>
<li>/#log4j.appender.DATABASE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n  </li>
<li></li>
<li>/# 每天新建日志  </li>
<li>log4j.appender.A1=org.apache.log4j.DailyRollingFileAppender  </li>
<li>log4j.appender.A1.File=C:/log4j/log  </li>
<li>log4j.appender.A1.Encoding=GBK  </li>
<li>log4j.appender.A1.Threshold=DEBUG  </li>
<li>log4j.appender.A1.DatePattern=&#39;.&#39;yyyy-MM-dd  </li>
<li>log4j.appender.A1.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.A1.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L : %m%n  </li>
<li></li>
<li>/#应用于文件  </li>
<li>log4j.appender.FILE=org.apache.log4j.FileAppender  </li>
<li>log4j.appender.FILE.File=C:/log4j/file.log  </li>
<li>log4j.appender.FILE.Append=false  </li>
<li>log4j.appender.FILE.Encoding=GBK  </li>
<li>log4j.appender.FILE.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n  </li>
<li></li>
<li>/# 应用于文件回滚  </li>
<li>log4j.appender.ROLLING_FILE=org.apache.log4j.RollingFileAppender  </li>
<li>log4j.appender.ROLLING_FILE.Threshold=ERROR  </li>
<li>log4j.appender.ROLLING_FILE.File=rolling.log  </li>
<li>log4j.appender.ROLLING_FILE.Append=true  </li>
<li>log4j.appender.CONSOLE_FILE.Encoding=GBK  </li>
<li>log4j.appender.ROLLING_FILE.MaxFileSize=10KB  </li>
<li>log4j.appender.ROLLING_FILE.MaxBackupIndex=1  </li>
<li>log4j.appender.ROLLING_FILE.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.ROLLING_FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n  </li>
<li></li>
<li>/#自定义Appender  </li>
<li>log4j.appender.im = net.cybercorlin.util.logger.appender.IMAppender  </li>
<li>log4j.appender.im.host = mail.cybercorlin.net  </li>
<li>log4j.appender.im.username = username  </li>
<li>log4j.appender.im.password = password  </li>
<li>log4j.appender.im.recipient = corlin@cybercorlin.net  </li>
<li>log4j.appender.im.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.im.layout.ConversionPattern =[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n  </li>
<li></li>
<li>/#应用于socket  </li>
<li>log4j.appender.SOCKET=org.apache.log4j.RollingFileAppender  </li>
<li>log4j.appender.SOCKET.RemoteHost=localhost  </li>
<li>log4j.appender.SOCKET.Port=5001  </li>
<li>log4j.appender.SOCKET.LocationInfo=true  </li>
<li>/# Set up for Log Facter 5  </li>
<li>log4j.appender.SOCKET.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.SOCET.layout.ConversionPattern=[start]%d{DATE}[DATE]%n%p[PRIORITY]%n%x[NDC]%n%t[THREAD]%n%c[CATEGORY]%n%m[MESSAGE]%n%n  </li>
<li>/# Log Factor 5 Appender  </li>
<li>log4j.appender.LF5_APPENDER=org.apache.log4j.lf5.LF5Appender  </li>
<li>log4j.appender.LF5_APPENDER.MaxNumberOfRecords=2000  </li>
<li></li>
<li>/# 发送日志给邮件  </li>
<li>log4j.appender.MAIL=org.apache.log4j.net.SMTPAppender  </li>
<li>log4j.appender.MAIL.Threshold=FATAL  </li>
<li>log4j.appender.MAIL.BufferSize=10  </li>
<li>log4j.appender.MAIL.From=web@www.wuset.com  </li>
<li>log4j.appender.MAIL.SMTPHost=www.wusetu.com  </li>
<li>log4j.appender.MAIL.Subject=Log4J Message  </li>
<li>log4j.appender.MAIL.To=web@www.wusetu.com  </li>
<li>log4j.appender.MAIL.layout=org.apache.log4j.PatternLayout  </li>
<li>log4j.appender.MAIL.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n<br>log4j.rootLogger=DEBUG,CONSOLE,DATABASE,FILE log4j.addivity.org.apache=true /# 应用于控制台 log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender log4j.appender.CONSOLE.Threshold=INFO log4j.appender.CONSOLE.Target=System.out log4j.appender.CONSOLE.Encoding=GBK log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout log4j.appender.CONSOLE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n /# 用于数据库 /#log4j.appender.DATABASE=org.apache.log4j.jdbc.JDBCAppender /#log4j.appender.DATABASE.URL=jdbc:mysql://localhost:3306/ww /#log4j.appender.DATABASE.driver=com.mysql.jdbc.Driver /#log4j.appender.DATABASE.user=root /#log4j.appender.DATABASE.password=123 /#log4j.appender.CONSOLE.Threshold=WARN /#log4j.appender.DATABASE.sql=INSERT INTO LOG4J(stamp,thread, infolevel,class,messages) VALUES (&#39;%d{yyyy-MM-dd HH:mm:ss}&#39;, &#39;%t&#39;, &#39;%p&#39;, &#39;%l&#39;, &#39;%m&#39;) /# INSERT INTO LOG4J (Message) VALUES (&#39;[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n&#39;) /# 写入数据库中的表LOG4J的Message字段中，内容％d（日期）%c: 日志信息所在地（类名）%p: 日志信息级别%m: 产生的日志具体信息 %n: 输出日志信息换行 /#log4j.appender.DATABASE.layout=org.apache.log4j.PatternLayout /#log4j.appender.DATABASE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n /# 每天新建日志 log4j.appender.A1=org.apache.log4j.DailyRollingFileAppender log4j.appender.A1.File=C:/log4j/log log4j.appender.A1.Encoding=GBK log4j.appender.A1.Threshold=DEBUG log4j.appender.A1.DatePattern=&#39;.&#39;yyyy-MM-dd log4j.appender.A1.layout=org.apache.log4j.PatternLayout log4j.appender.A1.layout.ConversionPattern=%d{ABSOLUTE} %5p %c{1}:%L : %m%n /#应用于文件 log4j.appender.FILE=org.apache.log4j.FileAppender log4j.appender.FILE.File=C:/log4j/file.log log4j.appender.FILE.Append=false log4j.appender.FILE.Encoding=GBK log4j.appender.FILE.layout=org.apache.log4j.PatternLayout log4j.appender.FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n /# 应用于文件回滚 log4j.appender.ROLLING_FILE=org.apache.log4j.RollingFileAppender log4j.appender.ROLLING_FILE.Threshold=ERROR log4j.appender.ROLLING_FILE.File=rolling.log log4j.appender.ROLLING_FILE.Append=true log4j.appender.CONSOLE_FILE.Encoding=GBK log4j.appender.ROLLING_FILE.MaxFileSize=10KB log4j.appender.ROLLING_FILE.MaxBackupIndex=1 log4j.appender.ROLLING_FILE.layout=org.apache.log4j.PatternLayout log4j.appender.ROLLING_FILE.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n /#自定义Appender log4j.appender.im = net.cybercorlin.util.logger.appender.IMAppender log4j.appender.im.host = mail.cybercorlin.net log4j.appender.im.username = username log4j.appender.im.password = password log4j.appender.im.recipient = corlin@cybercorlin.net log4j.appender.im.layout=org.apache.log4j.PatternLayout log4j.appender.im.layout.ConversionPattern =[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n /#应用于socket log4j.appender.SOCKET=org.apache.log4j.RollingFileAppender log4j.appender.SOCKET.RemoteHost=localhost log4j.appender.SOCKET.Port=5001 log4j.appender.SOCKET.LocationInfo=true /# Set up for Log Facter 5 log4j.appender.SOCKET.layout=org.apache.log4j.PatternLayout log4j.appender.SOCET.layout.ConversionPattern=[start]%d{DATE}[DATE]%n%p[PRIORITY]%n%x[NDC]%n%t[THREAD]%n%c[CATEGORY]%n%m[MESSAGE]%n%n /# Log Factor 5 Appender log4j.appender.LF5_APPENDER=org.apache.log4j.lf5.LF5Appender log4j.appender.LF5_APPENDER.MaxNumberOfRecords=2000 /# 发送日志给邮件 log4j.appender.MAIL=org.apache.log4j.net.SMTPAppender log4j.appender.MAIL.Threshold=FATAL log4j.appender.MAIL.BufferSize=10 log4j.appender.MAIL.From=web@www.wuset.com log4j.appender.MAIL.SMTPHost=www.wusetu.com log4j.appender.MAIL.Subject=Log4J Message log4j.appender.MAIL.To=web@www.wusetu.com log4j.appender.MAIL.layout=org.apache.log4j.PatternLayout log4j.appender.MAIL.layout.ConversionPattern=[framework] %d - %c -%-4r [%t] %-5p %c %x - %m%n</li>
</ol>
<p><a href="http://ff861.iteye.com/blog/505750" title="java中判断字符串是否为数字的方法 " target="_blank">java中判断字符串是否为数字的方法</a> | <a href="http://ff861.iteye.com/blog/447203" title="根据wsdl地址或文件生成webservice客户端" target="_blank">根据wsdl地址或文件生成webservice客户端</a></p>
<ul>
<li>13:41</li>
<li>浏览 (202)</li>
<li><a href="http://ff861.iteye.com/blog/459983#comments" target="_blank">评论</a> (0)</li>
<li>分类: <a href="http://ff861.iteye.com/category/69932" target="_blank">application</a></li>
<li><a href="http://www.iteye.com/wiki/topic/459983" target="_blank">相关推荐</a></li>
</ul>
<h3 id="-">评论</h3>
<p><a href=""></a></p>
<h3 id="-">发表评论</h3>
<h3 id="-">表情图标</h3>
<p><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""><img src="" alt=""></p>
<p>字体颜色: 标准深红红色橙色棕色黄色绿色橄榄青色蓝色深蓝靛蓝紫色灰色白色黑色 字体大小: 标准1 (xx-small)2 (x-small)3 (small)4 (medium)5 (large)6 (x-large)7 (xx-large) 对齐: 标准居左居中居右</p>
<p>提示：选择您需要装饰的文字, 按上列按钮即可添加上相应的标签</p>
<p>您还没有登录，请<a href="http://ff861.iteye.com/login" target="_blank">登录</a>后发表评论(快捷键 Alt+S / Ctrl+Enter)</p>
<p><a href="http://ff861.iteye.com/" target="_blank"><img src="&quot;ff861的博客: 蓝色贝壳&quot;" alt="ff861的博客"></a></p>
<p>ff861</p>
<ul>
<li>浏览: 7862 次</li>
<li>性别: <img src="&quot;女&quot;" alt="Icon_minigender_2"></li>
<li>来自: 上海</li>
<li><img src="" alt=""></li>
<li><a href="http://ff861.iteye.com/blog/profile" target="_blank">详细资料</a> <a href="http://ff861.iteye.com/blog/guest_book" target="_blank">留言簿</a></li>
</ul>
<h3 id="-">搜索本博客</h3>
<h3 id="-http-ff861-iteye-com-blog-user_visits-">最近访客 <a href="http://ff861.iteye.com/blog/user_visits" target="_blank">&gt;&gt;更多访客</a></h3>
<p><a href="http://yahon.iteye.com/" target="_blank"><img src="&quot;yahon的博客: yahon&quot;" alt="yahon的博客"></a></p>
<p><a href="http://yahon.iteye.com/" target="_blank">yahon</a></p>
<p><a href="http://spike2012.iteye.com/" target="_blank"><img src="&quot;spike2012的博客: &quot;" alt="spike2012的博客"></a></p>
<p><a href="http://spike2012.iteye.com/" target="_blank">spike2012</a>
<a href="http://kirasun.iteye.com/" target="_blank"><img src="&quot;kirasun的博客: &quot;" alt="kirasun的博客"></a></p>
<p><a href="http://kirasun.iteye.com/" target="_blank">kirasun</a></p>
<p><a href="http://q-wong.iteye.com/" target="_blank"><img src="&quot;q_wong的博客: 小Q的代码仓库&quot;" alt="q_wong的博客"></a></p>
<p><a href="http://q-wong.iteye.com/" target="_blank">q_wong</a></p>
<h3 id="-">博客分类</h3>
<ul>
<li><a href="http://ff861.iteye.com/" target="_blank">全部博客 (19)</a></li>
<li><a href="http://ff861.iteye.com/category/66188" target="_blank">jdbc (0)</a></li>
<li><a href="http://ff861.iteye.com/category/66189" target="_blank">database (3)</a></li>
<li><a href="http://ff861.iteye.com/category/66191" target="_blank">eclipse (1)</a></li>
<li><a href="http://ff861.iteye.com/category/69582" target="_blank">page (3)</a></li>
<li><a href="http://ff861.iteye.com/category/69932" target="_blank">application (8)</a></li>
<li><p><a href="http://ff861.iteye.com/category/72334" target="_blank">Anomalies encountered in the study (2)</a></p>
<h3 id="-http-ff861-iteye-com-blog-guest_book-">我的留言簿 <a href="http://ff861.iteye.com/blog/guest_book" target="_blank">&gt;&gt;更多留言</a></h3>
</li>
<li><p>漂过
-- by <a href="http://ff861.iteye.com/blog/guest_book#25885" target="_blank">lxit_yangzhuan</a></p>
</li>
<li>你很好看！ 好厉害
-- by <a href="http://ff861.iteye.com/blog/guest_book#15356" target="_blank">wangjungongyan</a></li>
<li>hello
-- by <a href="http://ff861.iteye.com/blog/guest_book#12625" target="_blank">zenqqi1314</a></li>
</ul>
<h3 id="-">其他分类</h3>
<ul>
<li><a href="http://ff861.iteye.com/blog/favorite" target="_blank">我的收藏</a> (2)</li>
<li><a href="http://ff861.iteye.com/blog/code_favorite" target="_blank">我的代码</a> (0)</li>
<li><a href="http://ff861.iteye.com/blog/topic" target="_blank">我的论坛主题帖</a> (0)</li>
<li><a href="http://ff861.iteye.com/blog/post" target="_blank">我的所有论坛帖</a> (0)</li>
<li><a href="http://ff861.iteye.com/blog/article" target="_blank">我的精华良好帖</a> (0)<h3 id="-">最近加入群组</h3>
</li>
</ul>
<h3 id="-">存档</h3>
<ul>
<li><a href="http://ff861.iteye.com/blog/monthblog/2010-05" target="_blank">2010-05</a> (1)</li>
<li><a href="http://ff861.iteye.com/blog/monthblog/2010-04" target="_blank">2010-04</a> (5)</li>
<li><a href="http://ff861.iteye.com/blog/monthblog/2010-02" target="_blank">2010-02</a> (1)</li>
<li><p><a href="http://ff861.iteye.com/blog/monthblog_more" target="_blank">更多存档...</a></p>
<h3 id="-">评论排行榜</h3>
</li>
<li><p><a href="http://ff861.iteye.com/rss" target="_blank"><img src="" alt="Rss"></a></p>
</li>
<li><a href="http://fusion.google.com/add?feedurl=http://ff861.iteye.com/rss" target="_blank"><img src="" alt="Rss_google"></a>
声明：ITeye文章版权属于作者，受法律保护。没有作者书面许可不得转载。若作者同意转载，必须以超链接形式标明文章原始出处和作者。
© 2003-2011 ITeye.com. All rights reserved. [ 京ICP证110151号 ]
<img src="" alt=""></li>
</ul>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/log4j/">log4j</a></li></span></span> | <span class="tags">Tagged <a href="/tags/log4j/" class="label label-primary">log4j</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:37"datetime="2014-03-07 09:54:37"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-log4j--log4jproperties参数-蓝色贝壳-ITeye技术网站/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-log4j--log4jproperties参数-蓝色贝壳-ITeye技术网站" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-Httpclient--注意设置httpclient连接数/">注意设置httpclient连接数</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:37.000Z"> <a href="/2014/02/02/2014-02-02-Httpclient--注意设置httpclient连接数/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-httpclient-">注意设置httpclient连接数</h1>
<h3 id="-http-blog-csdn-net-lovingprince-"><a href="http://blog.csdn.net/lovingprince" target="_blank">黄刚</a></h3>
<p>在使用Httpclient的过程中，线上的酒店出现过一个问题，就是当访问量增大的时候，会发现本地的连接等待时间急剧增加，例如从400ms增加到 78000ms，之前一直以为是航信系统问题，后面经过检查才发现，原来是本地httpclient设置时，最大连接数采用了默认设置的原因，而默认的最大连接数只有2个，所以当有大量连接需要建立时，大多数连接只有等待。后面将连接数设置修改成32个之后，这个响应时间就基本上很少出现很大的时候。</p>
<pre><code>  HttpConnectionManager httpConnectionManager = new MultiThreadedHttpConnectionManager();
    HttpConnectionManagerParams params = httpConnectionManager.getParams();
    params.setConnectionTimeout(5000);
    params.setSoTimeout(20000);
    params.setDefaultMaxConnectionsPerHost(32);//very important!!
    params.setMaxTotalConnections(256);//very important!!
    this.client = new HttpClient(httpConnectionManager);
    // 设置编码
    this.client.getParams().setContentCharset(CharsetHelper.GBK);
    this.client.getParams().setHttpElementCharset(CharsetHelper.GBK);
</code></pre><p>我们一般很容易注意到设置超时时间，例如这里的红色部分，但是极有可能忘记设置每个主机的最大连接数(绿色)，因此大家注意一下，本来是最简单的，但也最容易被忽略。</p>
<p>发表于 @ 2009年09月03日　18:39:00 </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Httpclient/">Httpclient</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Httpclient/" class="label label-primary">Httpclient</a></span> | <span class="time">recent updated:<time title="2014-04-07 17:02:54"datetime="2014-04-07 17:02:54"> abr. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-Httpclient--注意设置httpclient连接数/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-Httpclient--注意设置httpclient连接数" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-linux--linux命令字符集/">linux 命令 字符集</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-linux--linux命令字符集/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="linux-">linux 命令 字符集</h1>
<p> locale -a 查看本地字符集
 locale -m 查看所有支持的字符集
  echo $LANG</p>
<p>用export LANG=zh_CN.UTF-8这样只下次重起又要重设置</p>
<p>修改 /etc/sysconfig/i18n 文件，如 
LANG=&quot;en_US&quot;，xwindow会显示英文界面， 
LANG=&quot;zh_CN.GB18030&quot;，xwindow会显示中文界面。</p>
<p>编辑/etc/sysconfig/i18n这个文件，
LANG=&quot;zh_CN.GB18030&quot;
SUPPORTED=&quot;zh_CN.GB18030:zh_CN:zh:en_US.UTF-8:en_US:en&quot;
SYSFONT=&quot;latarcyrheb-sun16&quot;
保存,重起.OK了
注:
I18N 是 internationalization 的缩写形式，意即在 i 和 n 之间有 18 个字母，本意是指软件的“国际化”.
I18N支持多种语言，但是同一时间只能是英文和一种选定的语言，例如英文+中文、英文+德文、英文+韩文等等；
原来的:
LANG=&quot;zh_CN.UTF-8&quot;
SUPPORTED=&quot;zh_CN.UTF-8:zh_CN:zh&quot;
SYSFONT=&quot;latarcyrheb-sun16&quot;
来源： <a href="[http://www.cnitblog.com/windone0109/archive/2008/04/28/42901.html](http://www.cnitblog.com/windone0109/archive/2008/04/28/42901.html)">[http://www.cnitblog.com/windone0109/archive/2008/04/28/42901.html](http://www.cnitblog.com/windone0109/archive/2008/04/28/42901.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/linux/">linux</a></li></span></span> | <span class="tags">Tagged <a href="/tags/linux/" class="label label-primary">linux</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-linux--linux命令字符集/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-linux--linux命令字符集" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--NotesforHadoopthedefinitiveguide/">Notes for Hadoop the definitive guide</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--NotesforHadoopthedefinitiveguide/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="notes-for-hadoop-the-definitive-guide">Notes for Hadoop the definitive guide</h1>
<h1 id="1-introduction-to-hdfs">1. Introduction to HDFS</h1>
<h2 id="1-1-hdfs-concepts">1.1. HDFS Concepts</h2>
<h3 id="1-1-1-blocks">1.1.1. Blocks</h3>
<p>l HDFS too has the concept of a block, but it is a much larger unit 64 MB by default.</p>
<p>l Like in a filesystem for a single disk, files in HDFS are broken into block-sized chunks, which are stored as independent units.</p>
<p>l Unlike a filesystem for a single disk, a file in HDFS that is smaller than a single block does not occupy a full block’s worth of underlying storage.</p>
<h3 id="1-1-2-namenodes-and-datanodes">1.1.2. Namenodes and Datanodes</h3>
<p>l The namenode manages the filesystem namespace.</p>
<p>n It maintains the filesystem tree and the metadata for all the files and directories in the tree.</p>
<p>n This information is stored persistently on the local disk in the form of two files: the namespace image and the edit log.</p>
<p>n The namenode also knows the datanodes on which all the blocks for a given file are located, however, it does not store block locations persistently, since this information is reconstructed from datanodes when the system starts.</p>
<p>l Datanodes are the work horses of the filesystem.</p>
<p>n They store and retrieve blocks when they are told to (by clients or the namenode)</p>
<p>n They report back to the namenode periodically with lists of blocks that they are storing.</p>
<p>l secondary namenode</p>
<p>n It does not act as a namenode.</p>
<p>n Its main role is to periodically merge the namespace image with the edit log to prevent the edit log from becoming too large.</p>
<p>n It keeps a copy of the merged name space image, which can be used in the event of the namenode failing.</p>
<h3 id="namenode-directory-structure">Namenode directory structure</h3>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image002_2.jpg" target="_blank"><img src="&quot;clip_image002&quot;" alt="clip_image002"></a></p>
<p>l The VERSION file is a Java properties file that contains information about the version of HDFS that is running</p>
<p>n The layoutVersion is a negative integer that defines the version of HDFS’s persistent data structures.</p>
<p>n The namespaceID is a unique identifier for the filesystem, which is created when the filesystem is first formatted.</p>
<p>n The cTime property marks the creation time of the namenode’s storage.</p>
<p>n The storageType indicates that this storage directory contains data structures for a namenode.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image004_2.jpg" target="_blank"><img src="&quot;clip_image004&quot;" alt="clip_image004"></a></p>
<h3 id="the-filesystem-image-and-edit-log">The filesystem image and edit log</h3>
<p>l When a filesystem client performs a write operation, it is first recorded in the edit log.</p>
<p>l The namenode also has an in-memory representation of the filesystem metadata, which it updates after the edit log has been modified.</p>
<p>l The edit log is flushed and synced after every write before a success code is returned to the client.</p>
<p>l The fsimage file is a persistent checkpoint of the filesystem metadata. it is not updated for every filesystem write operation.</p>
<p>l If the namenode fails, then the latest state of its metadata can be reconstructed by loading the fsimage from disk into memory, then applying each of the operations in the edit log.</p>
<p>l This is precisely what the namenode does when it starts up.</p>
<p>l The fsimage file contains a serialized form of all the directory and file inodes in the filesystem.</p>
<p>l The secondary namenode is to produce checkpoints of the primary’s in-memory filesystem metadata.</p>
<p>l The checkpointing process proceeds as follows :</p>
<p>n The secondary asks the primary to roll its edits file, so new edits go to a new file.</p>
<p>n The secondary retrieves fsimage and edits from the primary (using HTTP GET).</p>
<p>n The secondary loads fsimage into memory, applies each operation from edits, then creates a new consolidated fsimage file.</p>
<p>n The secondary sends the new fsimage back to the primary (using HTTP POST).</p>
<p>n The primary replaces the old fsimage with the new one from the secondary, and the old edits file with the new one it started in step 1. It also updates the fstime file to record the time that the checkpoint was taken.</p>
<p>n At the end of the process, the primary has an up-to-date fsimage file, and a shorter edits file.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image006_2.jpg" target="_blank"><img src="&quot;clip_image006&quot;" alt="clip_image006"></a></p>
<h3 id="secondary-namenode-directory-structure">Secondary namenode directory structure</h3>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image008_2.jpg" target="_blank"><img src="&quot;clip_image008&quot;" alt="clip_image008"></a></p>
<h3 id="datanode-directory-structure">Datanode directory structure</h3>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image010_2.jpg" target="_blank"><img src="&quot;clip_image010&quot;" alt="clip_image010"></a></p>
<p>l A datanode’s VERSION file</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image012_2.jpg" target="_blank"><img src="&quot;clip_image012&quot;" alt="clip_image012"></a></p>
<p>l The other files in the datanode’s current storage directory are the files with the blk_ prefix.</p>
<p>n There are two types: the HDFS blocks themselves (which just consist of the file’s raw bytes) and the metadata for a block (with a .meta suffix).</p>
<p>n A block file just consists of the raw bytes of a portion of the file being stored;</p>
<p>n the metadata file is made up of a header with version and type information, followed by a series of checksums for sections of the block.</p>
<p>l When the number of blocks in a directory grows to a certain size, the datanode creates a new subdirectory in which to place new blocks and their accompanying metadata.</p>
<h2 id="1-2-data-flow">1.2. Data Flow</h2>
<h3 id="1-2-1-anatomy-of-a-file-read">1.2.1. Anatomy of a File Read</h3>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image014_2.jpg" target="_blank"><img src="&quot;clip_image014&quot;" alt="clip_image014"></a></p>
<p>l The client opens the file it wishes to read by calling open() on the FileSystem object (step 1).</p>
<p>l DistributedFileSystem calls the namenode, using RPC, to determine the locations of the blocks for the first few blocks in the file (step 2).</p>
<p>l For each block, the namenode returns the addresses of the datanodes that have a copy of that block.</p>
<p>l The datanodes are sorted according to their proximity to the client.</p>
<p>l The DistributedFileSystem returns a FSDataInputStream to the client for it to read data from.</p>
<p>l The client then calls read() on the stream (step 3).</p>
<p>l DFSInputStream connects to the first (closest) datanode for the first block in the file.</p>
<p>l Data is streamed from the datanode back to the client (step 4).</p>
<p>l When the end of the block is reached, DFSInputStream will close the connection to the datanode, then find the best datanode for the next block (step 5).</p>
<p>l When the client has finished reading, it calls close() on the FSDataInputStream (step 6).</p>
<p>l During reading, if the client encounters an error while communicating with a datanode, then it will try the next closest one for that block.</p>
<p>l It will also remember datanodes that have failed so that it doesn’t needlessly retry them for later blocks.</p>
<p>l The client also verifies checksums for the data transferred to it from the datanode. If a corrupted block is found, it is reported to the namenode.</p>
<h3 id="1-2-2-anatomy-of-a-file-write">1.2.2. Anatomy of a File Write</h3>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image016_2.jpg" target="_blank"><img src="&quot;clip_image016&quot;" alt="clip_image016"></a></p>
<p>l The client creates the file by calling create() (step 1).</p>
<p>l DistributedFileSystem makes an RPC call to the namenode to create a new file in the filesystem’s namespace, with no blocks associated with it (step 2).</p>
<p>l The namenode performs various checks to make sure the file doesn’t already exist, and that the client has the right permissions to create the file. If these checks pass, the namenode makes a record of the new file; otherwise, file creation fails and the client is thrown an IOException.</p>
<p>l The DistributedFileSystem returns a FSDataOutputStream for the client to start writing data to.</p>
<p>l As the client writes data (step 3), DFSOutputStream splits it into packets, which it writes to an internal queue, called the data queue.</p>
<p>l The data queue is consumed by the Data Streamer, whose responsibility it is to ask the namenode to allocate new blocks by picking a list of suitable datanodes to store the replicas. The list of datanodes forms apipeline.</p>
<p>l The DataStreamer streams the packets to the first datanode in the pipeline, which stores the packet and forwards it to the second datanode in the pipeline. Similarly, the second datanode stores the packet and forwards it to the third (and last) datanode in the pipe line (step 4).</p>
<p>l DFSOutputStream also maintains an internal queue of packets that are waiting to be acknowledged by datanodes, called the ack queue. A packet is removed from the ack queue only when it has been acknowledged by all the datanodes in the pipeline (step 5).</p>
<p>l If a datanode fails while data is being written to it,</p>
<p>n First the pipeline is closed, and any packets in the ack queue are added to the front of the data queue.</p>
<p>n The current block on the good datanodes is given a new identity by the namenode, so that the partial block on the failed datanode will be deleted if the failed data node recovers later on.</p>
<p>n The failed datanode is removed from the pipeline and the remainder of the block’s data is written to the two good datanodes in the pipeline.</p>
<p>n The namenode notices that the block is under-replicated, and it arranges for a further replica to be created on another node.</p>
<p>l When the client has finished writing data it calls close() on the stream (step 6). This action flushes all the remaining packets to the datanode pipeline and waits for acknowledgments before contacting the namenode to signal that the file is complete (step7).</p>
<h1 id="2-meet-map-reduce">2. Meet Map/Reduce</h1>
<p>l MapReduce has two phases: the map phase and the reduce phase.</p>
<p>l Each phase has key-value pairs as input and output (the types can be specified).</p>
<p>n The input key-value types of the map phase is determined by the input format</p>
<p>n The output key-value types of the map phase should match the input key value types of the reduce phase</p>
<p>n The output key-value types of the reduce phase can be set in the JobConf interface.</p>
<p>l The programmer specifies two functions: the map function and the reduce function.</p>
<h2 id="2-1-mapreduce-logical-data-flow">2.1. MapReduce logical data flow</h2>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image018_2.jpg" target="_blank"><img src="&quot;clip_image018&quot;" alt="clip_image018"></a></p>
<h2 id="2-2-mapreduce-code">2.2. MapReduce Code</h2>
<h3 id="2-2-1-the-map-function-is-represented-by-an-implementation-of-the-mapper-interface-which-declares-a-map-method-">2.2.1. The map function is represented by an implementation of the Mapper interface, which declares a map() method.</h3>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image020_2.jpg" target="_blank"><img src="&quot;clip_image020&quot;" alt="clip_image020"></a></p>
<h3 id="2-2-2-the-reduce-function-is-defined-using-a-reducer">2.2.2. The reduce function is defined using a Reducer</h3>
<p>l The input types of the reduce function must match the output type of the map function.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image022_2.jpg" target="_blank"><img src="&quot;clip_image022&quot;" alt="clip_image022"></a></p>
<h3 id="2-2-3-the-code-runs-the-mapreduce-job">2.2.3. The code runs the MapReduce job</h3>
<p>l An input path is specified by calling the static addInputPath() method on FileInputFormat</p>
<p>n It can be a single file, a directory, or a file pattern.</p>
<p>n addInputPath() can be called more than once to use input from multiple paths.</p>
<p>l The output path is specified by the static setOutputPath() method on FileOutputFormat.</p>
<p>n It specifies a directory where the output files from the reducer functions are written.</p>
<p>n The directory shouldn’t exist before running the job</p>
<p>l The map and reduce types can be specified via the setMapperClass() and setReducerClass() methods.</p>
<p>l The setOutputKeyClass() and setOutputValueClass() methods control the output types for the map and the reduce functions, which are often the same.</p>
<p>n If they are different, then the map output types can be set using the methods setMapOutputKeyClass() and setMapOutputValueClass().</p>
<p>l The input types are controlled via the input format, which we have not explicitly set since we are using the default TextInputFormat.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image024_2.jpg" target="_blank"><img src="&quot;clip_image024&quot;" alt="clip_image024"></a></p>
<h2 id="2-3-scaling-out">2.3. Scaling Out</h2>
<h3 id="2-3-1-mapreduce-data-flow-with-a-single-reduce-task">2.3.1. MapReduce data flow with a single reduce task</h3>
<p>l A MapReduce job is a unit of work that the client wants to be performed: it consists of the input data, the MapReduce program, and configuration information.</p>
<p>l Hadoop runs the job by dividing it into tasks, of which there are two types: map tasks and reduce tasks.</p>
<p>l There are two types of nodes that control the job execution process: a jobtracker and a number of tasktrackers.</p>
<p>n The jobtracker coordinates all the jobs run on the system by scheduling tasks to run on tasktrackers.</p>
<p>n Tasktrackers run tasks and send progress reports to the jobtracker, which keeps a record of the overall progress of each job.</p>
<p>n If a tasks fails, the jobtracker can reschedule it on a different tasktracker.</p>
<p>l Hadoop divides the input to a MapReduce job into fixed-size input splits.</p>
<p>l Hadoop creates one map task for each split, which runs the user defined map function for each record in the split.</p>
<p>l Hadoop does its best to run the map task on a node where the input data resides in HDFS.</p>
<p>n This is called the data locality optimization.</p>
<p>n This is why the optimal split size is the same as the block size: it is the largest size of input that can be guaranteed to be stored on a single node.</p>
<p>l Reduce tasks don’t have the advantage of data locality</p>
<p>n The input to a single reduce task is normally the output from all mappers.</p>
<p>n The output of the reduce is normally stored in HDFS for reliability.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image026_2.jpg" target="_blank"><img src="&quot;clip_image026&quot;" alt="clip_image026"></a></p>
<h3 id="2-3-2-mapreduce-data-flow-with-multiple-reduce-tasks">2.3.2. MapReduce data flow with multiple reduce tasks</h3>
<p>The number of reduce tasks is not governed by the size of the input, but is specified independently.</p>
<p>l When there are multiple reducers, the map tasks partition their output, each creating one partition for each reduce task.</p>
<p>l There can be many keys (and their associated values) in each partition, but the records for every key are all in a single partition.</p>
<p>l The partitioning can be controlled by a user-defined partitioning function</p>
<p>n Normally the default partitioner which buckets keys using a hash function.</p>
<p>n conf.setPartitionerClass(HashPartitioner.class);</p>
<p>n conf.setNumReduceTasks(1);</p>
<p>l The data flow between map and reduce tasks is “the shuffle,” as each reduce task is fed by many map tasks.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image028_2.jpg" target="_blank"><img src="&quot;clip_image028&quot;" alt="clip_image028"></a></p>
<p>l It’s also possible to have zero reduce tasks. This can be appropriate when you don’t need the shuffle since the processing can be carried out entirely in parallel</p>
<h1 id="3-mapreduce-types-and-formats">3. MapReduce Types and Formats</h1>
<h2 id="3-1-mapreduce-types">3.1. MapReduce Types</h2>
<p>l The map and reduce functions in Hadoop MapReduce have the following general form:</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image030_2.jpg" target="_blank"><img src="&quot;clip_image030&quot;" alt="clip_image030"></a></p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image032_2.jpg" target="_blank"><img src="&quot;clip_image032&quot;" alt="clip_image032"></a></p>
<p>l The partition function operates on the intermediate key and value types (K2 and V2), and returns the partition index.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image034_2.jpg" target="_blank"><img src="&quot;clip_image034&quot;" alt="clip_image034"></a></p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image036_2.jpg" target="_blank"><img src="&quot;clip_image036&quot;" alt="clip_image036"></a></p>
<h3 id="3-1-1-configuration-of-mapreduce-types">3.1.1. Configuration of MapReduce types</h3>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image038_2.jpg" target="_blank"><img src="&quot;clip_image038&quot;" alt="clip_image038"></a></p>
<p>l Input types are set by the input format.</p>
<p>n For instance, a TextInputFormat generates keys of type LongWritable and values of type Text.</p>
<p>l A minimal MapReduce driver, with the defaults explicitly set</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image040_2.jpg" target="_blank"><img src="&quot;clip_image040&quot;" alt="clip_image040"></a></p>
<p>l The default input format is TextInputFormat, which produces keys of type LongWritable (the offset of the beginning of the line in the file) and values of type Text (the line of text).</p>
<p>l The setNumMapTasks() call does not necessarily set the number of map tasks to one</p>
<p>n The actual number of map tasks depends on the size of the input</p>
<p>l The default mapper is IdentityMapper</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image042_2.jpg" target="_blank"><img src="&quot;clip_image042&quot;" alt="clip_image042"></a></p>
<p>l Map tasks are run by MapRunner, the default implementation of MapRunnable that calls the Mapper’s map() method sequentially with each record.</p>
<p>l The default partitioner is HashPartitioner, which hashes a record’s key to determine which partition the record belongs in.</p>
<p>n Each partition is processed by a reduce task, so the number of partitions is equal to the number of reduce tasks for the job</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image044_2.jpg" target="_blank"><img src="&quot;clip_image044&quot;" alt="clip_image044"></a></p>
<p>l The default reducer is IdentityReducer</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image046_2.jpg" target="_blank"><img src="&quot;clip_image046&quot;" alt="clip_image046"></a></p>
<p>l Records are sorted by the MapReduce system before being presented to the reducer.</p>
<p>l The default output format is TextOutputFormat, which writes out records, one per line, by converting keys and values to strings and separating them with a tab character.</p>
<h2 id="3-2-input-formats">3.2. Input Formats</h2>
<h3 id="3-2-1-input-splits-and-records">3.2.1. Input Splits and Records</h3>
<p>l An input split is a chunk of the input that is processed by a single map.</p>
<p>l Each split is divided into records, and the map processes each record—a key-value pair—in turn.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image048_2.jpg" target="_blank"><img src="&quot;clip_image048&quot;" alt="clip_image048"></a></p>
<p>l An InputSplit has a length in bytes, and a set of storage locations, which are just hostname strings.</p>
<p>l A split doesn’t contain the input data; it is just a reference to the data.</p>
<p>l The storage locations are used by the MapReduce system to place map tasks as close to the split’s data as possible</p>
<p>l The size is used to order the splits so that the largest get processed first</p>
<p>l An InputFormat is responsible for creating the input splits, and dividing them into records.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image050_2.jpg" target="_blank"><img src="&quot;clip_image050&quot;" alt="clip_image050"></a></p>
<p>l The JobClient calls the getSplits() method, passing the desired number of map tasks as the numSplits argument.</p>
<p>l Having calculated the splits, the client sends them to the jobtracker, which uses their storage locations to schedule map tasks to process them on the tasktrackers.</p>
<p>l On a tasktracker, the map task passes the split to the getRecordReader() method on InputFormat to obtain a RecordReader for that split.</p>
<p>l A RecordReader is little more than an iterator over records, and the map task uses one to generate record key-value pairs, which it passes to the map function.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image052_2.jpg" target="_blank"><img src="&quot;clip_image052&quot;" alt="clip_image052"></a></p>
<p>l The same key and value objects are used on each invocation of the map() method—only their contents are changed. If you need to change the value out of map, make a copy of the object you want to hold on to.</p>
<h3 id="3-2-2-fileinputformat">3.2.2. FileInputFormat</h3>
<p>l FileInputFormat is the base class for all implementations of InputFormat that use files as their data source.</p>
<p>l It provides two things: a place to define which files are included as the input to a job, and an implementation for generating splits for the input files.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image054_2.jpg" target="_blank"><img src="&quot;clip_image054&quot;" alt="clip_image054"></a></p>
<p>l FileInputFormat input paths may represent a file, a directory, or, by using a glob, a collection of files and directories.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image056_2.jpg" target="_blank"><img src="&quot;clip_image056&quot;" alt="clip_image056"></a></p>
<p>l To exclude certain files from the input, you can set a filter using the setInputPathFilter() method on FileInputFormat</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image058_2.jpg" target="_blank"><img src="&quot;clip_image058&quot;" alt="clip_image058"></a></p>
<p>l FileInputFormat splits only large files. Here “large” means larger than an HDFS block.</p>
<p>l Properties for controlling split size</p>
<p>n The minimum split size is usually 1 byte, by setting this to a value larger than the block size, they can force splits to be larger than a block.</p>
<p>n The maximum split size defaults to the maximum value that can be represented by a Java long type. It has an effect only when it is less than the block size, forcing splits to be smaller than a block.</p>
<h3 id="small-files-and-combinefileinputformat">Small files and CombineFileInputFormat</h3>
<p>l Hadoop works better with a small number of large files than a large number of small files.</p>
<p>l Where FileInputFormat creates a split per file, CombineFileInputFormat packs many files into each split so that each mapper has more to process.</p>
<p>l One technique for avoiding the many small files case is to merge small files into larger files by using a SequenceFile: the keys can act as filenames and the values as file contents.</p>
<h3 id="3-2-3-text-input">3.2.3. Text Input</h3>
<p>l TextInputFormat is the default InputFormat.</p>
<p>n Each record is a line of input.</p>
<p>n The key, a LongWritable, is the byte offset within the file of the beginning of the line.</p>
<p>n The value is the contents of the line, excluding any line terminators, and is packaged as a Text object.</p>
<p>l The logical records that FileInputFormats define do not usually fit neatly into HDFS blocks.</p>
<p>l A single file is broken into lines, and the line boundaries do not correspond with the HDFS block boundaries.</p>
<p>l Splits honor logical record boundaries</p>
<p>n The first split contains line 5, even though it spans the first and second block.</p>
<p>n The second split starts at line 6.</p>
<p>l Data-local maps will perform some remote reads.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image060_2.jpg" target="_blank"><img src="&quot;clip_image060&quot;" alt="clip_image060"></a></p>
<h3 id="keyvaluetextinputformat">KeyValueTextInputFormat</h3>
<p>l It is common for each line in a file to be a key-value pair, separated by a delimiter such as a tab character.</p>
<p>l You can specify the separator via the key.value.separator.in.input.line property.</p>
<h3 id="nlineinputformat">NLineInputFormat</h3>
<p>l If you want your mappers to receive a fixed number of lines of input, then NLineInputFormat is the InputFormat to use.</p>
<p>l Like TextInputFormat, the keys are the byte offsets within the file and the values are the lines themselves.</p>
<p>l N refers to the number of lines of input that each mapper receives.</p>
<h3 id="3-2-4-binary-input">3.2.4. Binary Input</h3>
<h3 id="sequencefileinputformat">SequenceFileInputFormat</h3>
<p>l Hadoop’s sequence file format stores sequences of binary key-value pairs.</p>
<p>l To use data from sequence files as the input to MapReduce, you use SequenceFileInputFormat.</p>
<p>l The keys and values are determined by the sequence file, and you need to make sure that your map input types correspond.</p>
<p>l For example, if your sequence file has IntWritable keys and Text values, then the map signature would be Mapper<IntWritable, Text, K, V>.</p>
<h3 id="sequencefileastextinputformat">SequenceFileAsTextInputFormat</h3>
<p>l SequenceFileAsTextInputFormat is a variant of SequenceFileInputFormat that converts the sequence file’s keys and values to Text objects.</p>
<h3 id="sequencefileasbinaryinputformat">SequenceFileAsBinaryInputFormat</h3>
<p>l SequenceFileAsBinaryInputFormat is a variant of SequenceFileInputFormat that retrieves the sequence file’s keys and values as opaque binary objects.</p>
<p>l They are encapsulated as BytesWritable objects</p>
<h3 id="sequencefile">SequenceFile</h3>
<p>l Writing a SequenceFile</p>
<p>n To create a SequenceFile, use one of its createWriter() static methods, which returns a SequenceFile.Writer instance.</p>
<p>n specify a stream to write to (either a FSDataOutputStream or a FileSystem and Path pairing), a Configuration object, and the key and value types.</p>
<p>n Once you have a SequenceFile.Writer, you then write key-value pairs, using the append() method.</p>
<p>n Then when you’ve finished you call the close() method</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image062_2.jpg" target="_blank"><img src="&quot;clip_image062&quot;" alt="clip_image062"></a></p>
<p>l Reading a SequenceFile</p>
<p>n Reading sequence files from beginning to end is a matter of creating an instance of SequenceFile.Reader, and iterating over records by repeatedly invoking one of the next() methods.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image064_2.jpg" target="_blank"><img src="&quot;clip_image064&quot;" alt="clip_image064"></a></p>
<p>l The SequenceFile Format</p>
<p>n A sequence file consists of a header followed by one or more records.</p>
<p>n The first three bytes of a sequence file are the bytes SEQ, which acts a magic number, followed by a single byte representing the version number.</p>
<p>n The header contains other fields including the names of the key and value classes, compression details, user-defined metadata, and the sync marker.</p>
<p>n The sync marker is used to allow a reader to synchronize to a record boundary from any position in the file.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image066_2.jpg" target="_blank"><img src="&quot;clip_image066&quot;" alt="clip_image066"></a></p>
<h3 id="3-2-5-multiple-inputs">3.2.5. Multiple Inputs</h3>
<p>l The MultipleInputs class allows you to specify the InputFormat and Mapper to use on a per-path basis.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image068_2.jpg" target="_blank"><img src="&quot;clip_image068&quot;" alt="clip_image068"></a></p>
<h2 id="3-3-output-formats">3.3. Output Formats</h2>
<h3 id="3-3-1-text-output">3.3.1. Text Output</h3>
<p>l The default output format, TextOutputFormat, writes records as lines of text.</p>
<p>l Its keys and values may be of any type, since TextOutputFormat turns them to strings by calling toString() on them.</p>
<p>l Each key-value pair is separated by a tab character, although that may be changed using the mapred.textoutputformat.separator property.</p>
<h3 id="3-3-2-binary-output">3.3.2. Binary Output</h3>
<p>l SequenceFileOutputFormat</p>
<p>l SequenceFileAsBinaryOutputFormat</p>
<p>l MapFileOutputFormat</p>
<h3 id="writing-a-mapfile">Writing a MapFile</h3>
<p>l You create an instance of MapFile.Writer, then call the append() method to add entries in order.</p>
<p>l Keys must be instances of WritableComparable, and values must be Writable</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image070_2.jpg" target="_blank"><img src="&quot;clip_image070&quot;" alt="clip_image070"></a></p>
<p>l If we look at the MapFile, we see it’s actually a directory containing two files called data and index:</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image072_2.jpg" target="_blank"><img src="&quot;clip_image072&quot;" alt="clip_image072"></a></p>
<p>l Both files are SequenceFiles. The data file contains all of the entries, in order:</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image074_2.jpg" target="_blank"><img src="&quot;clip_image074&quot;" alt="clip_image074"></a></p>
<p>l The index file contains a fraction of the keys, and contains a mapping from the key to that key’s offset in the data file:</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image076_2.jpg" target="_blank"><img src="&quot;clip_image076&quot;" alt="clip_image076"></a></p>
<h3 id="reading-a-mapfile">Reading a MapFile</h3>
<p>l you create a MapFile.Reader, then call the next() method until it returns false</p>
<h3 id="3-3-3-multiple-outputs">3.3.3. Multiple Outputs</h3>
<h3 id="multipleoutputformat">MultipleOutputFormat</h3>
<p>l MultipleOutputFormat allows you to write data to multiple files whose names are derived from the output keys and values.</p>
<p>n conf.setOutputFormat(StationNameMultipleTextOutputFormat.class);</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image078_2.jpg" target="_blank"><img src="&quot;clip_image078&quot;" alt="clip_image078"></a></p>
<h3 id="multipleoutputs">MultipleOutputs</h3>
<p>l MultipleOutputs can emit different types for each output.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image080_2.jpg" target="_blank"><img src="&quot;clip_image080&quot;" alt="clip_image080"></a></p>
<h1 id="4-developing-a-mapreduce-application">4. Developing a MapReduce Application</h1>
<h2 id="4-1-the-configuration-api">4.1. The Configuration API</h2>
<p>l An instance of the Configuration class (found in the org.apache.hadoop.conf package) represents a collection of configuration properties and their values.</p>
<p>l Configurations read their properties from resources—XML files</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image082_2.jpg" target="_blank"><img src="&quot;clip_image082&quot;" alt="clip_image082"></a></p>
<p>l we can access its properties using a piece of code like this:</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image084_2.jpg" target="_blank"><img src="&quot;clip_image084&quot;" alt="clip_image084"></a></p>
<h2 id="4-2-configuring-the-development-environment">4.2. Configuring the Development Environment</h2>
<h3 id="4-2-1-managing-configuration">4.2.1. Managing Configuration</h3>
<p>l When developing Hadoop applications, it is common to switch between running the application locally and running it on a cluster.</p>
<p>l hadoop-local.xml</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image086_2.jpg" target="_blank"><img src="&quot;clip_image086&quot;" alt="clip_image086"></a></p>
<p>l hadoop-localhost.xml</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image088_2.jpg" target="_blank"><img src="&quot;clip_image088&quot;" alt="clip_image088"></a></p>
<p>l hadoop-cluster.xml</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image090_2.jpg" target="_blank"><img src="&quot;clip_image090&quot;" alt="clip_image090"></a></p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image092_2.jpg" target="_blank"><img src="&quot;clip_image092&quot;" alt="clip_image092"></a></p>
<p>l With this setup, it is easy to use any configuration with the -conf command-line switch.</p>
<p>l For example, the following command shows a directory listing on the HDFS server running in pseudo-distributed mode on localhost:</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image094_2.jpg" target="_blank"><img src="&quot;clip_image094&quot;" alt="clip_image094"></a></p>
<h3 id="4-2-2-genericoptionsparser-tool-and-toolrunner">4.2.2. GenericOptionsParser, Tool, and ToolRunner</h3>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image096_2.jpg" target="_blank"><img src="&quot;clip_image096&quot;" alt="clip_image096"></a></p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image098_2.jpg" target="_blank"><img src="&quot;clip_image098&quot;" alt="clip_image098"></a></p>
<h1 id="5-how-mapreduce-works">5. How MapReduce Works</h1>
<h2 id="5-1-anatomy-of-a-mapreduce-job-run">5.1. Anatomy of a MapReduce Job Run</h2>
<p>l There are four independent entities:</p>
<p>n The client, which submits the MapReduce job.</p>
<p>n The jobtracker, which coordinates the job run. The jobtracker is a Java application whose main class is JobTracker.</p>
<p>n The tasktrackers, which run the tasks that the job has been split into. Tasktrackers are Java applications whose main class is TaskTracker.</p>
<p>n The distributed filesystem, which is used for sharing job files between the other entities.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image100_2.jpg" target="_blank"><img src="&quot;clip_image100&quot;" alt="clip_image100"></a></p>
<h3 id="5-1-1-job-submission">5.1.1. Job Submission</h3>
<p>l The runJob() method on JobClient creates a new JobClient instance and calls submitJob() on it.</p>
<p>l Having submitted the job, runJob() polls the job’s progress once a second, and reports the progress to the console if it has changed since the last report.</p>
<p>l When the job is complete, if it was successful, the job counters are displayed. Otherwise, the error that caused the job to fail is logged to the console.</p>
<h3 id="the-job-submission-process">The job submission process</h3>
<p>l Asks the jobtracker for a new job ID (by calling getNewJobId() on JobTracker)</p>
<p>l Checks the output specification of the job.</p>
<p>l Computes the input splits for the job.</p>
<p>l Copies the resources needed to run the job, including the job JAR file, the configuration file and the computed input splits, to the jobtracker’s filesystem in a directory named after the job ID.</p>
<p>l Tells the jobtracker that the job is ready for execution (by calling submitJob() on JobTracker)</p>
<h3 id="5-1-2-job-initialization">5.1.2. Job Initialization</h3>
<p>l When the JobTracker receives a call to its submitJob() method, it puts it into an internal queue from where the job scheduler will pick it up and initialize it.</p>
<p>l Initialization involves creating an object to represent the job being run, which encapsulates its tasks, and bookkeeping information to keep track of the tasks’ status and progress.</p>
<p>l To create the list of tasks to run, the job scheduler first retrieves the input splits computed by the JobClient from the shared filesystem.</p>
<p>l It then creates one map task for each split.</p>
<p>l Tasks are given IDs at this point.</p>
<h3 id="5-1-3-task-assignment">5.1.3. Task Assignment</h3>
<p>l Tasktrackers run a simple loop that periodically sends heartbeat method calls to the jobtracker.</p>
<p>l As a part of the heartbeat, a tasktracker will indicate whether it is ready to run a new task, and if it is, the jobtracker will allocate it a task, which it communicates to the tasktracker using the heartbeat return value</p>
<p>l Before it can choose a task for the tasktracker, the jobtracker must choose a job to select the task from according to priority.(setJobPriority() and FIFO)</p>
<p>l Tasktrackers have a fixed number of slots for map tasks and for reduce tasks.</p>
<p>l The default scheduler fills empty map task slots before reduce task slots</p>
<p>l To choose a reduce task the jobtracker simply takes the next in its list of yet-to-be-run reduce tasks, since there are no data locality considerations.</p>
<h3 id="5-1-4-task-execution">5.1.4. Task Execution</h3>
<p>l Now the tasktracker has been assigned a task, the next step is for it to run the task.</p>
<p>l First, it localizes the job JAR by copying it from the shared filesystem to the tasktracker’s filesystem.</p>
<p>l It also copies any files needed from the distributed cache by the application to the local disk</p>
<p>l Second, it creates a local working directory for the task, and un-jars the contents of the JAR into this directory.</p>
<p>l Third, it creates an instance of TaskRunner to run the task.</p>
<p>l TaskRunner launches a new Java Virtual Machine to run each task in</p>
<p>l It is however possible to reuse the JVM between tasks;</p>
<p>l The child process communicates with its parent through the umbilical interface.</p>
<h3 id="5-1-5-job-completion">5.1.5. Job Completion</h3>
<p>l When the jobtracker receives a notification that the last task for a job is complete, it changes the status for the job to “successful.” T</p>
<p>l hen, when the JobClient polls for status, it learns that the job has completed successfully, so it prints a message to tell the user, and then returns from the runJob() method.</p>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image102_2.jpg" target="_blank"><img src="&quot;clip_image102&quot;" alt="clip_image102"></a></p>
<h2 id="5-2-failures">5.2. Failures</h2>
<h3 id="5-2-1-task-failure">5.2.1. Task Failure</h3>
<p>l The most common way is when user code in the map or reduce task throws a runtime exception.</p>
<p>n the child JVM reports the error back to its parent tasktracker, before it exits.</p>
<p>n The error ultimately makes it into the user logs.</p>
<p>n The tasktracker marks the task attempt as failed, freeing up a slot to run another task.</p>
<p>l Another failure mode is the sudden exit of the child JVM</p>
<p>n the tasktracker notices that the process has exited, and marks the attempt as failed.</p>
<p>l Hanging tasks are dealt with differently.</p>
<p>n The tasktracker notices that it hasn’t received a progress update for a while, and proceeds to mark the task as failed.</p>
<p>n The child JVM process will be automatically killed after this period</p>
<p>l When the jobtracker is notified of a task attempt that has failed (by the tasktracker’s heartbeat call) it will reschedule execution of the task.</p>
<p>n The jobtracker will try to avoid rescheduling the task on a tasktracker where it has previously failed.</p>
<p>n If a task fails more than four times, it will not be retried further.</p>
<h3 id="5-2-2-tasktracker-failure">5.2.2. Tasktracker Failure</h3>
<p>l If a tasktracker fails by crashing, or running very slowly, it will stop sending heartbeats to the jobtracker (or send them very infrequently).</p>
<p>l The jobtracker will notice a tasktracker that has stopped sending heartbeats and remove it from its pool of tasktrackers to schedule tasks on.</p>
<p>l The jobtracker arranges for map tasks that were run and completed successfully on that tasktracker to be rerun if they belong to incomplete jobs, since their intermediate output residing on the failed tasktracker’s local filesystem may not be accessible to the reduce task. Any tasks in progress are also rescheduled.</p>
<h3 id="5-2-3-jobtracker-failure">5.2.3. Jobtracker Failure</h3>
<h2 id="5-3-shuffle-and-sort">5.3. Shuffle and Sort</h2>
<p><a href="http://images.cnblogs.com/cnblogs_com/forfuture1978/WindowsLiveWriter/NotesforHadoopthedefinitiveguide_14109/clip_image104_2.jpg" target="_blank"><img src="&quot;clip_image104&quot;" alt="clip_image104"></a></p>
<h3 id="5-3-1-the-map-side">5.3.1. The Map Side</h3>
<p>l When the map function starts producing output, it is not simply written to disk.</p>
<p>l Each map task has a circular memory buffer that it writes the output to.</p>
<p>l When the contents of the buffer reach a certain threshold size, a background thread will start to spill the contents to disk.</p>
<p>l Spills are written in round-robin fashion to the directories specified by the mapred.local.dir property</p>
<p>l Before it writes to disk, the thread first divides the data into partitions corresponding to the reducers that they will ultimately be sent to.</p>
<p>l Within each partition, the background thread performs an in-memory sort by key.</p>
<p>l Each time the memory buffer reaches the spill threshold, a new spill file is created, so after the map task has written its last output record there could be several spill files.</p>
<p>l Before the task is finished, the spill files are merged into a single partitioned and sorted output file.</p>
<p>l The output file’s partitions are made available to the reducers over HTTP.</p>
<p>l The number of worker threads used to serve the file partitions is controlled by the task tracker.http.threads property</p>
<h3 id="5-3-2-the-reduce-side">5.3.2. The Reduce Side</h3>
<p>l As map tasks complete successfully, they notify their parent tasktracker of the status update, which in turn notifies the jobtracker.</p>
<p>l for a given job, the jobtracker knows the mapping between map outputs and tasktrackers.</p>
<p>l A thread in the reducer periodically asks the jobtracker for map output locations until it has retrieved them all.</p>
<p>l The reduce task needs the map output for its particular partition from several map tasks across the cluster.</p>
<p>l The map tasks may finish at different times, so the reduce task starts copying their outputs as soon as each completes. This is known as the copy phase of the reduce task.</p>
<p>l The reduce task has a small number of copier threads so that it can fetch map outputs in parallel.</p>
<p>l As the copies accumulate on disk, a background thread merges them into larger, sorted files.</p>
<p>l When all the map outputs have been copied, the reduce task moves into the sort phase (which should properly be called the merge phase, as the sorting was carried out on the map side), which merges the map outputs, maintaining their sort ordering.</p>
<p>l During the reduce phase the reduce function is invoked for each key in the sorted output. The output of this phase is written directly to the output filesystem, typically HDFS.
来源： &lt;<a href="http://www.cnblogs.com/forfuture1978/archive/2010/02/27/1674955.html" target="_blank">Notes for Hadoop the definitive guide - 觉先 - 博客园</a>&gt; </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--NotesforHadoopthedefinitiveguide/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--NotesforHadoopthedefinitiveguide" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/104/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/102/">102</a></li><li><a class="page-number" href="/page/103/">103</a></li><li><a class="page-number" href="/page/104/">104</a></li><li class="active"><li><span class="page-number current">105</span></li><li><a class="page-number" href="/page/106/">106</a></li><li><a class="page-number" href="/page/107/">107</a></li><li><a class="page-number" href="/page/108/">108</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/161/">161</a></li><li><a class="page-number" href="/page/162/">162</a></li><li><a class="extend next" href="/page/106/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Site powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a>  update time: <em>2014-04-07 19:25:39</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
