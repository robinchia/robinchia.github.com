
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 110 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--Hadoop知识分享文稿byquqi99-技术并艺术着/">Hadoop知识分享文稿 ( by quqi99 ) </a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--Hadoop知识分享文稿byquqi99-技术并艺术着/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="hadoop-by-quqi99-">Hadoop知识分享文稿 ( by quqi99 ) - 技术并艺术着</h1>
<p>您还未登录！|<a href="https://passport.csdn.net/account/login" target="_blank">登录</a>|<a href="https://passport.csdn.net/account/register" target="_blank">注册</a>|<a href="https://passport.csdn.net/help/faq" target="_blank">帮助</a></p>
<ul>
<li><a href="http://www.csdn.net/" target="_blank">首页</a></li>
<li><a href="http://news.csdn.net/" target="_blank">业界</a></li>
<li><a href="http://mobile.csdn.net/" target="_blank">移动</a></li>
<li><a href="http://cloud.csdn.net/" target="_blank">云计算</a></li>
<li><a href="http://sd.csdn.net/" target="_blank">研发</a></li>
<li><a href="http://bbs.csdn.net/" target="_blank">论坛</a></li>
<li><a href="http://blog.csdn.net/" target="_blank">博客</a></li>
<li><a href="http://download.csdn.net/" target="_blank">下载</a></li>
<li><h2 id="-"><a href="">更多</a></h2>
</li>
</ul>
<h1 id="-http-blog-csdn-net-quqi99-"><a href="http://blog.csdn.net/quqi99" target="_blank">技术并艺术着</a></h1>
<h2 id="-blog">张华的技术Blog</h2>
<ul>
<li><a href="http://blog.csdn.net/quqi99?viewmode=contents" target="_blank"><img src="" alt="">目录视图</a></li>
<li><a href="http://blog.csdn.net/quqi99?viewmode=list" target="_blank"><img src="" alt="">摘要视图</a></li>
<li><a href="http://blog.csdn.net/quqi99/rss/list" target="_blank"><img src="" alt="">订阅</a>
<a href="https://code.csdn.net/blog/12" target="_blank">公告：博客新增直接引用代码功能</a>        <a href="http://www.csdn.net/article/2013-08-06/2816471" target="_blank">专访李铁军：从医生到金山首席安全专家的转变</a>      <a href="http://blog.csdn.net/csdnproduct/article/details/9495139" target="_blank">CSDN博客频道自定义域名、标签搜索功能上线啦！</a>      <a href="http://blog.csdn.net/adali/article/details/9813651" target="_blank">独一无二的职位：开源社区经理</a></li>
</ul>
<h3 id="-hadoop-by-quqi99-"><a href="">[置顶] Hadoop知识分享文稿 ( by quqi99 )</a></h3>
<p>分类： <a href="http://blog.csdn.net/quqi99/article/category/328029" target="_blank">Seach Engine</a>  2011-03-31 15:19 1977人阅读 <a href="">评论</a>(0) <a href="&quot;收藏&quot;">收藏</a> <a href="&quot;举报&quot;">举报</a>
<a href="http://blog.csdn.net/tag/details.html?tag=hadoop" target="_blank">hadoop</a><a href="http://blog.csdn.net/tag/details.html?tag=%e4%bb%bb%e5%8a%a1" target="_blank">任务</a><a href="http://blog.csdn.net/tag/details.html?tag=mapreduce" target="_blank">mapreduce</a><a href="http://blog.csdn.net/tag/details.html?tag=%e4%bb%bb%e5%8a%a1%e8%b0%83%e5%ba%a6" target="_blank">任务调度</a><a href="http://blog.csdn.net/tag/details.html?tag=%e9%9b%86%e7%be%a4" target="_blank">集群</a><a href="http://blog.csdn.net/tag/details.html?tag=%e4%bd%9c%e4%b8%9a" target="_blank">作业</a></p>
<p>目录<a href="&quot;系统根据文章中H1到H6标签自动生成文章目录&quot;">(?)</a><a href="&quot;展开&quot;">[+]</a></p>
<ol>
<li><a href="">作者张华 写于2010-08-15   发表于2011-03-31 版权声明可以任意转载转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</a></li>
<li><a href="">httpblogcsdnnetquqi99</a></li>
<li><p><a href="">hadoop 理论基础</a></p>
</li>
<li><p><a href="">hadoop 是什么</a></p>
</li>
<li><a href="">hadoop 项目</a></li>
<li><a href="">MapReduce 任务的运行流程</a></li>
<li><p><a href="">MapReduce 任务的数据流图</a></p>
</li>
<li><p><a href="">hadoop 入门实战</a></p>
</li>
<li><p><a href="">测试环境</a></p>
</li>
<li><a href="">测试程序</a></li>
<li><a href="">属性配置</a></li>
<li><a href="">免密码 SSH 设置</a></li>
<li><a href="">配置 hosts</a></li>
<li><a href="">格式化 HDFS 文件系统</a></li>
<li><a href="">启动守护进程</a></li>
<li><p><a href="">运行程序</a></p>
</li>
<li><p><a href="">hadoop 高级进阶</a></p>
</li>
<li><a href="">hadoop 应用案例</a></li>
<li><a href="">参考文献</a><pre><code>                       **Hadoop知识分享文稿 ( by quqi99 )**
</code></pre></li>
</ol>
<h2 id="-2010-08-15-2011-03-31"><a href=""></a>作者：张华 写于：2010-08-15   发表于：2011-03-31</h2>
<p>版权声明：可以任意转载，转载时请务必以超链接形式标明文章原始出处和作者信息及本版权声明</p>
<h2 id="-http-blog-csdn-net-quqi99-"><a href=""></a>( <a href="http://blog.csdn.net/quqi99">http://blog.csdn.net/quqi99</a> )</h2>
<p><strong>内容目录</strong></p>
<p>目 录</p>
<p>1 hadoop 理论基础 3</p>
<p>1.1 hadoop 是什么 3</p>
<p>1.2 hadoop 项目 3</p>
<p>1.3 Map/Reduce 任务的运行流程 4</p>
<p>1.4 Map/Reduce 任务的数据流图 5</p>
<p>2 hadoop 入门实战 7</p>
<p>2.1  测试环境 7</p>
<p>2.2  测试程序 7</p>
<p>2.3  属性配置 9</p>
<p>2.4  免密码SSH 设置 10</p>
<p>2.5  配置hosts 11</p>
<p>2.6  格式化HDFS 文件系统 11</p>
<p>2.7  启动守护进程 11</p>
<p>2.8  运行程序 11</p>
<p>3 hadoop 高级进阶 12</p>
<p>4 hadoop 应用案例 12</p>
<p>5  参考文献 12</p>
<h1 id="-1-hadoop-"><a href=""></a>1 hadoop  理论基础</h1>
<h2 id="-1-1-hadoop-"><a href=""></a>1.1 hadoop  是什么</h2>
<p>Hadoop  是 Doug Cutting  开发的，他是一个相当牛的哥们，他同时是大名鼎鼎的 Lucene  及 Nutch  的作者。</p>
<p>我是这样理解 hadoop  的，它就是用来对海量数据进行存储与分析的一个开源软件。它包括两块：</p>
<p>1  ） HDFS ( Hadoop Distrubuted File System )  ，可以对重要数据进行冗余存储，有点类似于冗余磁盘陈列。</p>
<p>2  ）对 Map/Reduce  编程模型的一个实现。当然，关系型数据库（ RDBMS  ）也能做类似的事情，但为什么不用 RDBMS  呢？我们知道，让计算移动于数据上比让数据移动到计算更有效率。这使得 Map/Reduce  适合数据被一次写入和多次读取的应用，而 RDBMS  更适合持续更新的数据集。</p>
<h2 id="-1-2-hadoop-"><a href=""></a>1.2 hadoop  项目</h2>
<p>如今，广义上的 Hadoop  已经发展成为一个分布式计算基础架构这把“大伞”下相关子项目的集合，其技术栈如下图所示：</p>
<p>图：</p>
<pre><code>                                     ![]()
</code></pre><p><img src="http://blog.csdn.net/root/Library/Caches/TemporaryItems/moz-screenshot-4.png" alt=""></p>
<pre><code>                                                图1 hadoop 的子项目
</code></pre><ul>
<li>Core ： 一系列分布式文件系统和通用I/O 的组件和接口( 序列化、Java RPC 和持久化数据结构) 。</li>
<li>Avro ： 用于数据的序列化，当然，JDK 中也有Seriable 接口，但hadoop 中有它自己的序列化方式，具说更有效率。</li>
<li>MapReduce ： 分布式数据处理模式和执行环境，运行于大型商用机集群。</li>
<li>HDFS ： 分布式文件系统，运行于大型商用机集群。</li>
<li>Pig ： HDFS 上的数据检索语言，类似于RDBMS 中的SQL 语言。</li>
<li>Hbase ： 一个分布式的、列存储数据库。HBase 使用HDFS 作为底层存储，同时支持MapReduce 的批量式计算和点查询( 随机读取) 。</li>
<li>ZooKeeper ： 一个分布式的、高可用性的协调服务。ZooKeeper 提供分布式锁之类的基本服务用于构建分布式应用。</li>
<li>Hive ： 分布式数据仓库。Hive 管理HDFS 中存储的数据，并提供基于SQL 的查询语言( 由运行时引擎翻译成MapReduce 作业) 用以查询数据。</li>
<li>Chukwa ： 分布式数据收集和分析系统。Chukwa 运行HDFS 中存储数据的收集器，它使用MapReduce 来生成报告。</li>
</ul>
<h2 id="-1-3-map-reduce-"><a href=""></a> 1.3 Map/Reduce  任务的运行流程</h2>
<pre><code>                 ![]()
</code></pre><p>JobClient  的  submitJob()  方法的作业提交过程如下：</p>
<p>1  ）向 Jobtraker  请求一个新作业 ID</p>
<p>2  ） 调用 JobTracker  的 getNewJobId()</p>
<p>3  ）  JobClient  进行作业划分，并将划分后的输入及作业的 JAR  文件、配置文件等复制到 HDFS  中去</p>
<p>4  ） 提交作业，会把此调用放入到一个内部的队列中，交由作业调度器进行调度。值得一提的是，针对  Map  任务与 Reduce  任务，任务调度器是优先选择 Map  任务的，另外，任务调度器在选择 Reduce  任务时并没有考虑数据的本地化。然而，针对一个 Map  任务，它考虑的是 Tasktracker  网络位置和选取一个距离其输入划分文件最近的 Tasktracker  ，它可能是数据本地化的，也可能是机架本地化的，还可能得到不同的机架上取数据。</p>
<p>5  ） 初始化包括创建一个代表该正在运行的作业的对象，它封装任务和记录信息，以便跟踪任务的状态和进度。</p>
<p>6  ） JobTracker  任务调度器首先从共享文件系统中获取 JobClient  已计算好的输入划分信息，然后为每个划分创建一个 Map  任务。创建 的 reduce  任务的数量是由 JobConf  的 Mapred.reduce.tasks  属性决定，它是用 setNumReduceTask()  方法来设置的。</p>
<p>7  ） TaskTracker  执行一个简单的循环，定期发送心跳（ Heartbeat  ）方法调用 Jobtracker  告诉是否还活着，同时，心跳还会报告任务运行的是否已经准备运行新的任务。</p>
<p>8  ） TaskTracker  已经被分配了任务，下一步是运行任务。首先它需要将它所需的全部文件从 HDFS  中复制到本地磁盘。</p>
<p>9  ）紧接着，它要启动一个新的 Java  虚拟机来运行每个任务，这使得用户所定义的 Map  和 Reduce  函数的任务缺陷都不会影响 TaskTracker  （比如导致它崩溃或者挂起）</p>
<p>10  ）运行 Map  任务或者 Reduce  任务，值得一提的是，这些任务使用标准输入与输出流，换句话说，你可以用任务语言（如 JAVA  ， C++  ， Shell  等）来实现 Map  和 Reduce  ，只要保证它们也使用标准输入与输出流，就可以将输出的键值对传回给 JAVA  进程了。</p>
<h2 id="-1-4-map-reduce-"><a href=""></a> 1.4 Map/Reduce  任务的数据流图</h2>
<p><img src="" alt=""></p>
<pre><code>    图3  Map/Reduce  中单一 Reduce  任务的数据流图
</code></pre><p><img src="" alt=""></p>
<pre><code>             图4  Map/Reduce  中多个 Reduce  任务的数据流图
</code></pre><p><img src="" alt=""></p>
<pre><code>            图5  MapReduce  中没有 Reduce  任务的数据流图
</code></pre><p><strong>任务粒度</strong>   ： 分片的个数，在将原始大数据切割成小数据集时，通常让小数据集小于或等于 HDFS  中的一个 Block  的大小（缺省是 64M)  ，这样能够保证一个小数据集位于一台计算机上，便于本地计算。 有 M   个 小数据集 待处理，就启动 M   个 Map   任务，注意这 M   个 Map   任务分布于 N   台计算机上并行运行，Reduce   任务的数量 R   则可由用户指定 。</p>
<p><strong>Map</strong>   ： 输入 <k1, v1>   输出 List(<k2,v2>)</p>
<p><strong>Reduce</strong>   ： 输入 <k2,List(v2)>   输出 <k3,v3></p>
<p><strong>分区（</strong>  <strong>Partition)</strong>  :   把 Map   任务输出的中间结果按 key   的范围划分成 R   份 ( R  是预先定义的 Reduce  任务的个数) ，划分时通常使用 hash  函数如: hash(key) mod R ，这样可以保证某一段范围内的 key ，一定是由一个 Reduce  任务来处理，可以简化 Reduce  的过程。</p>
<p><strong>Combine</strong>   :   在  partition   之前，还可以对中间结果先做  combine  ，即将中间结果中有相同  key  的  <key, value>   对合并成一对。 combine   的过程与  Reduce   的过程类似，很多情况下就可以直接使用  Reduce   函数，但  combine   是作为  Map   任务的一部分，在执行完  Map   函数后紧接着执行的。 Combine   能够减少中间结果中  <key, value>   对的数目，从而减少网络流量。</p>
<p>下面举个例子来着重说明 Combine  ， hadoop  允许用户声明一个 combiner  运行在 Map  的输出上，它的输出再作为 Reduce  的输入。例如，找出每一年的最调气温：</p>
<p>假如用户的输入的分片数是 2  ，那么：</p>
<p>1  ）第一个 Map  的输出如下：</p>
<p>（ 1950  ， 0  ）</p>
<p>（ 1950  ， 20  ）</p>
<p>（ 1950  ， 10  ）</p>
<p>2  ） 第二个 Map  的输出如下：</p>
<p>（ 1950  ， 25  ）</p>
<p>（ 1950  ， 15  ）</p>
<p>3  ） Reduce  的输入如下：</p>
<p>（ 1950  ，［ 0  ， 20  ， 10  ， 25  ， 15  ］）</p>
<p><strong>注意：如果有</strong>   <strong>combine</strong>    <strong>的话，此时</strong>   <strong>Reduce</strong>    <strong>的输入应该是：</strong></p>
<p><strong>max(0, 20, 10, 25, 15) = max(max(0,20,10), max(25,15)) = max(20,25)</strong></p>
<p><strong>combine</strong>    <strong>并不能取代</strong>   <strong>reduce,</strong>    <strong>例如，如果我们计算平均气温，便不能使用</strong>   <strong>combine</strong>    <strong>，因为：</strong></p>
<p><strong>mean(0,20,10,25,15) = 14</strong></p>
<p><strong>但是：</strong></p>
<p><strong>mean(mean(0,20,10), mean(25,15)) = mean(10,20) = 15</strong></p>
<p>4  ） Reduce  的输出如下：</p>
<p>（ 1950  ， 25  ）</p>
<h1 id="-2-hadoop-"><a href=""></a>2 hadoop  入门实战</h1>
<p>hadoop  有三种部署模式：</p>
<ul>
<li>单机模式：没有守护进程，一切都运行在单个 JVM  上，适合测试与调试。</li>
<li>伪集群模式：守护进程在本地运行，适合模拟集群。</li>
<li>集群模式：守护进程运行在集群的某台机器上。</li>
</ul>
<p>所以，在以上任一特定模式运行 hadoop  时，只需要做两件事情：</p>
<p>1  ） 设置适当属性</p>
<p>2  ）启动 hadoop  的守护进程（名称节点，二级名称节名，数据节点）</p>
<p>hadoop  默认的是单机模式，下面，我们将着重介绍在集群模式是如何部署？</p>
<h2 id="-2-1-"><a href=""></a>2.1   测试环境</h2>
<p>用两台机器做为测试环境 ,   通常，集群里的一台机器被指定为  NameNode  ，另一台不同的机器被指定为 JobTracker  ，这些机器是 <strong>masters;</strong>  余下的机器即作为 DataNode  <strong>也</strong> 作为 TaskTracker  ，这些机器是 <strong>slaves</strong>  <strong>。</strong></p>
<p>1  ）  master (JobTracker &amp; NameNode)  ：我的工作机  ( zhanghua  .quqi.com)</p>
<p>2  ）  slave (TaskTracker &amp; DataNode)  ：我的开发机 ( tadev03  .quqi.com)</p>
<p>3)   两机均已安装 ssh   与  rsync</p>
<h2 id="-2-2-"><a href=""></a>2.2   测试程序</h2>
<p>1  ）  /home/workspace/hadoopExample/input/file01:</p>
<p>Hello World Bye World</p>
<p>2) /home/workspace/hadoopExample/input/file02:</p>
<p>Hello  Hadoop    Goodbye  Hadoop</p>
<ol>
<li>WordCount.java</li>
</ol>
<p><strong>package</strong>    com.TripResearch.hadoop;</p>
<p><strong>import</strong>   java.io.IOException;</p>
<p><strong>import</strong>   java.util.Iterator;</p>
<p><strong>import</strong>   java.util.StringTokenizer;</p>
<p><strong>import</strong>   org.apache.hadoop.fs.Path;</p>
<p><strong>import</strong>   org.apache.hadoop.io.IntWritable;</p>
<p><strong>import</strong>   org.apache.hadoop.io.LongWritable;</p>
<p><strong>import</strong>   org.apache.hadoop.io.Text;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred. FileInputFormat  ;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred.FileOutputFormat;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred.JobClient;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred. JobConf  ;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred. MapReduceBase  ;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred. Mapper  ;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred.OutputCollector;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred. Reducer  ;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred.Reporter;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred. TextInputFormat  ;</p>
<p><strong>import</strong>   org.apache.hadoop.mapred. TextOutputFormat  ;</p>
<p>//<em>/</em></p>
<p>/<em>  <em>*@author</em></em>    huazhang</p>
<p>/*/</p>
<p>@SuppressWarnings ( &quot;deprecation&quot; )</p>
<p><strong>public</strong>    <strong>class</strong>   WordCount {</p>
<p><strong>public</strong>    <strong>static</strong>    <strong>class</strong>   MyMap  <strong>extends</strong>    MapReduceBase    <strong>implements</strong></p>
<p>Mapper <LongWritable, Text, Text, IntWritable> {</p>
<p><strong>private</strong>    <strong>final</strong>    <strong>static</strong>   IntWritable  <em>one</em>   =  <strong>new</strong>   IntWritable(1);</p>
<p><strong>private</strong>   Text  word  =  <strong>new</strong>   Text();</p>
<p><strong>public</strong>    <strong>void</strong>   map(LongWritable key, Text value,</p>
<p>OutputCollector<Text, IntWritable> output, Reporter reporter)</p>
<p><strong>throws</strong>   IOException {</p>
<p>String line = value.toString();</p>
<p>StringTokenizer tokenizer =  <strong>new</strong>   StringTokenizer(line);</p>
<p><strong>while</strong>   (tokenizer.hasMoreTokens()) {</p>
<p>word .set(tokenizer.nextToken());</p>
<p>output.collect( word ,  <em>one</em>  );</p>
<p>}</p>
<p>}</p>
<p>}</p>
<p><strong>public</strong>    <strong>static</strong>    <strong>class</strong>   MyReduce  <strong>extends</strong>    MapReduceBase    <strong>implements</strong></p>
<p>Reducer <Text, IntWritable, Text, IntWritable> {</p>
<p><strong>public</strong>    <strong>void</strong>   reduce(Text key, Iterator<IntWritable> values,</p>
<p>OutputCollector<Text, IntWritable> output, Reporter reporter)</p>
<p><strong>throws</strong>   IOException {</p>
<p><strong>int</strong>   sum = 0;</p>
<p><strong>while</strong>   (values.hasNext()) {</p>
<p>sum += values.next().get();</p>
<p>}</p>
<p>output.collect(key,  <strong>new</strong>   IntWritable(sum));</p>
<p>}</p>
<p>}</p>
<p><strong>public</strong>    <strong>static</strong>    <strong>void</strong>   main(String[] args)  <strong>throws</strong>   Exception {</p>
<p>JobConf   conf =  <strong>new</strong>   JobConf(WordCount. <strong>class</strong>  );</p>
<p>conf.setJobName( &quot;wordcount&quot; );</p>
<p>conf.setOutputKeyClass(Text. <strong>class</strong>  );</p>
<p>conf.setOutputValueClass(IntWritable. <strong>class</strong>  );</p>
<p>conf.setMapperClass(MyMap. <strong>class</strong>  );</p>
<p>conf.setCombinerClass(MyReduce. <strong>class</strong>  );</p>
<p>conf.setReducerClass(MyReduce. <strong>class</strong>  );</p>
<p>conf.setInputFormat( TextInputFormat  . <strong>class</strong>  );</p>
<p>conf.setOutputFormat( TextOutputFormat  . <strong>class</strong>  );</p>
<p>FileInputFormat  . <em>setInputPaths</em>  (conf,  <strong>new</strong>   Path(args[0]));</p>
<p>FileOutputFormat. <em>setOutputPath</em>  (conf,  <strong>new</strong>   Path(args[1]));</p>
<p>JobClient.<em>runJob</em> (conf);</p>
<p>}</p>
<p>}</p>
<p><img src="" alt=""></p>
<h2 id="-2-3-"><a href=""></a>2.3   属性配置</h2>
<p>按下图所示修改至少 3  个属性, 如下图所示：</p>
<p>   <img src="" alt=""></p>
<ol>
<li></li>
<li><p>conf/core-site.xml</p>
</li>
</ol>
<configuration>

<property>

<name>fs.default.name</name>

<value>hdfs://zhanghua  .quqi.com:9000</value>

</property>

</configuration>

<p>注意：此处如果是伪集群模式可配置为  hdfs://localhost:9000 ,    是本地模式则为：  localhost:9000   。另外，其他输入输入路径，是本地模式是本地文件系统的路径，是非地模式，用 hdfs  文件系统的路径格式。</p>
<ol>
<li>conf/hdfs-site.xml</li>
</ol>
<configuration>

<property>

<name>dfs.replication</name>

<value>1</value>

</property>

<p></configuration></p>
<ol>
<li>conf/mapred-site.xml</li>
</ol>
<configuration>

<property>

<name>mapred.job.tracker</name>

<value>zhanghua  .quqi.com:8021</value>

</property>

<p></configuration></p>
<ol>
<li>masters</li>
</ol>
<p>zhanghua  .quqi.com (   伪分布模式就配成  localhost)</p>
<ol>
<li>slaves</li>
</ol>
<p>tadev03  .quqi.com  (   伪分布模式就配成 localhost)</p>
<ol>
<li>将以上配置好的 hadoop  文件夹拷到所有机器的相同目录下：</li>
</ol>
<p>scp -r /home/soft/hadoop-0.20.2 <a href="mailto:root@tadev03.daodao.com">root@tadev03</a>   <a href="mailto:root@tadev03.daodao.com">.quqi.com</a>  :/home/soft/hadoop-0.20.2</p>
<p>注意：确保两台机器的  JAVA_HOME   的路径一致，如果不一致，就要改 。</p>
<p>hadoop  所有可配置的配置文件说明如下：</p>
<p>hadoop-env.sh   运行 hadoop  的脚本中使用的环境变量</p>
<p>core-site.xml hadoop  的核心配置，如 HDFS  和 MapReduce  中很普遍的 I/O  设置</p>
<p>hdfs-site.xml HDFS  后台程序设置的配置：名称节点，第二名称节点及数据节点</p>
<p>mapred-site.xml MapReduce  后台程序设置的配置： jobtracker  和 tasktracker</p>
<p>masters   记录运行第二名称节点 的机器（一行一个）的列表</p>
<p>slaves   记录运行数据节点的机器（一行一个）的列表</p>
<h2 id="-2-4-ssh-"><a href=""></a>2.4   免密码 SSH  设置</h2>
<p>免密码  ssh   设置， 保证至少从   master    可以不用口令登陆所有的   slaves    。</p>
<p>1  ）生成密钥对： ssh-keygen -t rsa -P &#39;&#39; -f /root/.ssh/id_rsa (  这样密钥就留在了客户端 )</p>
<p>2)   将公钥拷到要连接的服务器，</p>
<p>scp /root/.ssh/id_rsa.pub root@tadev03  .quqi.com:/tmp</p>
<p>ssh -l root tadev03  .quqi.com</p>
<p>more /tmp/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys</p>
<ol>
<li>ssh tadev03  .quqi.com   不需要输入密码即为成功。</li>
</ol>
<p>（注意：伪分布模式也要配置  ssh localhost   无密码登录，如果是  mac   ，请将  ssh   打开）</p>
<p>(  另外，在 mac  中请在 hadoop-config.sh  文件中配置  export JAVA_HOME=/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home)</p>
<p>三条控制线线：</p>
<p>SSH →   这样就可以直接从主节点远程启动从节点上的脚本，如  ssh tadev03  .quqi.com &#39;/var/aa.sh&#39;</p>
<p>NameNode (<a href="http://localhost:50030/" target="_blank"><a href="http://localhost:50070">http://localhost:50070</a></a> ) → DataNode</p>
<p>JobTracker ( <a href="http://localhost:50030/" target="_blank"><a href="http://localhost:50030">http://localhost:50030</a></a> )→ TaskTracker (<a href="http://localhost:50030/" target="_blank"><a href="http://localhost:50060">http://localhost:50060</a></a> )</p>
<h2 id="-2-5-hosts"><a href=""></a>2.5   配置 hosts</h2>
<p>必须配置 master   和 slaves   之间的双向 hosts.   修改 /etc/hosts   进行配置，略。</p>
<h2 id="-2-6-hdfs-"><a href=""></a>2.6   格式化 HDFS  文件系统</h2>
<p>和我们常见的 NTFS  ， FAT32  文件系统一样， NDFS  最开始也是需要格式化的。格式化过程用来创建存储目录以及名称节点的永久数据结构的初始版本来创建一个空的文件系统。命令如下：</p>
<p>hadoop namenode -format</p>
<p>已知问题：在重新格式化时，可能会报： SHUTDOWN_MSG: Shutting down NameNode</p>
<p>解决办法： rm -rf /tmp/hadoop-root/dfs/name</p>
<h2 id="-2-7-"><a href=""></a>2.7   启动守护进程</h2>
<p>1    ）启动   HDFS    守护进程：    start-dfs.sh</p>
<p>(      start-dfs.sh    脚本会参照 NameNode    上 ${HADOOP_CONF_DIR}/slaves    文件的内容，在所有列出的 slave    上启动 DataNode    守护进程。   )</p>
<p>已知问题：在已设置   JAVA_HOME    的情况下仍会报：   Error: JAVA_HOME is not set</p>
<p>解决办法：我是在  hadoop.sh  文件中加下面一句解决的：</p>
<p>JAVA_HOME=/System/Library/Frameworks/JavaVM.framework/Versions/1.6/Home</p>
<p>2  ）启动  Map/Reduce  守护进程：   start-mapred.sh</p>
<p>(      start-mapred.sh   脚本会参照 JobTracker   上 ${HADOOP_CONF_DIR}/slaves   文件的内容，在所有列出的 slave   上启动 TaskTracker   守护进程  )</p>
<p>3)   启动成功后，可以通过访问  <a href="http://localhost:50030" target="_blank">http://localhost:50030</a>   验证。</p>
<p>注意：也可直接使用  start-all.sh       与  stop-all.sh       脚本  ,       在主节点   master    上面启动   hadoop    ，主节点会启动  /    停止所有从节点的   hadoop    。会启动  5       个   java        进程  ,        同时会在   /tmp        目录下创建五个   pid        文件记录这些进程   ID        号。通过这五个文件，可以得知   namenode, datanode, secondary namenode, jobtracker, tasktracker        分别对应于哪一个   Java        进程。</p>
<p>已知问题：启动后，日志中报：  java.io.IOException: File /tmp/hadoop-root/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1</p>
<p>解决办法：原因是    从  tadev03     .quqi.com       机器上无法  ping zhanghua     .quqi.com</p>
<h2 id="-2-8-"><a href=""></a>2.8   运行程序</h2>
<p>先将测试数据及其他输入由本地文件系统拷到  HFDS  文件系统中去（注意：   jar   除外 ）</p>
<ol>
<li></li>
<li><p>hadoop fs -mkdir input</p>
</li>
<li>hadoop fs -ls .</li>
<li>hadoop fs -copyFromLocal /home/workspace/hadoopExample/input/file01 input/file01</li>
<li>hadoop fs -copyFromLocal /home/workspace/hadoopExample/input/file02 input/file02</li>
</ol>
<p>这时候就可以执行下列命令运行程序了，注意：后面的input , output  等目录都是HDFS  文件系统的路径。(  如果是本地模式，就用本地文件系统的绝对路径）</p>
<ol>
<li></li>
</ol>
<p>hadoop     jar   /home/workspace/hadoopExample/hadoopExample.jar com.TripResearch.hadoop.WordCount input/ output</p>
<p>已知问题：在集群模式下运行时任务会Pending</p>
<p>最后，运行下列命令查看结果：</p>
<p>/home/soft/hadoop-0.20.2/bin/hadoop fs -cat output/part-00000</p>
<p>也可访问下列地址查看状态：</p>
<p>NameNode – <a href="http://localhost:50070/" target="_blank"><a href="http://zhanghua">http://zhanghua</a></a>   <a href="http://localhost:50070/" target="_blank">.quqi.com</a> <a href="http://localhost:50070/" target="_blank">:50070/</a></p>
<p>JobTracker - <a href="http://localhost:50030/" target="_blank"><a href="http://zhanghua">http://zhanghua</a></a>   <a href="http://localhost:50030/" target="_blank">.quqi.com</a> <a href="http://localhost:50030/" target="_blank">:50030/</a></p>
<p>常用命令说明如下：</p>
<p>hadoop dfs –ls   查看 /usr/root  目录下的内容径；
hadoop dfs –rmr xxx xxx  就是删除目录；
hadoop dfsadmin -report   这个命令可以全局的查看 DataNode  的情况；
hadoop job -list   后面增加参数是对于当前运行的 Job  的操作，例如 list,kill  等；
hadoop balancer   均衡磁盘负载的命令。</p>
<h1 id="-3-hadoop-"><a href=""></a>3 hadoop  高级进阶</h1>
<h1 id="-4-hadoop-"><a href=""></a>4 hadoop  应用案例</h1>
<h1 id="-5-"><a href=""></a>5   参考文献</h1>
<ol>
<li><a href="http://hadoop.apache.org/common/docs/r0.18.2/cn/" target="_blank"><a href="http://hadoop.apache.org/common/docs/r0.18.2/cn/">http://hadoop.apache.org/common/docs/r0.18.2/cn/</a></a></li>
<li>hadoop 0.20.2  集群配置入门 <a href="http://dev.firnow.com/course/3_program/java/javajs/20100719/453042.html" target="_blank"><a href="http://dev.firnow.com/course/3_program/java/javajs/">http://dev.firnow.com/course/3_program/java/javajs/</a></a></li>
<li>Hadoop 分布式文件系统（HDFS ）初步实践 <a href="http://huatai.me/?p=352" target="_blank"><a href="http://huatai.me/?p=352">http://huatai.me/?p=352</a></a></li>
<li>Hadoop 分布式部署实验2_ 格式化分布式文件系统 <a href="http://hi.baidu.com/thinke365/blog/item/15602aa8f9074cf41e17a235.html" target="_blank"><a href="http://hi.baidu.com/thinke365/blog/item/15602aa8f9074cf41e17a235.html">http://hi.baidu.com/thinke365/blog/item/15602aa8f9074cf41e17a235.html</a></a></li>
<li>hadoop 安装出现问题（紧急），请前辈指教 <a href="http://forum.hadoop.tw/viewtopic.php?f=4&amp;t=90" target="_blank"><a href="http://forum.hadoop.tw/viewtopic.php?f=4&amp;t=90">http://forum.hadoop.tw/viewtopic.php?f=4&amp;t=90</a></a></li>
<li>用 Hadoop  进行分布式并行编程 <a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop1/index.html" target="_blank"><a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop1/index.html">http://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop1/index.html</a></a></li>
<li>用 Hadoop  进行分布式数据处理 <a href="http://tech.ddvip.com/2010-06/1275983295155033.html" target="_blank"><a href="http://tech.ddvip.com/2010-06/1275983295155033.html">http://tech.ddvip.com/2010-06/1275983295155033.html</a></a></li>
</ol>
<p>分享到： <a href="&quot;分享到新浪微博&quot;"></a><a href="&quot;分享到腾讯微博&quot;"></a></p>
<ol>
<li>上一篇：<a href="http://blog.csdn.net/quqi99/article/details/6160846" target="_blank">Lucene Scoring 评分机制 （ by quqi99 )</a></li>
<li><p>下一篇：<a href="http://blog.csdn.net/quqi99/article/details/6292472" target="_blank">深入理解各JEE服务器Web层集群原理 ( by quqi99 )</a>
查看评论<a href=""></a></p>
<p>暂无评论
您还没有登录,请<a href="">[登录]</a>或<a href="http://passport.csdn.net/account/register?from=http%3A%2F%2Fblog.csdn.net%2Fquqi99%2Farticle%2Fdetails%2F6291788" target="_blank">[注册]</a></p>
</li>
</ol>
<p>/* 以上用户言论只代表其个人观点，不代表CSDN网站的观点或立场<a href=""></a><a href=""></a>
<a href="&quot;回到顶部&quot;"><img src="" alt="TOP"></a></p>
<p>个人资料</p>
<p><a href="http://my.csdn.net/quqi99" target="_blank"><img src="&quot;访问我的空间&quot;" alt=""></a>
<a href="http://my.csdn.net/quqi99" target="_blank">quqi99</a></p>
<p><a href="&quot;[加关注]&quot;"></a> <a href="&quot;[发私信]&quot;"></a>
<a href="http://medal.blog.csdn.net/allmedal.aspx" target="_blank"><img src="" alt=""></a></p>
<ul>
<li>访问：198660次</li>
<li>积分：3337分</li>
<li><p>排名：第1895名</p>
</li>
<li><p>原创：146篇</p>
</li>
<li>转载：23篇</li>
<li>译文：0篇</li>
<li>评论：123条</li>
</ul>
<p>文章搜索</p>
<p><a href=""></a></p>
<p>文章分类</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/category/875141" target="_blank">VM / Cloud</a>(7)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/557281" target="_blank">Middleware / Java AppServer</a>(13)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/328029" target="_blank">Seach Engine</a>(5)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/674417" target="_blank">Linux / Unix / Shell</a>(24)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/328188" target="_blank">J2SE / JEE</a>(40)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/347580" target="_blank">DB / NoSQL</a>(9)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/803236" target="_blank">Architecture</a>(0)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/351802" target="_blank">Android</a>(3)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/803239" target="_blank">Life</a>(4)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/689016" target="_blank">Other</a>(9)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/1112756" target="_blank">OpenStack</a>(37)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/1139084" target="_blank">Python</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/category/1167554" target="_blank">C / C++</a>(2)</li>
<li><p><a href="http://blog.csdn.net/quqi99/article/category/1490633" target="_blank">Networking</a>(1)
文章存档</p>
</li>
<li><p><a href="http://blog.csdn.net/quqi99/article/month/2013/08" target="_blank">2013年08月</a>(4)</p>
</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2013/07" target="_blank">2013年07月</a>(13)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2013/06" target="_blank">2013年06月</a>(6)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2013/05" target="_blank">2013年05月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2013/04" target="_blank">2013年04月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2013/03" target="_blank">2013年03月</a>(3)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2013/02" target="_blank">2013年02月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2013/01" target="_blank">2013年01月</a>(9)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/12" target="_blank">2012年12月</a>(3)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/11" target="_blank">2012年11月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/08" target="_blank">2012年08月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/07" target="_blank">2012年07月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/06" target="_blank">2012年06月</a>(7)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/05" target="_blank">2012年05月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/04" target="_blank">2012年04月</a>(6)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/03" target="_blank">2012年03月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2012/02" target="_blank">2012年02月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2011/12" target="_blank">2011年12月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2011/09" target="_blank">2011年09月</a>(5)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2011/08" target="_blank">2011年08月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2011/06" target="_blank">2011年06月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2011/04" target="_blank">2011年04月</a>(5)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2011/03" target="_blank">2011年03月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2011/01" target="_blank">2011年01月</a>(4)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2010/12" target="_blank">2010年12月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2010/07" target="_blank">2010年07月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2010/05" target="_blank">2010年05月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2010/04" target="_blank">2010年04月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2010/03" target="_blank">2010年03月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2010/02" target="_blank">2010年02月</a>(4)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2010/01" target="_blank">2010年01月</a>(6)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2009/12" target="_blank">2009年12月</a>(6)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2009/11" target="_blank">2009年11月</a>(5)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2009/10" target="_blank">2009年10月</a>(6)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2009/09" target="_blank">2009年09月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2009/08" target="_blank">2009年08月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2009/06" target="_blank">2009年06月</a>(4)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2009/03" target="_blank">2009年03月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2008/11" target="_blank">2008年11月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2008/10" target="_blank">2008年10月</a>(2)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2008/08" target="_blank">2008年08月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2008/06" target="_blank">2008年06月</a>(3)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2008/04" target="_blank">2008年04月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2008/03" target="_blank">2008年03月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2008/02" target="_blank">2008年02月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2008/01" target="_blank">2008年01月</a>(3)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2007/12" target="_blank">2007年12月</a>(4)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2007/11" target="_blank">2007年11月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2007/10" target="_blank">2007年10月</a>(4)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2007/08" target="_blank">2007年08月</a>(5)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2007/07" target="_blank">2007年07月</a>(6)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2007/06" target="_blank">2007年06月</a>(1)</li>
<li><a href="http://blog.csdn.net/quqi99/article/month/2007/05" target="_blank">2007年05月</a>(8)</li>
</ul>
<p>展开</p>
<p>阅读排行</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/1916553" title="Android学习笔记 ( by quqi99 )" target="_blank">Android学习笔记 ( by quqi99 )</a>(22132)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1680647" title="java.lang.NoClassDefFoundError: org/apache/commons/io/output/DeferredFileOutputStream" target="_blank">java.lang.NoClassDefFoundError: org/apache/commons/io/output/DeferredFileOutputStream</a>(17851)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/7433285" title="建立openstack quantum开发环境" target="_blank">建立openstack quantum开发环境</a>(6747)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1755642" title="在linux中安装字库( by quqi99 )" target="_blank">在linux中安装字库( by quqi99 )</a>(5151)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1930304" title="Android手机客户端与Servlet交换数据(by quqi99)" target="_blank">Android手机客户端与Servlet交换数据(by quqi99)</a>(5140)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/5298017" title="ReentrantLock与synchronized的区别 ( by quqi99 )" target="_blank">ReentrantLock与synchronized的区别 ( by quqi99 )</a>(4864)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/5604732" title="个人户口档案转移笔记（适用北京集体户口）" target="_blank">个人户口档案转移笔记（适用北京集体户口）</a>(4802)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1624225" title="Magnolia学习笔记（一个基于JSR170的内容管理系统） ( by quqi99 )" target="_blank">Magnolia学习笔记（一个基于JSR170的内容管理系统） ( by quqi99 )</a>(4342)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1624218" title="JSpider学习笔记 ( by quqi99 )" target="_blank">JSpider学习笔记 ( by quqi99 )</a>(4149)</li>
<li><p><a href="http://blog.csdn.net/quqi99/article/details/3099945" title="Plone学习笔记 ( by quqi99 )" target="_blank">Plone学习笔记 ( by quqi99 )</a>(4057)
评论排行</p>
</li>
<li><p><a href="http://blog.csdn.net/quqi99/article/details/1916553" title="Android学习笔记 ( by quqi99 )" target="_blank">Android学习笔记 ( by quqi99 )</a>(21)</p>
</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1680647" title="java.lang.NoClassDefFoundError: org/apache/commons/io/output/DeferredFileOutputStream" target="_blank">java.lang.NoClassDefFoundError: org/apache/commons/io/output/DeferredFileOutputStream</a>(18)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1930304" title="Android手机客户端与Servlet交换数据(by quqi99)" target="_blank">Android手机客户端与Servlet交换数据(by quqi99)</a>(12)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/5604732" title="个人户口档案转移笔记（适用北京集体户口）" target="_blank">个人户口档案转移笔记（适用北京集体户口）</a>(8)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1624225" title="Magnolia学习笔记（一个基于JSR170的内容管理系统） ( by quqi99 )" target="_blank">Magnolia学习笔记（一个基于JSR170的内容管理系统） ( by quqi99 )</a>(7)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/2591768" title="使用itext生成word格式的报表(by quqi99)" target="_blank">使用itext生成word格式的报表(by quqi99)</a>(5)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/1755642" title="在linux中安装字库( by quqi99 )" target="_blank">在linux中安装字库( by quqi99 )</a>(4)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/6305061" title="Android分享文稿 ( by quqi99 )" target="_blank">Android分享文稿 ( by quqi99 )</a>(4)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/9156497" title="OpenDaylight学习 ( by quqi99 )" target="_blank">OpenDaylight学习 ( by quqi99 )</a>(3)</li>
<li><a href="http://blog.csdn.net/quqi99/article/details/2590703" title="使用jacob生成word(by quqi99)" target="_blank">使用jacob生成word(by quqi99)</a>(3)</li>
</ul>
<p>推荐文章
最新评论</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/9156497#comments" target="_blank">OpenDaylight学习 ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/quqi99" target="_blank">quqi99</a>: hi whoeversucks, 谢谢你的实时信息，非常有用，我已经更新到博客里了。另外，问个问题，...</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/9156497#comments" target="_blank">OpenDaylight学习 ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/whoeversucks" target="_blank">whoeversucks</a>: 注意，OpenDayLight Controller和OSCP实际上2个独立的SDN控制器项目（分别...</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/9102745#comments" target="_blank">给Linux虚机扩充硬盘空间 ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/quqi99" target="_blank">quqi99</a>: hi dalinhuang, 谢谢你的回复，你给的这个方法是只适合LVM场景的啊，我没有使用LVM。</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/9102745#comments" target="_blank">给Linux虚机扩充硬盘空间 ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/dalinhuang" target="_blank">dalinhuang</a>: 给根（/）扩充的步骤：（以你的virtualbox并使用LVM为例）1. 新增一块虚拟硬盘，给虚机。...</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/9156497#comments" target="_blank">OpenDaylight学习 ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/piaochenping" target="_blank">piaochenping</a>: 你好，为什么我安装时老是出现这个错误呢？ Failed to execute goal org.co...</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/7659905#comments" target="_blank">OpenStack CI测试之devstack-gate ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/quqi99" target="_blank">quqi99</a>: @sunyilong2012: 这种错误应该是差模块吧，可以单独安装一下试试, sudo pip i...</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/7411091#comments" target="_blank">Fedora 16上源码建立pydev + eclipse的OpenStack开发环境笔记草稿 ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/quqi99" target="_blank">quqi99</a>: openstack因为用到了一些linux特有的东西，如iptables，所以目前只能跑在linux...</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/7411091#comments" target="_blank">Fedora 16上源码建立pydev + eclipse的OpenStack开发环境笔记草稿 ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/javaerss" target="_blank">javaerss</a>: 大神...看哭了，为此特地跑去下载fedora 16来做实验。之前用ubuntu下用eclipse ...</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/6576375#comments" target="_blank">玩转play framework ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/nanfu08" target="_blank">nanfu08</a>: 你能看得清，如果只是自己看的话我没话说，这样的文字叫人怎么读？？</p>
<ul>
<li><a href="http://blog.csdn.net/quqi99/article/details/7659905#comments" target="_blank">OpenStack CI测试之devstack-gate ( by quqi99 )</a></li>
</ul>
<p><a href="http://blog.csdn.net/sunyilong2012" target="_blank">dragonsun</a>: 您好，我在做这个测试的时候遇到了无法导入statsd的问题，请问您有解决的方法吗？+ /home/j...</p>
<p><a href="http://www.csdn.net/company/about.html" target="_blank">公司简介</a>|<a href="http://www.csdn.net/company/recruit.html" target="_blank">招贤纳士</a>|<a href="http://www.csdn.net/company/marketing.html" target="_blank">广告服务</a>|<a href="http://www.csdn.net/company/account.html" target="_blank">银行汇款帐号</a>|<a href="http://www.csdn.net/company/contact.html" target="_blank">联系方式</a>|<a href="http://www.csdn.net/company/statement.html" target="_blank">版权声明</a>|<a href="http://www.csdn.net/company/layer.html" target="_blank">法律顾问</a>|<a href="mailto:webmaster@csdn.net">问题报告</a><a href="http://wpa.qq.com/msgrd?v=3&amp;uin=2355263776&amp;site=qq&amp;menu=yes" target="_blank">QQ客服</a> <a href="http://e.weibo.com/csdnsupport/profile" target="_blank">微博客服</a> <a href="http://bbs.csdn.net/forums/Service" target="_blank">论坛反馈</a> <a href="mailto:webmaster@csdn.net">联系邮箱：webmaster@csdn.net</a> 服务热线：400-600-2320京 ICP 证 070598 号北京创新乐知信息技术有限公司 版权所有世纪乐知(北京)网络技术有限公司 提供技术支持江苏乐知网络技术有限公司 提供商务支持Copyright © 1999-2012, CSDN.NET, All Rights Reserved <a href="http://www.hd315.gov.cn/beian/view.asp?bianhao=010202001032100010" target="_blank"><img src="" alt="GongshangLogo"></a>
<img src="http://counter.csdn.net/pv.aspx?id=24" alt=""></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--Hadoop知识分享文稿byquqi99-技术并艺术着/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--Hadoop知识分享文稿byquqi99-技术并艺术着" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）/">基于Hadoop 2.2.0的高可用性集群搭建步骤（64位）</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-hadoop-2-2-0-64-">基于Hadoop 2.2.0的高可用性集群搭建步骤（64位）</h1>
<p> 内容概要: CentSO_64bit集群搭建， hadoop2.2(64位)编译，安装，配置以及测试步骤</p>
<p>新版亮点:基于yarn计算框架和高可用性DFS的第一个稳定版本。</p>
<p>注1：官网只提供32位release版本, 若机器为64位，需要手动编译。</p>
<p>注2：目前网上传的2.2版本的安装步骤几乎都有问题，没有一个版本是完全正确的。若不懂新框架内部机制，不要照抄网传的版本。</p>
<p><strong>0. 编译前的准备</strong></p>
<p><strong>虚拟机vmware准备，64bit CentOS准备</strong></p>
<p><strong>节点ip</strong></p>
<p>cluster1   172.16.102. 201</p>
<p>cluster2  172.16.102. 202</p>
<p>cluster3  172.16.102. 203</p>
<p>cluster4  172.16.102. 204</p>
<p><strong>各节点职能划分</strong>     </p>
<p>cluster1        resourcemanager, nodemanager,</p>
<p>proxyserver,historyserver, datanode, namenode,</p>
<p>cluster2        datanode, nodemanager</p>
<p>cluster3 datanode, nodemanager</p>
<p>cluster4 datanode, nodemanager</p>
<p><strong>说明</strong></p>
<p>以下关于修改hostname, 设置静态ip, ssh免登陆，关闭防火墙等步骤，放在文章末尾，这些内容并不是本文讨论的重点。</p>
<p><strong>1. hadoop2.2**</strong>编译**
1说明：标准的</p>
<p>bash</p>
<p>提示符，root用户为</p>
<p>&#39;/#&#39;</p>
<p>，普通用户为</p>
<p>&#39;%&#39;</p>
<p>，由于博客编辑器的缘故，</p>
<p>&#39;/#&#39;</p>
<p>提示符会被默认为comment, 因此在这篇博文中不再区分root和普通user的提示符， 默认全部为</p>
<p>&#39;$&#39;</p>
<p>因为我们安装的CentOS是64bit的，而官方release的hadoop2.2.0版本没有对应的64bit安装包，故需要自行编译。</p>
<p>首先需要去oracle下载64位jdk:
1</p>
<p>2
$</p>
<p>su</p>
<p>root</p>
<p>$wget http:</p>
<p>//download</p>
<p>.oracle.com</p>
<p>/otn-pub/java/jdk/7u45-b18/jdk-7u45-linux-x64</p>
<p>.</p>
<p>tar</p>
<p>.gz</p>
<p>注: prompt（提示符）为%默认为当前用户， /#则为root,注意以下各步骤中的prompt类型。</p>
<p>下面为hadoop编译步骤（注：中间部分的文本框里内容提要只是一些补充说明，不要执行框里的命令）</p>
<p>1.1 BOTPROTO改为”dhcp”
1</p>
<p>2
$</p>
<p>su</p>
<p>root</p>
<p>$</p>
<p>sed</p>
<p>–i  s</p>
<p>/static/dhcp/g</p>
<p>/etc/sysconfig/network-scripts/ifcfg-eth0</p>
<p>/#servicenetwork restart</p>
<p>1.2 下载hadoop2.2.0 源码</p>
<p>1</p>
<p>2
3$</p>
<p>su</p>
<p>grid</p>
<p>$</p>
<p>cd</p>
<p>~
wget  http:</p>
<p>//apache</p>
<p>.dataguru.cn</p>
<p>/hadoop/common/stable/hadoop-2</p>
<p>.2.0-src.</p>
<p>tar</p>
<p>.gz</p>
<p>1.3 安装maven</p>
<p>1</p>
<p>2
3</p>
<p>4
5$</p>
<p>su</p>
<p>root</p>
<p>$</p>
<p>cd</p>
<p>/opt
wget http:</p>
<p>//apache</p>
<p>.fayea.com</p>
<p>/apache-mirror/maven/maven-3/3</p>
<p>.1.1</p>
<p>/binaries/apache-maven-3</p>
<p>.1.1-bin.</p>
<p>tar</p>
<p>.gz</p>
<p>$</p>
<p>tar</p>
<p>zxvf apache-maven-3.1.1-bin.</p>
<p>tar</p>
<p>.gz
$</p>
<p>cd</p>
<p>apache-maven-3.1.1</p>
<p><em>**</em>修改系统环境变量有两种方式，修改/etc/profile， 或者在/etc/profile.d/下添加定制的shell文件，</p>
<p>鉴于profile文件的重要性，尽量不要在profile文件里添加内容，官方建议采用第二种，以保证profile文件的绝对安全。</p>
<p>下面采用第二种方式：</p>
<p>首先，创建一个简单shell脚脚本并添加相关内容进去：
1</p>
<p>2
$</p>
<p>cd</p>
<p>/etc/profile</p>
<p>.d/</p>
<p>$</p>
<p>touch</p>
<p>maven.sh     其次，maven.sh里添加内容如下：1</p>
<p>2
3/#environmentvariable settings for mavn2</p>
<p>export</p>
<p>MAVEN_HOME=</p>
<p>&#39;/opt/apache-maven-3.1.1&#39;</p>
<p>3
export</p>
<p>PATH=$MAVEN_HOME</p>
<p>/bin</p>
<p>:$PATH</p>
<p>最后，source一下</p>
<p>1$</p>
<p>source</p>
<p>/etc/profile</p>
<p><br><br>$</p>
<p>source</p>
<p>/etc/profile1</p>
<p>2
3&lt;em</p>
<p>id</p>
<p>=</p>
<p>&quot;__mceDel&quot;</p>
<blockquote>
<p>$mvn -version</p>
</blockquote>
<p>Apache Maven 3.1.1
&lt;</p>
<p>/em</p>
<p>&gt;</p>
<p>1.4 安装protobuf</p>
<p>注意apache官方网站上的提示“NOTE: You will need protoc 2.5.0 installed.”
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
$</p>
<p>su</p>
<p>root</p>
<p>$</p>
<p>cd</p>
<p>/opt
wget https:</p>
<p>//protobuf</p>
<p>.googlecode.com</p>
<p>/files/protobuf-2</p>
<p>.5.0.</p>
<p>tar</p>
<p>.bz2</p>
<p>$</p>
<p>tar</p>
<p>xvf protobuf-2.5.0.</p>
<p>tar</p>
<p>.bz2 (注意压缩文件后缀， maven安装包是—</p>
<p>gzip</p>
<p>文件，解压时需加–z)
$</p>
<p>cd</p>
<p>protobuf-2.5.0</p>
<p>.</p>
<p>/configure</p>
<p>安装protobuf时提示报错”configure: error: C++ preprocessor &quot;/lib/cpp&quot; failssanity check”</p>
<p>安装gcc
1$yum</p>
<p>install</p>
<p>gcc</p>
<p>1.5 编译hadoop</p>
<p>首先从官网下载hadoop2.2.0source code:
1</p>
<p>2
3$</p>
<p>su</p>
<p>grid;</p>
<p>$</p>
<p>cd</p>
<p>~grid/
wget http:</p>
<p>//apache</p>
<p>.dataguru.cn</p>
<p>/hadoop/common/stable/hadoop-2</p>
<p>.2.0-src.</p>
<p>tar</p>
<p>.gz</p>
<p>好了，痛苦的编译过程来了。</p>
<p>解压之：
1</p>
<p>2
$</p>
<p>tar</p>
<p>zxvf hadoop-2.2.0-src.</p>
<p>tar</p>
<p>.gz</p>
<p>$</p>
<p>cd</p>
<p>hadoop-2.2.0-src</p>
<p>1.6 给maven指定国内镜像源</p>
<p>1.6.1. 切换root权限, 修改/opt/apache-maven-3.1.1/conf/settings.xml
1</p>
<p>2
$</p>
<p>su</p>
<p>root</p>
<p>$vim</p>
<p>/opt/apache-maven-3</p>
<p>.1.1</p>
<p>/conf/settings</p>
<p>.xml</p>
<p>修改1. 在<mirrors>…</mirrors>里添加国内源（注意，保留原本就有的<mirrors>...</mirrors>）：</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
1  <mirrors> 2     <mirror>3         <id>nexus-osc</id>4         <mirrorOf>/*</mirrorOf>5     <name>Nexusosc</name>6     <url><a href="http://maven.oschina.net/content/groups/public/" target="_blank">http://maven.oschina.net/content/groups/public/</a></url>7     </mirror>8 </mirrors></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>修改2. 在<profiles>标签中增加以下内容（保留原来的<profiles>…</profiles>， jdk版本根据用户的情况填写）</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
 1  <profile> 2       <id>jdk-1.4</id> 3       <activation> 4         <jdk>1.4</jdk> 5       </activation> 6       <repositories> 7         <repository> 8           <id>nexus</id> 9           <name>local private nexus</name>10           <url><a href="http://maven.oschina.net/content/groups/public/">http://maven.oschina.net/content/groups/public/</a></url>11           <releases>12             <enabled>true</enabled>13           </releases>14           <snapshots>15             <enabled>false</enabled>16           </snapshots>17         </repository>18       </repositories>19       <pluginRepositories>20         <pluginRepository>21           <id>nexus</id>22           <name>local private nexus</name>23           <url><a href="http://maven.oschina.net/content/groups/public/" target="_blank">http://maven.oschina.net/content/groups/public/</a></url>24           <releases>25             <enabled>true</enabled>26           </releases>27           <snapshots>28             <enabled>false</enabled>29           </snapshots>30         </pluginRepository>31       </pluginRepositories>32     </profile>33 </profiles></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>   1.6.2 将刚才修改的配置文件拷到当前用户home目录下</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
$ su grid $ sudo cp /opt/apache-maven-3.1.1/conf/settings.xml ~/.m2//#若提示该用户不在sudoers里，执行以下步骤： $ su root  /#在sudoers里第99行添加当前用户（下面行号不要加）： $ cat /etc/sudoers98  root     ALL=(ALL)       ALL99  grid     ALL=(ALL)       ALL</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>1.7 现在执行官方的clean步骤： $mvn clean install –DskipTests</p>
<p>漫长的等待后发现安装一切正常。</p>
<p>1.8 安装3个依赖包
1</p>
<p>2
3Cmake</p>
<p>ncurses-devel
openssl-devel</p>
<p>执行以下步骤：</p>
<p>1</p>
<p>2
3</p>
<p>4
$</p>
<p>su</p>
<p>root</p>
<p>$yum</p>
<p>install</p>
<p>ncurses-devel
$yum</p>
<p>install</p>
<p>openssl-devel</p>
<p>$yum</p>
<p>install</p>
<p>cmake89</p>
<p>以上安装完成后，切回用户grid：</p>
<p>1</p>
<p>2
$</p>
<p>su</p>
<p>grid</p>
<p>$</p>
<p>cd</p>
<p>~</p>
<p>/hadoop-2</p>
<p>.2.0-src</p>
<p><em>**</em>1.9 所有依赖已安装完毕，开始编译</p>
<p>1$mvn package-Pdist,native -DskipTests -Dtar</p>
<p>漫长的等待后，编译成功，查看结果：</p>
<p><img src="http://m1.img.libdd.com/farm4/d/2013/1114/11/160569527B88184A5CFD1B4C6D260A60_B500_900_500_214.png" alt=""></p>
<p>一切正常。至此，hadoop2.2.0编译完成。</p>
<p><em>**</em>1.10 验证</p>
<p>下面验证编译结果是否符合预期, 注意我们当前是在目录~/hadoop-2.2.0-src下，
1</p>
<p>2
3$</p>
<p>cd</p>
<p>hadoop-dist/</p>
<p>$</p>
<p>ls
pom.xml  target</p>
<p>以上为maven编译的配置文件</p>
<p>1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
7$</p>
<p>cd</p>
<p>target</p>
<p>$</p>
<p>ls</p>
<p>-sF
total 276M</p>
<p>4.0K antrun/                    92M hadoop-2.2.0.</p>
<p>tar</p>
<p>.gz            4.0K maven-archiver/
4.0K dist-layout-stitching.sh  4.0K hadoop-dist-2.2.0.jar          4.0K</p>
<p>test</p>
<p>-</p>
<p>dir</p>
<p>/</p>
<p>4.0K dist-</p>
<p>tar</p>
<p>-stitching.sh     184M hadoop-dist-2.2.0-javadoc.jar
4.0K hadoop-2.2.0/             4.0K javadoc-bundle-options/</p>
<p>以上为maven编译后自动生成的目录文件，进入hadoop-2.2.0:</p>
<p>1</p>
<p>2
3$</p>
<p>cd</p>
<p>hadoop-2.2.023</p>
<p>$</p>
<p>ls
bin  etc  include  lib libexec  sbin  share</p>
<p>这才是和官方release2.2.0版本（官方只有32bit版本）的相同的目录结构。</p>
<p>1.10.1 下面主要验证两项：</p>
<p><em>**</em>a.验证版本号
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
7$bin</p>
<p>/hadoop</p>
<p>version</p>
<p>Hadoop 2.2.0
Subversion Unknown -r Unknown</p>
<p>Compiled by grid on 2013-11-06T13:51Z
Compiled with protoc 2.5.0</p>
<p>From</p>
<p>source</p>
<p>with checksum 79e53ce7994d1628b240f09af91e1af4
This</p>
<p>command</p>
<p>was run using</p>
<p>/home/grid/hadoop-2</p>
<p>.2.0-src</p>
<p>/hadoop-dist/target/hadoop-2</p>
<p>.2.0</p>
<p>/share/hadoop/common/hadoop-common-2</p>
<p>.2.0.jar</p>
<p>可以看到hadoop版本号，编译工具（protoc2.5.0版本号与官方要求一致）以及编译日期.</p>
<p><em>**</em>b.验证hadoop lib的位数
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
$</p>
<p>file</p>
<p>lib</p>
<p>//native/</p>
<p>/*</p>
<p>lib</p>
<p>//native/libhadoop</p>
<p>.a:        current ar archive
lib</p>
<p>//native/libhadooppipes</p>
<p>.a:   current ar archive</p>
<p>lib</p>
<p>//native/libhadoop</p>
<p>.so:       symbolic link to `libhadoop.so.1.0.0&#39;
lib</p>
<p>//native/libhadoop</p>
<p>.so.1.0.0:<strong>ELF 64-bitLSB&lt;</p>
<p>/strong</p>
<blockquote>
<p>shared object, x86-64, version 1 (SYSV), dynamically linked, notstripped1011 lib</p>
</blockquote>
<p>//native/libhadooputils</p>
<p>.a:   current ar archive1213 lib</p>
<p>//native/libhdfs</p>
<p>.a:          current ar archive1415 lib</p>
<p>//native/libhdfs</p>
<p>.so:         symbolic link to `libhdfs.so.0.0.0&#39;</p>
<p>lib</p>
<p>//native/libhdfs</p>
<p>.so.0.0.0:   <strong>ELF 64-bit LSB shared object&lt;</p>
<p>/strong</p>
<blockquote>
<p>, x86-64,version 1 (SYSV), dynamically linked, not stripped</p>
</blockquote>
<p>看到黑色的“ELF-64bit LSB”证明64bit hadoop2.2.0初步编译成功，查看我们之前的hadoop0.20.3版本，会发现lib//native/libhadoop.so.1.0.0是32bit，这是不正确的！。^_^</p>
<p><strong>2. hadoop2.2**</strong>配置**</p>
<p><strong>**</strong>2.1 home设置**</p>
<p>为了和MRv1区别， 2.2版本的home目录直接命名为yarn:
1</p>
<p>2
3</p>
<p>4
$</p>
<p>su</p>
<p>hadoop</p>
<p>$</p>
<p>cd</p>
<p>~
$</p>
<p>mkdir</p>
<p>–p yarn</p>
<p>/yarn_data67</p>
<p>$</p>
<p>cp</p>
<p>–a ~hadoop</p>
<p>/hadoop-2</p>
<p>.2.0-src</p>
<p>/hadoop-dist/target/hadoop-2</p>
<p>.2.0  ~hadoop</p>
<p>/yarn</p>
<p><strong>2.2 环境变量设置</strong></p>
<p>~/.bashrc里添加新环境变量：</p>
<p>1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
7</p>
<p>8
9</p>
<p>10
11</p>
<p>12
/# javaenv</p>
<p>export</p>
<p>JAVA_HOME=</p>
<p>&quot;/usr/java/jdk1.7.0_45&quot;</p>
<p>exportPATH=</p>
<p>&quot;$JAVA_HOME/bin:$PATH&quot;
/# hadoopvariable settings</p>
<p>export</p>
<p>HADOOP_HOME=</p>
<p>&quot;$HOME/yarn/hadoop-2.2.0&quot;
export</p>
<p>HADOOP_PREFIX=</p>
<p>&quot;$HADOOP_HOME/&quot;</p>
<p>export</p>
<p>YARN_HOME=$HADOOP_HOME
export</p>
<p>HADOOP_MAPRED_HOME=</p>
<p>&quot;$HADOOP_HOME&quot;</p>
<p>export</p>
<p>HADOOP_COMMON_HOME=</p>
<p>&quot;$HADOOP_HOME&quot;
export</p>
<p>HADOOP_HDFS_HOME=</p>
<p>&quot;$HADOOP_HOME&quot;</p>
<p>export</p>
<p>HADOOP_CONF_DIR=</p>
<p>&quot;$HADOOP_HOME/etc/hadoop/&quot;
export</p>
<p>YARN_CONF_DIR=$HADOOP_CONF_DIR</p>
<p>export</p>
<p>PATH=</p>
<p>&quot;$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH&quot;</p>
<p>以上操作注意2点：</p>
<ol>
<li>jdk一定要保证是64bit的</li>
</ol>
<p>2.HADOOP_PREFIX极其重要，主要是为了兼容MRv1，优先级最高（比 如寻找conf目录，即使我们配置了HADOOP_CONF_DIR,启动脚本依然会优先从$HADOOP_PREFIX/conf/里查找），一定要保 证此变量正确配置(也可不设置，则默认使用HADOOP_HOME/etc/hadoop/下的配置文件)</p>
<p><strong>**</strong>2.3 改官方启动脚本的bug**</p>
<p><em>**</em>说明：此版本虽然是release稳定版，但是依然有非常弱智的bug存在。</p>
<p>正常情况下，启动守护进程$YARN_HOME/sbin/hadoop-daemons.sh中可以指定node.</p>
<p>我们看下该启动脚本的说明：
1</p>
<p>2
$sbin</p>
<p>/hadoop-daemons</p>
<p>.sh</p>
<p>Usage:hadoop-daemons.sh [--config confdir] [--hosts hostlistfile] [start|stop]</p>
<p>command</p>
<p>args...</p>
<p>可以看到--hosts可以指定需要启动的存放节点名的文件名：</p>
<p>但这是无效的，此脚本调用的$YARN_HOME/libexec/hadoop-config.sh脚本有bug.</p>
<p>先建一个文件datanodefile 添加datanode节点，放入conf/文件夹下，然后执行一下启动脚本：
1</p>
<p>2
$sbin</p>
<p>/hadoop-daemons</p>
<p>.sh --hosts datanodefile start datanode</p>
<p>at:</p>
<p>/home/grid/yarn/hadoop-2</p>
<p>.2.0</p>
<p>/etc/hadoop//126571</p>
<p>:No such</p>
<p>file</p>
<p>or directory</p>
<p>分析脚本，定位到嵌套脚本$YARN_HOME/libexec/hadoop-config.sh第96行：</p>
<p>196        </p>
<p>export</p>
<p>HADOOP_SLAVES=</p>
<p>&quot;${HADOOP_CONF_DIR}/$$1&quot;</p>
<p>看到红色部分是不对的，应该修改为：</p>
<p>196        </p>
<p>export</p>
<p>HADOOP_SLAVES=</p>
<p>&quot;${HADOOP_CONF_DIR}/$1&quot;</p>
<p>备注1：此版本11月初发布至今，网上教程不论中文还是英文，均未提及此错误。</p>
<p>备注2：$YARN_HOME/libexec/hadoop-config.sh中分析hostfile的逻辑非常脑残：
1</p>
<p>2
3</p>
<p>4
593    </p>
<p>if</p>
<p>[</p>
<p>&quot;--hosts&quot;</p>
<p>=</p>
<p>&quot;$1&quot;</p>
<p>]</p>
<p>94    </p>
<p>then
95        </p>
<p>shift</p>
<p>96        </p>
<p>export</p>
<p>HADOOP_SLAVES=</p>
<p>&quot;${HADOOP_CONF_DIR}/%$1&quot;
97        </p>
<p>shift</p>
<p>因此，用户只能将自己的hostfile放在${HADOOP_CONF_DIR}/ 下面，放在其它地方是无效的。</p>
<p>备注3：按照$YARN_HOME/libexec/hadoop-config.sh脚本的逻辑，还有一种方式指定host
1$hadoop-daemons.sh –hostnames cluster1 start datanode</p>
<p>注意，因为bash脚本区分输入参数的分割符为\t或\s，所以限制了此种方式只能指定一个单独的节点</p>
<p>总结以上分析和修改步骤：
1</p>
<p>2
3</p>
<p>4
5$</p>
<p>cd</p>
<p>$YARN_HOME</p>
<p>/libexec/</p>
<p>$vim hadoop-config.sh
/#修改第96行代码为：</p>
<p>export</p>
<p>HADOOP_SLAVES=</p>
<p>&quot;${HADOOP_CONF_DIR}/$1&quot;
/#保存退出vim</p>
<p><strong>**</strong>2.4 配置文件设置**</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
 1 <!--$YARN_HOME/etc/hadoop/core-site.xml--> 2                                                                                                                                                                                                                                  3 &lt;?xml version=&quot;1.0&quot;?&gt; 4 &lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt; 5                                                                                                                                                                                                                                  6 <configuration> 7 <property> 8 <name>fs.defaultFS</name> 9   <value>hdfs://cluster1:9000</value>10 </property>11                                                                                                                                                                                                                                 12 <property>13 <name>hadoop.tmp.dir</name>14   <value>/home/grid/hadoop-2.2.0-src/hadoop-dist/target/hadoop-2.2.0//yarn_data/tmp/hadoop-grid</value>15 </property>16 </configuration>17   备注1：注意fs.defaultFS为新的变量，代替旧的：fs.default.name18 19  备注2：tmp文件夹放在我们刚才新建的$HOME/yarn/yarn_data/下面。20 21     <!--$YARN_HOME/etc/hadoop/hdfs-site.xml-->22 <configuration>23     <property>24     <name>dfs.replication</name>25     <value>3</value>26     </property>27 </configuration></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><em>**</em>备注1. 新：dfs.namenode.name.dir，旧：dfs.name.dir，新：dfs.datanode.name.dir，旧：dfs.data.dir</p>
<p><em>**</em>备注2. dfs.replication确定 data block的副本数目，hadoop基于rackawareness(机架感知)默认复制3份分block,（同一个rack下两个，另一个rack下一 份，按照最短距离确定具体所需block, 一般很少采用跨机架数据块，除非某个机架down了）</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
 1     <!--$YARN_HOME/etc/hadoop/yarn-site.xml--> 2                                                                                                                                                                                                                             3 <configuration> 4    <property> 5      <name>yarn.nodemanager.aux-services</name> 6      <value>mapreduce_shuffle</value> 7   </property> 8                                                                                                                                                                                                                             9   <property>10      <name>yarn.resourcemanager.address</name>11      <value>cluster1:8032</value>12   </property>13                                                                                                                                                                                                                            14   <property>15       <name>yarn.resourcemanager.resource-tracker.address</name>16       <value>cluster1:8031</value>17   </property>18                                                                                                                                                                                                                            19   <property>20       <name>yarn.resourcemanager.admin.address</name>21       <value>cluster1:8033</value>22   </property>23                                                                                                                                                                                                                            24   <property>25       <name>yarn.resourcemanager.scheduler.address</name>26       <value>cluster1:8030</value>27   </property>28                                                                                                                                                                                                                            29   <property>30       <name>yarn.nodemanager.loacl-dirs</name>31       <value>/home/grid/hadoop-2.2.0-src/hadoop-dist/target//hadoop-2.2.0/yarn_data/mapred/nodemanager</value>32       <final>true</final>33   </property>34                                                                                                                                                                                                                            35   <property>36       <name>yarn.web-proxy.address</name>37       <value>cluster1:8888</value>38   </property>39                                                                                                                                                                                                                            40   <property>41      <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>42      <value>org.apache.hadoop.mapred.ShuffleHandler</value>43   </property>44 </configuration></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>在此特意提醒：</strong></p>
<p>(1) 目前网上盛传的各种hadoop2.2的基于分布式集群的安装教程大部分都是错的,hadoop2.2配置里最重要的也莫过于yarn-site.xml里的变量了吧？</p>
<p>(2)不同于单机安装，基于集群的搭建必须设置</p>
<p>yarn-site.xml可选变量yarn.web-proxy.address
和</p>
<p>yarn.nodemanager.loacl-dirs
外的其它所有变量！后续会专门讨论yarn-site.xml里各个端口配置的含义。</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
1 <!--$YARN_HOME/etc/hadoop/mapred-site.xml-->2                                                                                                                                                                                                            3 <configuration>4     <property>5         <name>mapreduce.framework.name</name>6         <value>yarn</value>7     </property>8 </configuration></p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>备注1：新的计算框架取消了实体上的jobtracker, 故不需要再指定mapreduce.jobtracker.addres，而是要指定一种框架，这里选择yarn. 备注2：hadoop2.2.还支持第三方的计算框架，但没怎么关注过。
          配置好以后将$HADOOP_HOME下的所有文件，包括hadoop目录分别copy到其它3个节点上。</p>
<p><strong>2.5**</strong>各节点功能规划**</p>
<p>确保在每主机的/etc/hosts里添加了所有node的域名解析表（i.e.cluster1   198.0.0.1）；iptables已关闭；/etc/sysconfig/network-script/ifcfg-eth0里 BOTPROTO=static；/etc/sysconfig/network文件里已设置了各台主机的hostname, 静态ip地址，且已经重启过每台机器；jdk和hadoop都为64bit；ssh免登陆已配置；完成以上几项后，就可以启动hadoop2.2.0了。</p>
<p>注意到从头到尾都没有提到Master, Slave,也没有提到namenode,datanode,是因为，新的计算框架，新的hdfs中不存在物理上的Master节点，所有的节点都是等价的。</p>
<p>各节点职能划分在篇首已有说明， 在此重提一下：
1</p>
<p>2
3</p>
<p>4
cluster1    resourcemanager, nodemanager, proxyserver,historyserver, datanode, namenode,</p>
<p>cluster2    datanode, nodemanager
cluster3    datanode, nodemanager</p>
<p>cluster4    datanode, nodemanager</p>
<p><strong>2.6 hdfs 格式化</strong></p>
<p>1$bin</p>
<p>/hdfs</p>
<p>namenode –</p>
<p>format</p>
<p>(注意：hadoop 2.2.0的格式化步骤和旧版本不一样，旧的为 $YARN_HOME/bin/hadoop namenode –format)</p>
<p><strong>2.7 hadoop整体启动</strong></p>
<p><em>**</em>启动方式（1）分别登录各自主机开启</p>
<p>在cluster1节点上，分别启动resourcemanager,nodemanager, proxyserver, historyserver, datanode, namenode,</p>
<p>在cluster2, cluster3, cluster4 节点主机上，分别启动datanode,nodemanager</p>
<p><strong>备注</strong>：如果resourcemanager是 独立的，则除了resourcemanager,其余每一个节点都需要一个nodemanager，我们可以在$YARN_HOME/etc /hadoop/下新建一个nodehosts, 在里面添加所有的除了resourcemanager外的所有node，因为此处我们配置的resourcemanager和namenode是同一台主 机，所以此处也需要添加nodemanager</p>
<p>执行步骤如下：
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
7</p>
<p>8
9</p>
<p>10
11</p>
<p>12
13$</p>
<p>hostname</p>
<p>/#查看host名字</p>
<p>cluster1
$sbin</p>
<p>/hadoop-daemon</p>
<p>.sh  --script hdfs start namenode</p>
<p>/# 启动namenode</p>
<p>$sbin</p>
<p>/hadoop-daemon</p>
<p>.sh --script hdfs start datanode</p>
<p>/# 启动datanode
$sbin</p>
<p>/yarndaemon</p>
<p>.shstart nodemanager</p>
<p>/#启动nodemanager</p>
<p>$sbin</p>
<p>/yarn-daemon</p>
<p>.sh   start resourcemanager</p>
<p>/# 启动resourcemanager
$sbin</p>
<p>/yarn-daemon</p>
<p>.shstart proxyserver</p>
<p>/# 启动web App proxy, 作用类似jobtracker,若yarn-site.xml里没有设置yarn.web-proxy.address的host和端口，或者设置了和 resourcemanager相同的host和端口，则hadoop默认proxyserver和resourcemanager共享 host:port</p>
<p>$sbin</p>
<p>/mr-jobhistory-daemon</p>
<p>.sh   start historyserver</p>
<p>/#你懂得
$</p>
<p>ssh</p>
<p>cluster2 </p>
<p>/#登录cluster2</p>
<p>$</p>
<p>hostname</p>
<p>/#查看host名字cluster2
$sbin</p>
<p>/yarndaemon</p>
<p>.shstart nodemanager</p>
<p>/# 启动nodemanager</p>
<p>$sbin</p>
<p>/hadoop-daemon</p>
<p>.sh  --script hdfs start datanode</p>
<p>/# 启动datanode
$</p>
<p>ssh</p>
<p>cluster3 </p>
<p>/#登录cluster3.../# cluster2, cluster3, cluster4启动方式和cluster2一样。</p>
<p>启动方式（2）使用hadoop自带的批处理脚本开启</p>
<p>Step1.确认已登录cluster1:
1$</p>
<p>hostname</p>
<p>cluster1</p>
<p>在$YARN_HOME/etc/hadoop/下新建namenodehosts,添加所有namenode节点</p>
<p>1</p>
<p>2</p>
<p>$</p>
<p>cat</p>
<p>$YARN_HOME</p>
<p>/etc/hadoop/namenodehosts</p>
<p>cluster1</p>
<p>在$YARN_HOME/etc/hadoop/下新建datanodehosts,添加所有datanode节点</p>
<p>1</p>
<p>2
3</p>
<p>4
$</p>
<p>cat</p>
<p>$YARN_HOME</p>
<p>/etc/hadoop/datanodehosts</p>
<p>cluster2
cluster3</p>
<p>cluster4</p>
<p>在$YARN_HOME/etc/hadoop/下新建nodehosts,添加所有datanode和namenode节点</p>
<p>1</p>
<p>2
3</p>
<p>4
5$</p>
<p>cat</p>
<p>$YARN_HOME</p>
<p>/etc/hadoop/datanodehosts</p>
<p>cluster1
cluster2</p>
<p>cluster3
cluster4</p>
<p><strong>备注</strong>：以上的hostfile名字是随便起的，可以是任意的file1,file2,file3, 但是必须放在$YARN_HOME/etc/hadoop/下面！</p>
<p>Step2.执行脚本
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
$sbin</p>
<p>/hadoop-daemons</p>
<p>.sh--hosts namenodehosts --script  hdfsstart  namenode</p>
<p>$sbin</p>
<p>/hadoop-daemons</p>
<p>.sh--hosts datanodehosts --script  hdfsstart  datanode
$sbin</p>
<p>/yarn-daemons</p>
<p>.sh--hostnames cluster1 start resourcemanager</p>
<p>$sbin</p>
<p>/yarn-daemons</p>
<p>.sh--hosts allnodehosts start nodemanager
$sbin</p>
<p>/yarn-daemons</p>
<p>.sh--hostnames cluster1 start proxyserver</p>
<p>$sbin</p>
<p>/mr-jobhistory-daemon</p>
<p>.sh   start  historyserver</p>
<p><strong>在这里不得不纠正一个其他教程上关于对hadoop2.2做相关配置和运行时的错误!</strong></p>
<p>我们在core-site.xml指定了default filesystem为cluster1, 并指定了其节点ip（或节点名）和端口号， 这意味着若启动hadoop时不额外添加配置（启动hadoop时命令行里加--conf指定用户配置文件的存放位置)，则默认的namenode就一 个，那就是cluster1, 如果随意指定namenode必然会出现错误！</p>
<p>如果你要还要再启动一个新的namenode(以cluster3为例)，则必须如下操作：</p>
<p>a. 新建一个core-site.xml，添加fs.defaultFS的value为hdfs://cluster3:9000</p>
<p>b. command：
1$sbin</p>
<p>/hadoop-daemon</p>
<p>.sh --hostnames cluster3 --conf you_conf_dir --script hdfs --start namenode</p>
<p>我们之前启动的namenode为cluster1, 假如要查看放在此文件系统根目录下的文件input_file，则它的完整路径为 hdfs://cluster1:9000/input_file</p>
<p>Step3.查看启动情况</p>
<p>在cluster1上：
1</p>
<p>2
3</p>
<p>4
5</p>
<p>6
$jps</p>
<p>22411 NodeManager
23356 Jps</p>
<p>22292 ResourceManager
22189 DataNode</p>
<p>22507 WebAppProxyServer</p>
<p>在cluster2上</p>
<p>1</p>
<p>2
3</p>
<p>4
$jps</p>
<p>8147 DataNode
8355 Jps</p>
<p>8234 NodeManagercluster3，cluster4上和cluster2一样。</p>
<p><em>**</em>Step4.查看各节点状态以及yarncluster运行状态</p>
<p>（1）查看各节点状态</p>
<p>FireFox进入： <a href="http://cluster1:50070(cluster1为namenode所在节点" target="_blank">http://cluster1:50070(cluster1为namenode所在节点</a>)</p>
<p>在主页面（第一张图）上点击Live Node，查看（第二张图）上各Live Node状态：</p>
<p><img src="http://m1.img.libdd.com/farm4/d/2013/1114/14/5D0856F11A09F93C0BD97246AE6DEE43_B500_900_500_218.png" alt=""></p>
<p>（2）查看resourcemanager上cluster运行状态</p>
<p>Firefox进入：<a href="http://cluster2:8088(node1为resourcemanager所在节点" target="_blank">http://cluster2:8088(node1为resourcemanager所在节点</a>)</p>
<p><img src="http://m3.img.libdd.com/farm4/d/2013/1114/14/5B46215F81D52CF3C3DB80D2DEFF8770_B500_900_500_195.png" alt=""></p>
<p><strong> </strong>Step5. Cluster上MapReduce测试</p>
<p>现提供3个test cases</p>
<p><strong>Test Case 1 testimated_value_of_pi</strong></p>
<p>command:
$sbin/yarnjar $YARN_HOME/share/hadoop//mapreduce/hadoop-mapreduce-examples-2.2.0.jar \pi 101000000</p>
<p>console输出：</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
Number of Maps  =10                        Samples per Map = 1000000                         Wrote input for Map /#0                          Wrote input for Map /#1                          Wrote input for Map /#2                         Wrote input for Map /#3                        Wrote input for Map /#4                       Wrote input for Map /#5                         Wrote input for Map /#6                        Wrote input for Map /#7                        Wrote input for Map /#8                        Wrote input for Map /#9                        Starting Job                        13/11/06 23:20:07 INFO Configuration.deprecation: mapred.map.tasksis deprecated. Instead, use mapreduce.job.maps                        13/11/06 23:20:07 INFO Configuration.deprecation:mapred.output.key.class is deprecated. Instead, usemapreduce.job.output.key.class                         13/11/06 23:20:07 INFO Configuration.deprecation:mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir                         13/11/06 23:20:11 INFO mapreduce.JobSubmitter: Submittingtokens for job: job_1383806445149_0001                         13/11/06 23:20:15 INFO impl.YarnClientImpl: Submittedapplication application_1383806445149_0001 to ResourceManager at /0.0.0.0:8032                       13/11/06 23:20:16 INFO mapreduce.Job: The url to trackthe job: <a href="http://Node1:8088/proxy/application_1383806445149_0001/" target="_blank">http://Node1:8088/proxy/application_1383806445149_0001/</a>                        13/11/06 23:20:16 INFO mapreduce.Job: Running job:job_1383806445149_0001                         13/11/06 23:21:09 INFO mapreduce.Job: Jobjob_1383806445149_0001 running in uber mode : false                        13/11/06 23:21:10 INFO mapreduce.Job:  map 0% reduce 0%                          13/11/06 23:24:28 INFO mapreduce.Job:  map 20% reduce 0%                         13/11/06 23:24:30 INFO mapreduce.Job:  map 30% reduce 0%                          13/11/06 23:26:56 INFO mapreduce.Job:  map 57% reduce 0%                          13/11/06 23:26:58 INFO mapreduce.Job:  map 60% reduce 0%                          13/11/06 23:28:33 INFO mapreduce.Job:  map 70% reduce 20%                         13/11/06 23:28:35 INFO mapreduce.Job:  map 80% reduce 20%                         13/11/06 23:28:39 INFO mapreduce.Job:  map 80% reduce 27%                         13/11/06 23:30:06 INFO mapreduce.Job:  map 90% reduce 27%                         13/11/06 23:30:09 INFO mapreduce.Job:  map 100% reduce 27%                         13/11/06 23:30:12 INFO mapreduce.Job:  map 100% reduce 33%                         13/11/06 23:30:25 INFO mapreduce.Job:  map 100% reduce 100%                          13/11/06 23:30:54 INFO mapreduce.Job: Jobjob_1383806445149_0001 completed successfully                          13/11/06 23:31:10 INFO mapreduce.Job: Counters: 43                                    File SystemCounters                                             FILE:Number of bytes read=226                                             FILE:Number of bytes written=879166                                              FILE:Number of read operations=0                                             FILE:Number of large read operations=0                                            FILE:Number of write operations=0                                             HDFS:Number of bytes read=2590                                               HDFS:Number of bytes written=215                                               HDFS:Number of read operations=43                                               HDFS:Number of large read operations=0                                                 HDFS:Number of write operations=3                                    JobCounters                                              Launchedmap tasks=10                                                Launchedreduce tasks=1                                               Data-localmap tasks=10                                                Totaltime spent by all maps in occupied slots (ms)=1349359                                             Totaltime spent by all reduces in occupied slots (ms)=190811                                    Map-ReduceFramework                                             Mapinput records=10                                              Mapoutput records=20                                                Mapoutput bytes=180                                                 Mapoutput materialized bytes=280                                                Inputsplit bytes=1410                                                 Combineinput records=0                                                Combineoutput records=0                                                  Reduceinput groups=2                                                 Reduceshuffle bytes=280                                              Reduceinput records=20                                                Reduceoutput records=0                                                 SpilledRecords=40                                                 ShuffledMaps =10                                                  FailedShuffles=0                                                MergedMap outputs=10                                                 GCtime elapsed (ms)=45355                                                 CPUtime spent (ms)=29860                                                 Physicalmemory (bytes) snapshot=1481818112                                                 Virtualmemory (bytes) snapshot=9214468096                                                 Totalcommitted heap usage (bytes)=1223008256                                        ShuffleErrors                                              BAD_ID=0                                              CONNECTION=0                                             IO_ERROR=0                                              WRONG_LENGTH=0                                               WRONG_MAP=0                                            WRONG_REDUCE=0                                    File InputFormat Counters                                              BytesRead=1180                                    File OutputFormat Counters                                             BytesWritten=97                           13/11/06 23:31:15 INFO mapred.ClientServiceDelegate:Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirectingto job history server                           Job Finished in 719.041 seconds                           Estimated value of Pi is 3.14158440000000000000</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>说明</strong>：可以看到最后输出值为该job使用了 10个maps, job id为job<em>1383806445149_000, 最后计算得Pi的值为13.14158440000000000000， job Id分配原则为job</em>年月日时分<em>job序列号，序列号从0开始，上限值为1000， task id分配原则为job</em>年月日时分<em>job序列号_task序列号_m, job</em>年月日时分_job序列号_task序列号_r, m代表map taskslot , r代表reduce task slot, task 序列号从0开始，上限值为1000.</p>
<p><strong>Test Case 2 random_writting</strong>
/#command line $sbin/yarnjar $YARN_HOME/share/hadoop//mapreduce/hadoop-mapreduce-examples-2.2.0.jar \randomwriter/user/grid/test/test_randomwriter/out</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>/#Console输出摘录：                                                                                                                                                    Running 10 maps.Job started: Wed Nov 0623:42:17 PST 201313/11/0623:42:17 INFO client.RMProxy: Connecting toResourceManager at /0.0.0.0:803213/11/0623:42:19 INFO mapreduce.JobSubmitter: number ofsplits:1013/11/0623:42:20 INFO mapreduce.JobSubmitter: Submittingtokens for job: job_1383806445149_000213/11/0623:42:21 INFO impl.YarnClientImpl: Submittedapplication application_1383806445149_0002 to ResourceManager at /0.0.0.0:803213/11/0623:42:21 INFO mapreduce.Job: The url to trackthe job: <a href="http://Master:8088/proxy/application_1383806445149_0002/13/11/0623:42:21" target="_blank">http://Master:8088/proxy/application_1383806445149_0002/13/11/0623:42:21</a> INFO mapreduce.Job: Running job:job_1383806445149_000213/11/0623:42:40 INFO mapreduce.Job: Jobjob_1383806445149_0002 running in uber mode : false13/11/0623:42:40 INFO mapreduce.Job:  map 0% reduce 0%                  13/11/0623:55:02 INFO mapreduce.Job:  map 10% reduce 0%                    13/11/0623:55:14 INFO mapreduce.Job:  map 20% reduce 0%                  13/11/0623:55:42 INFO mapreduce.Job:  map 30% reduce 0%                    13/11/0700:06:55 INFO mapreduce.Job:  map 40% reduce 0%                    13/11/0700:07:10 INFO mapreduce.Job:  map 50% reduce 0%                   13/11/0700:07:36 INFO mapreduce.Job:  map 60% reduce 0%                    13/11/0700:13:47 INFO mapreduce.Job:  map 70% reduce 0%                     13/11/0700:13:54 INFO mapreduce.Job:  map 80% reduce 0%                     13/11/0700:13:58 INFO mapreduce.Job:  map 90% reduce 0%                    13/11/0700:16:29 INFO mapreduce.Job:  map 100% reduce 0%                    13/11/0700:16:37 INFO mapreduce.Job: Jobjob_1383806445149_0002 completed successfully        File OutputFormat Counters                  BytesWritten=10772852496Job ended: Thu Nov 0700:16:40 PST 2013The job took 2062 seconds.</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>说明</strong>：电脑存储空间足够的话，可以从hdfs里down下来看看。</p>
<p>现只能看一看输出文件存放的具体形式：</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
./bin/hadoopfs -ls /user/grid/test/test_randomwriter/out/Found 11items-rw-r--r--   2 grid supergroup          02013-11-0700:16/user/grid/test/test_randomwriter/out/_SUCCESS-rw-r--r--   2 grid supergroup 10772782142013-11-0623:54 /user/grid/test/test_randomwriter/out/part-m-00000                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772827512013-11-0623:55 /user/grid/test/test_randomwriter/out/part-m-00001                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772802982013-11-0623:55 /user/grid/test/test_randomwriter/out/part-m-00002                                                                                                                                                   -rw-r--r--   2 grid supergroup 10773031522013-11-0700:07 /user/grid/test/test_randomwriter/out/part-m-00003                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772842402013-11-0700:06 /user/grid/test/test_randomwriter/out/part-m-00004                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772866042013-11-0700:07 /user/grid/test/test_randomwriter/out/part-m-00005                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772843362013-11-0700:13 /user/grid/test/test_randomwriter/out/part-m-00006                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772848292013-11-0700:13 /user/grid/test/test_randomwriter/out/part-m-00007                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772897062013-11-0700:13 /user/grid/test/test_randomwriter/out/part-m-00008                                                                                                                                                   -rw-r--r--   2 grid supergroup 10772783662013-11-0700:16 /user/grid/test/test_randomwriter/out/part-m-00009</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>Test Case3 word_count</strong></p>
<p>（1）Locaol上创建文件：
$mkdirinput%echo ‘hello,world’ &gt;&gt; input/file1.in$echo ‘hello, ruby’ &gt;&gt; input/file2.in</p>
<p>（2）上传到hdfs上：
./bin/hadoop fs -mkdir -p /user/grid/test/test_wordcount/./bin/hadoop fs –put input/user/grid/test/test_wordcount/in</p>
<p>（3）用yarn新计算框架运行mapreduce：</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
/#command line $bin/yarn jar$YARN_HOME/share/hadoop//mapreduce/hadoop-mapreduce-examples-2.2.0.jarwordcount  /user/grid/test/test_wordcount/in/user/grid/test/test_wordcount/out                                                                                                                                             /#ConSole输出摘录：3/11/0700:35:03 INFO client.RMProxy:Connecting to ResourceManager at /0.0.0.0:803213/11/0700:35:05 INFO input.FileInputFormat:Total input paths to process : 213/11/0700:35:05 INFO mapreduce.JobSubmitter:number of splits:213/11/0700:35:06 INFO mapreduce.JobSubmitter:Submitting tokens for job: job_1383806445149_000313/11/0700:35:08 INFO impl.YarnClientImpl:Submitted application application_1383806445149_0003 to ResourceManager at /0.0.0.0:803213/11/0700:35:08 INFO mapreduce.Job: The urlto track the job: <a href="http://Master:8088/proxy/application_1383806445149_0003/13/11/0700:35:08" target="_blank">http://Master:8088/proxy/application_1383806445149_0003/13/11/0700:35:08</a> INFO mapreduce.Job: Runningjob: job_1383806445149_000313/11/0700:35:25 INFO mapreduce.Job: Jobjob_1383806445149_0003 running in uber mode : false13/11/0700:35:25 INFO mapreduce.Job:  map 0% reduce 0%                                                                                                                                              13/11/0700:37:50 INFO mapreduce.Job:  map 33% reduce 0%                                                                                                                                              13/11/0700:37:54 INFO mapreduce.Job:  map 67% reduce 0%                                                                                                                                              13/11/0700:37:55 INFO mapreduce.Job:  map 83% reduce 0%                                                                                                                                              13/11/0700:37:58 INFO mapreduce.Job:  map 100% reduce 0%                                                                                                                                              13/11/0700:38:51 INFO mapreduce.Job:  map 100% reduce 100%                                                                                                                                              13/11/0700:38:54 INFO mapreduce.Job: Jobjob_1383806445149_0003 completed successfully13/11/0700:38:56 INFO mapreduce.Job:Counters: 43</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p><strong>说明</strong>：查看word count的计算结果：
1</p>
<p>2
3</p>
<p>4
$bin</p>
<p>/hadoop</p>
<p>fs -</p>
<p>cat</p>
<p>/user/grid/test//test_wordcount/out/</p>
<p>/*</p>
<p>hadoop 1
hello  1</p>
<p>ruby</p>
<p><strong>补充</strong>：因为新的YARN为了保持与MRv1框 架的旧版本兼容性，很多老的API还是可以用，但是会有INFO。此处通过修改$YARN_HOME/etc/hadoop /log4j.properties可以turn offconfiguration deprecation warnings.</p>
<p>建议去掉第138行的注释（可选），确保错误级别为WARN（默认为INFO级别，详见第20行：hadoop.root.logger=INFO,console）：
1138 log4j.logger.org.apache.hadoop.conf.Configuration.deprecation=WARN</p>
<p>附文：</p>
<p><strong>集群搭建、配置步骤（基于CentOS_64bit）</strong></p>
<p><strong>0. 说明</strong></p>
<p>大体规划如下：</p>
<p>虚拟机： VMware-workstation-full-8.0.3-703057（VMware10中文版不完整，此版本内含vmware tools，为设定共享文件夹所必须）</p>
<p>电脑1，VMWare,内装2个虚拟系统，(cluster1, cluster2)</p>
<p>电脑2,，VMware内装2个虚拟系统，(cluster3, cluster4)</p>
<p>虚拟主机： CentOS x86 64bit</p>
<p>局域网IP设置：<em>**</em>
1</p>
<p>2
3</p>
<p>4</p>
<p>cluster1  172.16.102. 201</p>
<p>cluster2   172.16.102. 202
cluster3   172.16.102. 203</p>
<p>cluster4   172.16.102. 204</p>
<p>网关</p>
<p>1172.16.102.254</p>
<p><strong>1. Linux集群安装</strong></p>
<p>(1) 准备</p>
<p>Vmware: VMware-workstation-full-8.0.3-703057(此安装包自带VMWare Tools)</p>
<p>Linux:CentOS.iso</p>
<p>(2) VMWare配置</p>
<p>VMWare以及所有安装的虚拟机均为桥接</p>
<p>Step1. 配置VMWare 联网方式： Editor-&gt;Virtual Network Editor-&gt;选择Bridged， 点击确定</p>
<p>Step2. 安装虚拟机</p>
<p>Step3.配置各虚拟机接网方式：右键已安装虚拟机-&gt;点击NetworkAdapter, 选择桥接，确定</p>
<p>Step4. 为所有安装好的虚拟系统设置一个共享目录(类似FTP，但是设置共享目录更方便) ：右键已安装虚拟机-&gt;点击Virtual Machine Settings对话框上部Options， 选择Shared Folder， 在本地新建SharedFolder并添加进来,确定。</p>
<p>(3) linux下网卡以及IP配置</p>
<p>以下配置在三个虚拟系统里均相同, 以cluster1为例：</p>
<p>配置前需切换为root</p>
<p>Step1. 修改主机名， 设置为开启网络</p>
<p>配置/etc/sysconfig/network：
1</p>
<p>2
3[root@localhost ~]</p>
<p>/# cat /etc/sysconfig/network</p>
<p>NETWORKING=</p>
<p>yes
HOSTNAME=cluster1</p>
<p>Step2.修改当前机器的IP， 默认网关， IP分配方式， 设置网络接口为系统启动时有效：</p>
<p>a.查看配置前的ip:
1</p>
<p>2
3</p>
<p>4
[root@localhost ~]</p>
<p>/# ifconfig</p>
<p>eth0      Link encap:Ethernet  HWaddr 00:0C:29:E1:FB:95 
inet addr:172.16.102.3  Bcast:172.16.102.255  Mask:255.255.255.0</p>
<p>inet6 addr: fe80::20c:29ff:fee1:fb95</p>
<p>/64</p>
<p>Scope:Lin</p>
<p>b.配置/etc/sysconfig/network-scripts/ifcfg-eth0</p>
<p>注意以下几项：</p>
<p>BOOTPROTO=&quot;static&quot; (IP分配方式, 设为static则主机ip即为IPADDR里所设，若为”dhcp”, 此时只有局域网有效，则vmware会启动自带虚拟”dhcp”, 动态分配ip， 此时可以连接互联网 )</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
IPV6INIT=&quot;no&quot;  /#你懂得 IPADDR=&quot;172.16.102.201&quot; /#ip地址 GETEWAY=&quot;172.16.102.254&quot; /#默认网关地址 ONBOOT=&quot;yes&quot; /#系统启动时网络接口有效 [root@localhost ~]/# cat /etc/sysconfig/network-scripts/ifcfg-eth0  DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;HWADDR=&quot;00:0C:29:E1:FB:95&quot;BOOTPROTO=&quot;dhcp&quot;IPV6INIT=&quot;no&quot;IPADDR=&quot;172.16.102.201&quot;GETEWAY=&quot;172.16.102.254&quot;ONBOOT=&quot;yes&quot;NM_CONTROLLED=&quot;yes&quot;TYPE=&quot;Ethernet&quot;UUID=&quot;79612b26-326b-472c-94af-9ab151fc2831</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>c.使当前设置生效：
$service network restart $ifdown eth0 /#关闭默认网卡 $ifup eth/#重新启用默认网卡 $service network restart; ifdown eth0; ifup eth0</p>
<p>d.查看新设置的ip:
$ifconfigeth0      Link encap:Ethernet  HWaddr 00:0C:29:E1:FB:95  inet addr:192.168.1.200  Bcast:192.168.1.255  Mask:255.255.255.0inet6 addr: fe80::20c:29ff:fee1:fb95/64 Scope:Link UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</p>
<p>Step3. 修改hosts文件，此文件会被ＤＮＳ解析，类似linux里的alias, 设置后以后，hostname就是ip地址， 两者可以互换。</p>
<p>配置/etc/hosts, 添加三行如下， （注意，此3行在3个虚拟主机里都相同，切必须全部都要加上）</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a>
[root@localhost ~]/# cat /etc/hosts127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6 cluster1   172.16.102. 201cluster2   172.16.102. 202cluster3   172.16.102. 203cluster4   172.16.102. 204</p>
<p><a href="&quot;复制代码&quot;"><img src="http://common.cnblogs.com/images/copycode.gif" alt="复制代码"></a></p>
<p>Step4. 按照以上3个步骤分别设置两外两个虚拟主机，</p>
<p>配置完以后必须按照之前的三个命令分别重启 network, ifeth0:
$service network restart $ifdown eth0 $ifup eth0</p>
<p>重新初始化以后查看各自主机的ip配置是否正确。</p>
<p>在任意一台主机上执行： ping cluster1; ping cluster2; ping cluster3; ping cluster4</p>
<p>若配置正确，一定可以ping通，否则，请检查各个主机的/etc/hosts文件是否已经添加新的映射！至此，linux集群已成功配置。</p>
<p><strong>2. 设置 ssh免登陆</strong></p>
<p>a. 新建一个用户</p>
<p>在三台主机上分别以root权限新建一个用户，此处默认为grid:</p>
<p>cluster1,cluster2, cluster3, cluster4上：
$useradd –m grid $passwd grid 1qaz!QAZ</p>
<p>注意一定要保证4台主机上有相同的用户名， 以实现同一个用户在4台主机上登录。</p>
<p>b. 在cluster1上生成RSA密钥</p>
<p>切换回user: grid
$su grid $cd ~</p>
<p>生成密钥对：</p>
<p>1</p>
<p>2
3$</p>
<p>ssh</p>
<p>-keygen –t rsa</p>
<p>/#一路回车到最后（ 此处生成无需密码的秘钥-公钥对）。
/#上一个步骤 ssh-keygen –t rsa会在grid的home目录下生成一个.ssh文件夹</p>
<p>之后：</p>
<p>$cd ~/.ssh/$cp id_rsa.pub authorized_keys</p>
<p>c. 在另外3个主机上的grid用户home目录下也声称相应的密钥对, 并在.ssh目录下生成一个</p>
<p>authorized_keys
文件</p>
<p>d. 想办法将4台主机grid用户下刚生成的</p>
<p>authorized_keys
里的内容整合成一个完整的</p>
<p>authorized_keys.</p>
<p>比如将4个authorized_keys里的内容全部复制到cluster1上的authorized_keys里， 然后：
$chmod 600 authorized_keys $scp .ssh/authorized_keys  cluster2:/home/grid/.ssh/$scp .ssh/authorized_keys  cluster3:/home/grid/.ssh/$scp .ssh/authorized_keys  cluster4:/home/grid/.ssh/</p>
<p>若要求输入密码，则输入之前新建用户grid时设置的密码， 一路回车到最后.</p>
<p>e. 下面尝试ssh无秘钥登录：</p>
<p>在cluster1主机上：ssh cluster2， 依次尝试登陆cluster2, cluster3, cluster4</p>
<p>若均可可以免密码登录，则直接跳到下一步骤，否则，请看下面的解决方案：</p>
<p>可能出现的问题有3，</p>
<p>第一种可能，.ssh文件夹非自动生成，而是你手动新建的，若如此，会出现.ssh的安全上下文问题， 解决方案， 在三个主机上以grid用户，删除刚才生成的.ssh文件夹，重新进入home目录，务必用 /# ssh-keygen –t rsa 生成秘钥， 此过程ssh程序会自动在home目录下成成一个.ssh文件夹</p>
<p>第二种可能, authorized_keys权限不一致。 在各自.ssh目录下：ls–alauthorizedkeys,查看此文件的权限，一定为600(−rw−−−−−−−),即只对当前用户grid开放可读可写权限，若不是，则修改authorizedkeys文件权限chmod 600 authorized_keys</p>
<p>若经过以上两步还不行，则执行以下命令，重新启动ssh-agent， 且加入当前用户秘钥id_rsa
$ssh-add ~grid/.ssh/id_rsa</p>
<p>经过以上三步，一定可以实现grid从cluster1到其它3个节点的免秘钥登录。</p>
<p>因为hadoop2.2新架构的缘故，我们还应该设置为每一个节点到其它任意节点免登陆。</p>
<p>具体步骤:</p>
<p>1.在将cluster2, cluster3, cluster4上各自的.ssh/id_rsa.pub 分别复制到cluster1的.ssh/下： scp id_rsa.pub cluster1:/home/grid/.ssh/tmp2, scp id_rsa.pub cluster1:/home/grid/.ssh/tmp3 ...</p>
<p>2.将cluster1节点/home/grid/.ssh/下的tmp2, tmp3, tmp4分别appand到authorized_keys里， 并请将各自节点上的id_rsa.pub也append到各自节点的authorized_keys里，以实现本地登陆（类似： ssh localhost)</p>
<p>至此，ssh免秘钥登陆设置完成。</p>
<p><strong>3. 安装jdk</strong></p>
<p>Step1. 记得之前在安装cluster1时在VMWare里设置的共享目录吗？</p>
<p>在Windows下将Hadoop安装包，jdk安装包Copy到共享目录下，然后在linux下从/mnt/hgfs/Data-shared/下cp到/home/grid/下，直接执行jdk安装包，不需要解压。</p>
<p>注意：若在安装过程中提示”Extracting… install.sfx 5414: /lib/ld-linux.50.2 No such file or directory, 则执行以下命令:</p>
<p>a.我们之前为了测试自定义的ip是否有效，已将各台主机的ip分配方式设为了BOOTPROTO=”static”, 这种方式是无法连入外部网络的，所以此时为了安装缺省的包，切换到root, 修改/etc/sysconfig/network-script/ifcfg-eth0，将BOOTPROTO=”static” 修改为BOOTPROTO=”dhcp”,</p>
<p>b.重启网络服务和网卡: 在root权限下:
$service network restart; ifdown eth0; ifup eth0 $yum install glibc.i686</p>
<p>d.切换回grid,重新安装jdk</p>
<p>$cd /usr/java/  /#注意必须进入java文件夹，因为java安装包默认安装在当前目录下 $./jdk-6u25-linux-i586.bin /#安装jdk</p>
<p>安装完以后，记得将eth0文件修改回来：</p>
<p>$sed -i s/dhcp/static/g /etc/sysconfig/network-scripts/ifcfg-eth0 /#此处用sed直接替换，若不放心也可以用编辑器修改 /#service network restart; ifdown eth0;ifup eth0</p>
<p>至此，jdk已在linux下安装完毕。</p>
<p>最后，将java安装好的路径append到$PATH变量里（处于个人习惯，新环境变量一律添加到所需用户的.bashrc文件里， 即只对当前用户有效）
$su grid $vim ~/.bashrc （修改.bashrc文件，添加如下两行：） $tail -2 ~/.bashrc export JAVA_HOME=&quot;/usr/java/jdk1.6.0_25/&quot;export PATH=&quot;${PATH}:${JAVA_HOME}/bin&quot;</p>
<p>测试一下java是否可以正常启动：</p>
<p>$source ~/.bashrc $which java $/usr/java/jdk1.6.0_25/bin/java</p>
<p>至此，jdk安装完毕。</p>
<p>用同样的方式在另外3台虚拟主机上安装jdk, 提示：先复制到home下
$scp -r /mnt/hgfs/Data-shared/Archive/jdk-6u25-linux-i586.bin  cluster2:/home/grid/$scp -r /mnt/hgfs/Data-shared/Archive/jdk-6u25-linux-i586.bin  cluster3:/home/grid/$scp -r /mnt/hgfs/Data-shared/Archive/jdk-6u25-linux-i586.bin  cluster4:/home/grid/</p>
<p>再切root, copy到/usr/java下， cd /usr/java, 然后再安装.</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--深入理解Hadoop集群和网络/">深入理解Hadoop集群和网络</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--深入理解Hadoop集群和网络/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-hadoop-">深入理解Hadoop集群和网络</h1>
<p>原文出处： <a href="http://bradhedlund.com/2011/09/10/understanding-hadoop-clusters-and-the-network/" target="_blank">bradhedlund</a>   译文出处： <a href="http://blog.csdn.net/kickxxx/article/details/8230328" target="_blank">kickxxx</a></p>
<p>本文侧重于Hadoop集群的体系结构和方法，以及它与网络和服务器基础设施的关系。文章的素材主要来自于研究工作以及同现实生活中运行Hadoop集群客户的讨论。如果你也在你的数据中心运行产品级的Hadoop集群，那么我希望你能写下有价值的评论。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl01.png" title="srljhjqhwl01" target="_blank"><img src="&quot;srljhjqhwl01&quot;" alt=""></a></p>
<p>Hadoop集群部署时有三个角色：Client machines、 Master nodes和Slave nodes。</p>
<p>Master nodes负责Hadoop的两个关键功能：数据存储（HDFS）；以及运行在这个数据之上的并行计算，又称为Map-Reduce。Name node负责调度数据存储，而Job Tracker则负责并行数据处理的调度（使用Map-Reduce技术）。Slave nodes由大量的机器组成，完成数据存储以及运行计算这样的脏活。每个slave node都运行Data node和Task Tracker daemon，这些slave daemon和master nodes的相应daemon进行通信。Task tracker daemon由Job Tracker管理，Data node Daemon由Name node管理。</p>
<p>Client机器包含了Hadoop集群的所有设置，但是它既不是Master也不是Slave。Client的角色是向集群保存数据，提交Map-Reduce jobs（描述如何处理数据），获取查看MR jobs的计算结果。在小型集群中（40节点）你可能会发现一个物理机器扮演多个角色，比如既是Job Tracker又是Name node，在中等或者大规模集群中，一般都是用独立的服务器负责单独的角色。</p>
<p>在真正的产品集群中，不存在虚拟服务器和虚拟机平台，因为他们仅会导致不必要的性能损耗。Hadoop最好运行在linux机器上，直接工作于底层硬件之上。换句话说，Hadoop可以工作在虚拟机之上，对于学习Hadoop是一个不错的廉价方法，我本身就有一个6-node的Hadoop cluster运行Windows 7 laptop的VMware Workstation之上</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl02.png" title="srljhjqhwl02" target="_blank"><img src="&quot;srljhjqhwl02&quot;" alt=""></a></p>
<p>上图是Hadoop集群的典型架构。机架服务器（不是刀锋服务器）分布在多个机架中，连接到一个1GB(2GB)带宽的机架交换机，机架交换机连接到上一层的交换机，这样所有的节点通过最上层的交换机连接到一起。大部分的服务器都是Slave nodes配置有大的磁盘存储 中等的CPU和DRAM，少部分是Master nodes配置较少的存储空间 但是有强大的CPU和大DRAM</p>
<p>本文中，我们不讨论网络设计的各种细节，而是把精力放在其他方面。首先我们看下应用的工作流程。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl03.png" title="srljhjqhwl03" target="_blank"><img src="&quot;srljhjqhwl03&quot;" alt=""></a></p>
<p>为什么会出现Hadoop？ 它又解决了什么问题？ 简单的说，是由于商业和政府有大量的数据需要快速分析和处理，如果我们把这些巨大的数据切分为小的数据块分散到多台计算机中，并且用这些计算机并行处理分配给他们的小块数据，可以快速的得到结果，这就是Hadoop能做的事情。</p>
<p>在我们的简单例子中，我们有一个大文件保存着所有发给客户服务部分的邮件，想要快速统计单词”Refund”被输入了多少次，这个结果有助于评估对退换货部门的需求，以指定相应对策。这是一个简单的单词计数练习。Client上传数据到集群(File.txt)，提交一个job来描述如何分析数据，集群存储结果到一个新文件(Result.txt)，然后Client读取结果文件。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl04.png" title="srljhjqhwl04" target="_blank"><img src="&quot;srljhjqhwl04&quot;" alt=""></a></p>
<p>没有加载数据，Hadoop集群就没有任何用途。所以我们首先从加载大文件File.txt到集群中以便处理。目标是能够快速并行处理许多数据，为了达到这个目的需要尽可能多的机器能够同时操纵文件数据。Client把数据文件切分成许多小blocks，然后把他们分散到集群的不同机器上。块数越多，用来处理这些数据的机器就越多。同时这些机器一定会失效，所以要确保每个数据块保存到多个机器上以防止数据丢失。所以每个数据块在存入集群时会进行复制。Hadoop的标准设定是集群中的每个block有三份copy，这个配置可以由hdfs-site.xml的dfs.replication 参数设置</p>
<p>Client把文件File.txt分成3块，对于每一块，Client和Name node协商获取可以保存它以及备份块的Data nodes列表。Client然后直接写block数据到Data node，Data node负责写入数据并且复制copy到其他的Data nodes。重复操作，直到所有的块写完。Name node本身不参与数据保存，Name node仅仅提供文件数据位置以及数据可用位置（文件系统元数据）</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl05.png" title="srljhjqhwl05" target="_blank"><img src="&quot;srljhjqhwl05&quot;" alt=""></a></p>
<p>Hadoop引入了Rack Awareness的概念。作为Hadoop系统管理员，你能够手动定义集群中每一个slave Data node的rack号。为什么要把自己置于这种麻烦呢？有两个关键的原因：数据丢失和网络性能。记住每一个数据块都会被复制到多台Data node上，以防止某台机器失效导致数据丢失。有没有可能一份数据的所有备份恰好都在同一个机架上，而这个机架又出现了故障，比如交换机失效或者电源失效。为了防止这种情况，Name node需要知道Data nodes在网络拓扑中的位置，并且使用这个信息决定数据应该复制到集群的什么位置。</p>
<p>我们还假定同一机架的两台机器间相比不同机架的两台机器间 有更高的带宽和更低的网络延迟，在大部分情况下是正确的。机架交换机的上行带宽通常小于下行带宽。此外，机架内延迟通常低于机架间延迟。如果上面的假定成立，那么采用Rack Awareness既可以通过优化位置保护数据，同时提升网络性能，岂不是太cool了。是的，的确是这样，非常cool，对不对。</p>
<p>别急，Not cool的是Rack Awareness是需要手工定义的，并且要持续的更新它，并且保证这个信息精确。如果机架交换机可以自动提供它下面的Data node列表给Name node，那就更cool了。或者如果Data nodes可以自动告知Name node他们属于哪个交换机，一样很cool.</p>
<p>此外，让人感兴趣的是<a href="http://bradhedlund.com/2011/04/21/data-center-scale-openflow-sdn/" target="_blank">OpenFlow</a> 网络，Name node可以请求OpenFlow控制器关于节点位置的拓扑情况。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl06.png" title="srljhjqhwl06" target="_blank"><img src="&quot;srljhjqhwl06&quot;" alt=""></a></p>
<p>Client准备写文件File.txt到集群时，把文件划分为块，块A为第一个块。Client向Name node申请写文件File.txt，从Name node获得许可，并且接收到一个Data nodes列表（3个表项），每一个Data nodes用来写入块A的一个copy。Name node使用Rack Awareness来决定这个Data nodes列表。规则是：对于每一个数据块，两个 copy存放在一个机架上，另外一个copy存放在另外一个机架上。</p>
<p>在Client写Block A之前，它要知道准备接受”Block A“ copy的Data nodes是否以及做好了准备。首先，Client选择list中的第一个节点Data Node1，打开一个TCP50010链接然后请求：“hey，准备接受一个block，这是一个Data nodes列表（2个表项），Data node5和Data node6”，请确保他们两个也准备好了“；于是Data Node1打开一个到Data node5的TCP500100连接然后说：”Hey，准备接受一个block，这是一个Data nodes列表（1个表项），Data node6”，请确保他准备好了“；Data Node5同样会问Data Node6：“Hey, 准备好接收一个block吗“</p>
<p>”准备就绪“的响应通过已经创建好的TCP pipeline传回来，直到Data Node1发送一个”Ready”给Client。现在Client可以开始写入数据了。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl07.png" title="srljhjqhwl07" target="_blank"><img src="&quot;srljhjqhwl07&quot;" alt=""></a></p>
<p>写入数据的过程中，在涉及写操作的Data nodes之间创建一个复制pipeline。也就是说一个数据节点接收数据的同时，同时会把这份数据通过pipeline push到下一个Node中。</p>
<p>从上图可以看到，Rack Awareness起到了改善集群性能的做用。Data node5和Data node6在同一个机架上，因此pipeline的最后一步复制是发生在机架内，这就受益于机架内带宽以及低延迟。在Data node1, Data node5, Data node6完成block A之前，block B的操作不会开始。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl08.png" title="srljhjqhwl08" target="_blank"><img src="&quot;srljhjqhwl08&quot;" alt=""></a></p>
<p>当三个Nodes成功的接收到Block A后，挥发送”Block received”报告给Name node，同时发送”Success”到pipeline中，然后关闭TCP事务。Client在接收到Success信息后，通知Name node数据块已经成功的写入。Name node更新File.txt中Block A的metadata信息（包含Name locations信息）</p>
<p>Client现在可以开始Block B的传输了</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl09.png" title="srljhjqhwl09" target="_blank"><img src="&quot;srljhjqhwl09&quot;" alt=""></a></p>
<p>随着File.txt的块被写入，越来越多的Data nodes涉及到pipeline中，散落到机架内的热点，以及跨机架的复制</p>
<p>Hadoop占用了很多的网络带宽和存储空间。Hadoop专为处理大文件而生，比如TB级尺寸的文件。每一个文件在网络和存储中都被复制了三次。如果你有一个1TB的文件，那么将消耗3TB的网络带宽，同时要消耗3TB的磁盘空间存贮这个文件。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl10.png" title="srljhjqhwl10" target="_blank"><img src="&quot;srljhjqhwl10&quot;" alt=""></a></p>
<p>随着每块的复制pipeline的完成，文件被成功的写入集群。文件散落在集群内的机器上，每个机器保存文件的一小部分数据。组成文件的块数目越多，数据散落的机器就越多，将来更多的CPU和磁盘驱动器就能参与到并行处理中来，提供更强大更快的处理能力。这也是建造巨大集群的原动力。当机器的数变多，集群则变得wide，网络也相应的需要扩展。</p>
<p>扩展集群的另外一种方法是deep扩展。就是维持机器数据不便，而是增加机器的CPU处理能力和磁盘驱动器的数目。在这种情况下，需要提高网络的I/O吞吐量以适应增大的机器处理能力，因此如何让Hadoop集群运行10GB nodes称为一个重要的考虑。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl11.png" title="srljhjqhwl11" target="_blank"><img src="&quot;srljhjqhwl11&quot;" alt=""></a></p>
<p>Name node保存集群内所有文件的metadata，监督Data nodes的健康以及协调数据的存取。Name node是HDFS的控制中心。它本身并不保存任何cluster data。Name node知道一个文件由哪些块组成以及这些块存放在集群内的什么地方。Name node告诉Client需要和哪些Data node交互，管理集群的存储容量，掌握Data node的健康状况，确保每一个数据块都符合系统备份策略。</p>
<p>Data node每3秒钟发送一个heartbeats给Name node ，二者使用TCP9000端口的TCP握手来实现heartbeats。每十个heartbeats会有一个block report，Data node告知它所保存的数据块。block report使得Namenode能够重建它的metadata以确保每个数据block有足够的copy，并且分布在不同的机架上。</p>
<p>Name node是Hadoop Distributed File System(HDFS)的关键部件。没有Name node，clients无法从HDFS读写数据，也无法执行Map Reduce jobs。因此Name node 最好配置为一台高冗余的企业级服务器：双电源，热插拔风扇，冗余NIC连接等。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl12.png" title="srljhjqhwl12" target="_blank"><img src="&quot;srljhjqhwl12&quot;" alt=""></a></p>
<p>如果Name node收不到某Data node的heartbeats，那么Name node假定这个Data node死机并且Data node上的所有数据也丢失了。通过这台dead Data node的block report，Name node知道哪些block copies需要复制到其他Data nodes。Name node参考Rack Awareness数据来选择接收新copy的Data node，并遵守以下复制规则：一个机架保存两份copies，另一个机架保存第三份copy。</p>
<p>考虑由于机架交换机或者机架电源失败导致的整个机架Data node都失效的情况。Name node将指导集群内的剩余Data nodes开始复制失效机架上的所有数据。如果失效机架上服务器的存储容量为12TB，那么这将导致数百TB的数据在网络中传输。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl13.png" title="srljhjqhwl13" target="_blank"><img src="&quot;srljhjqhwl13&quot;" alt=""></a></p>
<p>Secondary Name node是Hadoop的一种服务器角色。一个很普遍的误解是它提供了对Name node的高可用性备份，实际上不是。</p>
<p>Secondary Name node偶尔会连接到Name node(缺省为每小时)，同步Name node in-memory metadata以及保存metadata的文件。Secondary Name node合并这些信息到一个组新的文件中，保存到本地的同时把这些文件发送回Name Node。</p>
<p>当Name node宕机，保存在Secondary Name node中的文件可以用来恢复Name node。在一个繁忙的集群中，系统管理员可以配置同步时间为更小的时间间隔，比如每分钟。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl14.png" title="srljhjqhwl14" target="_blank"><img src="&quot;srljhjqhwl14&quot;" alt=""></a></p>
<p>当一个Client想要从HDFS获取一个文件时，比如job的输出结果。Client首先从Name node查询文件block的位置。Name node返回一个包含所有block位置的链表，每个block位置包含全部copies所在的Data node</p>
<p>Client选取一个数据块的Data node位置，通过TCP50010端口从这个Data node读取一块，在读取完当前块之前，Client不会处理下一块。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl15.png" title="srljhjqhwl15" target="_blank"><img src="&quot;srljhjqhwl15&quot;" alt=""></a></p>
<p>在某些情况下Data node daemon本身需要从HDFS读取数据块。比如Data Node被请求处理自身不存在的数据，因而它必须从网络上的其他Data node获得数据然后才能开始处理。</p>
<p>另外一种情况是Name node的Rack Awareness信息提供的网络优化行为。当Data node向Name node查询数据块位置信息，Name node优先查看请求者所在的机架内的Data nodes包含这个数据块。如果包含，那么Name node把这个Data node提供给请求的Data node。这样可以保证数据仅在in-rack内流动，可以加快数据的处理速度以及job的完成速度</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl16.png" title="srljhjqhwl16" target="_blank"><img src="&quot;srljhjqhwl16&quot;" alt=""></a></p>
<p>现在File.txt分散到集群的机器中这样就可以提供更快更有效的并行处理速度。Hadoop并行处理框架称为Map Reduce，名称来自于并行处理的两个重要步骤：Map和Reduce</p>
<p>第一步是Map 过程，这个步骤同时请求所有包含数据的Data node运行计算。在我们的例子中则是请求这些Data node统计存储在他们上的File.txt数据块包含多少此Refund</p>
<p>要达到这个目的，Client首先提交Map Reduce job给Job tracker，发送请求：“How many times does Refund occur in file.txt”。Job tracker向Name node查询哪些Data nodes包含文件File.txt的数据块。然后Job Tracker在这些Data nodes上运行Java代码 在Data node的本地数据上执行Map计算。Task Tracker启动一个Map task监测这些tasks的执行。Task Tracker通过heartbeats向Job Tracker汇报task的状态。</p>
<p>当每一个Map task都完成后，计算结果保存在这些节点的临时存储区内，我们称之为”intermediate data”。下一步是把这些中间数据通过网络发送给运行Reduce的节点以便完成最后的计算。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl17.png" title="srljhjqhwl17" target="_blank"><img src="&quot;srljhjqhwl17&quot;" alt=""></a></p>
<p>Job tracker总是尝试选择包含待处理数据的Data node做Map task，但是有时不会这样。比如，所有包含这块数据的Data node已经有太多的tasks正在运行，不再接收其他的task.</p>
<p>这种情况下，Job Tracker将询问Name node，Name node会根据Rack Awareness建议一个in-rack Data node。Job tracker把task分配给这个in-rack Data node。这个Data node会在Name node的指导下从包含待处理数据的in-rack Data node获取数据。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl18.png" title="srljhjqhwl18" target="_blank"><img src="&quot;srljhjqhwl18&quot;" alt=""></a></p>
<p>Map Reduce 框架的第二部分叫做Reduce。Map task已经完成了计算，计算结果保存在intermediate data。现在我们需要把所有的中间数据汇集到一起作进一步处理得到最终结果。</p>
<p>Job Tracker可以在集群内的任意一个node上执行Reduce，它指导Reduce task从所有完成Map trasks的Data node获取中间数据。这些Map tasks可能同时响应Reducer，这就导致了很多nodes几乎同时向单一节点发起TCP连接。我们称之为incast或者fan-in(微突发流)。如果这种微突发流比较多，那么就要求网络交换机有良好的内部流量管理能力，以及相应的buffers。这种间歇性的buffers使用可能会影响其他的网络行为。这需要另开一篇详细讨论。</p>
<p>Reducer task已经收集了所有intermediate data，现在可以做最后计算了。在这个例子中，我们只需简单的把数字相加就得到了最终结果，写入result.txt</p>
<p>我们的这个例子并没有导致很多的intermediate data在网络间传输。然而其他的jobs可能会产生大量的intermediate data：比如，TB级数据的排序，输出的结果是原始数据集的重新排序，结果尺寸和原始文件大小一致。Map Reduce过程会产生多大的网络流量王权依赖于给定的Job类型。</p>
<p>如果你对网络管理很感兴趣，那么你将了解更多Map Reduce和你运行集群的Jobs类型，以及这些Jobs类型如何影响到网络。如果你是一个Hadoop网络的狂热爱好者，那么你可能会建议写更好的Map Reduce jobs代码来优化网络性能，更快的完成Job</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl19.png" title="srljhjqhwl19" target="_blank"><img src="&quot;srljhjqhwl19&quot;" alt=""></a></p>
<p>Hadoop通过在现有数据的基础上提供某种商业价值，从而在你的组织内获得成功。当人们意识到它的价值，那么你可能获得更多的资金购买更多的机架和服务器，来扩展现有的Hadoop集群。</p>
<p>当增加一个装满服务器的新机架到Hadoop集群中时，你可能会面临集群不平衡的局面。在上图的例子中，Rack1和Rack2是已经存在的机器，保存着文件File.txt并且正在运行Map Reduce jogs。当我们增加两个新的机架到集群中时，File.txt 数据并不会神奇的自动散布到新的机架中。</p>
<p>新的Data node服务器由于没有数据只能空闲着，直到Client开始保存新的数据到集群中。此外当Rack1和Rack2上的服务器都满负荷的工作，那么Job Tracker可能没有别的选择，只能把作用在File.txt上的Map task分配到这些没有数据的新服务器上，新服务器需要通过网络跨机架获取数据。这就导致更多的网络流量，更慢的处理速度。</p>
<p><a href="http://cdn2.jobbole.com/2013/07/srljhjqhwl20.png" title="srljhjqhwl20" target="_blank"><img src="&quot;srljhjqhwl20&quot;" alt=""></a></p>
<p>为了处理这种情况，Hadoop包含一个时髦的工具叫做 balancer</p>
<p>Balancer查看节点可用存储的差异性，在达到特定的阀值后尝试执行balance。有很多空闲空间的新节点将被检测到，然后balancer开始从空闲空间很少的Data node拷贝数据到这个新节点。Balancer通过控制台的命令行启动，通过控制台取消或者关闭balancer</p>
<p>Balancer可用的网络流量是非常低的，缺省设置为1MB/s。可以通过hdfs-site.xml的df.balance.bandwidthPerSec参数来修改。</p>
<p>Balancer是你的集群的好管家。在你增加服务器时一定会用到它，定期（每周）运行一次也是一个好主意。Balancer使用缺省带宽可能会导致很长时间才能完成工作，比如几天或者几周。</p>
<p>本文是基于<a href="http://www.cloudera.com/hadoop-training/" target="_blank">Training from Cloudera</a> 的学习 以及对我的Hadoop实验环境的观测。这里讨论的内容都是基于<a href="https://ccp.cloudera.com/display/SUPPORT/Downloads" target="_blank">latest stable release of Cloudera’s CDH3 distribution of Hadoop</a> 。本文并没有讨论Hadoop的新技术，比如：<a href="http://hadoop.apache.org/common/docs/r0.21.0/hod_scheduler.html#Introduction" target="_blank">Hadoop on Demand(HOD)</a>和<a href="http://www.hortonworks.com/an-introduction-to-hdfs-federation/" target="_blank">HDFS Federation</a> ，但是这些的确值得花时间去研究。
<img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"><img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"><img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"><img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"><img src="&quot;1 vote, average: 5.00 out of 5&quot;" alt="1 vote, average: 5.00 out of 5"> (<strong>*1</strong> 个评分，平均: <strong>5.00*</strong>)</p>
<p><img src="&quot;Loading ...&quot;" alt="Loading ..."> Loading ...</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--深入理解Hadoop集群和网络/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--深入理解Hadoop集群和网络" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-hadoop--漫步云中网络/">漫步云中网络</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--漫步云中网络/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-">漫步云中网络</h1>
<p><a href="http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/#author1" target="_blank">张 华</a>, 高级软件工程师, IBM</p>
<p><a href="http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/#author2" target="_blank">龚 永生</a>, 资深软件工程师, IBM</p>
<p><strong>简介：</strong> 在生产环境中，云中的网络通常被划分为公共网络、管理网络和服务网络。本文首先通过三个小试验向您介绍了如何通过 TAP/TUN、NAT、Linux Bridge、VLAN 等技术实现云中网络的一般原理。有了这些基础，相信您会对接下来介绍的一个具体的 OpenStack 云的示例网络配置倍感亲切。同理，这些基础也将助您在其他云中网络中轻松漫步。
来源： <a href="[http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/](http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/)">[http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/](http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/)</a> </p>
<p>阅读本文前，最好能先了解以下的知识：</p>
<ul>
<li>了解 OpenStack 将有助于对本文的理解。本文讲解的是 Linux 虚拟网络中的一般原理方法 , 虽不仅限于应用在 OpenStack 之中 , 但本文的实验是以 OpenStack 为基础的。OpenStack 是一个开源的 IaaS 云 , 您可以从 devstack 脚本 (<a href="http://devstack.org/" target="_blank"><a href="http://devstack.org/">http://devstack.org/</a></a>) 开始熟悉它。</li>
<li>了解 QEMU 也将有助于对本文的理解。QEMU 是一种支持多种 CPU 的机器模拟器 , 本文采用 QEMU 来创建虚拟机验证本文中的试验。</li>
</ul>
<p><a href="">什么是云？</a></p>
<p>什么是云？我的理解是，为多租户提供各层次上的服务（如操作系统层、中间件层、应用软件层等）的可动态水平扩展的服务器集群称之为云。所以云具有大规模、高可扩展性、按需服务、自动化、节能环保、高可靠性等特点。下图１从软件堆栈视角勾画了云的架构：
<a href=""><strong>图 1. 云的架构</strong></a>
<img src="" alt="图 1. 云的架构"> </p>
<ul>
<li><strong>IaaS, Infrastructure as a Service，基础设施即服务：</strong>您可以简单理解为将可伸缩的操作系统（虚机或实机）实例作为基础设施服务卖给多租户，然后按需计算费用。当然，将操作系统作为基础设施服务只是 IaaS 中的一种，且是最主要的一种，我怕大家概念混淆所以就只重点提了这种。实际上，只要是基础设施提供服务了从概念上讲都应该叫 IaaS，比如说关系型数据库，如果是集群部署的话，它也是基础设施提供服务了，也应该叫 IaaS。这类产品如 IBM 的 Smart Cloud Entry，如开源的 OpenStack。</li>
<li><strong>PaaS, Platform as a Service, 平台即服务：</strong>您可以简单理解为将可伸缩的中间件资源作为平台服务卖给多租户，然后按需计算费用。举个例子，如果 SaaS 应用程序的并发瞬间加大的话，PaaS 可以自动实时地启动一个由 IaaS 提供的操作系统实例，然后自动在它上面部署中间件应用服务器（如 IBM 的 WebSphere），最后再部署一套该 SaaS 应用实例，并自动将它们纳入到负载均衡体系之中，从而实现平台服务的自动伸缩，这就是 PaaS。这类产品如 IBM 的 IWD，如 Google 的 App Engine。</li>
<li><strong>SaaS, Software as a Service, 软件即服务：</strong>您可以简单理解为可伸缩的分布式软件作为软件服务为用户提供某种在线服务，如视频服务，地图服务等。</li>
<li><strong>XaaS, X as a Server, 一切即服务：</strong>只要是给多租户按需提供服务都可以叫 XaaS, 像在 OpenStack 中，将网络部分代码单独抽出来组成 Quantum 工程，就可以叫网络即服务（NaaS, Network as a Service)；像使用 xCat 自动部署裸机可以叫裸机即服务（MaaS, Bare-metal as a Service)。</li>
</ul>
<p><a href="http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/#ibm-pcon" target="_blank">回页首</a></p>
<p><a href="">什么是云中网络？</a></p>
<p>在传统的数据中心中，每个网口对应唯一一个物理机；有了云，一台物理网卡可能会承载多个虚拟网卡。物理网卡与虚拟网卡之间的关系无外乎就是下列三种情况：</p>
<ol>
<li>一对一，一个物理网卡对应对一个虚拟网卡，是下面一对多情况的一种特例</li>
<li>一对多，一个物理网卡对应多个虚拟网卡，是本文要介绍的情况</li>
<li>多对一，多个物理网对应一个虚拟网卡，即我们常说的 Bonding，用作负载均衡
<a href=""><strong>图 2. 虚拟网络的主要内容</strong></a>
<img src="" alt="图 2. 虚拟网络的主要内容"> </li>
</ol>
<p>上图 2 显示了虚拟网络的主要内容：</p>
<ol>
<li>目前，对网络的虚拟化主要集中在第 2 层和第 3 层</li>
<li>在 Linux 中，第 2 层通常使用 TAP 设备来实现虚拟网卡，使用 Linux Bridge 来实现虚拟交换机</li>
<li>在 Linux 中，第 3 层通常是基于 Iptable 的 NAT，路由及转发</li>
<li>对于网络隔离，可以采用传统的基于 802.1Q 协议的 VLAN 技术，但这受限于 VLAN ID 大小范围的限制，并且需要手动地在各物理交换机上配置 VLAN；也可以采用虚拟交换机软件，如 Openvswitch，它可以自动创建 GRE 隧道来避免手动去为物理交换机配置 VLAN。</li>
</ol>
<p>下面将结合一个生产环境中的网络实例来讲解如何实现一个虚拟网络。</p>
<p><a href="http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/#ibm-pcon" target="_blank">回页首</a></p>
<p><a href="">云中网络实验</a></p>
<p>在生产环境中，按通用做法一般将云中网络划分为三大部分，公共网络、管理&amp;存储网络、服务网络。</p>
<p><strong>公共网络：</strong>用于云向外部租户提供 API 调用或者访问</p>
<p><strong>管理网络：</strong>用于云中各物理机之间的通信</p>
<p><strong>存储网络：</strong>用于 iSCSI 服务端与客户端之间的流量，一般与管理网络同</p>
<p><strong>服务网络：</strong>虚机内部使用的网络</p>
<p>为了将上述网络的实现原理讲清楚，我们选择了两台物理机做实验，并将采用 NAT、Linux Bridge、VLAN 技术分步实现一个典型的 OpenStack 云的网络拓扑。当然，这种网络的原理是通用的，并不仅限于 OpenStack 云。</p>
<ol>
<li>台式机 (node1)， 双有线网卡， 将作为控制节点、存储节点及一个计算节点</li>
<li>笔记本 (node2)，一有线网卡，将作为一个计算节点</li>
<li>路由器，家中 ADSL 宽带出口</li>
<li>交换机 , 用于连接各物理机</li>
</ol>
<p>值得一提的是，如果采用了 VLAN 技术进行网络隔离，且想要两台物理机上的虚机能够互访的话，交换机必须是支持 VLAN 的，且需要手动将交换机相应的端口配置成 Trunk 模式。因为我没有支持 VLAN 的物理交换机，在本实验中，我是采用直连线直接连接两台实验机器的。</p>
<p>下图 3 显示了实验网络拓扑：
<a href=""><strong>图 3. OpenStack 实验网络拓扑</strong></a>
<img src="" alt=""> </p>
<p><strong>公共网络：</strong>192.168.99.0/24 网段，外网用户通过公共网络上提供的服务来访问云。注意：在实际的生产环境中，公共网络一般采用外网 IP，因为我没有外网 IP，所以用 192.168.99.0 网段模拟。将台式机的一有线网卡 eth1 与 TP-Link 路由器相连即可。</p>
<p><strong>管理＆存储网络：</strong>172.16.99.0/24 网段，管理网络用于 OpenStack 各组件以及 DB、MQ 之间进行通信；存储网络用于存储节点和需要使用外部存储的计算节点之间的通信。将台式机的另一有线网卡 eth0 和笔记本电脑的有线网卡 eth0 连接到交换机即可。</p>
<p><strong>服务网络：</strong>10.0.0.0/8 网段，用于虚机内部。</p>
<p>两个节点的基本网络配置如下：
<a href=""><strong>清单 1. node1 的基本网络配置</strong></a></p>
<p>root@node1:/home/hua/# cat /etc/network/interfaces
auto lo</p>
<p>iface lo inet loopback
auto eth1</p>
<p>iface eth1 inet dhcp
up iptables -t nat -A POSTROUTING -s 172.16.99.0/24 -o eth1 -j MASQUERADE</p>
<p>auto eth0
iface eth0 inet static</p>
<p>address 172.16.99.108
netmask 255.255.255.0</p>
<p>network 172.16.99.0
broadcast 172.16.99.255</p>
<p><a href=""><strong>清单 2. node2 的基本网络配置</strong></a>
[</p>
<p>cat /etc/sysconfig/network-scripts/ifcfg-eth0
DEVICE=eth0</p>
<p>HWADDR=00:21:86:94:63:27
ONBOOT=yes</p>
<p>BOOTPROTO=static
USERCTL=yes</p>
<p>PEERDNS=yes
IPV6INIT=no</p>
<p>NM_CONTROLLED=yes
TYPE=Ethernet</p>
<p>NETMASK=255.255.255.0
IPADDR=172.16.99.109</p>
<p>NETWORK=172.16.99.0
GATEWAY=172.16.99.108</p>
<p>DNS1=202.106.195.68
DNS2=202.106.46.151</p>
<p>我虽然只用了两台物理机来模拟实际生产环境的部署模型， 但文中的这种部署结构是典型的，如果是大规模部署的话，只需要将控制节点上的每一个进程（如 DB、MQ、glance、keystone、nova-api、nova-schedule、nova-network 等）分布部署在每一台物理机即可。想要进一步的 HA 的话，可以：</p>
<ul>
<li>将 DB 配置成集群模式</li>
<li>将 MQ 配置成集群模式</li>
<li>采用 multi-host 模式，将 nova-network 同时安装在计算节点 (nova-compute) 上</li>
<li>将 nova-api、nova-schedule 这些无状态的服务也同时部署在计算节点上，再加上负载均衡器分发负载</li>
<li>采用多网卡做 Bonding
]()</li>
</ul>
<p><a href=""></a><a href="">NAT</a></p>
<p>node2 可以通过 NAT 方式访问外网，数据流向如下：</p>
<ol>
<li>node2 中需设置网关指向 node1 的 eth0，例： GATEWAY=172.16.99.108</li>
<li>在 node1 中打开 ipv4 转发功能，这样，node1 会相当于一台路由器，在 eth0 收到来自 node2 的数据之后，会将数据包转发到其他网卡 eth1， sysctl -w net.ipv4.ip_forward=1</li>
<li>在 node1 上设置 NAT 规则，这样，从 node2（172.16.99.0/24 网段）发出的数据包看来起就像从 node1 的 eth1 发出的一样： iptables -t nat -A POSTROUTING -s 172.16.99.0/24 -o eth1 -j MASQUERADE</li>
</ol>
<p><a href="">Linux Bridge</a></p>
<p>网桥 ( Bridge ) 工作在二层，了解链路层协议，按帧转发数据。就是交我们常说的交换机，所以连接到网桥的设备处于同一网段。
<a href=""><strong>图 4. 网桥示例</strong></a>
<img src="" alt="图 4. 网桥示例"> </p>
<p>上图 4 显示了 node1 网桥中的 VM1 与 node2 网桥中的 VM2 是如何通信的。在 openstack 中，这是典型的 multi-host 模式，即每一个计算节点均部署了网络服务来提供网关服务。Linux Bridge 充当了交换机的功能，而将 sysctl -w net.ipv4.ip_forward 设置为 1 也相当于 node1 同时充当了一个路由器（路由器的实质就是一个具有多个网卡的机器，因为它的多网卡同时具有这些不同网段的 IP 地址，所以它能将一个网络的流量路由转发到另一个网络）。</p>
<p>网桥，交换机，是用来连接两个 LAN 的。 是根据 MAC 与端口的映射进行转发的，而在虚机的网卡都是知道的，若从转发数据库知道目的 MAC 地址，以太网帧就只会正确的网桥端口传输，否则，就会扩散到网桥设备的所有端口。</p>
<p>因为网桥工作在第二层，所以 eth0.1, tap0, tap1 这些网卡均不需要设置 IP（因为对于上层路由器来说，它们是同一个子网，只需要将 IP 设置在 br1 上即可）。同时， 对 Linux 而言，网桥是虚拟设备，因此，除非将一个或多个真实设备绑定到网桥设备上，否则它就无法接收或传输任何东西。所以需要将一个真实设备（如 eth0）或者真实设备的 vlan 接口（如 eth0.1) 加入到网桥。对于前一种情况，将 eth0 加入到网桥之后，eth0 便不再具有 IP，这时候它与 tap0 这些虚拟网卡均通过 br1 处于 10.0.1.0/24 网络，当然我们也可以为网桥 br1 设置一个别名让它也具有 172.16.99.0/24 网管网段的 IP 地址。）</p>
<p>下面，我们来实现这个示例网桥，在 node1 与 node2 上分别执行下述脚本（对重要命令的描述请参见注释）：
<a href=""><strong>清单 3. node1 与 node2 的 Linux Bridge 配置脚本</strong></a></p>
<p>/#!/bin/sh
TAP=tap0</p>
<p>BRIDGE=br1
IFACE=eth0</p>
<p><strong>MANAGE_IP=172.16.99.108</strong></p>
<p>SERVICE_IP=10.0.1.1
GATEWAY=10.0.1.1</p>
<p>BROADCAST=10.0.1.255
/# 设置物理网卡为混杂模式</p>
<p>ifdown $IFACE
ifconfig $IFACE 0.0.0.0 promisc up</p>
<p>/# 创建网桥，并物理网卡加入网桥，同时设置网桥的 IP 为服务网络网段
brctl addbr $BRIDGE</p>
<p>brctl addif $BRIDGE $IFACE
brctl stp $BRIDGE on</p>
<p>ifconfig $BRIDGE $SERVICE_IP netmask 255.255.255.0 broadcast $BROADCAST
route add default gw $GATEWAY</p>
<p>/# 在网桥上设置多 IP，让它同时具有管理网段的 IP
ifconfig ${BRIDGE}:0 $MANAGE_IP netmask 255.255.255.0 broadcast 172.16.99.255</p>
<p>注意，上述黑体的一句在 node2 中需要作相应修改，其余不变，如下：
MANAGE_IP=172.16.99.109</p>
<p><a href="">VLAN</a></p>
<p>图 4 同样适用于 VLAN 网络，下面我们来实现它。在 node1 与 node2 上分别执行下述脚本：
<a href=""><strong>清单 4. node1 与 node2 的 VLAN 配置脚本</strong></a></p>
<p><strong>MAC=c8:3a:35:d7:86:da</strong></p>
<p>IP=10.0.1.1/24
ip link add link eth1 name eth1.1 type vlan id 1</p>
<p>ip link set eth1.1 up
brctl addbr br1</p>
<p>brctl setfd br1 0
brctl stp br1 on</p>
<p>ip link set br1 address $MAC
ip link set br1 up</p>
<p>brctl addif br1 eth1.1
ip addr add $IP dev br1</p>
<p>注意，上述黑体的一句在 node2 中需要作相应修改，其余不变，如下：
MAC= c8:3a:35:d7:86:db</p>
<p><a href="">测试</a></p>
<p>我们采用 QEMU 创建虚拟机来进行测试，其中网络部分的配置为：
  <interface type='bridge'></p>
<p>   <mac address='52:54:00:00:01:89'/>
 　　  <source bridge='br1'/></p>
<p> 　　  <address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>
  </interface></p>
<p>我们使用一个现成的镜像，下载地址：
curl <a href="http://wiki.qemu.org/download/linux-0.2.img.bz2" target="_blank">http://wiki.qemu.org/download/linux-0.2.img.bz2</a> -o /bak/kvmimages/linux-0.2.img</p>
<p>在 node1 与 node2 上分别用下列配置定义两个虚机，注意，下面打粗体的部分（<mac address='52:54:00:00:01:89'/>）在两个节点中请设置不一样的值。</p>
<p>cat /etc/libvirt/qemu/test.xml
<a href=""><strong>清单 5. node1 与 node2 的虚机定义文件</strong></a></p>
<domain type='qemu'>
 <strong><name>VM1</name></strong>

<uuid></uuid>
<memory>393216</memory>

<currentMemory>393216</currentMemory>
<vcpu>1</vcpu>

<os>
<type arch='i686' machine='pc-1.0'>hvm</type>

<boot dev='hd'/>
</os>

<features>
<acpi/>

</features>
<clock offset='utc'/>

<on_poweroff>destroy</on_poweroff>
<on_reboot>restart</on_reboot>

<on_crash>destroy</on_crash>
<devices>

<emulator>/usr/bin/qemu-system-i386</emulator>
<disk type='block' device='disk'>

<driver name='qemu' type='raw'/>
<source dev='/bak/kvmimages/linux-0.2.img'/>

<target dev='hda' bus='ide'/>
<address type='drive' controller='0' bus='0' unit='0'/>

</disk>
<controller type='ide' index='0'>

<address type='pci' domain='0x0000' bus='0x00' slot='0x01' function='0x1'/>
</controller>

<interface type='bridge'>
 <strong><mac address='52:54:00:00:01:89'/></strong>

<source bridge='br1'/>
<address type='pci' domain='0x0000' bus='0x00' slot='0x03' function='0x0'/>

</interface>
<input type='tablet' bus='usb'/>

<input type='mouse' bus='ps2'/>
<graphics type='vnc' port='-1' autoport='yes' listen='127.0.0.1'>

<listen type='address' address='127.0.0.1'/>
</graphics>

<video>
<model type='cirrus' vram='9216' heads='1'/>

<address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/>
</video>

<memballoon model='virtio'>
<address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/>

</memballoon>
</devices>

</domain>

<p>然后用上述配置创建虚机（virsh define /etc/libvirt/qemu/test.xml ），接着启动虚机（ virsh start test ），最后设置虚机的 IP 和默认网关， 如下：</p>
<p><strong>VM1：</strong></p>
<p>ifconfig eth0 10.0.1.2 netmask 255.255.255.0 broadcast 10.0.1.255
route add default gw 10.0.1.1</p>
<p><strong>VM3：</strong>
ifconfig eth0 10.0.1.3 netmask 255.255.255.0 broadcast 10.0.1.255</p>
<p>route add default gw 10.0.1.1</p>
<p>这时候在一虚机上 ping 另一虚机 , 如果能够 ping 通，成功。若想要 ping 外网的话，还需在 /etc/resolv.conf 文件中添加域名，如下图 5 所示：
<a href=""><strong>图 5. 验证实验是否成功</strong></a>
<img src="" alt="图 5. 验证实验是否成功"> </p>
<p><a href="http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/#ibm-pcon" target="_blank">回页首</a></p>
<p><a href="">OpenStack 云中网络拓扑配置示例</a></p>
<p>在掌握了上述基本原理之后，应该不难理解下面 OpenStack 云中的网络拓扑。</p>
<p>在 OpenStack 中，目前存在着 nova-network 与 quantum 两种网络组件。nova-network 仅支持下列三种网络拓扑：</p>
<ul>
<li>FlatManager, 不支持 VLAN，也不支持 DHCP 的扁平网络</li>
<li>FlatDHCPManager，不支持 VLAN，但支持 DHCP 的扁平网络</li>
<li>VlanManager，支持 VLAN，也支持 DHCP 的 VLAN 隔离网络</li>
</ul>
<p>如今 nova-network 的代码已经全部挪到了 Quantum 工程中，但在网络拓扑方面，二者的原理是一致的，所以下面只给出一个典型的 nova-network 的网络配置，有了上面的基础，现在看这段配置是否会感到很亲切呢？
<a href=""><strong>清单 6. /etc/nova/nova.conf 中的网络配置示例</strong></a></p>
<p>/#/#/#/#/# nova-network /#/#/#/#/#
network_manager=nova.network.manager.VlanManager</p>
<p>public_interface=eth1
vlan_interface=eth0</p>
<p>network_host=node1
fixed_range=10.0.0.0/8</p>
<p>network_size=1024
dhcpbridge_flagfile=/etc/nova/nova.conf</p>
<p>dhcpbridge=/usr/bin/nova-dhcpbridge
force_dhcp_release=True</p>
<p>fixed_ip_disassociate_timeout=30
my_ip=172.16.99.108</p>
<p>routing_source_ip=192.168.99.108</p>
<p>相关参数说明如下：</p>
<ul>
<li>network_manager，目前支持 VlanManager、FlatManager、FlatDHCPManager 三种拓扑</li>
<li>public_interface, 接外网的物理网卡 , floating ip 功能需要用到它</li>
<li>valn_interface, 用于划分 VLAN 的物理网卡</li>
<li>fixed_range, 服务网络，即虚机内部所用的网络地址</li>
<li>my_ip，管理网络，用于安装 Openstack 组件的物理机之间的通信。例如：本实验中的控制节点同时具有外网网络地址 192.168.99.108 与管理网络地址 172.16.99.108，另一计算节点的管理网络地址为 172.16.99.109，所以 my_ip 应该设置为 172.16.99.108</li>
<li>routing_source_ip, NAT 映射后的公共网络 IP，设置了此参数，会自动执行 NAT 命令： iptables -t nat -A POSTROUTING -s 172.16.99.0/24 -o eth1 -j SNAT --to 192.168.99.108</li>
</ul>
<p>显然，如果没有区分公共网络与管理网络，即它们处于同一网段的话，并不需要配置 my_ip 及 routing_source_ip 两个参数。</p>
<p><a href="http://www.ibm.com/developerworks/cn/cloud/library/1209_zhanghua_openstacknetwork/#ibm-pcon" target="_blank">回页首</a></p>
<p><a href="">结论</a></p>
<p>云中网络一般被划分为公共网络、管理网络 &amp; 存储网络与服务网络三大类。虚拟网络拓扑一般有 NAT、Bridge、VLAN 三种情形。我们手工一步一步地通过 NAT、Bridge、VLAN 三个试验简单实现了一个上述典型的云中网络。原理都是相通的，您再看 OpenStack 云中网络或才其他云的网络时都会倍感亲切。</p>
<p><a href="">参考资料</a></p>
<p><strong>学习</strong></p>
<ul>
<li>参考 <a href="http://devstack.org/" target="_blank">Devstack 官网</a>，您可以从 devstack 脚本快速上手 Openstack。 </li>
<li>参考 <a href="http://docs.openstack.org/" target="_blank">Openstack 官网</a>，您可以获得更多关于 Openstack 的知识。 </li>
<li>参考 <a href="http://wiki.openstack.org/Quantum-Linux-Bridge-Plugin/" target="_blank">Quantum Wiki</a>, 您可以获得关于 Linux Bridge 网络的一般原理。 </li>
<li>“<a href="http://www.ibm.com/developerworks/cn/cloud/library/cl-openstack-cloud/" target="_blank">使用 OpenStack 实现云计算和存储</a>”（developerWorks，2012 年 9 月）：Infrastructure as a Service (IaaS) 云平台种类繁多，例如像 Nebula 和 Eucalyptus 这样为人熟知的解决方案。而此领域的一个新来者已展示了其不俗的增长，不仅包括用户数量的增长，还包括支持公司的数量的大量增长。在本文中，我们将了解这个开源平台 OpenStack，发现它是否真的是一种开源云操作系统。</li>
<li><p><a href="https://www.ibm.com/developerworks/cn/cloud/index.html" target="_blank">developerWorks 云计算站点</a> 提供了有关云计算的更新资源，包括</p>
</li>
<li><p>云计算 <a href="http://www.ibm.com/developerworks/cn/cloud/newto.html" target="_blank">简介</a>。</p>
</li>
<li>更新的 <a href="http://www.ibm.com/developerworks/cn/cloud/resources.html" target="_blank">技术文章和教程，以及网络广播</a>，让您的开发变得轻松，<a href="http://www.ibm.com/developerworks/cn/cloud/events.html" target="_blank">专家研讨会和录制会议</a> 帮助您成为高效的云开发人员。</li>
<li>连接转为云计算设计的 <a href="http://www.ibm.com/developerworks/cn/cloud/products.html" target="_blank">IBM 产品下载和信息</a>。</li>
<li>关于 <a href="http://www.ibm.com/developerworks/cn/cloud/collaborate.html" target="_blank">社区最新话题</a> 的活动聚合。</li>
<li>加入<a href="https://www.ibm.com/developerworks/mydeveloperworks/groups/service/html/communityview?communityUuid=e69e9c57-3210-49b0-a603-ca597c736557" target="_blank">云计算讨论组</a>，了解和讨论云计算的最新技术、解决方案、趋势等内容。 </li>
</ul>
<p><strong>讨论</strong></p>
<ul>
<li>加入 <a href="http://www.ibm.com/developerworks/cn/community/" target="_blank">developerWorks 中文社区</a>。查看开发人员推动的博客、论坛、组和维基，并与其他 developerWorks 用户交流。</li>
</ul>
<p><a href="">作者简介</a>
<a href=""></a>张华，IBM 高级软件工程师热衷于技术钻研，拥有丰富的搜索引擎、应用服务器、互联网、云计算领域的行业经验，精通 Java、JavaEE、Linux、Network 等技术，目前正从事 OpenStack 相关的工作。</p>
<p><a href=""></a>龚永生，IBM 资深软件工程师，热衷于开源软件，具有多年的 Linux，Java 和 JavaEE 经验。目前是 OpenStack 项目的积极贡献者。</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--漫步云中网络/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--漫步云中网络" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事1：外企也就那么回事/">IT外企那点儿事(1)：外企也就那么回事</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事1：外企也就那么回事/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="it-1-">IT外企那点儿事(1)：外企也就那么回事</h1>
<p><a href=""></a></p>
<h1 id="-http-www-cnblogs-com-forfuture1978-"><a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a></h1>
<p>  <a href="http://www.cnblogs.com/" target="_blank">博客园</a> :: <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">首页</a> :: <a href="http://q.cnblogs.com/" target="_blank">博问</a> :: <a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?opt=1" target="_blank">新随笔</a> :: <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">联系</a> :: <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank">订阅</a> <a href="http://www.cnblogs.com/forfuture1978/rss" target="_blank"><img src="" alt="订阅"></a> :: <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx" target="_blank">管理</a> :: <img src="" alt="">   130 随笔 :: 0 文章 :: 544 评论 :: 0 引用
<a href="">&lt;</a>2010年4月<a href="">&gt;</a>日一二三四五六28293031123<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/04.html" target="_blank">4</a>56<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/07.html" target="_blank">7</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/08.html" target="_blank">8</a>9101112<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/13.html" target="_blank">13</a>14<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/15.html" target="_blank">15</a>161718192021<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/22.html" target="_blank">22</a>2324<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/25.html" target="_blank">25</a>26<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/27.html" target="_blank">27</a>28<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/29.html" target="_blank">29</a><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/30.html" target="_blank">30</a>12345678</p>
<h3 id="-">公告</h3>
<p>昵称：<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
园龄：<a href="http://home.cnblogs.com/u/forfuture1978/" title="入园时间：2009-12-10" target="_blank">3年7个月</a>
荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
粉丝：<a href="http://home.cnblogs.com/u/forfuture1978/followers/" target="_blank">560</a>
关注：<a href="http://home.cnblogs.com/u/forfuture1978/followees/" target="_blank">3</a></p>
<p><a href="">+加关注</a></p>
<h3 id="-">搜索</h3>
<h3 id="-">常用链接</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/MyPosts.html" target="_blank">我的随笔</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/MyComments.html" target="_blank">我的评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/OtherPosts.html" title="我发表过评论的随笔" target="_blank">我的参与</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/RecentComments.html" target="_blank">最新评论</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/tag/" target="_blank">我的标签</a></li>
</ul>
<h3 id="-">随笔分类</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300670.html" target="_blank">Hadoop原理与代码分析(7)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事(12)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345798.html" target="_blank">Java(2)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345797.html" target="_blank">Linux(14)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300665.html" target="_blank">Lucene原理与代码分析(38)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300666.html" target="_blank">长尾理论(16)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345794.html" target="_blank">管理学(10)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345800.html" target="_blank">经济学(4)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345796.html" target="_blank">算法(1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/345795.html" target="_blank">闲话IT业(3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300667.html" target="_blank">心理学与管理学效应(9)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/category/300668.html" target="_blank">组织行为学(15)</a></li>
</ul>
<h3 id="-">随笔档案</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11.html" target="_blank">2012年11月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/01.html" target="_blank">2012年1月 (5)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/12.html" target="_blank">2011年12月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/10.html" target="_blank">2011年10月 (3)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2011/09.html" target="_blank">2011年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11.html" target="_blank">2010年11月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/10.html" target="_blank">2010年10月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/09.html" target="_blank">2010年9月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08.html" target="_blank">2010年8月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/07.html" target="_blank">2010年7月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06.html" target="_blank">2010年6月 (6)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05.html" target="_blank">2010年5月 (22)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04.html" target="_blank">2010年4月 (18)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/03.html" target="_blank">2010年3月 (8)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02.html" target="_blank">2010年2月 (39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/01.html" target="_blank">2010年1月 (1)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12.html" target="_blank">2009年12月 (6)</a></li>
</ul>
<h3 id="-">相册</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/gallery/247104.html" target="_blank">IT外企那点儿事</a></li>
</ul>
<h3 id="-">最新评论</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2727561" target="_blank">1. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li>楼主怎么之后没有更新hadoop的相关信息了呢？是没有再研究了吗？</li>
<li>--lyeoswu</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html#2713121" target="_blank">2. Re:Lucene 原理与代码分析完整版</a></li>
<li>提个建议，你生成的pdf中没有目录，影响阅读，用office转制的过程中其实设置一下即可，方便大众嘛~，还望能发我一份，谢谢！
sendreams@hotmail.com</li>
<li>--sendreams</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2712415" target="_blank">3. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>mojunbin
现在这公司，本来做的Siverlight，我进去后没多久就转JAVA了，最近在公司折腾JAVA的一些东西，业余时间玩玩游戏，看看CLR、并折腾linux。现在观点有所转变，觉得学技术更多的是为了扩宽思维、提高眼界</li>
<li>--峰顶飞龙</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html#2711923" target="_blank">4. Re:IT外企那点儿事(12)：也说跳槽</a></li>
<li><a href="&quot;查看所回复的评论&quot;">@</a>峰顶飞龙
您的经历和我差不多，呵呵。不晓得现在兄弟在搞C/C++呢？</li>
<li>--mojunbin</li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/23/1884967.html#2708814" target="_blank">5. Re:Hadoop学习总结之五：Hadoop的运行痕迹</a></li>
<li>楼主你好，在远程调试MapReduce时，本地代码进入不了自定义的job类，而是进入到Credentials class中，此类在hadoop-core-1.0.4.jar中，请问楼主在调试过程可否遇到此问题？</li>
<li>--彭莉珊</li>
</ul>
<h3 id="-">阅读排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">1. IT外企那点儿事(8)：又是一年加薪时(26799)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">2. Lucene 原理与代码分析完整版(25616)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/02/23/1671909.html" target="_blank">3. 从技术生命周期看IT历史(20878)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2009/12/21/1628546.html" target="_blank">4. 101个著名的管理学及心理学效应(20828)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/11/14/1877086.html" target="_blank">5. Hadoop学习总结之三：Map-Reduce入门(18681)</a></li>
</ul>
<h3 id="-">评论排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(68)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/05/1727644.html" target="_blank">2. IT外企那点儿事(4)：激动人心的入职演讲(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">3. IT外企那点儿事(6)：管理路线和技术路线(37)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">4. IT外企那点儿事(8)：又是一年加薪时(35)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">5. IT外企那点儿事(12)：也说跳槽(33)</a></li>
</ul>
<h3 id="-">推荐排行榜</h3>
<ul>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/06/13/1757479.html" target="_blank">1. Lucene 原理与代码分析完整版(55)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/03/1726200.html" target="_blank">2. IT外企那点儿事(3)：奇怪的面试(39)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/08/04/1791660.html" target="_blank">3. IT外企那点儿事(8)：又是一年加薪时(36)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2012/11/26/2788610.html" target="_blank">4. IT外企那点儿事(12)：也说跳槽(34)</a></li>
<li><a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/13/1734162.html" target="_blank">5. IT外企那点儿事(6)：管理路线和技术路线(27)</a></li>
</ul>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/30/1725341.html" target="_blank">IT外企那点儿事(1)：外企也就那么回事</a></p>
<p>外企，一个听起来似乎充满光环的名字，每年众多大学毕业生向往的地方。</p>
<p>说起外企，总能让人联想到很多令人心动的名词：高薪，人性化，浮动工作制，年假，完善的流程，各种福利如：旅游，室内乒乓球台，健身房，按摩椅，小食品，酸奶……</p>
<p>然而真正进入了外企，时间长了，也就发现，其实外企也就那么回事。</p>
<h2 id="-">高薪</h2>
<p>所谓高薪，严格意义上来讲是高起薪，也即刚毕业的时候每个企业公开的秘密，同学们总能够从师哥师姐那里打听到这个数字，有的企业甚至爆出较去年惊人的数字来做宣传。一个个光鲜的数字吸引着尚未毕业的大学生们，宣讲会的人数是基本和这个数字成正比的。</p>
<p>然而由于大多数的外企，由于规模比较大，机构也相对的稳定，高起薪的背后是稳定的加薪，每年7%~10%是常道，20%则是皇恩浩荡了，除非你能够取得整个Team都认可的成就，然而如果不幸参与的项目是一个多年的产品，至多是修改一些Bug或者增加一些边边角角的功能，又有多少这样的机会呢？大约在下看到的是这样的，也许并不符合所有外企的情形。</p>
<p>于是当毕业生中的佼佼者很幸运的加入大的外企的时候，不如你的同学只有默默的加入了不算太大的民企。</p>
<p>这一直是你引以为豪的资本，并总在同学聚会的时候大说特说你们公司的薪水，福利，在你的同学抱怨民企的加班声中附和着，心中却莫名的产生了一种优越感。</p>
<p>这种优越感使得你进一步沉浸在美好的外企生活中，却发现越来越没有那么优越了。三年，五年，你一次次的听说你的同学升职了，又升职了，而你还是一个普通的engineer，因为外企的升职基本是由严格的年限的，有时候多少有些按资排辈的味道。你一次一次听说你的同学加薪了，又加薪了，薪水直逼你当前的薪水，甚至在五年的关头超过你。</p>
<p>你越来越发现你的同学逐渐的掌握了一个系统前前后后的模块，能够完整的负责起一个项目的时候，你却还是螺丝钉，每天接受外国人的指示，在yes, ok, no problem, i am 100% agree的声音中继续做你的螺丝钉般的小功能。</p>
<p>我不知道十年后会如何，在参加了多次的开发者大会后，我发现几乎所有的外企的演讲者都是外国人，中国的演讲者则多来自本土的创业企业，当听着他们如数家珍的谈着自己的创业企业如何一步步做大，系统如何一步步改进，直到今天的架构，他们外企的同学能有这种机会吗？</p>
<h2 id="-">人性化</h2>
<p>所谓人性化，用外企的语言就是我们是很Open的。</p>
<p>Open体现在很多方面，诸如高管的办公室的门始终是开着的，你可以在任何时刻走到任何的高官的办公室里发表自己的看法，只是你必须保证，当你满怀激情的走进高官的办公室，关上门，半个小时后同样满怀激情走出办公室，你的顶头上司对你没有看法，即便你确实没有说什么，仅仅谈论了一下午餐而已。</p>
<p>所以除非高层主动安排和你谈话，尽量不要没事跑到高层那里，在你的顶头上司控制范围之外和他的上司进行私密的谈话，要知道有一种关系叫表面上支持，心中的隔阂。即便是高层主动要和你谈话，最好事先和你的顶头上司事先沟通，当然不用太正式，比如在闲聊的时间抱怨一下：&quot;今天下午又要被老大找去One on One，项目这么忙，不知道有啥事情可谈的&quot;，呵呵，一些术而已，姑妄言之姑听之吧。</p>
<p>对你最重要的永远是你的顶头上司，当高层听完你的建议，OK, I will take it into consideration之后，便和你没有啥关系了，绝不会存在当你的顶头上司决定给你涨薪7%的时候，高层会出来说一句，我觉得他表现还不错，涨10%吧。</p>
<p>当然，按照公司的规定，你的顶头上司也会过一段时间和你来一次One on One，问问当前的情况，问问有啥意见等等，这可不是推心置腹的时候，需要把握火候，对当前的情况说的太满意，感觉不真诚，太不满意自然领导不爱听，说没意见显得对Team不够关心，说太多意见会让人感觉你不安全。</p>
<p>所以总的原则是：</p>
<ul>
<li>要多提改善性意见(&quot;code review预留的时间应该更长一些&quot;)，少提颠覆性意见(&quot;现在的项目流程有很大问题&quot;)，</li>
<li>多提有证据的具体意见(&quot;我们有几十个Bug，可能一个星期确实做不完&quot;)，少提抽象型意见(&quot;Team之间的沟通有问题&quot;)，</li>
<li>多说与项目相关的意见，少说与自己相关的意见(尤其不要太真实的说自己的人生规划)，</li>
<li>多说在领导意料范围之内的意见(这样会给领导以对Team的控制感，比如说天天加班到10点，领导也看在眼中，可以提一下)，少说在领导意料之外的意见(即便有，请事先沟通，让领导在One on One之前就心里有数)。</li>
</ul>
<p>Open还体现来另外的方面，比如领导会和员工一起参加各种工作之外的活动，比如打球，比如年会表演，比如一起健身等等，而且在此过程中，往往是充满的欢声笑语的，但一定不要忘记领导就是领导，哪怕不在项目中，千万不要因为你曾经是学校的篮球高手，或是文艺主干，就能在此类的活动中充当领袖角色，在你的项目领导面前指手画脚，虽然在活动中他会夸你，没想到你还有这方面的才能，但是在领导面前充老大，这笔账是迟早要还的，比如在项目的后期不能够完成美国派来的任务的时候，你会被冠以虽然前一阵成功组织了活动，但是耽误了一些项目进度的罪名，从而影响你的绩效。</p>
<p>如果你在健身房遇到领导，和你一起健身，你们可以边健身边聊的很开心，但是领导的心中的第一个想法一定是，这小子项目干完了吗，还有空工作时间健身？，并且会在以后的工作中反映出来，比如时常关心你的工作进度，加大你的工作量等。</p>
<h2 id="-">浮动工作制</h2>
<p>所谓浮动工作制，很好听的名字，就是你早上可以推迟来，晚上可以早些走，只要能够完成任务，每天工作6个小时都可以。</p>
<p>初入外企的时候，看到很多前辈可以早上十点，甚至十一点才到公司，认为浮动工作制太好了，于是拼命的工作，企图在6小时干完10个小时的活，然后有时间或学习或休息。然而最后发现，活是永远干不完的，资本家花钱请了你，会让你轻松应对？</p>
<p>浮动工作制，其实就是加班不给加班费的另一种说法，也即合同中也许会写着&quot;所有的加班费已经被计入了薪水中&quot;。只要能够完成任务，每天工作12个小时也是应该的。晚上留下来很晚，或是早上很早被拉起来和老美开会，也是浮动的时间之中，你无话可说。为了改美国客户的一个Bug，深夜加班，你无话可说。在中国是休息日，但美国不是休息日的时候派去美国，并不补偿你的休息日，也不给三倍工资，你无话可说。</p>
<h2 id="-">年假</h2>
<p>外企的年假是相对较多的，也是外企在校园宣讲中经常引以为豪的一点。然而年假又有多少真正能够落到实处呢？其时大部分是休不到的，项目不允许，领导不允许，外国人也不允许。</p>
<p>不允许当然不是显式的，而是潜规则的。项目永远是紧的，即便不那么紧，也会被人们喊得使大家觉得很紧，如果一个Team有很多人休很多假，对领导来说，好像对上面不太好交代。</p>
<p>如果Team中你单独休假，你会被提醒，现在大家都在赶进度，不要因为你这个模块把项目block了。</p>
<p>如果Team中大家想一起休假，领导会说，大家都在这个时候休，连backup都没有，出了事情找不到人啊。</p>
<p>如果你平时想休息一天，领导会说，有什么事情吗？没什么事情可以等项目闲了些集中休息一下，明天早上可以晚来些，可能这一阵确实太累了。</p>
<p>如果你想连着长假一起休，领导会说，本来就有一个星期了，还另外请，不如平时累的时候休息一天，效果好。</p>
<p>如果美国人放假(如圣诞)，中国不放假，美国人会在放假前有很多任务布置过来，要在这个期间赶上美国的进度。</p>
<p>如果美国不放假，中国放假(如过年)，总不能让美国老板找不到人吧。</p>
<p>当然以上借口只是在你提出请假的时候，以商量的口气被提及，如果你真想请假，领导还是会毫不犹豫的批准的，因为我们是Open的嘛。然而以上借口却会使得多数员工不太敢于请假，因为大家都明白，有一种关系叫表面上支持，心中的隔阂。</p>
<p>当然即便假期被批准，还是有条件的，比如&quot;没问题，好好休息，走之前把文档(报告，邮件，代码)发出来(提交到svn)就行了&quot;。一般这个附加条件都会耗费一些时间的，一般是第二天休，前一天晚上至少九十点走，早上请，中午才能走，中午请，下午三点多才能走。</p>
<h2 id="-">完善的流程</h2>
<p>外企的流程是非常完善的，甚至是极度的完善，过分的完善。</p>
<p>所以外企一般都会有会议室预定系统，会议室永远是被占着的，一天一天的总是开会，讨论。</p>
<p>例会就有模块组的，开发组的(包含多个模块)，项目组的(开发和测试)，Group的(同一个大老板的多个项目)，all-hands的(整个公司)。</p>
<p>写一篇文档要模块组review，开发组review，测试组review，和美国开会review，重新改了第二轮review。以及code review，bug review。</p>
<p>每个项目组作了一个阶段后给整个项目组的demo，甚至给整个group及老外demo，说是增加visualbility。</p>
<p>一般要到下午晚些时候才能够清净些写代码，晚餐后才是代码的高峰期。</p>
<p>这也是为什么小公司半年作出来的东西，大公司要做几年。当然大公司这样做自然有它的道理，大公司稳定，不愁客户资源，不差钱，今年做出来或是明年做出来，客户别无选择，员工也养得起。这些小公司都做不到，必须尽快的满足客户的需要，必须在钱花完之前拉到下一个项目。</p>
<p>然而这对程序员的职业生涯来说好么，我不敢评价。只是在和很多朋友讨论的时候，他们发现，自己一直在忙啊忙，当跳槽试图总结自己做了啥的时候，却发现就不多的东西，不多的技术，当他们去面创业公司的时候，经常会被问，你们这么长时间，怎么就做了这么个东西？</p>
<p>大公司完善的流程还有一个特点，就是这个流程是完全为此公司定制的，当然公司大，自然可以有钱从头到尾弄自己的东西，既不用常用的，也不用开源的，无论是开发工具，测试工具，代码管理工具。这也导致了员工的粘性特别强，当走出这家公司，就像换了一片天地，原来会的别人用不到，别人常用的，却不怎么会，最后只好在公司养老，好在薪水也不错，福利也不错。</p>
<h2 id="-">设施</h2>
<p>最后提及的是各种美好的设施，这是很有吸引力的。然而为了您的前途，虽不能说敬而远之，也要注意享用的时间，如中午，晚上。</p>
<p>尽量不要在工作时间娱乐，甚至喧哗，人民的眼睛是雪亮的，领导的眼睛也是雪亮的，尤其是对于软件这种成果极难量化的产品，有时候表现和态度反而成了一种指标，不像销售一样，给公司带来的是真金白银，我无论怎么玩，能拿回单子就行，然而对于软件，你有绝对的证据证明成果超越别人吗？</p>
<p>所以外企有个很有意思的现象，一个团队的座位，离食品的距离越近越好，离娱乐设备的距离越远越好。离食品近，取用方便，领导看到你拿吃的也不会说什么，然而离娱乐设备近，领导办公室的门都开着，有谁胆敢长时间玩耍啊。所以娱乐设备上面玩耍的人一般都是座位离得比较远的。</p>
<p>此篇就写到这里的，在外企多年，其实发生了很多有趣的事情和现象，当走过几个外企的时候，发现有很多相似的潜规则。</p>
<p>进入中国的外企，其实是有中国特色的外企。中华文化的强大，使得所有的东西一到中国就会中国化，甚至改变了味道。很多民族如满族，回族的很多人都失去了原来民族的特色。也只有在中国，才可能存在儒释道三教合一的说法，不知道释迦摩尼有何感想。上学的时候，一个我很佩服的大物老师，年纪很大，他是坚定的马克思主义者，但是他曾经说，上个星期我病的厉害，差点就去见马克思了。我笑道，马克思是唯物的，是不相信死后有鬼的，死后去见阎王是迷信，去见马克思就不是了？</p>
<p>等有空的时候，再接着给大家讲外企的故事。</p>
<p>分类: <a href="http://www.cnblogs.com/forfuture1978/category/300669.html" target="_blank">IT外企那点儿事</a></p>
<p>绿色通道： <a href="">好文要顶</a> <a href="">关注我</a> <a href="">收藏该文</a><a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" target="_blank">与我联系</a> <a href="&quot;分享至新浪微博&quot;"><img src="" alt=""></a>
<a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank"><img src="" alt=""></a></p>
<p><a href="http://home.cnblogs.com/u/forfuture1978/" target="_blank">觉先</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followees" target="_blank">关注 - 3</a>
<a href="http://home.cnblogs.com/u/forfuture1978/followers" target="_blank">粉丝 - 560</a></p>
<p>荣誉：<a href="http://www.cnblogs.com/expert/" target="_blank">推荐博客</a>
<a href="">+加关注</a></p>
<p>18</p>
<p>0
(请您对文章做出评价)</p>
<p><a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/29/1723417.html" target="_blank">«</a> 上一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/04/29/1723417.html" title="发布于2010-04-29 00:24" target="_blank">高级Linux程序设计第五章：进程间通信</a>
<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/01/1725761.html" target="_blank">»</a> 下一篇：<a href="http://www.cnblogs.com/forfuture1978/archive/2010/05/01/1725761.html" title="发布于2010-05-01 20:57" target="_blank">信息检索导论(译)：第一章 布尔检索(1)</a>
posted on 2010-04-30 21:30 <a href="http://www.cnblogs.com/forfuture1978/" target="_blank">觉先</a> 阅读(8943) 评论(26) <a href="http://www.cnblogs.com/forfuture1978/admin/EditPosts.aspx?postid=1725341" target="_blank">编辑</a> <a href="">收藏</a></p>
<p><a href=""></a></p>
<h3 id="-">评论</h3>
<p><a href="">/#1楼</a><a href=""></a>  2010-04-30 21:54  <a href="http://www.cnblogs.com/lguyss/">土星的狗狗</a> <a href="http://space.cnblogs.com/msg/send/%e5%9c%9f%e6%98%9f%e7%9a%84%e7%8b%97%e7%8b%97" title="发送站内短消息" target="_blank"> </a></p>
<p>写的太好了，又学习了~哈哈，直接映射了我之前的日本公司。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u23929.jpg" target="_blank">http://pic.cnitblog.com/face/u23929.jpg</a></p>
<p><a href="">/#2楼</a><a href=""></a>  2010-04-30 23:57  <a href="http://www.cnblogs.com/wenjl520/">温景良(Jason)</a> <a href="http://space.cnblogs.com/msg/send/%e6%b8%a9%e6%99%af%e8%89%af(Jason" target="_blank"> </a> &quot;发送站内短消息&quot;)</p>
<p>没去过,期待中</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u33118.jpg" target="_blank">http://pic.cnitblog.com/face/u33118.jpg</a></p>
<p><a href="">/#3楼</a><a href=""></a>  2010-05-01 10:41  <a href="http://www.cnblogs.com/ilovedotnet/">ilovedotnet</a> <a href="http://space.cnblogs.com/msg/send/ilovedotnet" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>土星的狗狗
我觉得日企和韩企不能算是真正的外企，大家通常说的外企只包括欧美企业。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u26921.jpg" target="_blank">http://pic.cnitblog.com/face/u26921.jpg</a></p>
<p><a href="">/#4楼</a><a href=""></a>  2010-05-01 21:59  <a href="http://www.cnblogs.com/skyyang/">DarroldYang</a> <a href="http://space.cnblogs.com/msg/send/DarroldYang" title="发送站内短消息" target="_blank"> </a></p>
<p>说的很像
加入这样的工作环境没多久
他们一个项目也是做了几年了
后面就一直在bug</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u23975.png" target="_blank">http://pic.cnitblog.com/face/u23975.png</a></p>
<p><a href="">/#5楼</a><a href=""></a>  2010-05-04 09:26  <a href="http://www.cnblogs.com/peon/">加菲猫</a> <a href="http://space.cnblogs.com/msg/send/%e5%8a%a0%e8%8f%b2%e7%8c%ab" title="发送站内短消息" target="_blank"> </a></p>
<p>作者深得外企三味，不过假如你有心，在薪水上超过大部分民企的同学问题不大，华为腾讯的除外</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u28333.jpg" target="_blank">http://pic.cnitblog.com/face/u28333.jpg</a></p>
<p><a href="">/#6楼</a><a href=""></a>  2010-05-05 09:28  <a href="http://www.cnblogs.com/jciwolf/">Jerry Qian</a> <a href="http://space.cnblogs.com/msg/send/Jerry+Qian" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主打击人啦，我现在在学英语啊。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#7楼</a><a href=""></a>  2010-05-05 11:43  <a href="http://www.cnblogs.com/bobliu/">Bob Liu</a> <a href="http://space.cnblogs.com/msg/send/Bob+Liu" title="发送站内短消息" target="_blank"> </a></p>
<p>看看，了解一下外企～</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u126058.jpg" target="_blank">http://pic.cnitblog.com/face/u126058.jpg</a></p>
<p><a href="">/#8楼</a><a href=""></a>  2010-05-05 12:01  <a href="http://www.cnblogs.com/Aaron_Anubis/">Aaron_Aanubis</a> <a href="http://space.cnblogs.com/msg/send/Aaron_Aanubis" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主，太好了···把这些说出来，叫我们更加了解外企，我们就更能根据自身来进行职业规划了！！！3q</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#9楼</a><a href=""></a>  2010-05-05 12:25  <a href="http://www.cnblogs.com/Jong/">Caspar Jiong</a> <a href="http://space.cnblogs.com/msg/send/Caspar+Jiong" title="发送站内短消息" target="_blank"> </a></p>
<p>深有同感！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#10楼</a><a href=""></a>  2010-05-05 12:51  <a href="http://www.cnblogs.com/jerry_cong/">鸟瞰</a> <a href="http://space.cnblogs.com/msg/send/%e9%b8%9f%e7%9e%b0" title="发送站内短消息" target="_blank"> </a></p>
<p>对外企的经营模式，如果想老板的朋友们，某些地方还是比较值得借鉴的</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u122874.jpg?id=16080143" target="_blank">http://pic.cnitblog.com/face/u122874.jpg?id=16080143</a></p>
<p><a href="">/#11楼</a><a href=""></a>  2010-05-05 15:13  <a href="http://www.cnblogs.com/facingwaller/">撞破南墙</a> <a href="http://space.cnblogs.com/msg/send/%e6%92%9e%e7%a0%b4%e5%8d%97%e5%a2%99" title="发送站内短消息" target="_blank"> </a></p>
<p>看了觉得果然很中国化，不知道GG也是这样的吗？</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u69696.jpg?id=16133304" target="_blank">http://pic.cnitblog.com/face/u69696.jpg?id=16133304</a></p>
<p><a href="">/#12楼</a><a href=""></a>  2010-05-05 15:46  <a href="http://www.cnblogs.com/ArthasCui/">Arthas-Cui</a> <a href="http://space.cnblogs.com/msg/send/Arthas-Cui" title="发送站内短消息" target="_blank"> </a></p>
<p>你知道的太多了。。。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u37616.jpg?id=29112918" target="_blank">http://pic.cnitblog.com/face/u37616.jpg?id=29112918</a></p>
<p><a href="">/#13楼</a><a href=""></a>  2010-05-05 16:11  <a href="http://www.cnblogs.com/daxianren/">卡通一下</a> <a href="http://space.cnblogs.com/msg/send/%e5%8d%a1%e9%80%9a%e4%b8%80%e4%b8%8b" title="发送站内短消息" target="_blank"> </a></p>
<p>大家可能不太清楚，在美国顶头上司才是你真正的老板。他要开你走，董事会是不会举行表决的，哈哈！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#14楼</a><a href=""></a>  2010-05-05 16:15  <a href="http://www.cnblogs.com/daxianren/">卡通一下</a> <a href="http://space.cnblogs.com/msg/send/%e5%8d%a1%e9%80%9a%e4%b8%80%e4%b8%8b" title="发送站内短消息" target="_blank"> </a></p>
<p>楼主文章的题目，<strong>“外企那点儿事”；“也就那么回事”</strong>，可以看出楼主当前的心态！
就好象世上有人说的，一不小心发财了！一不小心成功了......
呵呵！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#15楼</a><a href=""></a>[楼主]  2010-05-05 18:36  <a href="http://www.cnblogs.com/forfuture1978/">觉先</a> <a href="http://space.cnblogs.com/msg/send/%e8%a7%89%e5%85%88" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>卡通一下
外企那点儿事是学了当前的流行语，明朝那点儿事，Java那点儿事...
及历史是什么玩意儿等，吸引人注意的一个噱头而已。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u103165.jpg" target="_blank">http://pic.cnitblog.com/face/u103165.jpg</a></p>
<p><a href="">/#16楼</a><a href=""></a>  2010-05-05 19:20  <a href="http://www.cnblogs.com/daxianren/">卡通一下</a> <a href="http://space.cnblogs.com/msg/send/%e5%8d%a1%e9%80%9a%e4%b8%80%e4%b8%8b" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看引用原文&quot;">引用</a>觉先：
@卡通一下
外企那点儿事是学了当前的流行语，明朝那点儿事，Java那点儿事...
及历史是什么玩意儿等，吸引人注意的一个噱头而已。
朋友间聊天我们也经常地说，只是在正式场合是不说的，呵呵！</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#17楼</a><a href=""></a>  2010-05-09 21:17  <a href="http://www.cnblogs.com/dytes/">dytes</a> <a href="http://space.cnblogs.com/msg/send/dytes" title="发送站内短消息" target="_blank"> </a></p>
<p>不要一概而论，就我的经历而言，还是相当宽松的。-</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#18楼</a><a href=""></a>  2010-05-10 13:02  <a href="http://www.cnblogs.com/Koy/">Koy</a> <a href="http://space.cnblogs.com/msg/send/Koy" title="发送站内短消息" target="_blank"> </a></p>
<p>講得好好，頂一下。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#19楼</a><a href=""></a>  2010-05-10 22:53  <a href="http://home.cnblogs.com/u/127908/">小飞哥</a> <a href="http://space.cnblogs.com/msg/send/%e5%b0%8f%e9%a3%9e%e5%93%a5" title="发送站内短消息" target="_blank"> </a></p>
<p>哈哈楼主你知道得太多了</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#20楼</a><a href=""></a>  2010-05-13 10:56  <a href="http://www.cnblogs.com/KissKnife/">SnowToday</a> <a href="http://space.cnblogs.com/msg/send/SnowToday" title="发送站内短消息" target="_blank"> </a></p>
<p>基本上是这个样子，不过外企跟外企也不太一样，部门跟部门不太一样，项目跟项目不太一样，比如请假放假，我们这请假绝大多数不会有问题，请假就请了，不会有那么多顾虑，还有老外的一些重要节日我们也会跟着放比如圣诞、复活节。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u10907.jpg" target="_blank">http://pic.cnitblog.com/face/u10907.jpg</a></p>
<p><a href="">/#21楼</a><a href=""></a>  2010-05-13 11:11  <a href="http://home.cnblogs.com/u/132808/">足球王子</a> <a href="http://space.cnblogs.com/msg/send/%e8%b6%b3%e7%90%83%e7%8e%8b%e5%ad%90" title="发送站内短消息" target="_blank"> </a></p>
<p>在外企参与项目的机会会少很多，但是没有进过外企，就好像没怎么见过世面一样。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">/#22楼</a><a href=""></a>  2010-05-13 15:46  <a href="http://www.cnblogs.com/Abbott/">Abbott zhao</a> <a href="http://space.cnblogs.com/msg/send/Abbott+zhao" title="发送站内短消息" target="_blank"> </a></p>
<p>这也是为什么小公司半年作出来的东西，大公司要做几年。当然大公司这样做自然有它的道理，大公司稳定，不愁客户资源，不差钱，今年做出来或是明年做出来，客户别无选择，员工也养得起。这些小公司都做不到，必须尽快的满足客户的需要，必须在钱花完之前拉到下一个项目。
这句话有点偏。小公司做的产品真的不能恭维。</p>
<p><a href="">支持(1)</a><a href="">反对(0)</a></p>
<p><a href="">/#23楼</a><a href=""></a>  2010-05-13 21:28  <a href="http://www.cnblogs.com/417533880/">Forrest Liu</a> <a href="http://space.cnblogs.com/msg/send/Forrest+Liu" title="发送站内短消息" target="_blank"> </a></p>
<p>我也在一家小外企工作，最近遇到点事很郁闷。前两天女朋友来公司附近办事，我就带她在公司里待会，等着和我一起吃午饭。。结果她待了没有十分钟，公司老板从我身边过就看到她了，过了一会我的team leader就用communicater跟我说，让她出去，我就带她出去了。。回来后我的leader跟我说老板看到我女朋友了，很生气。因为我之前的公司很随便，以前也带朋友同学什么的进去过。当时也就觉得没什么。今天早上leader又跟我谈话，说客户那边反应对我的工作不满意。我当时很奇怪，因为我跟我的客户一直保持沟通，而且分配给我的task我也都完成的很不错。前一个月的时候我还特意问过客户对我的工作有什么意见，我在哪方面可以做的更好，结果客户给我回复说对我的工作很满意。我不知道是因为我得罪了谁或者我做错了什么。。现在很困惑，前辈给我指点一下吧~~</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u39386.jpg" target="_blank">http://pic.cnitblog.com/face/u39386.jpg</a></p>
<p><a href="">/#24楼</a><a href=""></a>  2010-05-14 18:32  <a href="http://www.cnblogs.com/cjc1021/">开心每一天ㄨ</a> <a href="http://space.cnblogs.com/msg/send/%e5%bc%80%e5%bf%83%e6%af%8f%e4%b8%80%e5%a4%a9%e3%84%a8" title="发送站内短消息" target="_blank"> </a></p>
<p><a href="&quot;查看所回复的评论&quot;">@</a>Forrest Liu
感觉比较没有人情味就是。做事都是规规矩矩的。
如果你在民企或者是小企，哪怕是国企可能都不一定。外企业也是不一样，但你目前所处的就是挺没人情味的感觉~</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u25669.jpg" target="_blank">http://pic.cnitblog.com/face/u25669.jpg</a></p>
<p><a href="">/#25楼</a><a href=""></a>  2010-05-14 23:16  <a href="http://www.cnblogs.com/qingteng1983/">无待</a> <a href="http://space.cnblogs.com/msg/send/%e6%97%a0%e5%be%85" title="发送站内短消息" target="_blank"> </a></p>
<p>有意思，受教了。</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a>
<a href="http://pic.cnitblog.com/face/u131056.jpg?id=02141056" target="_blank">http://pic.cnitblog.com/face/u131056.jpg?id=02141056</a></p>
<p><a href="">/#26楼</a><a href=""></a>18306582010/5/22 21:08:21  2010-05-22 21:08  <a href="http://home.cnblogs.com/u/134973/">fyljf</a> <a href="http://space.cnblogs.com/msg/send/fyljf" title="发送站内短消息" target="_blank"> </a></p>
<p>有些点真是深有体会</p>
<p><a href="">支持(0)</a><a href="">反对(0)</a></p>
<p><a href="">刷新评论</a><a href="">刷新页面</a><a href="">返回顶部</a></p>
<p>注册用户登录后才能发表评论，请 <a href="">登录</a> 或 <a href="">注册</a>，<a href="http://www.cnblogs.com/" target="_blank">访问</a>网站首页。
<a href="http://www.cnblogs.com/" title="程序员的网上家园" target="_blank">博客园首页</a><a href="http://q.cnblogs.com/" title="程序员问答社区" target="_blank">博问</a><a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">新闻</a><a href="http://home.cnblogs.com/ing/" target="_blank">闪存</a><a href="http://job.cnblogs.com/" target="_blank">程序员招聘</a><a href="http://kb.cnblogs.com/" target="_blank">知识库</a></p>
<p><strong>最新IT新闻</strong>:
· <a href="http://news.cnblogs.com/n/182486/" target="_blank">新硬硬整合时代</a>
· <a href="http://news.cnblogs.com/n/182485/" target="_blank">狗血的百度91并购案啊 阿里和周鸿祎都曾掺和</a>
· <a href="http://news.cnblogs.com/n/182483/" target="_blank">如何让搜索引擎抓取AJAX内容？</a>
· <a href="http://news.cnblogs.com/n/182482/" target="_blank">避免代码注释的五大理由</a>
· <a href="http://news.cnblogs.com/n/182481/" target="_blank">OpenWrt——适用于路由器的Linux系统</a>
» <a href="http://news.cnblogs.com/" title="IT新闻" target="_blank">更多新闻...</a></p>
<p><strong>最新知识库文章</strong>:
· <a href="http://kb.cnblogs.com/page/141892/" target="_blank">阿里巴巴集团去IOE运动的思考与总结</a>
· <a href="http://kb.cnblogs.com/page/182265/" target="_blank">硅谷归来7点分享：创业者，做你自己</a>
· <a href="http://kb.cnblogs.com/page/182200/" target="_blank">我为什么不能坚持？</a>
· <a href="http://kb.cnblogs.com/page/168725/" target="_blank">成为高效程序员的7个重要习惯</a>
· <a href="http://kb.cnblogs.com/page/182047/" target="_blank">谈谈对BPM的理解</a>
» <a href="http://kb.cnblogs.com/" target="_blank">更多知识库文章...</a>
Powered by:
<a href="http://www.cnblogs.com/" target="_blank">博客园</a>
Copyright © 觉先</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/zhiya/">zhiya</a></li></span><span class="breadcrumb"><li><a href="/categories/职涯/">职涯</a></li><li><a href="/categories/职涯/IT外企/">IT外企</a></li></span></span> | <span class="tags">Tagged <a href="/tags/IT外企/" class="label label-primary">IT外企</a><a href="/tags/zhiya/" class="label label-success">zhiya</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-zhiya-IT外企--IT外企那点儿事1：外企也就那么回事/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-zhiya-IT外企--IT外企那点儿事1：外企也就那么回事" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/109/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/107/">107</a></li><li><a class="page-number" href="/page/108/">108</a></li><li><a class="page-number" href="/page/109/">109</a></li><li class="active"><li><span class="page-number current">110</span></li><li><a class="page-number" href="/page/111/">111</a></li><li><a class="page-number" href="/page/112/">112</a></li><li><a class="page-number" href="/page/113/">113</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/164/">164</a></li><li><a class="page-number" href="/page/165/">165</a></li><li><a class="extend next" href="/page/111/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Blog powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a> Theme <strong><a href='https://github.com/chenall/hexo-theme-chenall'>chenall</a></strong>(Some change in it)<span class="pull-right"> 更新时间: <em>2014-03-15 13:06:28</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
