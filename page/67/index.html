
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 67 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-性能调优--性能调优攻略-Coolshell/">性能调优攻略 </a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:40.000Z"> <a href="/2014/02/02/2014-02-02-性能调优--性能调优攻略-Coolshell/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-coolshell">性能调优攻略 -Coolshell</h1>
<h2 id="-">性能调优攻略</h2>
<p>2012年6月20日<a href="http://coolshell.cn/articles/author/haoel" title="由 陈皓 发布" target="_blank">陈皓</a><a href="http://coolshell.cn/articles/7490.html#respond" target="_blank">发表评论</a><a href="http://coolshell.cn/articles/7490.html#comments" target="_blank">阅读评论</a>48,645 人阅读    </p>
<p><img src="&quot;Performance Tuning&quot;" alt="">关于性能优化这是一个比较大的话题，在《<a href="http://coolshell.cn/articles/6470.html" title="由12306.cn谈谈网站性能技术" target="_blank">由12306.cn谈谈网站性能技术</a>》中我从业务和设计上说过一些可用的技术以及那些技术的优缺点，今天，想从一些技术细节上谈谈性能优化，主要是一些代码级别的技术和方法。<strong>本文的东西是我的一些经验和知识，并不一定全对，希望大家指正和补充</strong>。</p>
<p>在开始这篇文章之前，大家可以移步去看一下酷壳以前发表的《<a href="http://coolshell.cn/articles/2967.html" title="代码优化概要" target="_blank">代码优化概要</a>》，这篇文章基本上告诉你——<strong>要进行优化，先得找到性能瓶颈</strong>！ 但是在讲如何定位系统性能瓶劲之前，请让我讲一下系统性能的定义和测试，因为没有这两件事，后面的定位和优化无从谈起。</p>
<h3 id="-">一、系统性能定义</h3>
<p>让我们先来说说如何什么是系统性能。这个定义非常关键，如果我们不清楚什么是系统性能，那么我们将无法定位之。我见过很多朋友会觉得这很容易，但是仔细一问，其实他们并没有一个比较系统的方法，所以，在这里我想告诉大家如何系统地来定位性能。 总体来说，系统性能就是两个事：</p>
<ol>
<li><strong>Throughput</strong> ，吞吐量。也就是每秒钟可以处理的请求数，任务数。</li>
<li><strong>Latency</strong>， 系统延迟。也就是系统在处理一个请求或一个任务时的延迟。</li>
</ol>
<p>一般来说，一个系统的性能受到这两个条件的约束，缺一不可。比如，我的系统可以顶得住一百万的并发，但是系统的延迟是2分钟以上，那么，这个一百万的负载毫无意义。系统延迟很短，但是吞吐量很低，同样没有意义。所以，一个好的系统的性能测试必然受到这两个条件的同时作用。 有经验的朋友一定知道，这两个东西的一些关系：</p>
<ul>
<li><strong>Throughput越大，Latency会越差。</strong>因为请求量过大，系统太繁忙，所以响应速度自然会低。</li>
<li><strong>Latency越好，能支持的Throughput就会越高。</strong>因为Latency短说明处理速度快，于是就可以处理更多的请求。</li>
</ul>
<h3 id="-">二、系统性能测试</h3>
<p>经过上述的说明，我们知道要测试系统的性能，需要我们收集系统的Throughput和Latency这两个值。</p>
<ul>
<li><p>首先，<strong>需要定义Latency这个值</strong>，比如说，对于网站系统响应时间必需是5秒以内（对于某些实时系统可能需要定义的更短，比如5ms以内，这个更根据不同的业务来定义）</p>
</li>
<li><p>其次，<strong>开发性能测试工具</strong>，一个工具用来制造高强度的Throughput，另一个工具用来测量Latency。对于第一个工具，你可以参考一下“<a href="http://coolshell.cn/articles/2589.html" title="十个免费的Web压力测试工具" target="_blank">十个免费的Web压力测试工具</a>”，关于如何测量Latency，你可以在代码中测量，但是这样会影响程序的执行，而且只能测试到程序内部的Latency，真正的Latency是整个系统都算上，包括操作系统和网络的延时，你可以使用Wireshark来抓网络包来测量。这两个工具具体怎么做，这个还请大家自己思考去了。</p>
</li>
<li><p>最后，<strong>开始性能测试</strong>。你需要不断地提升测试的Throughput，然后观察系统的负载情况，如果系统顶得住，那就观察Latency的值。这样，你就可以找到系统的最大负载，并且你可以知道系统的响应延时是多少。</p>
</li>
</ul>
<p>再多说一些，</p>
<ul>
<li><p>关于Latency，如果吞吐量很少，这个值估计会非常稳定，当吞吐量越来越大时，系统的Latency会出现非常剧烈的抖动，所以，我们在测量Latency的时候，我们需要注意到Latency的分布，也就是说，有百分之几的在我们允许的范围，有百分之几的超出了，有百分之几的完全不可接受。也许，平均下来的Latency达标了，但是其中仅有50%的达到了我们可接受的范围。那也没有意义。</p>
</li>
<li><p>关于性能测试，我们还需要定义一个时间段。比如：在某个吞吐量上持续15分钟。因为当负载到达的时候，系统会变得不稳定，当过了一两分钟后，系统才会稳定。另外，也有可能是，你的系统在这个负载下前几分钟还表现正常，然后就不稳定了，甚至垮了。所以，需要这么一段时间。这个值，我们叫做峰值极限。</p>
</li>
<li><p>性能测试还需要做Soak Test，也就是在某个吞吐量下，系统可以持续跑一周甚至更长。这个值，我们叫做系统的正常运行的负载极限。</p>
</li>
</ul>
<p>性能测试有很多很复要的东西，比如：burst test等。 这里不能一一详述，这里只说了一些和性能调优相关的东西。总之，性能测试是一细活和累活。</p>
<h3 id="-">三、定位性能瓶颈</h3>
<p><img src="&quot;bottleneck&quot;" alt="">有了上面的铺垫，我们就可以测试到到系统的性能了，再调优之前，我们先来说说如何找到性能的瓶颈。我见过很多朋友会觉得这很容易，但是仔细一问，其实他们并没有一个比较系统的方法。</p>
<h3 id="3-1-">3.1）查看操作系统负载</h3>
<p>首先，当我们系统有问题的时候，我们不要急于去调查我们代码，这个毫无意义。我们首要需要看的是操作系统的报告。看看操作系统的CPU利用率，看看内存使用率，看看操作系统的IO，还有网络的IO，网络链接数，等等。Windows下的perfmon是一个很不错的工具，Linux下也有很多相关的命令和工具，比如：<a href="http://sourceware.org/systemtap/" target="_blank">SystemTap</a>，<a href="https://latencytop.org/" target="_blank">LatencyTOP</a>，vmstat, sar, iostat, top, tcpdump等等 。通过观察这些数据，我们就可以知道我们的软件的性能基本上出在哪里。比如：</p>
<p>1）先看CPU利用率，如果CPU利用率不高，但是系统的Throughput和Latency上不去了，这说明我们的程序并没有忙于计算，而是忙于别的一些事，比如IO。（另外，CPU的利用率还要看内核态的和用户态的，内核态的一上去了，整个系统的性能就下来了。而对于多核CPU来说，CPU 0 是相当关键的，如果CPU 0的负载高，那么会影响其它核的性能，因为CPU各核间是需要有调度的，这靠CPU0完成）</p>
<p>2）然后，我们可以看一下IO大不大，IO和CPU一般是反着来的，CPU利用率高则IO不大，IO大则CPU就小。关于IO，我们要看三个事，一个是磁盘文件IO，一个是驱动程序的IO（如：网卡），一个是内存换页率。这三个事都会影响系统性能。</p>
<p>3）然后，查看一下网络带宽使用情况，在Linux下，你可以使用iftop, iptraf, ntop, tcpdump这些命令来查看。或是用Wireshark来查看。</p>
<p>4）如果CPU不高，IO不高，内存使用不高，网络带宽使用不高。但是系统的性能上不去。这说明你的程序有问题，比如，你的程序被阻塞了。可能是因为等那个锁，可能是因为等某个资源，或者是在切换上下文。</p>
<p><strong>通过了解操作系统的性能，我们才知道性能的问题，比如：带宽不够，内存不够，TCP缓冲区不够，等等，很多时候，不需要调整程序的，只需要调整一下硬件或操作系统的配置就可以了</strong>。</p>
<h3 id="3-2-profiler-">3.2）使用Profiler测试</h3>
<p>接下来，我们需要使用性能检测工具，也就是使用某个Profiler来差看一下我们程序的运行性能。如：Java的JProfiler/TPTP/CodePro Profiler，GNU的gprof，IBM的PurifyPlus，Intel的VTune，AMD的CodeAnalyst，还有Linux下的OProfile/perf，后面两个可以让你对你的代码优化到CPU的微指令级别，如果你关心CPU的L1/L2的缓存调优，那么你需要考虑一下使用VTune。 使用这些Profiler工具，可以让你程序中各个模块函数甚至指令的很多东西，如：<strong>运行的时间</strong> ，<strong>调用的次数</strong>，<strong>CPU的利用率</strong>，等等。这些东西对我们来说非常有用。</p>
<p>我们重点观察运行时间最多，调用次数最多的那些函数和指令。这里注意一下，对于调用次数多但是时间很短的函数，你可能只需要轻微优化一下，你的性能就上去了（比如：某函数一秒种被调用100万次，你想想如果你让这个函数提高0.01毫秒的时间 ，这会给你带来多大的性能）</p>
<p>使用Profiler有个问题我们需要注意一下，因为Profiler会让你的程序运行的性能变低，像PurifyPlus这样的工具会在你的代码中插入很多代码，会导致你的程序运行效率变低，从而没发测试出在高吞吐量下的系统的性能，对此，一般有两个方法来定位系统瓶颈：</p>
<p>1）在你的代码中自己做统计，使用微秒级的计时器和函数调用计算器，每隔10秒把统计log到文件中。</p>
<p>2）分段注释你的代码块，让一些函数空转，做Hard Code的Mock，然后再测试一下系统的Throughput和Latency是否有质的变化，如果有，那么被注释的函数就是性能瓶颈，再在这个函数体内注释代码，直到找到最耗性能的语句。</p>
<p>最后再说一点，<strong>对于性能测试，不同的Throughput会出现不同的测试结果，不同的测试数据也会有不同的测试结果。所以，用于性能测试的数据非常重要，性能测试中，我们需要观测试不同Throughput的结果</strong>。</p>
<h3 id="-">四、常见的系统瓶颈</h3>
<p>下面这些东西是我所经历过的一些问题，也许并不全，也许并不对，大家可以补充指正，我<strong>纯属抛砖引玉</strong>。关于系统架构方面的性能调优，大家可移步看一下《<a href="http://coolshell.cn/articles/6470.html" title="由12306.cn谈谈网站性能技术" target="_blank">由12306.cn谈谈网站性能技术</a>》，关于Web方面的一些性能调优的东西，大家可以看看《<a href="http://coolshell.cn/articles/6043.html" title="Web开发中需要了解的东西" target="_blank">Web开发中需要了解的东西</a>》一文中的性能一章。我在这里就不再说设计和架构上的东西了。</p>
<p><em>**</em>一般来说，性能优化也就是下面的几个策略：</p>
<ul>
<li><p><strong>用空间换时间</strong>。各种cache如CPU L1/L2/RAM到硬盘，都是用空间来换时间的策略。这样策略基本上是把计算的过程一步一步的保存或缓存下来，这样就不用每次用的时候都要再计算一遍，比如数据缓冲，CDN，等。这样的策略还表现为冗余数据，比如数据镜象，负载均衡什么的。</p>
</li>
<li><p><strong>用时间换空间</strong>。有时候，少量的空间可能性能会更好，比如网络传输，如果有一些压缩数据的算法（如前些天说的“<a href="http://coolshell.cn/articles/7459.html" title="Huffman 编码压缩算法" target="_blank">Huffman 编码压缩算法</a>” 和 “<a href="http://coolshell.cn/articles/7425.html" title="rsync 的核心算法" target="_blank">rsync 的核心算法</a>”），这样的算法其实很耗时，但是因为瓶颈在网络传输，所以用时间来换空间反而能省时间。</p>
</li>
<li><p><strong>简化代码</strong>。最高效的程序就是不执行任何代码的程序，所以，代码越少性能就越高。关于代码级优化的技术大学里的教科书有很多示例了。如：减少循环的层数，减少递归，在循环中少声明变量，少做分配和释放内存的操作，尽量把循环体内的表达式抽到循环外，条件表达的中的多个条件判断的次序，尽量在程序启动时把一些东西准备好，注意函数调用的开销（栈上开销），注意面向对象语言中临时对象的开销，小心使用异常（不要用异常来检查一些可接受可忽略并经常发生的错误），…… 等等，等等，这连东西需要我们非常了解编程语言和常用的库。</p>
</li>
<li><p><strong>并行处理</strong>。如果CPU只有一个核，你要玩多进程，多线程，对于计算密集型的软件会反而更慢（因为操作系统调度和切换开销很大），CPU的核多了才能真正体现出多进程多线程的优势。并行处理需要我们的程序有Scalability，不能水平或垂直扩展的程序无法进行并行处理。从架构上来说，这表再为——是否可以做到不改代码只是加加机器就可以完成性能提升？</p>
</li>
</ul>
<p>总之，<strong>根据2：8原则来说，20%的代码耗了你80%的性能，找到那20%的代码，你就可以优化那80%的性能</strong>。 下面的一些东西都是我的一些经验，我只例举了一些最有价值的性能调优的的方法，供你参考，也欢迎补充。</p>
<p><strong>4.1）算法调优</strong>。算法非常重要，好的算法会有更好的性能。举几个我经历过的项目的例子，大家可以感觉一下。</p>
<ul>
<li><p>一个是<strong>过滤算法</strong>，系统需要对收到的请求做过滤，我们把可以被filter in/out的东西配置在了一个文件中，原有的过滤算法是遍历过滤配置，后来，我们找到了一种方法可以对这个过滤配置进行排序，这样就可以用二分折半的方法来过滤，系统性能增加了50%。</p>
</li>
<li><p>一个是<strong>哈希算法</strong>。计算哈希算法的函数并不高效，一方面是计算太费时，另一方面是碰撞太高，碰撞高了就跟单向链表一个性能（可参看<a href="http://coolshell.cn/articles/6424.html" title="Hash Collision DoS 问题" target="_blank">Hash Collision DoS 问题</a>）。我们知道，算法都是和需要处理的数据很有关系的，就算是被大家所嘲笑的“冒泡排序”在某些情况下（大多数数据是排好序的）其效率会高于所有的排序算法。哈希算法也一样，广为人知的哈希算法都是用英文字典做测试，但是我们的业务在数据有其特殊性，所以，对于还需要根据自己的数据来挑选适合的哈希算法。对于我以前的一个项目，公司内某牛人给我发来了一个哈希算法，结果让我们的系统性能上升了150%。（关于各种哈希算法，你一定要看看<a href="http://programmers.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed/145633#145633" target="_blank">StackExchange上的这篇关于各种hash算法的文章</a> ）</p>
</li>
<li><p><strong>分而治之和预处理</strong>。以前有一个程序为了生成月报表，每次都需要计算很长的时间，有时候需要花将近一整天的时间。于是我们把我们找到了一种方法可以把这个算法发成增量式的，也就是说我每天都把当天的数据计算好了后和前一天的报表合并，这样可以大大的节省计算时间，每天的数据计算量只需要20分钟，但是如果我要算整个月的，系统则需要10个小时以上（SQL语句在大数据量面前性能成级数性下降）。这种分而治之的思路在大数据面前对性能有很帮助，就像merge排序一样。SQL语句和数据库的性能优化也是这一策略，如：使用嵌套式的Select而不是笛卡尔积的Select，使用视图，等等。</p>
</li>
</ul>
<p><strong>4.2）代码调优</strong>。从我的经验上来说，代码上的调优有下面这几点：</p>
<ul>
<li><p><strong>字符串操作</strong>。这是最费系统性能的事了，无论是strcpy, strcat还是strlen，最需要注意的是字符串子串匹配。所以，能用整型最好用整型。举几个例子，第一个例子是N年前做银行的时候，我的同事喜欢把日期存成字符串（如：2012-05-29 08:30:02），我勒个去，一个select  where between语句相当耗时。另一个例子是，我以前有个同事把一些状态码用字符串来处理，他的理由是，这样可以在界面上直接显示，后来性能调优的时候，我把这些状态码全改成整型，然后用位操作查状态，因为有一个每秒钟被调用了150K次的函数里面有三处需要检查状态，经过改善以后，整个系统的性能上升了30%左右。还有一个例子是，我以前从事的某个产品编程规范中有一条是要在每个函数中把函数名定义出来，如：const char fname[]=”functionName()”, 这是为了好打日志，但是为什么不声明成 static类型的呢？</p>
</li>
<li><p><strong>多线程调优</strong>。有人说，thread is evil，这个对于系统性能在某些时候是个问题。因为多线程瓶颈就在于互斥和同步的锁上，以及线程上下文切换的成本，怎么样的少用锁或不用锁是根本（比如：<a href="http://coolshell.cn/articles/6790.html" title="多版本并发控制(MVCC)在分布式系统中的应用" target="_blank">多版本并发控制(MVCC)在分布式系统中的应用</a> 中说的乐观锁可以解决性能问题），此外，还有读写锁也可以解决大多数是读操作的并发的性能问题。这里多说一点在C++中，我们可能会使用线程安全的智能指针AutoPtr或是别的一些容器，只要是线程安全的，其不管三七二十一都要上锁，上锁是个成本很高的操作，使用AutoPtr会让我们的系统性能下降得很快，如果你可以保证不会有线程并发问题，那么你应该不要用AutoPtr。我记得我上次我们同事去掉智能指针的引用计数，让系统性能提升了50%以上。对于Java对象的引用计数，如果我猜的没错的话，到处都是锁，所以，Java的性能问题一直是个问题。另外，线程不是越多越好，线程间的调度和上下文切换也是很夸张的事，尽可能的在一个线程里干，尽可能的不要同步线程。这会让你有很多的性能。</p>
</li>
<li><p><strong>内存分配</strong>。不要小看程序的内存分配。malloc/realloc/calloc这样的系统调非常耗时，尤其是当内存出现碎片的时候。我以前的公司出过这样一个问题——在用户的站点上，我们的程序有一天不响应了，用GDB跟进去一看，系统hang在了malloc操作上，20秒都没有返回，重启一些系统就好了。这就是内存碎片的问题。这就是为什么很多人抱怨STL有严重的内存碎片的问题，因为太多的小内存的分配释放了。有很多人会以为用内存池可以解决这个问题，但是实际上他们只是重新发明了Runtime-C或操作系统的内存管理机制，完全于事无补。当然解决内存碎片的问题还是通过内存池，具体来说是一系列不同尺寸的内存池（这个留给大家自己去思考）。当然，少进行动态内存分配是最好的。说到内存池就需要说一下池化技术。比如线程池，连接池等。池化技术对于一些短作业来说（如http服务） 相当相当的有效。这项技术可以减少链接建立，线程创建的开销，从而提高性能。</p>
</li>
<li><p><strong>异步操作</strong>。我们知道Unix下的文件操作是有block和non-block的方式的，像有些系统调用也是block式的，如：Socket下的select，Windows下的WaitforObject之类的，如果我们的程序是同步操作，那么会非常影响性能，我们可以改成异步的，但是改成异步的方式会让你的程序变复杂。异步方式一般要通过队列，要注间队列的性能问题，另外，异步下的状态通知通常是个问题，比如消息事件通知方式，有callback方式，等，这些方式同样可能会影响你的性能。但是通常来说，异步操作会让性能的吞吐率有很大提升（Throughput），但是会牺牲系统的响应时间（latency）。这需要业务上支持。</p>
</li>
<li><p><strong>语言和代码库</strong>。我们要熟悉语言以及所使用的函数库或类库的性能。比如：STL中的很多容器分配了内存后，那怕你删除元素，内存也不会回收，其会造成内存泄露的假像，并可能造成内存碎片问题。再如，STL某些容器的size()==0  和 empty()是不一样的，因为，size()是O(n)复杂度，empty()是O(1)的复杂度，这个要小心。Java中的JVM调优需要使用的这些参数：-Xms -Xmx -Xmn -XX:SurvivorRatio -XX:MaxTenuringThreshold，还需要注意JVM的GC，GC的霸气大家都知道，尤其是full GC（还整理内存碎片），他就像“恐龙特级克赛号”一样，他运行的时候，整个世界的时间都停止了。</p>
</li>
</ul>
<p><strong>4.3）网络调优</strong></p>
<p>关于网络调优，尤其是TCP Tuning（你可以以这两个关键词在网上找到很多文章），这里面有很多很多东西可以说。看看Linux下TCP/IP的那么多参数就知道了（顺便说一下，你也许不喜欢Linux，但是你不能否认Linux给我们了很多可以进行内核调优的权力）。强烈建议大家看看《<a href="http://book.douban.com/subject/1088054/" target="_blank">TCP/IP 详解 卷1:协议</a>》这本书。我在这里只讲一些概念上的东西。</p>
<p><strong>A） TCP调优</strong></p>
<p>我们知道TCP链接是有很多开销的，一个是会占用文件描述符，另一个是会开缓存，一般来说一个系统可以支持的TCP链接数是有限的，我们需要清楚地认识到TCP链接对系统的开销是很大的。正是因为TCP是耗资源的，所以，很多攻击都是让你系统上出现大量的TCP链接，把你的系统资源耗尽。比如著名的SYNC Flood攻击。</p>
<p>所以，我们要注意配置KeepAlive参数，这个参数的意思是定义一个时间，如果链接上没有数据传输，系统会在这个时间发一个包，如果没有收到回应，那么TCP就认为链接断了，然后就会把链接关闭，这样可以回收系统资源开销。（注：HTTP层上也有KeepAlive参数）对于像HTTP这样的短链接，设置一个1-2分钟的keepalive非常重要。这可以在一定程度上防止DoS攻击。有下面几个参数（下面这些参数的值仅供参考）：
1</p>
<p>2
3 net.ipv4.tcp_keepalive_probes = 5</p>
<p>net.ipv4.tcp_keepalive_intvl = 20
net.ipv4.tcp_fin_timeout = 30</p>
<p>对于TCP的TIME_WAIT这个状态，主动关闭的一方进入TIME_WAIT状态，TIME_WAIT状态将持续2个MSL(Max Segment Lifetime)，默认为4分钟，TIME_WAIT状态下的资源不能回收。有大量的TIME_WAIT链接的情况一般是在HTTP服务器上。对此，有两个参数需要注意，</p>
<p>1</p>
<p>2
 net.ipv4.tcp_tw_reuse=1</p>
<p>net.ipv4.tcp_tw_recycle=1</p>
<p>前者表示重用TIME_WAIT，后者表示回收TIME_WAIT的资源。</p>
<p>TCP还有一个重要的概念叫RWIN（TCP Receive Window Size），这个东西的意思是，我一个TCP链接在没有向Sender发出ack时可以接收到的最大的数据包。为什么这个很重要？因为如果Sender没有收到Receiver发过来ack，Sender就会停止发送数据并会等一段时间，如果超时，那么就会重传。这就是为什么TCP链接是可靠链接的原因。重传还不是最严重的，如果有丢包发生的话，TCP的带宽使用率会马上受到影响（会盲目减半），再丢包，再减半，然后如果不丢包了，就逐步恢复。相关参数如下：
1</p>
<p>2
3</p>
<p>4
 net.core.wmem_default = 8388608</p>
<p>net.core.rmem_default = 8388608
net.core.rmem_max = 16777216</p>
<p>net.core.wmem_max = 16777216</p>
<p>一般来说，理论上的RWIN应该设置成：吞吐量  /* 回路时间。Sender端的buffer应该和RWIN有一样的大小，因为Sender端发送完数据后要等Receiver端确认，如果网络延时很大，buffer过小了，确认的次数就会多，于是性能就不高，对网络的利用率也就不高了。也就是说，对于延迟大的网络，我们需要大的buffer，这样可以少一点ack，多一些数据，对于响应快一点的网络，可以少一些buffer。因为，如果有丢包（没有收到ack），buffer过大可能会有问题，因为这会让TCP重传所有的数据，反而影响网络性能。（当然，网络差的情况下，就别玩什么高性能了） 所以，高性能的网络重要的是要让网络丢包率非常非常地小（基本上是用在LAN里），如果网络基本是可信的，这样用大一点的buffer会有更好的网络传输性能（来来回回太多太影响性能了）。</p>
<p>另外，我们想一想，如果网络质量非常好，基本不丢包，而业务上我们不怕偶尔丢几个包，如果是这样的话，那么，我们为什么不用速度更快的UDP呢？你想过这个问题了吗？</p>
<p><strong>B）UDP调优</strong></p>
<p>说到UDP的调优，有一些事我想重点说一样，那就是MTU——最大传输单元（其实这对TCP也一样，因为这是链路层上的东西）。所谓最大传输单元，你可以想像成是公路上的公交车，假设一个公交车可以最多坐70人，带宽就像是公路的车道数一样，如果一条路上最多可以容下100辆公交车，那意味着我最多可以运送7000人，但是如果公交车坐不满，比如平均每辆车只有20人，那么我只运送了2000人，于是我公路资源（带宽资源）就被浪费了。 所以，我们对于一个UDP的包，我们要尽量地让他大到MTU的最大尺寸再往网络上传，这样可以最大化带宽利用率。对于这个MTU，以太网是1500字节，光纤是4352字节，802.11无线网是7981。但是，当我们用TCP/UDP发包的时候，我们的有效负载Payload要低于这个值，因为IP协议会加上20个字节，UDP会加上8个字节（TCP加的更多），所以，一般来说，你的一个UDP包的最大应该是1500-8-20=1472，这是你的数据的大小。当然，如果你用光纤的话， 这个值就可以更大一些。（顺便说一下，对于某些NB的千光以态网网卡来说，在网卡上，网卡硬件如果发现你的包的大小超过了MTU，其会帮你做fragment，到了目标端又会帮你做重组，这就不需要你在程序中处理了）</p>
<p>再多说一下，使用Socket编程的时候，你可以使用setsockopt() 设置 SO_SNDBUF/SO_RCVBUF 的大小，TTL和KeepAlive这些关键的设置，当然，还有很多，具体你可以查看一下Socket的手册。</p>
<p>最后说一点，UDP还有一个最大的好处是multi-cast多播，这个技术对于你需要在内网里通知多台结点时非常方便和高效。而且，多播这种技术对于机会的水平扩展（需要增加机器来侦听多播信息）也很有利。</p>
<p><strong>C）网卡调优</strong></p>
<p><em>**</em>对于网卡，我们也是可以调优的，这对于千兆以及网网卡非常必要，在Linux下，我们可以用ifconfig查看网上的统计信息，如果我们看到overrun上有数据，我们就可能需要调整一下txqueuelen的尺寸（一般默认为1000），我们可以调大一些，如：ifconfig eth0 txqueuelen 5000。Linux下还有一个命令叫：ethtool可以用于设置网卡的缓冲区大小。在Windows下，我们可以在网卡适配器中的高级选项卡中调整相关的参数（如：Receive Buffers, Transmit Buffer等，不同的网卡有不同的参数）。把Buffer调大对于需要大数据量的网络传输非常有效。</p>
<p><strong>D）其它网络性能</strong></p>
<p>关于多路复用技术，也就是用一个线程来管理所有的TCP链接，有三个系统调用要重点注意：一个是select，这个系统调用只支持上限1024个链接，第二个是poll，其可以突破1024的限制，但是select和poll本质上是使用的轮询机制，轮询机制在链接多的时候性能很差，因主是O(n)的算法，所以，epoll出现了，epoll是操作系统内核支持的，仅当在链接活跃时，操作系统才会callback，这是由操作系统通知触发的，但其只有Linux Kernel 2.6以后才支持（准确说是2.5.44中引入的），当然，如果所有的链接都是活跃的，过多的使用epoll_ctl可能会比轮询的方式还影响性能，不过影响的不大。</p>
<p>另外，关于一些和DNS Lookup的系统调用要小心，比如：gethostbyaddr/gethostbyname，这个函数可能会相当的费时，因为其要到网络上去找域名，因为DNS的递归查询，会导致严重超时，而又不能通过设置什么参数来设置time out，对此你可以通过配置hosts文件来加快速度，或是自己在内存中管理对应表，在程序启动时查好，而不要在运行时每次都查。另外，在多线程下面，gethostbyname会一个更严重的问题，就是如果有一个线程的gethostbyname发生阻塞，其它线程都会在gethostbyname处发生阻塞，这个比较变态，要小心。（你可以试试GNU的gethostbyname_r()，这个的性能要好一些） 这种到网上找信息的东西很多，比如，如果你的Linux使用了NIS，或是NFS，某些用户或文件相关的系统调用就很慢，所以要小心。</p>
<p><strong>4.4）系统调优</strong></p>
<p><strong>A）I/O模型</strong></p>
<p>前面说到过select/poll/epoll这三个系统调用，我们都知道，Unix/Linux下把所有的设备都当成文件来进行I/O，所以，那三个操作更应该算是I/O相关的系统调用。说到  I/O模型，这对于我们的I/O性能相当重要，我们知道，Unix/Linux经典的I/O方式是（关于Linux下的I/O模型，大家可以读一下这篇文章《<a href="http://www.ibm.com/developerworks/cn/linux/l-async/" target="_blank">使用异步I/O大大提高性能</a>》）：</p>
<p>第一种，同步阻塞式I/O，这个不说了。</p>
<p>第二种，同步无阻塞方式。其通过fctnl设置 O_NONBLOCK 来完成。</p>
<p>第三种，对于select/poll/epoll这三个是I/O不阻塞，但是在事件上阻塞，算是：I/O异步，事件同步的调用。</p>
<p>第四种，AIO方式。这种I/O 模型是一种处理与 I/O 并行的模型。I/O请求会立即返回，说明请求已经成功发起了。在后台完成I/O操作时，向应用程序发起通知，通知有两种方式：一种是产生一个信号，另一种是执行一个基于线程的回调函数来完成这次 I/O 处理过程。</p>
<p>第四种因为没有任何的阻塞，无论是I/O上，还是事件通知上，所以，其可以让你充分地利用CPU，比起第二种同步无阻塞好处就是，第二种要你一遍一遍地去轮询。Nginx之所所以高效，是其使用了epoll和AIO的方式来进行I/O的。</p>
<p>再说一下Windows下的I/O模型，</p>
<p>a）一个是WriteFile系统调用，这个系统调用可以是同步阻塞的，也可以是同步无阻塞的，关于看文件是不是以Overlapped打开的。关于同步无阻塞，需要设置其最后一个参数Overlapped，微软叫Overlapped I/O，你需要WaitForSingleObject才能知道有没有写完成。这个系统调用的性能可想而知。</p>
<p>b）另一个叫WriteFileEx的系统调用，其可以实现异步I/O，并可以让你传入一个callback函数，等I/O结束后回调之， 但是这个回调的过程Windows是把callback函数放到了APC（<a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms681951(v=vs.85" target="_blank">Asynchronous Procedure Calls</a>.aspx)）的队列中，然后，只用当应用程序当前线程成为可被通知状态（Alterable）时，才会被回调。只有当你的线程使用了这几个函数时<a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms687036(v=vs.85" target="_blank">WaitForSingleObjectEx</a>.aspx), <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms687028(v=vs.85" target="_blank">WaitForMultipleObjectsEx</a>.aspx), <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms684245(v=vs.85" target="_blank">MsgWaitForMultipleObjectsEx</a>.aspx), <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms686293(v=vs.85" target="_blank">SignalObjectAndWait</a>.aspx) 和 <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms686307(v=vs.85" target="_blank">SleepEx</a>.aspx)，线程才会成为Alterable状态。可见，这个模型，还是有wait，所以性能也不高。</p>
<p>c）然后是IOCP – IO Completion Port，IOCP会把I/O的结果放在一个队列中，但是，侦听这个队列的不是主线程，而是专门来干这个事的一个或多个线程去干（老的平台要你自己创建线程，新的平台是你可以创建一个线程池）。IOCP是一个线程池模型。这个和Linux下的AIO模型比较相似，但是实现方式和使用方式完全不一样。</p>
<p>当然，真正提高I/O性能方式是把和外设的I/O的次数降到最低，最好没有，所以，对于读来说，内存cache通常可以从质上提升性能，因为内存比外设快太多了。对于写来说，cache住要写的数据，少写几次，但是cache带来的问题就是实时性的问题，也就是latency会变大，我们需要在写的次数上和相应上做权衡。</p>
<p><strong>B）多核</strong>CPU<strong>调优</strong></p>
<p>关于CPU的多核技术，我们知道，CPU0是很关键的，如果0号CPU被用得过狠的话，别的CPU性能也会下降，因为CPU0是有调整功能的，所以，我们不能任由操作系统负载均衡，因为我们自己更了解自己的程序，所以，我们可以手动地为其分配CPU核，而不会过多地占用CPU0，或是让我们关键进程和一堆别的进程挤在一起。</p>
<ul>
<li><p>对于Windows来说，我们可以通过“任务管理器”中的“进程”而中右键菜单中的“设置相关性……”（Set Affinity…）来设置并限制这个进程能被运行在哪些核上。</p>
</li>
<li><p>对于Linux来说，可以使用taskset命令来设置（你可以通过安装schedutils来安装这个命令：apt-get install schedutils）</p>
</li>
</ul>
<p>多核CPU还有一个技术叫<a href="http://en.wikipedia.org/wiki/Non-Uniform_Memory_Access" target="_blank">NUMA</a>技术（Non-Uniform Memory Access）。传统的多核运算是使用SMP(Symmetric Multi-Processor )模式，多个处理器共享一个集中的存储器和I/O总线。于是就会出现一致存储器访问的问题，一致性通常意味着性能问题。NUMA模式下，处理器被划分成多个node， 每个node有自己的本地存储器空间。关于NUMA的一些技术细节，你可以查看一下这篇文章《<a href="http://www.ibm.com/developerworks/cn/linux/l-numa/index.html" target="_blank">Linux 的 NUMA 技术</a>》，在Linux下，对NUMA调优的命令是：<strong>numactl </strong>。如下面的命令：（指定命令“myprogram arg1 arg2”运行在node 0 上，其内存分配在node 0 和 1上）
1 numactl --cpubind=0 --membind=0,1 myprogram arg1 arg2</p>
<p>当然，上面这个命令并不好，因为内存跨越了两个node，这非常不好。最好的方式是只让程序访问和自己运行一样的node，如：</p>
<p>1 $ numactl --membind 1 --cpunodebind 1 --localalloc myapplication</p>
<p><strong>C）文件系统调优</strong></p>
<p>关于文件系统，因为文件系统也是有cache的，所以，为了让文件系统有最大的性能。首要的事情就是分配足够大的内存，这个非常关键，在Linux下可以使用free命令来查看 free/used/buffers/cached，理想来说，buffers和cached应该有40%左右。然后是一个快速的硬盘控制器，SCSI会好很多。最快的是Intel SSD 固态硬盘，速度超快，但是写次数有限。</p>
<p>接下来，我们就可以调优文件系统配置了，对于Linux的Ext3/4来说，几乎在所有情况下都有所帮助的一个参数是关闭文件系统访问时间，在/etc/fstab下看看你的文件系统 有没有noatime参数（一般来说应该有），还有一个是dealloc，它可以让系统在最后时刻决定写入文件发生时使用哪个块，可优化这个写入程序。还要注间一下三种日志模式：data=journal、data=ordered和data=writeback。默认设置data=ordered提供性能和防护之间的最佳平衡。</p>
<p>当然，对于这些来说，ext4的默认设置基本上是最佳优化了。</p>
<p>这里介绍一个Linux下的查看I/O的命令—— iotop，可以让你看到各进程的磁盘读写的负载情况。</p>
<p>其它还有一些关于NFS、XFS的调优，大家可以上google搜索一些相关优化的文章看看。关于各文件系统，大家可以看一下这篇文章——《<a href="http://www.ibm.com/developerworks/cn/linux/l-jfs/" target="_blank">Linux日志文件系统及性能分析</a>》</p>
<p><strong>4.5）数据库调优</strong></p>
<p>数据库调优并不是我的强项，我就仅用我非常有限的知识说上一些吧。注意，下面的这些东西并不一定正确，因为在不同的业务场景，不同的数据库设计下可能会得到完全相反的结论，所以，我仅在这里做一些一般性的说明，具体问题还要具体分析。</p>
<p><strong>A）数据库引擎调优</strong></p>
<p>我对数据库引擎不是熟，但是有几个事情我觉得是一定要去了解的。</p>
<ul>
<li><strong>数据库的锁的方式</strong>。这个非常非常地重要。并发情况下，锁是非常非常影响性能的。各种隔离级别，行锁，表锁，页锁，读写锁，事务锁，以及各种写优先还是读优先机制。性能最高的是不要锁，所以，分库分表，冗余数据，减少一致性事务处理，可以有效地提高性能。NoSQL就是牺牲了一致性和事务处理，并冗余数据，从而达到了分布式和高性能。</li>
<li><strong>数据库的存储机制</strong>。不但要搞清楚各种类型字段是怎么存储的，更重要的是数据库的数据存储方式，是怎么分区的，是怎么管理的，比如Oracle的数据文件，表空间，段，等等。了解清楚这个机制可以减轻很多的I/O负载。比如：MySQL下使用show engines;可以看到各种存储引擎的支持。不同的存储引擎有不同的侧重点，针对不同的业务或数据库设计会让你有不同的性能。</li>
<li><strong>数据库的分布式策略</strong>。最简单的就是复制或镜像，需要了解分布式的一致性算法，或是主主同步，主从同步。通过了解这种技术的机理可以做到数据库级别的水平扩展。</li>
</ul>
<p><strong>B）SQL语句优化</strong></p>
<p>关于SQL语句的优化，首先也是要使用工具，比如：<a href="http://www.mysql.com/products/enterprise/query.html" target="_blank">MySQL SQL Query Analyzer</a>，<a href="http://www.oracle-base.com/articles/11g/sql-performance-analyzer-11gr1.php" target="_blank">Oracle SQL Performance Analyzer</a>，或是微软<a href="http://msdn.microsoft.com/en-us/library/aa216945(v=sql.80" target="_blank">SQL Query Analyzer</a>.aspx)，基本上来说，所有的RMDB都会有这样的工具，来让你查看你的应用中的SQL的性能问题。 还可以使用explain来看看SQL语句最终Execution Plan会是什么样的。</p>
<p>还有一点很重要，数据库的各种操作需要大量的内存，所以服务器的内存要够，优其应对那些多表查询的SQL语句，那是相当的耗内存。</p>
<p>下面我根据我有限的数据库SQL的知识说几个会有性能问题的SQL：</p>
<ul>
<li><p><strong>全表检索</strong>。比如：select /* from user where lastname = “xxxx”，这样的SQL语句基本上是全表查找，线性复杂度O(n)，记录数越多，性能也越差（如：100条记录的查找要50ms，一百万条记录需要5分钟）。对于这种情况，我们可以有两种方法提高性能：一种方法是分表，把记录数降下来，另一种方法是建索引（为lastname建索引）。索引就像是key-value的数据结构一样，key就是where后面的字段，value就是物理行号，对索引的搜索复杂度是基本上是O(log(n)) ——用B-Tree实现索引（如：100条记录的查找要50ms，一百万条记录需要100ms）。</p>
</li>
<li><p><strong>索引</strong>。对于索引字段，最好不要在字段上做计算、类型转换、函数、空值判断、字段连接操作，这些操作都会破坏索引原本的性能。当然，索引一般都出现在Where或是Order by字句中，所以对Where和Order by子句中的子段最好不要进行计算操作，或是加上什么NOT之类的，或是使用什么函数。</p>
</li>
<li><p><strong>多表查询</strong>。关系型数据库最多的操作就是多表查询，多表查询主要有三个关键字，EXISTS，IN和JOIN（关于各种join，可以参看<a href="http://coolshell.cn/articles/3463.html" title="图解SQL的Join" target="_blank">图解SQL的Join</a>一文）。基本来说，现代的数据引擎对SQL语句优化得都挺好的，JOIN和IN/EXISTS在结果上有些不同，但性能基本上都差不多。有人说，EXISTS的性能要好于IN，IN的性能要好于JOIN，我各人觉得，这个还要看你的数据、schema和SQL语句的复杂度，对于一般的简单的情况来说，都差不多，所以千万不要使用过多的嵌套，千万不要让你的SQL太复杂，宁可使用几个简单的SQL也不要使用一个巨大无比的嵌套N级的SQL。还有人说，如果两个表的数据量差不多，Exists的性能可能会高于In，In可能会高于Join，如果这两个表一大一小，那么子查询中，Exists用大表，In则用小表。这个，我没有验证过，放在这里让大家讨论吧。另，有一篇关于SQL Server的文章大家可以看看《<a href="http://explainextended.com/2009/06/16/in-vs-join-vs-exists/" target="_blank">IN vs JOIN vs EXISTS</a>》</p>
</li>
<li><p><strong>JOIN操作</strong>。有人说，Join表的顺序会影响性能，只要Join的结果集是一样，性能和join的次序无关。因为后台的数据库引擎会帮我们优化的。Join有三种实现算法，嵌套循环，排序归并，和Hash式的Join。（MySQL只支持第一种）</p>
</li>
<li><p>嵌套循环，就好像是我们常见的多重嵌套循环。注意，前面的索引说过，数据库的索引查找算法用的是B-Tree，这是O(log(n))的算法，所以，整个算法复法度应该是O(log(n)) /* O(log(m)) 这样的。</p>
</li>
<li>Hash式的Join，主要解决嵌套循环的O(log(n))的复杂，使用一个临时的hash表来标记。</li>
<li>排序归并，意思是两个表按照查询字段排好序，然后再合并。当然，索引字段一般是排好序的。</li>
</ul>
<p>还是那句话，具体要看什么样的数据，什么样的SQL语句，你才知道用哪种方法是最好的。</p>
<ul>
<li><p><strong>部分结果集。</strong>我们知道MySQL里的Limit关键字，Oracle里的rownum，SQL Server里的Top都是在限制前几条的返回结果。这给了我们数据库引擎很多可以调优的空间。一般来说，返回top n的记录数据需要我们使用order by，注意在这里我们需要为order by的字段建立索引。有了被建索引的order by后，会让我们的select语句的性能不会被记录数的所影响。使用这个技术，一般来说我们前台会以分页方式来显现数据，Mysql用的是OFFSET，SQL Server用的是FETCH NEXT，这种Fetch的方式其实并不好是线性复杂度，所以，如果我们能够知道order by字段的第二页的起始值，我们就可以在where语句里直接使用&gt;=的表达式来select，这种技术叫seek，而不是fetch，seek的性能比fetch要高很多。</p>
</li>
<li><p><strong>字符串</strong>。正如我前面所说的，字符串操作对性能上有非常大的恶梦，所以，能用数据的情况就用数字，比如：时间，工号，等。</p>
</li>
<li><p><strong>全文检索</strong>。千万不要用Like之类的东西来做全文检索，如果要玩全文检索，可以尝试使用<a href="http://sphinxsearch.com/" target="_blank">Sphinx</a>。</p>
</li>
<li><p><strong>其它</strong>。</p>
</li>
<li><p>不要select /*，而是明确指出各个字段，如果有多个表，一定要在字段名前加上表名，不要让引擎去算。</p>
</li>
<li>不要用Having，因为其要遍历所有的记录。性能差得不能再差。</li>
<li>尽可能地使用UNION ALL  取代  UNION。</li>
<li>索引过多，insert和delete就会越慢。而update如果update多数索引，也会慢，但是如果只update一个，则只会影响一个索引表。</li>
<li>等等。</li>
</ul>
<p>关于SQL语句的优化，网上有很多文章， 不同的数据库引擎有不同的优化技巧，正如本站以前转发的《<a href="http://coolshell.cn/articles/1846.html" target="_blank">MySQL性能优化的最佳20+条经验</a>》</p>
<p>先写这么多吧，欢迎大家指正补充。
<strong>注：</strong>这篇文章的确是个大杂烩。其实其中的说到的很多技术在网上都有很多很多的技术文章，google一下就能找到一堆有很多细节的文章，所以我也就不写了。这篇性能调优的文章写作的动机是之前看到 <a href="http://weibo.com/n/%E6%B7%98%E5%AE%9D%E8%A4%9A%E9%9C%B8" target="_blank">@淘宝褚霸</a> 强推的<a href="http://highscalability.com/" target="_blank">highscalability.com</a>上的这篇文章：<a href="http://highscalability.com/blog/2012/5/16/big-list-of-20-common-bottlenecks.html" target="_blank">Big List Of 20 Common Bottlenecks</a>，觉得这篇文章泛泛而谈，觉得自己能写得比它好，所以就产生了动机。
来源： <a href="[http://coolshell.cn/articles/7490.html](http://coolshell.cn/articles/7490.html)">[http://coolshell.cn/articles/7490.html](http://coolshell.cn/articles/7490.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/性能调优/">性能调优</a></li></span></span> | <span class="tags">Tagged <a href="/tags/性能调优/" class="label label-primary">性能调优</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:40"datetime="2014-03-07 09:54:40"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-性能调优--性能调优攻略-Coolshell/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-性能调优--性能调优攻略-Coolshell" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-内存分析--Java工具（jmap-jstack）在linux上的源码分析/">Java 工具（jmap</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:40.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-内存分析--Java工具（jmap-jstack）在linux上的源码分析/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="java-jmap-jstack-linux-">Java 工具（jmap,jstack）在linux上的源码分析</h1>
<p><a href="http://blog.csdn.net/raintungli/article/details/7023092" target="_blank">Java 工具（jmap,jstack）在linux上的源码分析（一）</a></p>
<p>在我们常用的Jstack, Jmap 用于分析java虚拟机的状态的工具，通过起另一个虚拟机通过运行sun.tools包下的java文件，去跟踪另一个虚拟机的状态。</p>
<p>如果让你设计一个跟踪另一个进程的方法，你也通常会考虑这几种常用的方式。</p>
<p>第一种，就是通知被跟踪的进程，让进程执行相应的消息，同时对该消息做出反应。</p>
<p>第二种，就是通过内核的调用，直接能够访问进程的内存，堆栈情况，通过分析被跟踪的进程的内存结构，从而知道当前被跟踪的进程的状态。</p>
<p>第一种方式</p>
<p>优势：</p>
<p>对调用者和被调用者只要达成简单的通讯协议，调用者无需知道被调用者的逻辑，结构，只需要简单的发送命令的方式，被调用者能够接受到命令，并且对该命令进行回应就可以。</p>
<p>缺点：</p>
<p>如果被调用者当时的状态本来就不正常，或者繁忙，没办法对该命令做出响应，那这个跟踪进程往往是在规定的等待时间里，无法返回正确的需要的信息。其次被调用者在分析的过程中，有可能需要暂停进程中的其他的线程，而对被跟踪的进程有一定的影响。</p>
<p>第二种方式</p>
<p>优势：</p>
<p>通过内核的支持，访问被跟踪的内存，并作出快照，后台分析，很少影响被跟踪的进程。</p>
<p>缺点：</p>
<p>这种方式需要对被跟踪程的内存分配和使用非常的了解，无法解耦，而本身系统内核调用也会出问题。</p>
<p>Java工具类中也是大致实现了这2中方式，工具中会先选择第一种方式，如果发现第一种方式不能成功，将会建议使用-F参数，也就是第二种方式。</p>
<p>我们先讲第一种方式。</p>
<p>既然是需要向被跟踪进程发出命令，在linux中可以选择多种方式进行进程中通讯 共享内存，文件之类，其中创建socket的文件实现通讯是比较简单的方法。</p>
<p>下面是整个的流程图：</p>
<p><img src="" alt="">
来源： <a href="[http://blog.csdn.net/raintungli/article/details/7023092](http://blog.csdn.net/raintungli/article/details/7023092)">[http://blog.csdn.net/raintungli/article/details/7023092](http://blog.csdn.net/raintungli/article/details/7023092)</a> <a href="http://blog.csdn.net/raintungli/article/details/7034005" target="_blank">Java 工具（jmap,jstack）在linux上的源码分析（二）信号处理</a></p>
<p>当java虚拟机启动的时候，会启动很多内部的线程，这些线程主要在thread.cpp里的create_vm方法体里实现</p>
<p>而在thread.cpp里主要起了2个线程来处理信号相关的
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7034005#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7034005#" title="copy" target="_blank">copy</a></p>
<ol>
<li>JvmtiExport::enter_live_phase();  </li>
<li></li>
<li>// Signal Dispatcher needs to be started before VMInit event is posted  </li>
<li>os::signal_init();  </li>
<li></li>
<li>// Start Attach Listener if +StartAttachListener or it can&#39;t be started lazily  </li>
<li>if (!DisableAttachMechanism) {  </li>
<li>if (StartAttachListener || AttachListener::init_at_startup()) {  </li>
<li>AttachListener::init();  </li>
<li>}  </li>
<li>}  </li>
</ol>
<h3 id="-1-signal-dispatcher-"><a href=""></a>1. Signal Dispatcher 线程</h3>
<p>在os.cpp中的signal_init()函数中，启动了signal dispatcher 线程，对signal dispather 线程主要是用于处理信号，等待信号并且分发处理，可以详细看signal_thread_entry的方法
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7034005#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7034005#" title="copy" target="_blank">copy</a></p>
<ol>
<li>static void signal_thread_entry(JavaThread/* thread, TRAPS) {  </li>
<li>os::set_priority(thread, NearMaxPriority);  </li>
<li>while (true) {  </li>
<li>int sig;  </li>
<li>{  </li>
<li>// FIXME : Currently we have not decieded what should be the status  </li>
<li>//         for this java thread blocked here. Once we decide about  </li>
<li>//         that we should fix this.  </li>
<li>sig = os::signal_wait();  </li>
<li>}  </li>
<li>if (sig == os::sigexitnum_pd()) {  </li>
<li>// Terminate the signal thread  </li>
<li>return;  </li>
<li>}  </li>
<li></li>
<li>switch (sig) {  </li>
<li>case SIGBREAK: {  </li>
<li>// Check if the signal is a trigger to start the Attach Listener - in that  </li>
<li>// case don&#39;t print stack traces.  </li>
<li>if (!DisableAttachMechanism &amp;&amp; AttachListener::is_init_trigger()) {  </li>
<li>continue;  </li>
<li>}  </li>
<li>// Print stack traces  </li>
<li>// Any SIGBREAK operations added here should make sure to flush  </li>
<li>// the output stream (e.g. tty-&gt;flush()) after output.  See 4803766.  </li>
<li>// Each module also prints an extra carriage return after its output.  </li>
<li>VM_PrintThreads op;  </li>
<li>VMThread::execute(&amp;op);  </li>
<li>VM_PrintJNI jni_op;  </li>
<li>VMThread::execute(&amp;jni_op);  </li>
<li>VM_FindDeadlocks op1(tty);  </li>
<li>VMThread::execute(&amp;op1);  </li>
<li>Universe::print_heap_at_SIGBREAK();  </li>
<li>if (PrintClassHistogram) {  </li>
<li>VM_GC_HeapInspection op1(gclog_or_tty, true //<em> force full GC before heap inspection /</em>/,  </li>
<li>true //<em> need_prologue /</em>/);  </li>
<li>VMThread::execute(&amp;op1);  </li>
<li>}  </li>
<li>if (JvmtiExport::should_post_data_dump()) {  </li>
<li>JvmtiExport::post_data_dump();  </li>
<li>}  </li>
<li>break;  </li>
<li>}  </li>
<li>default: {  </li>
<li>// Dispatch the signal to java  </li>
<li>HandleMark hm(THREAD);  </li>
<li>klassOop k = SystemDictionary::resolve_or_null(vmSymbolHandles::sun_misc_Signal(), THREAD);  </li>
<li>KlassHandle klass (THREAD, k);  </li>
<li>if (klass.not_null()) {  </li>
<li>JavaValue result(T_VOID);  </li>
<li>JavaCallArguments args;  </li>
<li>args.push_int(sig);  </li>
<li>JavaCalls::call_static(  </li>
<li>&amp;result,  </li>
<li>klass,  </li>
<li>vmSymbolHandles::dispatch_name(),  </li>
<li>vmSymbolHandles::int_void_signature(),  </li>
<li>&amp;args,  </li>
<li>THREAD  </li>
<li>);  </li>
<li>}  </li>
<li>if (HAS_PENDING_EXCEPTION) {  </li>
<li>// tty is initialized early so we don&#39;t expect it to be null, but  </li>
<li>// if it is we can&#39;t risk doing an initialization that might  </li>
<li>// trigger additional out-of-memory conditions  </li>
<li>if (tty != NULL) {  </li>
<li>char klass_name[256];  </li>
<li>char tmp_sig_name[16];  </li>
<li>const char/* sig_name = &quot;UNKNOWN&quot;;  </li>
<li>instanceKlass::cast(PENDING_EXCEPTION-&gt;klass())-&gt;  </li>
<li>name()-&gt;as_klass_external_name(klass_name, 256);  </li>
<li>if (os::exception_name(sig, tmp_sig_name, 16) != NULL)  </li>
<li>sig_name = tmp_sig_name;  </li>
<li>warning(&quot;Exception %s occurred dispatching signal %s to handler&quot;  </li>
<li>&quot;- the VM may need to be forcibly terminated&quot;,  </li>
<li>klass_name, sig_name );  </li>
<li>}  </li>
<li>CLEAR_PENDING_EXCEPTION;  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
</ol>
<p>可以看到通过os::signal_wait();等待信号，而在linux里是通过sem_wait()来实现，接受到SIGBREAK(linux 中的QUIT)信号的时候（关于信号处理请参考笔者的另一篇博客<a href="http://blog.csdn.net/raintungli/article/details/7178472" target="_blank">:java 中关于信号的处理在linux下的实现</a>），第一次通过调用 AttachListener::is_init_trigger（）初始化attach listener线程，详细见2.Attach Listener 线程。</p>
<ol>
<li>第一次收到信号，会开始初始化，当初始化成功，将会直接返回，而且不返回任何线程stack的信息（通过socket file的操作返回），并且第二次将不在需要初始化。如果初始化不成功，将直接在控制台的outputstream中打印线程栈信息。</li>
<li>第二次收到信号，如果已经初始化过，将直接在控制台中打印线程的栈信息。如果没有初始化，继续初始化，走和第一次相同的流程。</li>
</ol>
<h3 id="-2-attach-listener-"><a href=""></a>2. Attach Listener 线程</h3>
<p>Attach Listener 线程是负责接收到外部的命令，而对该命令进行执行的并且吧结果返回给发送者。在jvm启动的时候，如果没有指定+StartAttachListener，该线程是不会启动的，刚才我们讨论到了在接受到quit信号之后，会调用 AttachListener::is_init_trigger（）通过调用用AttachListener::init（）启动了Attach Listener 线程，同时在不同的操作系统下初始化，在linux中 是在attachListener_Linux.cpp文件中实现的。</p>
<p>在linux中如果发现文件.attach_pid/#pid存在，才会启动attach listener线程，同时初始化了socket 文件，也就是通常jmap,jstack tool干的事情，先创立attach_pid/#pid文件，然后发quit信号,通过这种方式暗式的启动了Attach Listener线程（见博客：<a href="http://blog.csdn.net/raintungli/article/details/7023092" target="_blank"><a href="http://blog.csdn.net/raintungli/article/details/7023092">http://blog.csdn.net/raintungli/article/details/7023092</a></a>）。</p>
<p>线程的实现在 attach_listener_thread_entry 方法体中实现
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7034005#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7034005#" title="copy" target="_blank">copy</a></p>
<ol>
<li>static void attach_listener_thread_entry(JavaThread/* thread, TRAPS) {  </li>
<li>os::set_priority(thread, NearMaxPriority);  </li>
<li></li>
<li>if (AttachListener::pd_init() != 0) {  </li>
<li>return;  </li>
<li>}  </li>
<li>AttachListener::set_initialized();  </li>
<li></li>
<li>for (;;) {  </li>
<li>AttachOperation/* op = AttachListener::dequeue();    </li>
<li>if (op == NULL) {  </li>
<li>return;   // dequeue failed or shutdown  </li>
<li>}  </li>
<li></li>
<li>ResourceMark rm;  </li>
<li>bufferedStream st;  </li>
<li>jint res = JNI_OK;  </li>
<li></li>
<li>// handle special detachall operation  </li>
<li>if (strcmp(op-&gt;name(), AttachOperation::detachall_operation_name()) == 0) {  </li>
<li>AttachListener::detachall();  </li>
<li>} else {  </li>
<li>// find the function to dispatch too  </li>
<li>AttachOperationFunctionInfo/* info = NULL;  </li>
<li>for (int i=0; funcs[i].name != NULL; i++) {  </li>
<li>const char/* name = funcs[i].name;  </li>
<li>assert(strlen(name) &lt;= AttachOperation::name_length_max, &quot;operation &lt;= name_length_max&quot;);  </li>
<li>if (strcmp(op-&gt;name(), name) == 0) {  </li>
<li>info = &amp;(funcs[i]);  </li>
<li>break;  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>// check for platform dependent attach operation  </li>
<li>if (info == NULL) {  </li>
<li>info = AttachListener::pd_find_operation(op-&gt;name());  </li>
<li>}  </li>
<li></li>
<li>if (info != NULL) {  </li>
<li>// dispatch to the function that implements this operation  </li>
<li>res = (info-&gt;func)(op, &amp;st);  </li>
<li>} else {  </li>
<li>st.print(&quot;Operation %s not recognized!&quot;, op-&gt;name());  </li>
<li>res = JNI_ERR;  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>// operation complete - send result and output to client  </li>
<li>op-&gt;complete(res, &amp;st);  </li>
<li>}  </li>
<li>}  </li>
</ol>
<p>在AttachListener::dequeue(); 在liunx里的实现就是监听刚才创建的socket的文件，如果有请求进来，找到请求对应的操作，调用操作得到结果并把结果写到这个socket的文件，如果你把socket的文件删除，jstack/jmap会出现错误信息 unable to open socket file:........</p>
<p>我们经常使用 kill -3 pid的操作打印出线程栈信息，我们可以看到具体的实现是在Signal Dispatcher 线程中完成的，因为kill -3 pid 并不会创建.attach_pid/#pid文件，所以一直初始化不成功，从而线程的栈信息被打印到控制台中。
来源： <a href="[http://blog.csdn.net/raintungli/article/details/7034005](http://blog.csdn.net/raintungli/article/details/7034005)">[http://blog.csdn.net/raintungli/article/details/7034005](http://blog.csdn.net/raintungli/article/details/7034005)</a></p>
<h3 id="-java-jmap-jstack-linux-vm-thread-http-blog-csdn-net-raintungli-article-details-7045024-"><a href="http://blog.csdn.net/raintungli/article/details/7045024" target="_blank">Java 工具（jmap,jstack）在linux上的源码分析（三）执行的线程vm thread</a></h3>
<h3 id="-"> </h3>
<p>在前面的博客中（<a href="http://blog.csdn.net/raintungli/article/details/7034005" target="_blank"><a href="http://blog.csdn.net/raintungli/article/details/7034005">http://blog.csdn.net/raintungli/article/details/7034005</a></a>）所提到的信号转发线程，Attach Listener 线程都只是操作socket文件，并没有去执行比如stack 分析，或者heap的分析，真正的工作线程其实是vm thread.</p>
<p>（一）启动vm thread
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>jint Threads::create_vm(JavaVMInitArgs/<em> args, bool/</em> canTryAgain) {  </li>
<li>...  </li>
<li>// Create the VMThread  </li>
<li>{ TraceTime timer(&quot;Start VMThread&quot;, TraceStartupTime);  </li>
<li>VMThread::create();  </li>
<li>Thread/* vmthread = VMThread::vm_thread();  </li>
<li></li>
<li>if (!os::create_thread(vmthread, os::vm_thread))  </li>
<li>vm_exit_during_initialization(&quot;Cannot create VM thread. Out of system resources.&quot;);  </li>
<li></li>
<li>// Wait for the VM thread to become ready, and VMThread::run to initialize  </li>
<li>// Monitors can have spurious returns, must always check another state flag  </li>
<li>{  </li>
<li>MutexLocker ml(Notify_lock);  </li>
<li>os::start_thread(vmthread);  </li>
<li>while (vmthread-&gt;active_handles() == NULL) {  </li>
<li>Notify_lock-&gt;wait();  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
<li>...  </li>
<li></li>
<li></li>
<li>}  </li>
</ol>
<p>我们可以看到，在thread.cpp里启动了线程vm thread，在这里我们同时也稍微的略带的讲一下jvm在linux里如何启动线程的。</p>
<p>通常在linux中启动线程，是调用
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>int pthread_create((pthread_t /<em><strong>thread, </strong>const pthread_attr_t /</em><strong>attr,void /<em>(/</em></strong>start_routine) (void /<em>), void /</em>__arg));  </li>
</ol>
<p>而在java里却增加了os:create_thread --初始化线程 和os:start_thread--启动线程</p>
<p>我们去看一下jvm里面是如何在linux里做到的</p>
<p>在os_linux.cpp中来看create_thread的方法
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>bool os::create_thread(Thread/* thread, ThreadType thr_type, size_t stack_size) {  </li>
<li>....  </li>
<li>int ret = pthread_create(&amp;tid, &amp;attr, (void/<em> (/</em>)(void/*)) java_start, thread);  </li>
<li>....  </li>
<li>}  </li>
</ol>
<p>继续看java_start方法</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>static void /<em>java_start(Thread /</em>thread) {  </li>
<li>....  </li>
<li>// handshaking with parent thread  </li>
<li>{  </li>
<li>MutexLockerEx ml(sync, Mutex::_no_safepoint_check_flag);  </li>
<li></li>
<li>// notify parent thread  </li>
<li>osthread-&gt;set_state(INITIALIZED);  </li>
<li>sync-&gt;notify_all();  </li>
<li></li>
<li>// wait until os::start_thread()  </li>
<li>while (osthread-&gt;get_state() == INITIALIZED) {  </li>
<li>sync-&gt;wait(Mutex::_no_safepoint_check_flag);  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>// call one more level start routine  </li>
<li>thread-&gt;run();  </li>
<li></li>
<li>return 0;  </li>
<li>}  </li>
</ol>
<p>首先jvm先设置了当前线程的状态是Initialized, 然后notify所有的线程，</p>
<p> while (osthread-&gt;get_state() == INITIALIZED) {
      sync-&gt;wait(Mutex::_no_safepoint_check_flag);
    }</p>
<p>不停的查看线程的当前状态是不是Initialized, 如果是的话，调用了sync-&gt;wait()的方法等待。</p>
<p>来看os:start_thread的方法 os.cpp
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>void os::start_thread(Thread/* thread) {  </li>
<li>// guard suspend/resume  </li>
<li>MutexLockerEx ml(thread-&gt;SR_lock(), Mutex::_no_safepoint_check_flag);  </li>
<li>OSThread/* osthread = thread-&gt;osthread();  </li>
<li>osthread-&gt;set_state(RUNNABLE);  </li>
<li>pd_start_thread(thread);  </li>
<li>}  </li>
</ol>
<p>这时候设置了线程的状态为runnable,但没有notify线程</p>
<p>在 pd_start_thread(thread)中, os_linux.cpp中
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>void os::pd_start_thread(Thread/* thread) {  </li>
<li>OSThread /* osthread = thread-&gt;osthread();  </li>
<li>assert(osthread-&gt;get_state() != INITIALIZED, &quot;just checking&quot;);  </li>
<li>Monitor/* sync_with_child = osthread-&gt;startThread_lock();  </li>
<li>MutexLockerEx ml(sync_with_child, Mutex::_no_safepoint_check_flag);  </li>
<li>sync_with_child-&gt;notify();  </li>
<li>}  </li>
</ol>
<p>这时候我们看到了notify 线程的操作</p>
<p>也就是这时候notify了线程，因为这时候的线程的状态是RUNNABLE, 方法java_start继续往下执行，于是调用了thread-&gt;run()的方法</p>
<p>对于线程vm Thread 也就是调用了vmthread::run方法</p>
<p>vmThread.cpp
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>void VMThread::run() {  </li>
<li>...  </li>
<li>this-&gt;loop();  </li>
<li>...  </li>
<li>}  </li>
</ol>
<p>调用了loop函数，处理了VM_Operation 的queue 关于queue的级别和优先级处理算法：可以参考 另一篇博客：<a href="http://blog.csdn.net/raintungli/article/details/6553337" target="_blank"><a href="http://blog.csdn.net/raintungli/article/details/6553337">http://blog.csdn.net/raintungli/article/details/6553337</a></a></p>
<p>（二）Jstack 运行在vm thread里的VM_Operation</p>
<p>jstack 处理也就是在前面博客所提到的attach Listener 线程所做的 operation
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>static jint thread_dump(AttachOperation/<em> op, outputStream/</em> out) {  </li>
<li>bool print_concurrent_locks = false;  </li>
<li>if (op-&gt;arg(0) != NULL &amp;&amp; strcmp(op-&gt;arg(0), &quot;-l&quot;) == 0) {  </li>
<li>print_concurrent_locks = true;  </li>
<li>}  </li>
<li></li>
<li>// thread stacks  </li>
<li>VM_PrintThreads op1(out, print_concurrent_locks);  </li>
<li>VMThread::execute(&amp;op1);  </li>
<li></li>
<li>// JNI global handles  </li>
<li>VM_PrintJNI op2(out);  </li>
<li>VMThread::execute(&amp;op2);  </li>
<li></li>
<li>// Deadlock detection  </li>
<li>VM_FindDeadlocks op3(out);  </li>
<li>VMThread::execute(&amp;op3);  </li>
<li></li>
<li>return JNI_OK;  </li>
<li>}  </li>
</ol>
<p>简单看一下类VM_PrintThreads 它 继承了VM_Operation</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7045024#" title="copy" target="_blank">copy</a></p>
<ol>
<li>class VM_PrintThreads: public VM_Operation {  </li>
<li>private:  </li>
<li>outputStream/* _out;  </li>
<li>bool _print_concurrent_locks;  </li>
<li>public:  </li>
<li>VM_PrintThreads()                                                { _out = tty; _print_concurrent_locks = PrintConcurrentLocks; }  </li>
<li>VM_PrintThreads(outputStream/* out, bool print_concurrent_locks)  { _out = out; _print_concurrent_locks = print_concurrent_locks; }  </li>
<li>VMOp_Type type() const                                           {  return VMOp_PrintThreads; }  </li>
<li>void doit();  </li>
<li>bool doit_prologue();  </li>
<li>void doit_epilogue();  </li>
<li>};  </li>
</ol>
<p>当调用VMThread::execute()也就是将VM_PrintThreads 放入了_vm_queue中，交给vm thread 处理，对vm thread来说取出queue里的VM_Operation,并且调用doit方法。</p>
<p>在jstack里，attach listener 的线程产生了VM_PrintThreads，VM_PrintJNI，VM_FindDeadlocks 3个operations，交给了vm thread  的线程处理。
来源： <a href="[http://blog.csdn.net/raintungli/article/details/7045024](http://blog.csdn.net/raintungli/article/details/7045024)">[http://blog.csdn.net/raintungli/article/details/7045024](http://blog.csdn.net/raintungli/article/details/7045024)</a> <a href="http://blog.csdn.net/raintungli/article/details/7162468" target="_blank">Java 工具（jmap,jstack）在linux上的源码分析（四）safe point</a></p>
<p>safe point 顾明思意，就是安全点，当需要jvm做一些操作的时候，需要把当前正在运行的线程进入一个安全点的状态（也可以说停止状态），这样才能做一些安全的操作，比如线程的dump，堆栈的信息。</p>
<p>在jvm里面通常vm_thread（我们一直在谈论的做一些属于vm 份内事情的线程） 和cms_thread（内存回收的线程）做的操作，是需要将其他的线程通过调用SafepointSynchronize::begin 和 SafepointSynchronize:end来实现让其他的线程进入或者退出safe point 的状态。</p>
<h2 id="-safepoint-"><a href=""></a>通常safepoint 的有三种状态</h2>
<p>_not_synchronized 说明没有任何打断现在所有线程运行的操作，也就是vm thread, cms thread 没有接到操作的指令 _synchronizing vm thread,cms thread 接到操作指令，正在等待所有线程进入safe point _synchronized 所有线程进入safe point, vm thread, cms thread 可以开始指令操作</p>
<h2 id="-java-"><a href=""></a>Java线程的状态</h2>
<p>通常在java 进程中的Java 的线程有几个不同的状态，如何让这些线程进入safepoint 的状态中，jvm是采用不同的方式</p>
<h3 id="-a-"><a href=""></a>a. 正在解释执行</h3>
<p>由于java是解释性语言，而线程在解释java 字节码的时候，需要dispatch table,记录方法地址进行跳转的，那么这样让线程进入停止状态就比较容易了，只要替换掉dispatch table 就可以了，让线程知道当前进入softpoint 状态。</p>
<p>java里会设置3个DispatchTable，  _active_table，  _normal_table， _safept_table</p>
<p>_active_table 正在解释运行的线程使用的dispatch table</p>
<p>_normal_table 就是正常运行的初始化的dispatch table</p>
<p>_safept_table safe point需要的dispatch table</p>
<p>解释运行的线程一直都在使用_active_table,关键处就是在进入saftpoint 的时候，用_safept_table替换_active_table, 在退出saftpoint 的时候，使用_normal_table来替换_active_table</p>
<p>具体实现可以查看源码
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="copy" target="_blank">copy</a></p>
<ol>
<li>void TemplateInterpreter::notice_safepoints() {  </li>
<li>if (!_notice_safepoints) {  </li>
<li>// switch to safepoint dispatch table  </li>
<li>_notice_safepoints = true;  </li>
<li>copy_table((address/<em>)&amp;_safept_table, (address/</em>)&amp;_active_table, sizeof(_active_table) / sizeof(address));  </li>
<li>}  </li>
<li>}  </li>
<li></li>
<li>// switch from the dispatch table which notices safepoints back to the  </li>
<li>// normal dispatch table.  So that we can notice single stepping points,  </li>
<li>// keep the safepoint dispatch table if we are single stepping in JVMTI.  </li>
<li>// Note that the should_post_single_step test is exactly as fast as the  </li>
<li>// JvmtiExport::_enabled test and covers both cases.  </li>
<li>void TemplateInterpreter::ignore_safepoints() {  </li>
<li>if (_notice_safepoints) {  </li>
<li>if (!JvmtiExport::should_post_single_step()) {  </li>
<li>// switch to normal dispatch table  </li>
<li>_notice_safepoints = false;  </li>
<li>copy_table((address/<em>)&amp;_normal_table, (address/</em>)&amp;_active_table, sizeof(_active_table) / sizeof(address));  </li>
<li>}  </li>
<li>}  </li>
<li>}  </li>
</ol>
<h3 id="-"><a href=""></a></h3>
<p>b. 运行在native code</p>
<p>如果线程运行在native code的时候，vm thread 是不需要等待线程执行完的，只需要在从native code 返回的时候去判断一下 _state 的状态就可以了。</p>
<p>在方法体里就是前面博客也出现过的 SafepointSynchronize::do_call_back()
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="copy" target="_blank">copy</a></p>
<ol>
<li>inline static bool do_call_back() {  </li>
<li>return (_state != _not_synchronized);  </li>
<li>}  </li>
</ol>
<p>判断了_state 不是_not_synchronized状态</p>
<p>为了能让线程从native code 回到java 的时候为了能读到/设置正确线程的状态，通常的解决方法使用memory barrier，java 使用OrderAccess::fence(); 在汇编里使用<strong>asm</strong> volatile (&quot;lock; addl $0,0(%%rsp)&quot; : : : &quot;cc&quot;, &quot;memory&quot;); 保证从内存里读到正确的值，但是这种方法严重影响系统的性能，于是java使用了每个线程都有独立的内存页来设置状态。通过使用使用参数-XX:+UseMembar  参数使用memory barrier，默认是不打开的，也就是使用独立的内存页来设置状态。</p>
<h3 id="-c-"><a href=""></a> c. 运行编译的代码</h3>
<h3 id="-1-poling-page-"><a href=""></a>1. Poling page 页面</h3>
<p>Poling page是在jvm初始化启动的时候会初始化的一个单独的内存页面，这个页面是让运行的编译过的代码的线程进入停止状态的关键。</p>
<p>在linux里面使用了mmap初始化，源码如下
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="copy" target="_blank">copy</a></p>
<ol>
<li>address polling_page = (address) ::mmap(NULL, Linux::page_size(), PROT_READ, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0);  </li>
</ol>
<h3 id="-"><a href=""></a></h3>
<ol>
<li>编译</li>
</ol>
<p>java 的JIT 会直接编译一些热门的源码到机器码，直接执行而不需要在解释执行从而提高效率，在编译的代码中，当函数或者方法块返回的时候会去访问一个内存poling页面.</p>
<p>x86架构下
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="copy" target="_blank">copy</a></p>
<ol>
<li>void LIR_Assembler::return_op(LIR_Opr result) {  </li>
<li>assert(result-&gt;is_illegal() || !result-&gt;is_single_cpu() || result-&gt;as_register() == rax, &quot;word returns are in rax,&quot;);  </li>
<li>if (!result-&gt;is_illegal() &amp;&amp; result-&gt;is_float_kind() &amp;&amp; !result-&gt;is_xmm_register()) {  </li>
<li>assert(result-&gt;fpu() == 0, &quot;result must already be on TOS&quot;);  </li>
<li>}  </li>
<li></li>
<li>// Pop the stack before the safepoint code  </li>
<li>__ remove_frame(initial_frame_size_in_bytes());  </li>
<li></li>
<li>bool result_is_oop = result-&gt;is_valid() ? result-&gt;is_oop() : false;  </li>
<li></li>
<li>// Note: we do not need to round double result; float result has the right precision  </li>
<li>// the poll sets the condition code, but no data registers  </li>
<li>AddressLiteral polling_page(os::get_polling_page() + (SafepointPollOffset % os::vm_page_size()),  </li>
<li>relocInfo::poll_return_type);  </li>
<li></li>
<li>// NOTE: the requires that the polling page be reachable else the reloc  </li>
<li>// goes to the movq that loads the address and not the faulting instruction  </li>
<li>// which breaks the signal handler code  </li>
<li></li>
<li>__ test32(rax, polling_page);  </li>
<li></li>
<li>__ ret(0);  </li>
<li>}  </li>
</ol>
<p>在前面提到的SafepointSynchronize::begin 函数源码中</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="copy" target="_blank">copy</a></p>
<ol>
<li>if (UseCompilerSafepoints &amp;&amp; DeferPollingPageLoopCount &lt; 0) {  </li>
<li>// Make polling safepoint aware  </li>
<li>guarantee (PageArmed == 0, &quot;invariant&quot;) ;  </li>
<li>PageArmed = 1 ;  </li>
<li>os::make_polling_page_unreadable();  </li>
<li>}  </li>
</ol>
<p>这里提到了2个参数 UseCompilerSafepoints 和 DeferPollingPageLoopCount ，在默认的情况下这2个参数是true和-1</p>
<p>函数体将会调用os:make_polling_page_unreadable();在linux os 下具体实现是调用了mprotect(bottom,size,prot) 使polling 内存页变成不可读。</p>
<h3 id="-3-"><a href=""></a>3. 信号</h3>
<p>到当编译好的程序尝试在去访问这个不可读的polling页面的时候，在系统级别会产生一个错误信号SIGSEGV, 可以参考笔者的一篇博客中曾经讲过<a href="http://blog.csdn.net/raintungli/article/details/7178472" target="_blank">java 的信号处理</a>，可以知道信号SIGSEGV的处理函数在x86体系下见下源码：
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7162468#" title="copy" target="_blank">copy</a></p>
<ol>
<li>JVM_handle_linux_signal(int sig,  </li>
<li>siginfo_t/* info,  </li>
<li>void/* ucVoid,  </li>
<li>int abort_if_unrecognized){  </li>
<li>....  </li>
<li>if (sig == SIGSEGV &amp;&amp; os::is_poll_address((address)info-&gt;si_addr)) {  </li>
<li>stub = SharedRuntime::get_poll_stub(pc);  </li>
<li>}   </li>
<li>....  </li>
<li>}  </li>
</ol>
<p>在linux x86,64 bit的体系中，poll stub 的地址 就是 SafepointSynchronize::handle_polling_page_exception 详细程序可见shareRuntime_x86_64.cpp</p>
<p>回到safepoint.cpp中，SafepointSynchronize::handle_polling_page_exception通过取出线程的safepoint_stat,调用函数void ThreadSafepointState::handle_polling_page_exception，最后通过调用SafepointSynchronize::block(thread()); 来block当前线程。</p>
<h3 id="-d-block-"><a href=""></a>d. block 状态</h3>
<p>当线程进入block状态的时候，继续保持block状态。
来源： <a href="[http://blog.csdn.net/raintungli/article/details/7162468](http://blog.csdn.net/raintungli/article/details/7162468)">[http://blog.csdn.net/raintungli/article/details/7162468](http://blog.csdn.net/raintungli/article/details/7162468)</a><a href="http://blog.csdn.net/raintungli/article/details/7245709" target="_blank">Java 工具（jmap,jstack）在linux上的源码分析(五) -F 参数的bug</a></p>
<p>当使用jmap,jstack是用-F参数的时候，是通过调用系统调用ptrace来取的寄存器的信息，关于linux下的ptrace实现可以参考我的博客（<a href="http://blog.csdn.net/raintungli/article/details/6563867" target="_blank"><a href="http://blog.csdn.net/raintungli/article/details/6563867">http://blog.csdn.net/raintungli/article/details/6563867</a></a>）</p>
<p>在jdk6u23版本之前你会发现，当你使用jstack -F的时候 经常在logger 里面 看到错误信息，直接抛出异常，根本无法看到堆栈信息。</p>
<p>Thread 26724: (state = BLOCKED)
Error occurred during stack walking:
sun.jvm.hotspot.debugger.DebuggerException: sun.jvm.hotspot.debugger.DebuggerException: get_thread_regs failed for a lwp
        at sun.jvm.hotspot.debugger.linux.LinuxDebuggerLocal$LinuxDebuggerLocalWorkerThread.execute(LinuxDebuggerLocal.java:152)
        at sun.jvm.hotspot.debugger.....</p>
<p>通过查看源码，最后调用的函数是process_get_lwp_regs /ps_proc.c</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7245709#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7245709#" title="copy" target="_blank">copy</a></p>
<ol>
<li>static bool process_get_lwp_regs(struct ps_prochandle/<em> ph, pid_t pid, struct user_regs_struct /</em>user) {  </li>
<li>// we have already attached to all thread &#39;pid&#39;s, just use ptrace call  </li>
<li>// to get regset now. Note that we don&#39;t cache regset upfront for processes.  </li>
<li>// Linux on x86 and sparc are different.  On x86 ptrace(PTRACE_GETREGS, ...)  </li>
<li>// uses pointer from 4th argument and ignores 3rd argument.  On sparc it uses  </li>
<li>// pointer from 3rd argument and ignores 4th argument  </li>
<li>/#if defined(sparc) || defined(sparcv9)  </li>
<li>/#define ptrace_getregs(request, pid, addr, data) ptrace(request, pid, addr, data)  </li>
<li>/#else  </li>
<li>/#define ptrace_getregs(request, pid, addr, data) ptrace(request, pid, data, addr)  </li>
<li>/#endif  </li>
<li></li>
<li>/#ifdef _LP64  </li>
<li>/#ifdef PTRACE_GETREGS64  </li>
<li>/#define PTRACE_GETREGS_REQ PTRACE_GETREGS64  </li>
<li>/#endif  </li>
<li>/#else  </li>
<li>/#if defined(PTRACE_GETREGS) || defined(PT_GETREGS)  </li>
<li>/#define PTRACE_GETREGS_REQ PTRACE_GETREGS  </li>
<li>/#endif  </li>
<li>/#endif //<em> _LP64 /</em>/  </li>
<li></li>
<li>/#ifdef PTRACE_GETREGS_REQ  </li>
<li>if (ptrace_getregs(PTRACE_GETREGS_REQ, pid, user, NULL) &lt; 0) {  </li>
<li>print_debug(&quot;ptrace(PTRACE_GETREGS, ...) failed for lwp %d\n&quot;, pid);  </li>
<li>return false;  </li>
<li>}  </li>
<li>return true;  </li>
<li>/#else  </li>
<li>print_debug(&quot;ptrace(PTRACE_GETREGS, ...) not supported\n&quot;);  </li>
<li>return false;  </li>
<li>/#endif  </li>
<li></li>
<li>}  </li>
</ol>
<p>无法判断究竟是否是因为没有定义参数PTRACE_GETREGS_REQ，还是因为ptrace的调用参数错误所导致的，这样就必须打开print_debug，查看打印的信息。</p>
<p>通过源码，可以查到print_debug函数是通过环境变量LIBSAPROC_DEBUG来控制</p>
<p>设置 </p>
<p>export LIBSAPROC_DEBUG=1</p>
<p>运行</p>
<p>jstack -F processid</p>
<p>我们能看到错误中多了一行</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7245709#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7245709#" title="copy" target="_blank">copy</a></p>
<ol>
<li>Thread 26724: (state = BLOCKED)  </li>
<li>libsaproc DEBUG: ptrace(PTRACE_GETREGS, ...) not supported  </li>
</ol>
<p>产生的原因就非常清楚了，bug主要是因为宏定义PTRACE_GETREGS_REQ缺失，查看源码</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7245709#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7245709#" title="copy" target="_blank">copy</a></p>
<ol>
<li>/#ifdef _LP64  </li>
<li>/#ifdef PTRACE_GETREGS64  </li>
<li>/#define PTRACE_GETREGS_REQ PTRACE_GETREGS64  </li>
<li>/#endif  </li>
<li>/#else  </li>
<li>/#if defined(PTRACE_GETREGS) || defined(PT_GETREGS)  </li>
<li>/#define PTRACE_GETREGS_REQ PTRACE_GETREGS  </li>
<li>/#endif  </li>
<li>/#endif //<em> _LP64 /</em>/  </li>
</ol>
<p>_LP64 是64位机器的宏定义，而对ptrace的参数PTRACE_GETREGS64，显然Linux kernel 2.6.35里面并没有支持，导致了没有宏定义PTRACE_GETREGS_REQ，这里明显是jvm没有考虑到的情况。</p>
<p>解决办法</p>
<p>a. 因为这是jvm 编译级别的bug，除非你重现修改编译libsaproc.so，覆盖目录/jdk1.6.0_23/jre/lib/amd64</p>
<p>笔者自己编译了这个lib,可以在csdn上下载（<a href="http://download.csdn.net/detail/raintungli/4065304" target="_blank"><a href="http://download.csdn.net/detail/raintungli/4065304">http://download.csdn.net/detail/raintungli/4065304</a></a>），笔者编译的jdk版本是1.6.23 build(19.0)</p>
<p>b. 建议升级jvm到1.6.30版本，该版本已经测试过，已经修复该bug.</p>
<p>后话：</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7245709#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7245709#" title="copy" target="_blank">copy</a></p>
<ol>
<li>if (ptrace_getregs(PTRACE_GETREGS_REQ, pid, user, NULL) &lt; 0) {  </li>
<li>print_debug(&quot;ptrace(PTRACE_GETREGS, ...) failed for lwp %d\n&quot;, pid);  </li>
<li>return false;  </li>
<li>}  </li>
</ol>
<p>jvm可以在此处更清楚点，不是简单的判断&lt;0，而是在判断&lt;0的时候把errno打印出来，能更容易的判断出是什么原因无法ptrace 上。</p>
<p>来源： <a href="[http://blog.csdn.net/raintungli/article/details/7245709](http://blog.csdn.net/raintungli/article/details/7245709)">[http://blog.csdn.net/raintungli/article/details/7245709](http://blog.csdn.net/raintungli/article/details/7245709)</a><a href="http://blog.csdn.net/raintungli/article/details/7289639" target="_blank">Java 工具（jmap,jstack）在linux上的源码分析(六) -F 参数 读取动态链接共享库文件中的符号表</a></p>
<p>通常我们使用jmap,jstack 去检查堆栈信息的时候，是不会使用-f参数的，但有的时候系统在无法打印出堆栈信息的时候，会建议你使用参数-F。</p>
<p>关于-F参数与非-F参数的区别笔者已经在前面的博客中讲述（<a href="http://blog.csdn.net/raintungli/article/details/7023092" target="_blank"><a href="http://blog.csdn.net/raintungli/article/details/7023092">http://blog.csdn.net/raintungli/article/details/7023092</a></a>），简单的说也就是一种是让jvm进程自己打印出堆栈信息，另有一种是直接访问jvm的堆栈区通过固定的结构找出我们需要的信息。</p>
<h1 id="-1-linux-f-"><a href=""></a>1. Linux-F参数的实现</h1>
<p>在linux中可以使用ptrace的系统调用去访问运行中的进程的内存信息，具体如何实现可以参考笔者的博客（<a href="http://blog.csdn.net/raintungli/article/details/6563867" target="_blank"><a href="http://blog.csdn.net/raintungli/article/details/6563867">http://blog.csdn.net/raintungli/article/details/6563867</a></a>）</p>
<p>在java中使用动态加载的方式加载jvm自己的链接共享库，jvm的核心链接共享库是libjvm.so，linux中如何动态加载可以参考（<a href="http://www.ibm.com/developerworks/cn/linux/l-dynamic-libraries/#dynamiclinking" target="_blank"><a href="http://www.ibm.com/developerworks/cn/linux/l-dynamic-libraries//#dynamiclinking">http://www.ibm.com/developerworks/cn/linux/l-dynamic-libraries//#dynamiclinking</a></a>）</p>
<p>因为是动态共享库，当想查找具体的参数的值，内存的信息的时候，就需要计算出正确的参数或者函数的地址。</p>
<h1 id="-2-"><a href=""></a>2. 共享库中的符号相对地址偏移</h1>
<p>可运行程序，共享库使用ELF格式，当运行一个程序的时候，内核会把ELF加载到用户空间，里面记录了程序的函数和数据的地址和内容，elf文件格式就不具体描述了。</p>
<p>在linux 中可以使用结构体ELF_EHDR，ELF_PHDR，ELF_SHDR读出elf 的program header, section header, section data.</p>
<p>在jvm中源码具体实现请参考 /hotspot/agent/os/linux/salibelf.c </p>
<p>在linux中本身就自带一个读取elf格式的工具，readelf 你可以使用不同的参数读取不同的内容。</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7289639#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7289639#" title="copy" target="_blank">copy</a></p>
<ol>
<li>readelf -s libjvm.so  </li>
</ol>
<p>显示共享库中的方法参数的虚拟地址，类型，名字</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7289639#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7289639#" title="copy" target="_blank">copy</a></p>
<ol>
<li>readelf -l libjvm.so  </li>
</ol>
<p>读取program headers，其中出现2个LOAD的类型，第一个是程序的指令虚拟的起始地址，另一个是程序数据的起始地址</p>
<p>通过2个地址我们就能找到共享库中的参数，函数的相对地址的偏移</p>
<h1 id="-3-"><a href=""></a>3. 进程中的符号地址</h1>
<p>在第二章节中，得到的只是相对的地址偏移，并不是真实运行中的进程的符号地址，如何得到真实的地址在linux中就相对比较简单。</p>
<p><strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7289639#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7289639#" title="copy" target="_blank">copy</a></p>
<ol>
<li><p>cat /proc/$processid/maps<br>在maps里详细记录了进程的堆栈分配的地址，包括共享库的地址，那么起始地址就是这个库分配的最小地址
<strong>[cpp]</strong> <a href="http://blog.csdn.net/raintungli/article/details/7289639#" title="view plain" target="_blank">view plain</a><a href="http://blog.csdn.net/raintungli/article/details/7289639#" title="copy" target="_blank">copy</a></p>
</li>
<li><p>进程中共享库分配的最小地址+相对地址的偏移 =真实的进程中该函数或变量的真实地址  </p>
</li>
</ol>
<h1 id="-4-java-tool-"><a href=""></a>4. Java tool 保存的符号表</h1>
<p>在jmap/jstack 中，为了提高读取符号地址的性能，避免每一次要找符号的地址从elf文件中查找，只是在初始话的时候将符号表保存成哈希表，其中key是符号的名字，内容是符号的地址，长度。</p>
<p>具体实现可以参考  /hotspot/src/os/linux/symtab.c build_symtab_internal 函数</p>
<p>来源： <a href="[http://blog.csdn.net/raintungli/article/details/7289639](http://blog.csdn.net/raintungli/article/details/7289639)">[http://blog.csdn.net/raintungli/article/details/7289639](http://blog.csdn.net/raintungli/article/details/7289639)</a></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/内存分析/">内存分析</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/内存分析/" class="label label-success">内存分析</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:40"datetime="2014-03-07 09:54:40"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-内存分析--Java工具（jmap-jstack）在linux上的源码分析/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-内存分析--Java工具（jmap-jstack）在linux上的源码分析" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-内存分析--jstack命令JavaStackTrace/">jstack命令(Java Stack Trace)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:40.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-内存分析--jstack命令JavaStackTrace/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="jstack-java-stack-trace-">jstack命令(Java Stack Trace)</h1>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411999.aspx" target="_blank">JDK内置工具使用</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411924.aspx" target="_blank">一、javah命令(C Header and Stub File Generator)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411932.aspx" target="_blank">二、jps命令(Java Virtual Machine Process Status Tool)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411940.aspx" target="_blank">三、jstack命令(Java Stack Trace)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411951.aspx" target="_blank">四、jstat命令(Java Virtual Machine Statistics Monitoring Tool)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411953.aspx" target="_blank">五、jmap命令(Java Memory Map)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411958.aspx" target="_blank">六、jinfo命令(Java Configuration Info)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411965.aspx" target="_blank">七、jconsole命令(Java Monitoring and Management Console)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411969.aspx" target="_blank">八、jvisualvm命令(Java Virtual Machine Monitoring, Troubleshooting, and Profiling Tool)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411971.aspx" target="_blank">九、jhat命令(Java Heap Analyse Tool)</a></p>
<p><a href="http://blog.csdn.net/fenglibing/archive/2011/05/11/6411974.aspx" target="_blank">十、Jdb命令(The Java Debugger)</a></p>
<h2 id="-1-"><a href=""></a>1、介绍</h2>
<p>jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息，如果是在64位机器上，需要指定选项&quot;-J-d64&quot;，Windows的jstack使用方式只支持以下的这种方式：</p>
<p>jstack [-l] pid</p>
<p>如果java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。</p>
<p>2、命令格式
jstack [ option ] pid
jstack [ option ] executable core
jstack [ option ] [server-id@]remote-hostname-or-IP</p>
<h2 id="-3-"><a href=""></a>3、常用参数说明</h2>
<p>1)、options： </p>
<p>executable Java executable from which the core dump was produced.</p>
<p>(可能是产生core dump的java可执行程序)</p>
<p>core 将被打印信息的core dump文件</p>
<p>remote-hostname-or-IP 远程debug服务的主机名或ip</p>
<p>server-id 唯一id,假如一台主机上多个远程debug服务 </p>
<p>2）、基本参数：</p>
<p>-F当’jstack [-l] pid’没有相应的时候强制打印栈信息</p>
<p>-l长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表.</p>
<p>-m打印java和native c/c++框架的所有栈信息.</p>
<p>-h | -help打印帮助信息</p>
<p>pid 需要被打印配置信息的java进程id,可以用jps查询.</p>
<h2 id="-4-"><a href=""></a>4、使用示例</h2>
<h2 id="-"><a href=""></a><img src="" alt=""></h2>
<p>来源： <a href="[http://blog.csdn.net/fenglibing/article/details/6411940](http://blog.csdn.net/fenglibing/article/details/6411940)">[http://blog.csdn.net/fenglibing/article/details/6411940](http://blog.csdn.net/fenglibing/article/details/6411940)</a></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/内存分析/">内存分析</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/内存分析/" class="label label-success">内存分析</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:40"datetime="2014-03-07 09:54:40"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-内存分析--jstack命令JavaStackTrace/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-内存分析--jstack命令JavaStackTrace" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-内存分析--离线分析java内存/">离线分析java内存</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:40.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-内存分析--离线分析java内存/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-">离线分析java内存</h1>
<p> 如题，我这里简单说下我现在离线分析java内存的方式，所谓离线，就是需要dump出正在运行的java系统中的一些运行时堆栈数据，然后拿到线下来分析，分析可以包括内存，线程，GC等等，同时不会对正在运行的生产环境的机器造成很大的影响，对应着离线分析，当然是在线分析了，这个我在后面会尝试下，因为离线分析有些场景还是模拟不出来，需要借助LR来模拟压力，查看在线的java程序运行情况了。</p>
<pre><code>        首先一个简单的问题，如何dump出java运行时堆栈，这个SUN就提供了很好的工具，位于JAVA_HOME/bin目录下的jmap（java memory map之意），如果需要dump出当前运行的java进程的堆栈数据，则首先需要获得该java进程的进程ID,在linux下可以使用
</code></pre><p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
<ol>
<li>ps -aux  </li>
<li></li>
<li>ps -ef | grep java  </li>
</ol>
<p>或者使用jdk自带的一个工具jps，例如</p>
<p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
<ol>
<li>/JAVA_HOME/bin/jps  </li>
</ol>
<p>找到了当前运行的java进程的id后，就可以对正在运行的java进程使用jmap工具进行dump了，例如使用以下命令：</p>
<p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
<ol>
<li>JAVA_HOME/bin/jmap  -dump:format=b,file=heap.bin <pid>   </li>
</ol>
<p>其中file = heap.bin的意思是dump出的文件名叫heap.bin, 当然你可以选择你喜欢的名字，我这里选择叫/*.bin是为了后面使用方便，<pid>表示你需要dump的java进程的id。</p>
<p>这里需要注意的是，记住dump的进程是java进程，不会是jboss的进程，weblogic的进程等。dump过程中机器load可能会升高，但是在我这里测试发现load升的不是特别快，同时dump时需要的磁盘空间也比较大，例如我这里测试的几个系统，分别是500M 800M 1500M  3000M，所以确保你运行jmap命令时所在的目录中的磁盘空间足够，当然现在的系统磁盘空间都比较大。</p>
<p>以上是在java进程还存活的时候进行的dump，有的时候我们的java进程crash后，会生成一个core.pid文件，这个core.pid文件还不能直接被我们的java 内存分析工具使用，需要将其转换为java 内存分析工具可以读的文件（例如使用jmap工具dump出的heap.bin文件就是很多java 内存分析工具可以读的文件格式）。将core.pid文件转换为jmap工具dump出的文件格式还可以继续使用jmap工具，这个的说明可以见我前几篇中的一个转载（<a href="http://dikar.iteye.com/blog/643196" target="_blank">Create Java heapdumps with the help of core dumps</a>），这里我在补充点</p>
<p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
<ol>
<li>jmap -heap:format=b [java binary] [core dump file]  </li>
<li></li>
<li></li>
<li>64位下可以指定使用64位模式  </li>
<li></li>
<li>jmap -d64  -dump:format=b [java binary] [core dump file]  </li>
</ol>
<p>需要说明一下，使用jmap转换core.pid文件时，当文件格式比较大时，可能大于2G的时候就不能执行成功（我转换3G文件大小的时候没有成功）而报出</p>
<p>Error attaching to core file: Can&#39;t attach to the core file</p>
<p>查过sun的bug库中，这个bug还没有被修复，我想还是由于32位下用户进程寻址大小限制在2G的范围内引起的，在64位系统和64位jdk版本中，转换3G文件应该没有什么大的问题（有机会有环境得需要测试下）。如果有兴趣分析jmap转换不成功的同学，可以使用如下命令来分析跟踪命令的执行轨迹，例如使用</p>
<p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
<ol>
<li>strace  jmap -heap:format=b [java binary] [core dum  </li>
<li><p>p]  </p>
<p>对于strace的命令的说明，同样可以参考我前几篇文章中的一个<a href="http://dikar.iteye.com/blog/643201" target="_blank"> strace命令用法</a></p>
</li>
</ol>
<p>同时对于core.pid文件的调试我也补充一下, 其中&gt;&gt;表示命令提示符</p>
<p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
<ol>
<li><blockquote>
<blockquote>
<p>gdb JAVA_HOME/bin/java  core.pid  </p>
</blockquote>
</blockquote>
</li>
<li></li>
<li><blockquote>
<blockquote>
<p>bt  </p>
</blockquote>
</blockquote>
</li>
</ol>
<p>bt后就可以看到生成core.pid文件时，系统正在执行的一个操作，例如是哪个so文件正在执行等。</p>
<p>好了说了这么多，上面都是怎么生成java 运行期DUMP文件的，接下来我们就进入分析阶段，为了分析这个dump出的文件，需要将这个文件弄到你的分析程序所在的机器上，例如可以是windows上，linux上，这个和你使用的分析工具以及使用的操作系统有关。不管使用什么系统，总是需要把生产环境下打出的dump文件搞到你的分析机器上，由于dump出的文件经常会比较大，例如达到2G，这么大的文件不是很好的从生产环境拉下来，因此使用FTP的方式把文件拖到分析机器上，同时由于单个文件很大，因此为了快速的将文件下载到分析机器，我们可以使用分而治之的思想，先将文件切割为小文件下载，然后在合并为一个大文件即可，还好linux提供了很方便的工具，例如使用如下命令</p>
<p>Java代码  <a href="&quot;收藏这段代码&quot;"><img src="" alt="收藏代码"></a></p>
<ol>
<li>$ split -b 300m heap.bin  </li>
<li></li>
<li>$ cat x/* &gt; heap.bin  </li>
</ol>
<p>在上面的 split 命令行中的 “300m” 表示分割后的每个文件为 300MB，“heap.bin” 为待分割的dump文件，分割后的文件自动命名为 xaa，xab，xac等 
cat 命令可将这些分割后的文件合并为一个文件，例如将所有x开头的文件合并为heap.bin</p>
<p>如果我们是利用一个中间层的FTP服务器来保存数据的，那么我们还需要连接这个FTP服务器把合并后的文件拉下来，在windows下我推荐使用一个工具，速度很快而且简单，</p>
<p>winscp   <a href="http://winscp.net/eng/docs/lang:chs" target="_blank">http://winscp.net/eng/docs/lang:chs</a></p>
<p>好了分析的文件终于经过一翻周折到了你的分析机器上，现在我们就可以使用分析工具来分析这个dump出的程序了，这里我主要是分析内存的问题，所以我说下我选择的内存分析工具，我这里使用的是开源的由SAP 和IBM 支持的一个内存分析工具</p>
<h1 id="memory-analyzer-mat-">Memory Analyzer (MAT)</h1>
<p><a href="http://www.eclipse.org/mat/" target="_blank">http://www.eclipse.org/mat/</a></p>
<p>我建议下载 Stand-alone Eclipse RCP 版本，不要装成eclipse的插件，因为这个分析起来还是很耗内存。<em>**</em></p>
<p>下载好了，解压开来就可以直接使用了（基于eclipse的），打开以后，在菜单栏中选择打开文件，选择你刚刚的dump文件，然后一路的next就可以了，最后你会看到一个报告，这个报告里会告诉你可能的内存泄露的点，以及内存中对象的一个分布，关于mat的使用请参考官方说明，当然你也可以自己徜徉在学习的海洋中 。</p>
<p>对于dump文件的分析还可以使用jdk中提供的一个jhat工具来查看，不过这个很耗内存，而且默认的内存大小不够，还需要增加参数设置内存大小才能分析出，不过我看了下分析出的结果不是很满意，而且这个用起来很慢。还是推荐使用mat 。
来源： <a href="[http://dikar.iteye.com/blog/643436](http://dikar.iteye.com/blog/643436)">[http://dikar.iteye.com/blog/643436](http://dikar.iteye.com/blog/643436)</a> </p>
<p> 摘文：<a href="http://dikar.iteye.com/blog/643196" target="_blank">Create Java heapdumps with the help of core dumps</a></p>
<p>转载自：<a href="http://devops-abyss.blogspot.com/2010/03/create-java-heapdumps-with-help-of-core.html" target="_blank">http://devops-abyss.blogspot.com/2010/03/create-java-heapdumps-with-help-of-core.html</a></p>
<p>Hi,
for some time I had the problem, that taking Java heap dumps with jmap took too long. When one of my tomcats crashed by an OutOfMemoryException, I had no time to do a heap dump because it took some hours and the server had to be back online.
Now I found a sollution to my problem. The initial idea came from <a href="https://proxy.evlit.net/browse.php?u=http%3A%2F%2Fserverfault.com%2Fquestions%2F110153%2Fhow-to-reliably-take-java-heap-dumps%2F12545&amp;b=4#125451" target="_blank">this</a> post. It had a solution for Solaris, but with some googling and try and error I found a solution for linux too.</p>
<ol>
<li>create a core dump of your java process with gdb
gdb --pid=[java pid] 
gcore [file name] 
detach 
quit</li>
<li>restart the tomcat or do whatever you like with the java process</li>
<li>attach jmap to the core dump and create a Java heap dump
jmap -heap:format=b [java binary] [core dump file]</li>
<li><p>analyze your Java heap dump with your prefered tool</p>
<p>When you get the following error in step three:
Error attaching to core file: Can&#39;t attach to the core file</p>
</li>
</ol>
<p>This might help:
In my case the error apeared because I used the wrong java binary in the jmap call. When you are not sure about your java binary, open the core dump with gdb:</p>
<p>gdb --core=[core dump file]</p>
<p>You will get an output similar to this one:</p>
<p>GNU gdb 6.6 Copyright (C) 2006 Free Software Foundation, Inc. GDB is free software, covered by the GNU General Public License, and you are welcome to change it and/or distribute copies of it under certain conditions. Type &quot;show copying&quot; to see the conditions. There is absolutely no warranty for GDB.  Type &quot;show warranty&quot; for details. This GDB was configured as &quot;i586-suse-linux&quot;... (no debugging symbols found) Using host libthread_db library &quot;/lib/libthread_db.so.1&quot;. 
warning: core file may not match specified executable file. (no debugging symbols found) Failed to read a valid object file image from memory. Core was generated by `/opt/tomcat/bin/jsvc&#39;. /#0  0xffffe410 in _start ()</p>
<p> What you are looking for is in this line:</p>
<p>Core was generated by `/opt/tomcat/bin/jsvc&#39;.</p>
<p> Call jmap with this binary and you will get a heapdump.</p>
<p>来源： <a href="[http://dikar.iteye.com/blog/643196](http://dikar.iteye.com/blog/643196)">[http://dikar.iteye.com/blog/643196](http://dikar.iteye.com/blog/643196)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/内存分析/">内存分析</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/内存分析/" class="label label-success">内存分析</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-内存分析--离线分析java内存/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-内存分析--离线分析java内存" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-内存分析--一次Java内存溢出异常的分析过程/">一次Java内存溢出异常的分析过程</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:40.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-内存分析--一次Java内存溢出异常的分析过程/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-">一次Java内存溢出异常的分析过程</h1>
<p>前些天，<a href="http://server.chinabyte.com/" target="_blank">服务器</a>上一个服务跑了一个多月突然当掉了。看了下日志，程序抛出了java.lang.OutOfMemoryError，之前也出现过同样的错误，服务跑了三个月内存溢出。出现这个异常，初步判断是程序有内存泄漏，接下来需要利用一些工具来分析具体原因。</p>
<p>首先使用jdk自带的工具jmap转储(dump)java内存堆数据到本地文件中。jmap转储(dump)命令格式如下：</p>
<p>jmap -dump:</p>
<p>表示dump选项，表示需要dump的java应用程序的进程ID</p>
<p>dump-options可以有以下三种参数，参数之间用逗号隔开：</p>
<p>live，只dump活动的object，如果没有指定，表示dump所有object</p>
<p>format=b，字节流格式</p>
<p>file=，是转储文件的保存路径</p>
<p>下面是dump命令的一个例子:</p>
<p>jmap -dump:format=b,file=heap.bin 8023</p>
<p>dump完成后，用Eclipse Memory Analyzer打开转储文件进行分析。Eclipse Memory Analyzer是一个java内存堆转储文件分析工具，可以生成内存分析报告(包括内存泄露Leak Suspects )。下面是分析完成后查看Top Consumers所看到的图表:</p>
<p><img src="" alt=""></p>
<p><img src="" alt=""></p>
<p>看到这两张图表，问题就比较明朗了。berkeley db中的数据结点com.sleepycat.je.tree.BIN占用了大量内存，导致内存溢出了。为了提高访问效率，berkeley db会缓存大量的结点，缓存大小限制可以在EnvironmentConfig设置，默认为jvm内存大小限制的60%。而这个应用程序中使用了5个EnvironmentImpl，并且都未单独设置缓存大小，总的缓存限制为jvm内存限制的300%(图表中BIN结点已经占用了94.55%的内存)，远远超出java的内存限制。随着服务的运行，缓存数据越来越多，最后导致内存溢出错误。因此，为每个EnvironmentImpl设置合适的缓存大小限制，就可以避免再次发生内存溢出。
来源： <a href="[http://soft.chinabyte.com/database/475/12147475.shtml](http://soft.chinabyte.com/database/475/12147475.shtml)">[http://soft.chinabyte.com/database/475/12147475.shtml](http://soft.chinabyte.com/database/475/12147475.shtml)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/内存分析/">内存分析</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/内存分析/" class="label label-success">内存分析</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:40"datetime="2014-03-07 09:54:40"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-内存分析--一次Java内存溢出异常的分析过程/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-内存分析--一次Java内存溢出异常的分析过程" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/66/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/64/">64</a></li><li><a class="page-number" href="/page/65/">65</a></li><li><a class="page-number" href="/page/66/">66</a></li><li class="active"><li><span class="page-number current">67</span></li><li><a class="page-number" href="/page/68/">68</a></li><li><a class="page-number" href="/page/69/">69</a></li><li><a class="page-number" href="/page/70/">70</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/164/">164</a></li><li><a class="page-number" href="/page/165/">165</a></li><li><a class="extend next" href="/page/68/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Blog powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a> Theme <strong><a href='https://github.com/chenall/hexo-theme-chenall'>chenall</a></strong>(Some change in it)<span class="pull-right"> 更新时间: <em>2014-03-15 16:33:42</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
