
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 59 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--聊聊并发（四）——深入分析ConcurrentHashMap/">聊聊并发（四）——深入分析ConcurrentHashMap</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--聊聊并发（四）——深入分析ConcurrentHashMap/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-concurrenthashmap">聊聊并发（四）——深入分析ConcurrentHashMap</h1>
<h2 id="-">术语定义</h2>
<p>术语 英文 解释 哈希算法 hash algorithm 是一种将任意内容的输入转换成相同长度输出的加密方式，其输出被称为哈希值。 哈希表 hash table 根据设定的哈希函数H(key)和处理冲突方法将一组关键字映象到一个有限的地址区间上，并以关键字在地址区间中的象作为记录在表中的存储位置，这种表称为哈希表或散列，所得存储位置称为哈希地址或散列地址。</p>
<h2 id="-hashmap">线程不安全的HashMap</h2>
<p>因为多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap，如以下代码
final HashMap<String, String> map = new HashMap<String, String>(2);</p>
<p>Thread t = new Thread(new Runnable() {
@Override</p>
<p>public void run() {
for (int i = 0; i &lt; 10000; i++) {</p>
<p>new Thread(new Runnable() {
@Override</p>
<p>public void run() {
map.put(UUID.randomUUID().toString(), &quot;&quot;);</p>
<p>}
}, &quot;ftf&quot; + i).start();</p>
<p>}
}</p>
<p>}, &quot;ftf&quot;);
t.start();</p>
<p>t.join();</p>
<h2 id="-hashtable-">效率低下的HashTable容器</h2>
<p>HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时，其他线程访问HashTable的同步方法时，可能会进入阻塞或轮询状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。</p>
<h2 id="-">锁分段技术</h2>
<p>HashTable容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问HashTable的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。</p>
<h2 id="concurrenthashmap-">ConcurrentHashMap的结构</h2>
<p>我们通过ConcurrentHashMap的类图来分析ConcurrentHashMap的结构。</p>
<p><img src="" alt=""></p>
<p>ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。</p>
<p><img src="" alt=""></p>
<h2 id="concurrenthashmap-">ConcurrentHashMap的初始化</h2>
<p>ConcurrentHashMap初始化方法是通过initialCapacity，loadFactor, concurrencyLevel几个参数来初始化segments数组，段偏移量segmentShift，段掩码segmentMask和每个segment里的HashEntry数组 。</p>
<p>初始化segments数组。让我们来看一下初始化segmentShift，segmentMask和segments数组的源代码。
if (concurrencyLevel &gt; MAX_SEGMENTS)</p>
<p>concurrencyLevel = MAX_SEGMENTS;
// Find power-of-two sizes best matching arguments</p>
<p>int sshift = 0;
int ssize = 1;</p>
<p>while (ssize &lt; concurrencyLevel) {
++sshift;</p>
<p>ssize &lt;&lt;= 1;
}</p>
<p>segmentShift = 32 - sshift;
segmentMask = ssize - 1;</p>
<p>this.segments = Segment.newArray(ssize);</p>
<p>由上面的代码可知segments数组的长度ssize通过concurrencyLevel计算得出。为了能通过按位与的哈希算法来定位segments数组的索引，必须保证segments数组的长度是2的N次方（power-of-two size），所以必须计算出一个是大于或等于concurrencyLevel的最小的2的N次方值来作为segments数组的长度。假如concurrencyLevel等于14，15或16，ssize都会等于16，即容器里锁的个数也是16。注意concurrencyLevel的最大大小是65535，意味着segments数组的长度最大为65536，对应的二进制是16位。</p>
<p>初始化segmentShift和segmentMask。这两个全局变量在定位segment时的哈希算法里需要使用，sshift等于ssize从1向左移位的次数，在默认情况下concurrencyLevel等于16，1需要向左移位移动4次，所以sshift等于4。segmentShift用于定位参与hash运算的位数，segmentShift等于32减sshift，所以等于28，这里之所以用32是因为ConcurrentHashMap里的hash()方法输出的最大数是32位的，后面的测试中我们可以看到这点。segmentMask是哈希运算的掩码，等于ssize减1，即15，掩码的二进制各个位的值都是1。因为ssize的最大长度是65536，所以segmentShift最大值是16，segmentMask最大值是65535，对应的二进制是16位，每个位都是1。</p>
<p>初始化每个Segment。输入参数initialCapacity是ConcurrentHashMap的初始化容量，loadfactor是每个segment的负载因子，在构造方法里需要通过这两个参数来初始化数组中的每个segment。
if (initialCapacity &gt; MAXIMUM_CAPACITY)</p>
<p>initialCapacity = MAXIMUM_CAPACITY;
int c = initialCapacity / ssize;</p>
<p>if (c /* ssize &lt; initialCapacity)
++c;</p>
<p>int cap = 1;
while (cap &lt; c)</p>
<p>cap &lt;&lt;= 1;
for (int i = 0; i &lt; this.segments.length; ++i)</p>
<p>this.segments[i] = new Segment<K,V>(cap, loadFactor);</p>
<p>上面代码中的变量cap就是segment里HashEntry数组的长度，它等于initialCapacity除以ssize的倍数c，如果c大于1，就会取大于等于c的2的N次方值，所以cap不是1，就是2的N次方。segment的容量threshold＝(int)cap/*loadFactor，默认情况下initialCapacity等于16，loadfactor等于0.75，通过运算cap等于1，threshold等于零。</p>
<h2 id="-segment">定位Segment</h2>
<p>既然ConcurrentHashMap使用分段锁Segment来保护不同段的数据，那么在插入和获取元素的时候，必须先通过哈希算法定位到Segment。可以看到ConcurrentHashMap会首先使用Wang/Jenkins hash的变种算法对元素的hashCode进行一次再哈希。
private static int hash(int h) {</p>
<p>h += (h &lt;&lt; 15) ^ 0xffffcd7d;
h ^= (h &gt;&gt;&gt; 10);</p>
<p>h += (h &lt;&lt; 3);
h ^= (h &gt;&gt;&gt; 6);</p>
<p>h += (h &lt;&lt; 2) + (h &lt;&lt; 14);
return h ^ (h &gt;&gt;&gt; 16);</p>
<p>}</p>
<p>之所以进行再哈希，其目的是为了减少哈希冲突，使元素能够均匀的分布在不同的Segment上，从而提高容器的存取效率。假如哈希的质量差到极点，那么所有的元素都在一个Segment中，不仅存取元素缓慢，分段锁也会失去意义。我做了一个测试，不通过再哈希而直接执行哈希计算。</p>
<p>System.out.println(Integer.parseInt(&quot;0001111&quot;, 2) &amp; 15);</p>
<p>System.out.println(Integer.parseInt(&quot;0011111&quot;, 2) &amp; 15);
System.out.println(Integer.parseInt(&quot;0111111&quot;, 2) &amp; 15);</p>
<p>System.out.println(Integer.parseInt(&quot;1111111&quot;, 2) &amp; 15);</p>
<p>计算后输出的哈希值全是15，通过这个例子可以发现如果不进行再哈希，哈希冲突会非常严重，因为只要低位一样，无论高位是什么数，其哈希值总是一样。我们再把上面的二进制数据进行再哈希后结果如下，为了方便阅读，不足32位的高位补了0，每隔四位用竖线分割下。</p>
<p>0100｜0111｜0110｜0111｜1101｜1010｜0100｜1110</p>
<p>1111｜0111｜0100｜0011｜0000｜0001｜1011｜1000
0111｜0111｜0110｜1001｜0100｜0110｜0011｜1110</p>
<p>1000｜0011｜0000｜0000｜1100｜1000｜0001｜1010</p>
<p>可以发现每一位的数据都散列开了，通过这种再哈希能让数字的每一位都能参加到哈希运算当中，从而减少哈希冲突。ConcurrentHashMap通过以下哈希算法定位segment。</p>
<p>final Segment<K,V> segmentFor(int hash) {</p>
<p>return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];
}</p>
<p>默认情况下segmentShift为28，segmentMask为15，再哈希后的数最大是32位二进制数据，向右无符号移动28位，意思是让高4位参与到hash运算中， (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask的运算结果分别是4，15，7和8，可以看到hash值没有发生冲突。</p>
<h2 id="concurrenthashmap-get-">ConcurrentHashMap的get操作</h2>
<p>Segment的get操作实现非常简单和高效。先经过一次再哈希，然后使用这个哈希值通过哈希运算定位到segment，再通过哈希算法定位到元素，代码如下：
public V get(Object key) {</p>
<p>int hash = hash(key.hashCode());
return segmentFor(hash).get(key, hash);</p>
<p>}</p>
<p>get操作的高效之处在于整个get过程不需要加锁，除非读到的值是空的才会加锁重读，我们知道HashTable容器的get方法是需要加锁的，那么ConcurrentHashMap的get操作是如何做到不加锁的呢？原因是它的get方法里将要使用的共享变量都定义成volatile，如用于统计当前Segement大小的count字段和用于存储值的HashEntry的value。定义成volatile的变量，能够在线程之间保持可见性，能够被多线程同时读，并且保证不会读到过期的值，但是只能被单线程写（有一种情况可以被多线程写，就是写入的值不依赖于原值），在get操作里只需要读不需要写共享变量count和value，所以可以不用加锁。之所以不会读到过期的值，是根据java内存模型的happen before原则，对volatile字段的写入操作先于读操作，即使两个线程同时修改和获取volatile变量，get操作也能拿到最新的值，这是用volatile替换锁的经典应用场景。</p>
<p>transient volatile int count;</p>
<p>volatile V value;</p>
<p>在定位元素的代码里我们可以发现定位HashEntry和定位Segment的哈希算法虽然一样，都与数组的长度减去一相与，但是相与的值不一样，定位Segment使用的是元素的hashcode通过再哈希后得到的值的高位，而定位HashEntry直接使用的是再哈希后的值。其目的是避免两次哈希后的值一样，导致元素虽然在Segment里散列开了，但是却没有在HashEntry里散列开。</p>
<p>hash &gt;&gt;&gt; segmentShift) &amp; segmentMask//定位Segment所使用的hash算法</p>
<p>int index = hash &amp; (tab.length - 1);// 定位HashEntry所使用的hash算法</p>
<h2 id="concurrenthashmap-put-">ConcurrentHashMap的Put操作</h2>
<p>由于put方法里需要对共享变量进行写入操作，所以为了线程安全，在操作共享变量时必须得加锁。Put方法首先定位到Segment，然后在Segment里进行插入操作。插入操作需要经历两个步骤，第一步判断是否需要对Segment里的HashEntry数组进行扩容，第二步定位添加元素的位置然后放在HashEntry数组里。</p>
<p>是否需要扩容。在插入元素前会先判断Segment里的HashEntry数组是否超过容量（threshold），如果超过阀值，数组进行扩容。值得一提的是，Segment的扩容判断比HashMap更恰当，因为HashMap是在插入元素后判断元素是否已经到达容量的，如果到达了就进行扩容，但是很有可能扩容之后没有新元素插入，这时HashMap就进行了一次无效的扩容。</p>
<p>如何扩容。扩容的时候首先会创建一个两倍于原容量的数组，然后将原数组里的元素进行再hash后插入到新的数组里。为了高效ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容。</p>
<h2 id="concurrenthashmap-size-">ConcurrentHashMap的size操作</h2>
<p>如果我们要统计整个ConcurrentHashMap里元素的大小，就必须统计所有Segment里元素的大小后求和。Segment里的全局变量count是一个volatile变量，那么在多线程场景下，我们是不是直接把所有Segment的count相加就可以得到整个ConcurrentHashMap大小了呢？不是的，虽然相加时可以获取每个Segment的count的最新值，但是拿到之后可能累加前使用的count发生了变化，那么统计结果就不准了。所以最安全的做法，是在统计size的时候把所有Segment的put，remove和clean方法全部锁住，但是这种做法显然非常低效。 因为在累加count操作过程中，之前累加过的count发生变化的几率非常小，所以ConcurrentHashMap的做法是先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小。</p>
<p>那么ConcurrentHashMap是如何判断在统计的时候容器是否发生了变化呢？使用modCount变量，在put , remove和clean方法里操作元素前都会将变量modCount进行加1，那么在统计size前后比较modCount是否发生变化，从而得知容器的大小是否发生变化。</p>
<h2 id="-">参考资料</h2>
<ol>
<li>JDK1.6源代码。</li>
<li>《Java并发编程实践》。</li>
<li><a href="http://www.goldendoc.org/2011/06/juc_concurrenthashmap/" target="_blank">Java并发编程之ConcurrentHashMap</a> 。</li>
</ol>
<h2 id="-">作者介绍</h2>
<p><strong>方腾飞</strong>，花名清英，淘宝资深开发工程师，关注并发编程，目前在广告技术部从事无线广告联盟的开发和设计工作。个人博客：<a href="http://ifeve.com/" target="_blank"><a href="http://ifeve.com">http://ifeve.com</a></a> 微博：<a href="http://weibo.com/kirals" target="_blank"><a href="http://weibo.com/kirals">http://weibo.com/kirals</a></a> 欢迎通过我的微博进行技术交流。</p>
<p>感谢<a href="http://www.infoq.com/cn/bycategory.action?authorName=%E5%BC%A0%E9%BE%99" target="_blank">张龙</a>对本文的审校。
来源： <a href="[http://www.infoq.com/cn/articles/ConcurrentHashMap](http://www.infoq.com/cn/articles/ConcurrentHashMap)">[http://www.infoq.com/cn/articles/ConcurrentHashMap](http://www.infoq.com/cn/articles/ConcurrentHashMap)</a></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--聊聊并发（四）——深入分析ConcurrentHashMap/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--聊聊并发（四）——深入分析ConcurrentHashMap" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析/">聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-concurrentlinkedqueue-">聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析</h1>
<h3 id="-">分享到</h3>
<ul>
<li><a href="">一键分享</a></li>
<li><a href="">QQ空间</a></li>
<li><a href="">新浪微博</a></li>
<li><a href="">百度搜藏</a></li>
<li><a href="">人人网</a></li>
<li><a href="">腾讯微博</a></li>
<li><a href="">百度相册</a></li>
<li><a href="">开心网</a></li>
<li><a href="">腾讯朋友</a></li>
<li><a href="">百度贴吧</a></li>
<li><a href="">豆瓣网</a></li>
<li><a href="">搜狐微博</a></li>
<li><a href="">百度新首页</a></li>
<li><a href="">QQ好友</a></li>
<li><a href="">和讯微博</a></li>
<li><a href="">更多...</a></li>
</ul>
<p><a href="">百度分享</a></p>
<ul>
<li><a href="http://www.infoq.com/cn/aboutus" title="关于我们" target="_blank">关于我们</a></li>
<li><p><a href="http://www.infoq.com/cn/contribute" title="让大家在InfoQ上听见你的声音" target="_blank">让大家在InfoQ上听见你的声音</a></p>
</li>
<li><p>欢迎关注我们的：</p>
</li>
<li><a href="http://e.weibo.com/infoqchina" target="_blank"><img src="" alt=""></a></li>
<li><a href="http://www.infoq.com/cn/news/2013/02/infoq-wechat" target="_blank"><img src="" alt=""></a></li>
<li><a href="http://www.infoq.com/cn/rss/rss.action?token=J6EBu2hcpyEuMs9msdo8GyNCZTcWG7pm" target="_blank"><img src="" alt=""></a></li>
</ul>
<h1 id="-concurrentlinkedqueue-">聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析</h1>
<p>作者 <a href="http://www.infoq.com/cn/author/%E6%96%B9%E8%85%BE%E9%A3%9E" target="_blank">方腾飞</a> 发布于 一月 09, 2013 <em>|</em> <a href="">5 评论</a></p>
<h2 id="1-">1. 引言</h2>
<p>在并发编程中我们有时候需要使用线程安全的队列。如果我们要实现一个线程安全的队列有两种实现方式：一种是使用阻塞算法，另一种是使用非阻塞算法。使用阻塞算法的队列可以用一个锁（入队和出队用同一把锁）或两个锁（入队和出队用不同的锁）等方式来实现，而非阻塞的实现方式则可以使用循环CAS的方式来实现，本文让我们一起来研究下Doug Lea是如何使用非阻塞的方式来实现线程安全队列ConcurrentLinkedQueue的，相信从大师身上我们能学到不少并发编程的技巧。</p>
<h2 id="2-concurrentlinkedqueue-">2. ConcurrentLinkedQueue的介绍</h2>
<p>ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait－free”算法来实现，该算法在Michael &amp; Scott算法上进行了一些修改, Michael &amp; Scott算法的详细信息可以参见<a href="http://www.cs.rochester.edu/u/michael/PODC96.html" target="_blank">参考资料一</a>。</p>
<h2 id="3-concurrentlinkedqueue-">3. ConcurrentLinkedQueue的结构</h2>
<p>我们通过ConcurrentLinkedQueue的类图来分析一下它的结构。</p>
<p><img src="" alt=""></p>
<p>（图1）</p>
<p>ConcurrentLinkedQueue由head节点和tair节点组成，每个节点（Node）由节点元素（item）和指向下一个节点的引用(next)组成，节点与节点之间就是通过这个next关联起来，从而组成一张链表结构的队列。默认情况下head节点存储的元素为空，tair节点等于head节点。
private transient volatile Node tail = head;</p>
<h2 id="4-">4. 入队列</h2>
<p><strong>入队列就是将入队节点添加到队列的尾部</strong>。为了方便理解入队时队列的变化，以及head节点和tair节点的变化，每添加一个节点我就做了一个队列的快照图。</p>
<p><img src="" alt=""></p>
<p>（图二）</p>
<ul>
<li>第一步添加元素1。队列更新head节点的next节点为元素1节点。又因为tail节点默认情况下等于head节点，所以它们的next节点都指向元素1节点。</li>
<li>第二步添加元素2。队列首先设置元素1节点的next节点为元素2节点，然后更新tail节点指向元素2节点。</li>
<li>第三步添加元素3，设置tail节点的next节点为元素3节点。</li>
<li>第四步添加元素4，设置元素3的next节点为元素4节点，然后将tail节点指向元素4节点。</li>
</ul>
<p>通过debug入队过程并观察head节点和tail节点的变化，发现入队主要做两件事情，第一是将入队节点设置成当前队列尾节点的下一个节点。第二是更新tail节点，如果tail节点的next节点不为空，则将入队节点设置成tail节点，如果tail节点的next节点为空，则将入队节点设置成tail的next节点，所以tail节点不总是尾节点，理解这一点对于我们研究源码会非常有帮助。</p>
<p>上面的分析让我们从单线程入队的角度来理解入队过程，但是多个线程同时进行入队情况就变得更加复杂，因为可能会出现其他线程插队的情况。如果有一个线程正在入队，那么它必须先获取尾节点，然后设置尾节点的下一个节点为入队节点，但这时可能有另外一个线程插队了，那么队列的尾节点就会发生变化，这时当前线程要暂停入队操作，然后重新获取尾节点。让我们再通过源码来详细分析下它是如何使用CAS算法来入队的。
public boolean offer(E e) { if (e == null) throw new NullPointerException(); //入队前，创建一个入队节点 Node<E> n = new Node<E>(e); retry: //死循环，入队不成功反复入队。 for (;;) { //创建一个指向tail节点的引用 Node<E> t = tail; //p用来表示队列的尾节点，默认情况下等于tail节点。 Node<E> p = t; for (int hops = 0; ; hops++) { //获得p节点的下一个节点。 Node<E> next = succ(p); //next节点不为空，说明p不是尾节点，需要更新p后在将它指向next节点 if (next != null) { //循环了两次及其以上，并且当前节点还是不等于尾节点 if (hops &gt; HOPS &amp;&amp; t != tail) continue retry; p = next; } //如果p是尾节点，则设置p节点的next节点为入队节点。 else if (p.casNext(null, n)) { //如果tail节点有大于等于1个next节点，则将入队节点设置成tair节点，更新失败了也 没关系，因为失败了表示有其他线程成功更新了tair节点。 if (hops &gt;= HOPS) casTail(t, n); // 更新tail节点，允许失败 return true; } // p有next节点,表示p的next节点是尾节点，则重新设置p节点 else { p = succ(p); } } } }</p>
<p><strong>从源代码角度来看整个入队过程主要做二件事情</strong>。第一是定位出尾节点，第二是使用CAS算法能将入队节点设置成尾节点的next节点，如不成功则重试。</p>
<p><strong>第一步定位尾节点</strong>。tail节点并不总是尾节点，所以每次入队都必须先通过tail节点来找到尾节点，尾节点可能就是tail节点，也可能是tail节点的next节点。代码中循环体中的第一个if就是判断tail是否有next节点，有则表示next节点可能是尾节点。获取tail节点的next节点需要注意的是p节点等于p的next节点的情况，只有一种可能就是p节点和p的next节点都等于空，表示这个队列刚初始化，正准备添加第一次节点，所以需要返回head节点。获取p节点的next节点代码如下
final Node<E> succ(Node<E> p) { Node<E> next = p.getNext(); return (p == next) ? head : next; }</p>
<p><strong>第二步设置入队节点为尾节点</strong>。p.casNext(null, n)方法用于将入队节点设置为当前队列尾节点的next节点，p如果是null表示p是当前队列的尾节点，如果不为null表示有其他线程更新了尾节点，则需要重新获取当前队列的尾节点。</p>
<p><strong>hops的设计意图</strong>。上面分析过对于先进先出的队列入队所要做的事情就是将入队节点设置成尾节点，doug lea写的代码和逻辑还是稍微有点复杂。那么我用以下方式来实现行不行？
public boolean offer(E e) { if (e == null) throw new NullPointerException(); Node<E> n = new Node<E>(e); for (;;) { Node<E> t = tail; if (t.casNext(null, n) &amp;&amp; casTail(t, n)) { return true; } } }</p>
<p>让tail节点永远作为队列的尾节点，这样实现代码量非常少，而且逻辑非常清楚和易懂。但是这么做有个缺点就是每次都需要使用循环CAS更新tail节点。如果能减少CAS更新tail节点的次数，就能提高入队的效率，所以doug lea使用hops变量来控制并减少tail节点的更新频率，并不是每次节点入队后都将 tail节点更新成尾节点，而是当 tail节点和尾节点的距离大于等于常量HOPS的值（默认等于1）时才更新tail节点，tail和尾节点的距离越长使用CAS更新tail节点的次数就会越少，但是距离越长带来的负面效果就是每次入队时定位尾节点的时间就越长，因为循环体需要多循环一次来定位出尾节点，但是这样仍然能提高入队的效率，因为从本质上来看它通过增加对volatile变量的读操作来减少了对volatile变量的写操作，而对volatile变量的写操作开销要远远大于读操作，所以入队效率会有所提升。</p>
<p>private static final int HOPS = 1;</p>
<p>还有一点需要注意的是入队方法永远返回true，所以不要通过返回值判断入队是否成功。</p>
<h2 id="5-">5. 出队列</h2>
<p>出队列的就是从队列里返回一个节点元素，并清空该节点对元素的引用。让我们通过每个节点出队的快照来观察下head节点的变化。</p>
<p><img src="" alt=""></p>
<p>从上图可知，并不是每次出队时都更新head节点，当head节点里有元素时，直接弹出head节点里的元素，而不会更新head节点。只有当head节点里没有元素时，出队操作才会更新head节点。这种做法也是通过hops变量来减少使用CAS更新head节点的消耗，从而提高出队效率。让我们再通过源码来深入分析下出队过程。
public E poll() { Node<E> h = head; // p表示头节点，需要出队的节点 Node<E> p = h; for (int hops = 0;; hops++) { // 获取p节点的元素 E item = p.getItem(); // 如果p节点的元素不为空，使用CAS设置p节点引用的元素为null,如果成功则返回p节点的元素。 if (item != null &amp;&amp; p.casItem(item, null)) { if (hops &gt;= HOPS) { //将p节点下一个节点设置成head节点 Node<E> q = p.getNext(); updateHead(h, (q != null) ? q : p); } return item; } // 如果头节点的元素为空或头节点发生了变化，这说明头节点已经被另外一个线程修改了。那么获取p节点的下一个节点 Node&lt;&gt; next = succ(p); // 如果p的下一个节点也为空，说明这个队列已经空了 if (next == null) { // 更新头节点。 updateHead(h, p); break; } // 如果下一个元素不为空，则将头节点的下一个节点设置成头节点 p = next; } return null; }</p>
<p>首先获取头节点的元素，然后判断头节点元素是否为空，如果为空，表示另外一个线程已经进行了一次出队操作将该节点的元素取走，如果不为空，则使用CAS的方式将头节点的引用设置成null，如果CAS成功，则直接返回头节点的元素，如果不成功，表示另外一个线程已经进行了一次出队操作更新了head节点，导致元素发生了变化，需要重新获取头节点。</p>
<h2 id="6-">6. 参考资料</h2>
<ul>
<li><a href="http://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf" target="_blank">简单，快速和实用的阻塞和非阻塞并发队列算法</a>。</li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-lo-concurrent/index.html" target="_blank">非阻塞算法在容器里的实现</a>。</li>
<li>JDK1.6中ConcurrentLinkedQueue源码和注释。</li>
</ul>
<h1 id="-">#</h1>
<h2 id="-">作者介绍</h2>
<p><strong>方腾飞</strong>，花名清英，淘宝资深开发工程师，关注并发编程，目前在广告技术部从事无线广告联盟的开发和设计工作。个人博客：<a href="http://ifeve.com/" target="_blank"><a href="http://ifeve.com">http://ifeve.com</a></a> 微博：<a href="http://weibo.com/kirals" target="_blank"><a href="http://weibo.com/kirals">http://weibo.com/kirals</a></a>欢迎通过我的微博进行技术交流。</p>
<p>感谢<a href="http://www.infoq.com/cn/bycategory.action?authorName=张龙" target="_blank">张龙</a>对本文的审校。</p>
<p>给InfoQ中文站投稿或者参与内容翻译工作，请邮件至<a href="mailto:editors@cn.infoq.com">editors@cn.infoq.com</a>。也欢迎大家通过新浪微博（<a href="http://www.weibo.com/infoqchina" target="_blank">@InfoQ</a>）或者腾讯微博（<a href="http://t.qq.com/infoqchina" target="_blank">@InfoQ</a>）关注我们，并与我们的编辑和其他读者朋友交流。</p>
<ul>
<li><a href="">Sections</a></li>
<li><a href="http://www.infoq.com/cn/development" target="_blank"><strong>语言 &amp; 开发</strong></a></li>
<li><a href="">Topics</a></li>
<li><a href="http://www.infoq.com/cn/Multi-threading" target="_blank">多线程</a></li>
<li><a href="http://www.infoq.com/cn/concurrency" target="_blank">并发</a></li>
<li><a href="http://www.infoq.com/cn/java" target="_blank">Java</a></li>
</ul>
<p>相关内容</p>
<h3 id="-http-www-infoq-com-cn-articles-atomic-operation-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/atomic-operation?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">聊聊并发（五）——原子操作的实现原理</a></h3>
<h3 id="-concurrenthashmap-http-www-infoq-com-cn-articles-concurrenthashmap-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/ConcurrentHashMap?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">聊聊并发（四）——深入分析ConcurrentHashMap</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-threadpool-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-threadPool?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">聊聊并发（三）——JAVA线程池的分析和使用</a></h3>
<h3 id="-volatile-http-www-infoq-com-cn-articles-ftf-java-volatile-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/ftf-java-volatile?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">聊聊并发（一）——深入分析Volatile的实现原理</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-7-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-7?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（七）——总结</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-7-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-7?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（七）——总结</a></h3>
<h3 id="-java-final-http-www-infoq-com-cn-articles-java-memory-model-6-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-6?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（六）——final</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-5-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/java-memory-model-5?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">深入理解Java内存模型（五）——锁</a></h3>
<h3 id="-http-www-infoq-com-cn-articles-atomic-operation-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/atomic-operation?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">聊聊并发（五）——原子操作的实现原理</a></h3>
<h3 id="-concurrenthashmap-http-www-infoq-com-cn-articles-concurrenthashmap-utm_source-infoq-utm_medium-related_content_link-utm_campaign-relatedcontent_articles_clk-"><a href="http://www.infoq.com/cn/articles/ConcurrentHashMap?utm_source=infoq&amp;utm_medium=related_content_link&amp;utm_campaign=relatedContent_articles_clk" target="_blank">聊聊并发（四）——深入分析ConcurrentHashMap</a></h3>
<h2 id="-">您好，陌生人！</h2>
<p>您需要 <a href="http://www.infoq.com/reginit.action" target="_blank">注册一个InfoQ账号</a> 或者 <a href="">登录</a> 才能进行评论。在您完成注册后还需要进行一些设置。</p>
<h2 id="-infoq-">获得来自InfoQ的更多体验。<a href=""></a></h2>
<p>允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p</p>
<p>当有人回复此评论时请E-mail通知我</p>
<p>社区评论 <a href="">Watch Thread</a></p>
<p><a href=""><strong>CAS 描述有错</strong> by lin lirs Posted 10/01/2013 05:35</a>
<a href=""><strong>Re: CAS 描述有错</strong> by 方 腾飞 Posted 11/01/2013 03:10</a></p>
<p><a href=""><strong>请教大师，有个地方不是很明白</strong> by huang shuihua Posted 18/01/2013 02:58</a>
<a href=""><strong>Re: 请教大师，有个地方不是很明白</strong> by 方 腾飞 Posted 18/01/2013 03:40</a></p>
<p><a href=""><strong>看着不过瘾，买了本书</strong> by 杨 亮 Posted 04/03/2013 01:42</a>
<a href=""></a></p>
<p><strong>CAS 描述有错</strong> 10/01/2013 05:35 by lin lirs</p>
<p>“它采用了“wait－free”算法（即CAS算法）来实现”， CAS不是指算法，而是一个原子操作，wait-free不等同CAS。
<a href="http://en.wikipedia.org/wiki/Compare-and-swap" target="_blank">en.wikipedia.org/wiki/Compare-and-swap</a></p>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a></li>
</ul>
<p><a href=""></a></p>
<p><strong>Re: CAS 描述有错</strong> 11/01/2013 03:10 by 方 腾飞</p>
<p>的确！CAS是一个原子操作指令，可以用来实现“wait－free”算法。这里用“既CAS算法”的确不太合适，我加上的初衷是希望读者能很好的理解“wait－free”算法，但这样会产生一些歧义，所以还是删掉比较合适，感谢您的纠正。</p>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a>
<a href=""></a></li>
</ul>
<p><strong>请教大师，有个地方不是很明白</strong> 18/01/2013 02:58 by huang shuihua</p>
<p>(如果tail节点的next节点不为空，则将入队节点设置成tail节点，如果tail节点的next节点为空，则将入队节点设置成tail的next节点，所以tail节点不总是尾节点),这个还是不是很明白，能否有更加清晰一点的原理图show一下，谢谢!</p>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a></li>
</ul>
<p><a href=""></a></p>
<p><strong>Re: 请教大师，有个地方不是很明白</strong> 18/01/2013 03:40 by 方 腾飞</p>
<p>tail节点并总是尾节点。入队的时候，入队节点要放在队列的尾部，那首先要定位尾节点是哪个节点？所以这里通过tail节点来定位尾节点。尾节点要么是tail节点，要么是tail的next节点。所以入队会有两种情况
情况1：tail节点的next节点不为空，那么插入后队列变成
旧的tail节点-&gt;旧tail节点的next节点-&gt;入队节点（新tail节点）
情况2：tail节点的next节点为空，那么插入后队列变成
tail节点-&gt;入队节点</p>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a>
<a href=""></a></li>
</ul>
<p><strong>看着不过瘾，买了本书</strong> 04/03/2013 01:42 by 杨 亮</p>
<p>聊聊并发这个系列都看了，结合内存模型系列，但还是看着不过瘾，买了本书看。</p>
<ul>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a></li>
</ul>
<p><a href="">关闭</a></p>
<h3 id="-by"><em>**</em>by</h3>
<p>发布于</p>
<ul>
<li><a href="">查看</a></li>
<li><a href="">回复</a></li>
<li><a href="">回到顶部</a>
<a href="">关闭</a> 主题  您的回复 <a href="">引用原消息</a></li>
</ul>
<p>允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p
当有人回复此评论时请E-mail通知我</p>
<p><a href="">关闭</a> 主题  您的回复</p>
<p>允许的HTML标签: a,b,br,blockquote,i,li,pre,u,ul,p
当有人回复此评论时请E-mail通知我
<a href="">关闭</a></p>
<ul>
<li>热点内容</li>
<li><a href="">本周</a></li>
<li><a href="">本月</a></li>
<li><a href="">近6个月</a><h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
</li>
</ul>
<h3 id="-thoughtworks-2013-5-http-www-infoq-com-cn-articles-thoughtworks-technology-radar-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/thoughtWorks-technology-radar?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">ThoughtWorks技术雷达（2013年5月）</a></h3>
<h3 id="-1-5-http-www-infoq-com-cn-articles-iqiyi-cloud-push-practices-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/iqiyi-cloud-push-practices?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">让1.5亿移动端用户第一时间获取消息</a></h3>
<h3 id="-thoughtworks-ceo-http-www-infoq-com-cn-news-2013-06-tw-guoxiao-on-talents-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/tw-guoxiao-on-talents?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">ThoughtWorks全球CEO郭晓谈软件人才的招聘与培养</a></h3>
<h3 id="-http-www-infoq-com-cn-news-2013-06-10-sins-for-scalability-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/10-sins-for-scalability?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">影响可扩展性的十宗罪</a></h3>
<h3 id="-6-http-www-infoq-com-cn-minibooks-architect-jun-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jun-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（6月刊）</a></h3>
<h3 id="-http-www-infoq-com-cn-articles-function-switch-realize-better-continuous-implementations-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/function-switch-realize-better-continuous-implementations?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">使用功能开关更好地实现持续部署</a></h3>
<h3 id="-eclipse-github-http-www-infoq-com-cn-news-2013-06-eclipse-github-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/eclipse-github?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Eclipse迁移到GitHub</a></h3>
<h3 id="-newegg-com-http-www-infoq-com-cn-presentations-newegg-big-data-practice-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/presentations/newegg-big-data-practice?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Newegg.com大数据实践</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-software-sys-architect-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/software-sys-architect?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">软件系统架构：使用视点和视角与利益相关者合作</a></h3>
<h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
<h3 id="-6-http-www-infoq-com-cn-minibooks-architect-jun-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jun-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（6月刊）</a></h3>
<h3 id="-rest-http-www-infoq-com-cn-news-2013-06-rest-drawbacks-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/rest-drawbacks?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">REST的缺点是什么？</a></h3>
<h3 id="-google-web-ui-polymer-http-www-infoq-com-cn-news-2013-06-webcomponents-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/webcomponents?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Google 发布新一代Web UI库Polymer</a></h3>
<h3 id="-http-www-infoq-com-cn-news-2013-06-dianping-xinnet-hacked-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/dianping-xinnet-hacked?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">大众点评网域名劫持事件概述</a></h3>
<h3 id="-node-js-grunt-js-http-www-infoq-com-cn-articles-gruntjs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/GruntJs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">基于Node.js的自动化构建工具Grunt.js</a></h3>
<h3 id="-node-js-node-js-http-www-infoq-com-cn-articles-what-is-nodejs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/what-is-nodejs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（一）：什么是Node.js</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-i-m-wrights-hard-code-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/i-m-wrights-hard-code?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">代码之殇·第二版</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-software-sys-architect-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/software-sys-architect?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">软件系统架构：使用视点和视角与利益相关者合作</a></h3>
<h3 id="-18-java-http-www-infoq-com-cn-news-2013-06-zhuhong-on-java-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/zhuhong-on-java?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">大家谈18岁的Java——朱鸿：开过跑车后再去开大巴车总是有点不爽的</a></h3>
<h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-1-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/java-memory-model-1?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入理解Java内存模型（一）——基础</a></h3>
<h3 id="-node-js-node-js-http-www-infoq-com-cn-articles-what-is-nodejs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/what-is-nodejs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（一）：什么是Node.js</a></h3>
<h3 id="-node-js-node-js-npm-http-www-infoq-com-cn-articles-nodejs-npm-install-config-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/nodejs-npm-install-config?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（二）：Node.js&amp;NPM的安装与配置</a></h3>
<h3 id="-3-http-www-infoq-com-cn-minibooks-architect-mar-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-mar-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（3月刊）</a></h3>
<h3 id="-1-http-www-infoq-com-cn-minibooks-architect-jan-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jan-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（1月刊）</a></h3>
<h3 id="-4-http-www-infoq-com-cn-minibooks-architect-apr-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-apr-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（4月刊）</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-threadpool-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/java-threadPool?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">聊聊并发（三）——JAVA线程池的分析和使用</a></h3>
<h3 id="-2-http-www-infoq-com-cn-minibooks-architect-feb-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-feb-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（2月刊）</a></h3>
<h3 id="-12306-github-http-www-infoq-com-cn-news-2013-01-12306-plugin-ddos-github-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/01/12306-plugin-ddos-github?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">12306订票助手插件拖垮GitHub事件原因始末</a></h3>
<h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
<h3 id="-thoughtworks-2013-5-http-www-infoq-com-cn-articles-thoughtworks-technology-radar-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/thoughtWorks-technology-radar?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">ThoughtWorks技术雷达（2013年5月）</a></h3>
<h3 id="-1-5-http-www-infoq-com-cn-articles-iqiyi-cloud-push-practices-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/iqiyi-cloud-push-practices?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">让1.5亿移动端用户第一时间获取消息</a></h3>
<h3 id="-thoughtworks-ceo-http-www-infoq-com-cn-news-2013-06-tw-guoxiao-on-talents-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/tw-guoxiao-on-talents?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">ThoughtWorks全球CEO郭晓谈软件人才的招聘与培养</a></h3>
<h3 id="-http-www-infoq-com-cn-news-2013-06-10-sins-for-scalability-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/10-sins-for-scalability?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">影响可扩展性的十宗罪</a></h3>
<h3 id="-6-http-www-infoq-com-cn-minibooks-architect-jun-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jun-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（6月刊）</a></h3>
<h3 id="-http-www-infoq-com-cn-articles-function-switch-realize-better-continuous-implementations-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/function-switch-realize-better-continuous-implementations?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">使用功能开关更好地实现持续部署</a></h3>
<h3 id="-eclipse-github-http-www-infoq-com-cn-news-2013-06-eclipse-github-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/eclipse-github?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Eclipse迁移到GitHub</a></h3>
<h3 id="-newegg-com-http-www-infoq-com-cn-presentations-newegg-big-data-practice-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/presentations/newegg-big-data-practice?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Newegg.com大数据实践</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-software-sys-architect-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/software-sys-architect?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">软件系统架构：使用视点和视角与利益相关者合作</a></h3>
<h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
<h3 id="-6-http-www-infoq-com-cn-minibooks-architect-jun-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jun-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（6月刊）</a></h3>
<h3 id="-rest-http-www-infoq-com-cn-news-2013-06-rest-drawbacks-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/rest-drawbacks?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">REST的缺点是什么？</a></h3>
<h3 id="-google-web-ui-polymer-http-www-infoq-com-cn-news-2013-06-webcomponents-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/webcomponents?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">Google 发布新一代Web UI库Polymer</a></h3>
<h3 id="-http-www-infoq-com-cn-news-2013-06-dianping-xinnet-hacked-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/dianping-xinnet-hacked?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">大众点评网域名劫持事件概述</a></h3>
<h3 id="-node-js-grunt-js-http-www-infoq-com-cn-articles-gruntjs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/GruntJs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">基于Node.js的自动化构建工具Grunt.js</a></h3>
<h3 id="-node-js-node-js-http-www-infoq-com-cn-articles-what-is-nodejs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/what-is-nodejs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（一）：什么是Node.js</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-i-m-wrights-hard-code-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/i-m-wrights-hard-code?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">代码之殇·第二版</a></h3>
<h3 id="-http-www-infoq-com-cn-minibooks-software-sys-architect-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/software-sys-architect?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">软件系统架构：使用视点和视角与利益相关者合作</a></h3>
<h3 id="-18-java-http-www-infoq-com-cn-news-2013-06-zhuhong-on-java-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/06/zhuhong-on-java?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">大家谈18岁的Java——朱鸿：开过跑车后再去开大巴车总是有点不爽的</a></h3>
<h3 id="-32-http-www-infoq-com-cn-news-2012-08-32-most-important-algorithms-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2012/08/32-most-important-algorithms?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">计算机科学中最重要的32个算法</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-memory-model-1-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/java-memory-model-1?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入理解Java内存模型（一）——基础</a></h3>
<h3 id="-node-js-node-js-http-www-infoq-com-cn-articles-what-is-nodejs-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/what-is-nodejs?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（一）：什么是Node.js</a></h3>
<h3 id="-node-js-node-js-npm-http-www-infoq-com-cn-articles-nodejs-npm-install-config-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/nodejs-npm-install-config?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">深入浅出Node.js（二）：Node.js&amp;NPM的安装与配置</a></h3>
<h3 id="-3-http-www-infoq-com-cn-minibooks-architect-mar-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-mar-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（3月刊）</a></h3>
<h3 id="-1-http-www-infoq-com-cn-minibooks-architect-jan-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-jan-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（1月刊）</a></h3>
<h3 id="-4-http-www-infoq-com-cn-minibooks-architect-apr-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-apr-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（4月刊）</a></h3>
<h3 id="-java-http-www-infoq-com-cn-articles-java-threadpool-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/articles/java-threadPool?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">聊聊并发（三）——JAVA线程池的分析和使用</a></h3>
<h3 id="-2-http-www-infoq-com-cn-minibooks-architect-feb-10-2013-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/minibooks/architect-feb-10-2013?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">架构师（2月刊）</a></h3>
<h3 id="-12306-github-http-www-infoq-com-cn-news-2013-01-12306-plugin-ddos-github-utm_source-infoq-utm_medium-popular_links_homepage-"><a href="http://www.infoq.com/cn/news/2013/01/12306-plugin-ddos-github?utm_source=infoq&amp;utm_medium=popular_links_homepage" target="_blank">12306订票助手插件拖垮GitHub事件原因始末</a></h3>
<h2 id="-">深度内容</h2>
<ul>
<li><a href="">全部</a></li>
<li><a href="">文章</a></li>
<li><a href="">演讲</a></li>
<li><a href="">访谈</a></li>
<li><a href="">迷你书</a></li>
</ul>
<h2 id="-juergen-fesslmeier-javascript-http-www-infoq-com-cn-interviews-end-to-end-javascript-juergen-fesslmeier-javascript-"><a href="http://www.infoq.com/cn/interviews/end-to-end-javascript" title="Juergen Fesslmeier谈端到端的JavaScript开发" target="_blank">Juergen Fesslmeier谈端到端的JavaScript开发</a></h2>
<p><a href="http://www.infoq.com/cn/author/Juergen-Fesslmeier" title="Juergen Fesslmeier" target="_blank">Juergen Fesslmeier</a> 七月 02, 2013</p>
<p><a href="http://www.infoq.com/cn/interviews/end-to-end-javascript" title="Juergen Fesslmeier谈端到端的JavaScript开发" target="_blank"><img src="" alt=""></a></p>
<h2 id="-http-www-infoq-com-cn-articles-design-pattern-automation-"><a href="http://www.infoq.com/cn/articles/Design-Pattern-Automation" title="设计模式自动化" target="_blank">设计模式自动化</a></h2>
<p><a href="http://www.infoq.com/cn/author/Gael-Fraiteur-and-Yan-Cui" title="Gael Fraiteur and Yan Cui" target="_blank">Gael Fraiteur and Yan Cui</a> 七月 01, 2013</p>
<p><a href="http://www.infoq.com/cn/articles/Design-Pattern-Automation" title="设计模式自动化" target="_blank"><img src="" alt=""></a></p>
<h2 id="-http-www-infoq-com-cn-articles-designing-a-world-at-your-fingertips-mobile-user-interfaces-"><a href="http://www.infoq.com/cn/articles/designing-a-world-at-your-fingertips-mobile-user-interfaces" title="设计指尖上的世界：移动用户界面一瞥" target="_blank">设计指尖上的世界：移动用户界面一瞥</a></h2>
<p><a href="http://www.infoq.com/cn/author/Forrest-Shull" title="Forrest Shull" target="_blank">Forrest Shull</a> 六月 28, 2013</p>
<p><a href="http://www.infoq.com/cn/articles/designing-a-world-at-your-fingertips-mobile-user-interfaces" title="设计指尖上的世界：移动用户界面一瞥" target="_blank"><img src="" alt=""></a></p>
<h2 id="-alm-http-www-infoq-com-cn-articles-integrated-alm-alm-"><a href="http://www.infoq.com/cn/articles/Integrated-ALM" title="成功的根本—集成的ALM工具" target="_blank">成功的根本—集成的ALM工具</a></h2>
<p><a href="http://www.infoq.com/cn/author/Dave-West" title="Dave West" target="_blank">Dave West</a> 六月 28, 2013</p>
<p><a href="http://www.infoq.com/cn/articles/Integrated-ALM" title="成功的根本—集成的ALM工具" target="_blank"><img src="" alt=""></a></p>
<h2 id="-http-www-infoq-com-cn-articles-atdd-by-example-book-"><a href="http://www.infoq.com/cn/articles/atdd-by-example-book" title="书评：验收测试驱动开发实践指南" target="_blank">书评：验收测试驱动开发实践指南</a></h2>
<p><a href="http://www.infoq.com/cn/author/Manuel-Pais" title="Manuel Pais" target="_blank">Manuel Pais</a> 六月 26, 2013</p>
<p><a href="http://www.infoq.com/cn/articles/atdd-by-example-book" title="书评：验收测试驱动开发实践指南" target="_blank"><img src="" alt=""></a></p>
<h2 id="-web-http-www-infoq-com-cn-presentations-across-device-web-web-"><a href="http://www.infoq.com/cn/presentations/across-device-web" title="跨终端的web" target="_blank">跨终端的web</a></h2>
<p><a href="http://www.infoq.com/cn/author/%E8%88%92%E6%96%87%E4%BA%AE" title="舒文亮" target="_blank">舒文亮</a> 六月 26, 2013</p>
<p><a href="http://www.infoq.com/cn/presentations/across-device-web" title="跨终端的web" target="_blank"><img src="" alt=""></a></p>
<ul>
<li><a href="">更早的 &gt;</a></li>
</ul>
<p><a href="">Close</a> E-mail  密码</p>
<p><a href="http://www.infoq.com/cn/social/googleLogin.action?fl=login" title="使用Google账号登录" target="_blank">使用Google账号登录</a> <a href="http://www.infoq.com/cn/social/liveLogin.action?fl=login" title="使用Microsoft账号登录" target="_blank">使用Microsoft账号登录</a>
<a href="">忘记密码？</a>
 InfoQ账号使用的E-mail 发送邮件</p>
<p><a href="">重新登录</a>
重新发送激活信息 重新发送</p>
<p><a href="">重新登录</a>
<a href="http://www.infoq.com/cn/reginit.action" target="_blank">没有用户名？</a></p>
<p><a href="http://www.infoq.com/cn/reginit.action" target="_blank">点击注册</a>
<img src="&quot;定义(粉红" alt="">&quot;)<img src="&quot;假设(蓝色" alt="">&quot;)<img src="&quot;分析(黄色" alt="">&quot;)<img src="&quot;结论(橘红" alt="">&quot;)<img src="&quot;优势(绿色" alt="">&quot;)<img src="&quot;缺陷(紫色" alt="">&quot;)<img src="&quot;注意(红色" alt="">&quot;)<img src="&quot;清除背景色&quot;" alt=""><img src="&quot;书签&quot;" alt=""><img src="&quot;设为目录项&quot;" alt=""><img src="&quot;在Google中搜索&quot;" alt=""><img src="&quot;查找解释&quot;" alt=""><img src="&quot;标注&quot;" alt=""><img src="&quot;链接到所选文件夹/标签/样式/文件&quot;" alt=""><img src="&quot;Wiz助手&quot;" alt=""><img src="&quot;稍后阅读(tag" alt="">&quot;)</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程--探索java多线程（连载）1守护线程-ikon-BlogJava/">探索java多线程（连载）1 守护线程 </a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程--探索java多线程（连载）1守护线程-ikon-BlogJava/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-1-ikon-blogjava">探索java多线程（连载）1 守护线程 - ikon - BlogJava</h1>
<h1 id="-ikon-http-www-blogjava-net-ikon-"><a href="http://www.blogjava.net/ikon/" target="_blank">ikon</a></h1>
<p>posts - 1, comments - 0, trackbacks - 0, articles - 1   <a href="http://www.blogjava.net/" target="_blank">BlogJava</a> :: <a href="http://www.blogjava.net/ikon/" target="_blank">首页</a> :: <a href="http://www.blogjava.net/ikon/admin/EditPosts.aspx?opt=1" target="_blank">新随笔</a> :: <a href="http://www.blogjava.net/ikon/contact.aspx?id=1" target="_blank">联系</a> :: <a href="http://www.blogjava.net/ikon/rss" target="_blank">聚合</a> <a href="http://www.blogjava.net/ikon/rss" target="_blank"><img src="" alt=""></a> :: <a href="http://www.blogjava.net/ikon/admin/EditPosts.aspx" target="_blank">管理</a> <img src="" alt=""></p>
<h3 id="-">日历</h3>
<p><a href="&quot;Go to the previous month&quot;">&lt;</a>2011年3月<a href="&quot;Go to the next month&quot;">&gt;</a>日一二三四五六2728123456789101112131415161718192021<a href="http://www.blogjava.net/ikon/archive/2011/03/22.html" target="_blank">22</a>232425262728293031123456789</p>
<p><img src="" alt=""></p>
<h3 id="-">常用链接</h3>
<ul>
<li><a href="http://www.blogjava.net/ikon/MyPosts.html" target="_blank">我的随笔</a></li>
<li><a href="http://www.blogjava.net/ikon/MyComments.html" target="_blank">我的评论</a></li>
<li><a href="http://www.blogjava.net/ikon/OtherPosts.html" target="_blank">我的参与</a>
<img src="" alt=""></li>
</ul>
<h3 id="-">留言簿</h3>
<ul>
<li><a href="http://www.blogjava.net/ikon/Contact.aspx?id=1" target="_blank">给我留言</a></li>
<li><a href="http://www.blogjava.net/ikon/default.aspx?opt=msg" target="_blank">查看公开留言</a></li>
<li><a href="http://www.blogjava.net/ikon/admin/MyMessages.aspx" target="_blank">查看私人留言</a></li>
</ul>
<p><img src="" alt=""></p>
<h3 id="-">随笔档案</h3>
<ul>
<li><a href="http://www.blogjava.net/ikon/archive/2011/03.html" target="_blank">2011年3月 (1)</a>
<img src="" alt=""></li>
</ul>
<h3 id="-">搜索</h3>
<ul>
<li></li>
</ul>
<p><img src="" alt=""></p>
<h3 id="-http-www-blogjava-net-ikon-commentsrss-aspx-java-1-">最新评论 <a href="http://www.blogjava.net/ikon/CommentsRSS.aspx" target="_blank"><img src="" alt=""></a> ## <a href="">探索java多线程（连载）1 守护线程</a></h3>
<p>Posted on 2011-03-22 19:25 <a href="http://www.blogjava.net/ikon/" target="_blank">ikon</a> 阅读(1692) <a href="http://www.blogjava.net/ikon/archive/2011/03/22/346738.html#Post" target="_blank">评论(0)</a>  <a href="http://www.blogjava.net/ikon/admin/EditPosts.aspx?postid=346738" target="_blank">编辑</a>  <a href="http://www.blogjava.net/ikon/AddToFavorite.aspx?id=346738" target="_blank">收藏</a> <img src="" alt=""></p>
<pre><code>  在java中有一类线程，专门在后台提供服务，此类线程无需显式关闭，当程序结束了，它也就结束了，这就是守护线程 daemon thread。如果还有非守护线程的线程在执行，它就不会结束。      守护线程有何用处呢？让我们来看个实践中的例子。

  在我们的系统中经常应用各种配置文件（黑名单，禁用词汇），当修改配置文件后，一般要重启服务，系统才能够加载；当重启服务的代价比较高的情况下，这种加载方式不能满足我们的要求，这个时候守护线程该发挥它的作用了，它可以实时加载你的配置文件，无需重启。（当然，相当重要的配置文件，不推荐实时加载）
</code></pre><p><img src="" alt="">package com.ikon.thread.daemon;
<img src="" alt="">
<img src="" alt="">import java.io.File;
<img src="" alt="">import java.util./<em>;
<img src="" alt="">
<img src="" alt=""><img src="" alt="">//</em>/<em> /</em>///<em>/</em>
<img src="" alt=""> /<em> 文件监测
<img src="" alt=""> /</em> @author ikon99999
<img src="" alt=""> /<em> 
<img src="" alt=""> /</em>/
<img src="" alt=""><img src="" alt="">public abstract class FileWatchdog extends Thread <img src="" alt="">{
<img src="" alt="">
<img src="" alt=""> 
<img src="" alt="">  static final public long DEFAULT_DELAY = 20/*1000; 
<img src="" alt=""> 
<img src="" alt=""><br><img src="" alt="">  protected HashMap fileList;
<img src="" alt=""> 
<img src="" alt="">  protected long delay = DEFAULT_DELAY; 
<img src="" alt=""><br><img src="" alt="">  boolean warnedAlready = false;
<img src="" alt=""><br><img src="" alt="">  boolean interrupted = false;
<img src="" alt="">
<img src="" alt="">  public static class Entity
<img src="" alt=""><img src="" alt="">  <img src="" alt="">{
<img src="" alt="">        File file;
<img src="" alt="">        long lastModify;
<img src="" alt="">        Entity(File file,long lastModify)
<img src="" alt=""><img src="" alt="">        <img src="" alt="">{
<img src="" alt="">            this.file = file;
<img src="" alt="">            this.lastModify = lastModify;
<img src="" alt="">        }
<img src="" alt="">  }
<img src="" alt=""><br><img src="" alt=""><img src="" alt="">  protected  FileWatchdog() <img src="" alt="">{
<img src="" alt="">      fileList = new HashMap ();
<img src="" alt="">    setDaemon(true);
<img src="" alt="">  }
<img src="" alt="">
<img src="" alt=""> 
<img src="" alt=""><img src="" alt="">  public  void setDelay(long delay) <img src="" alt="">{
<img src="" alt="">    this.delay = delay;
<img src="" alt="">  }
<img src="" alt="">
<img src="" alt="">  public void addFile(File file)
<img src="" alt=""><img src="" alt="">  <img src="" alt="">{
<img src="" alt="">        fileList.put(file.getAbsolutePath(),new Entity(file,file.lastModified()));<br><img src="" alt="">  }
<img src="" alt=""><br><img src="" alt="">  public boolean contains(File file)
<img src="" alt=""><img src="" alt="">  <img src="" alt="">{
<img src="" alt="">        if( fileList.get(file.getAbsolutePath()) != null) return true;
<img src="" alt="">        else return false;
<img src="" alt="">  }
<img src="" alt=""><br><img src="" alt="">  abstract   protected   void doOnChange(File file);
<img src="" alt="">
<img src="" alt=""><img src="" alt="">  protected  void checkAndConfigure() <img src="" alt="">{
<img src="" alt="">      HashMap map = (HashMap)fileList.clone(); 
<img src="" alt="">      Iterator it = map.values().iterator();
<img src="" alt=""><br><img src="" alt="">      while( it.hasNext())
<img src="" alt=""><img src="" alt="">      <img src="" alt="">{
<img src="" alt=""><br><img src="" alt="">            Entity entity = (Entity)it.next();
<img src="" alt=""><br><img src="" alt="">            boolean fileExists;
<img src="" alt=""><img src="" alt="">            try <img src="" alt="">{
<img src="" alt="">              fileExists = entity.file.exists();
<img src="" alt="">            } catch(SecurityException  e) 
<img src="" alt=""><img src="" alt="">            <img src="" alt="">{
<img src="" alt="">              System.err.println (&quot;Was not allowed to read check file existance, file:[&quot;+ entity.file .getAbsolutePath() +&quot;].&quot;);
<img src="" alt="">              interrupted = true; 
<img src="" alt="">              return;
<img src="" alt="">            }
<img src="" alt="">
<img src="" alt="">            if(fileExists) 
<img src="" alt=""><img src="" alt="">            <img src="" alt="">{
<img src="" alt=""><br><img src="" alt="">              long l = entity.file.lastModified(); // this can also throw a SecurityException
<img src="" alt=""><img src="" alt="">              if(l &gt; entity.lastModify) <img src="" alt="">{           // however, if we reached this point this
<img src="" alt="">                    entity.lastModify = l;              // is very unlikely.
<img src="" alt="">                    newThread(entity.file);
<img src="" alt="">              }
<img src="" alt="">            }
<img src="" alt="">            else 
<img src="" alt=""><img src="" alt="">            <img src="" alt="">{
<img src="" alt="">                System.err.println (&quot;[&quot;+entity.file .getAbsolutePath()+&quot;] does not exist.&quot;);
<img src="" alt="">            }
<img src="" alt="">      }
<img src="" alt="">  }
<img src="" alt=""><br><img src="" alt="">  private void newThread(File file)
<img src="" alt=""><img src="" alt="">  <img src="" alt="">{
<img src="" alt="">      class MyThread extends Thread
<img src="" alt=""><img src="" alt="">      <img src="" alt="">{
<img src="" alt="">            File f;
<img src="" alt="">            public MyThread(File f)
<img src="" alt=""><img src="" alt="">            <img src="" alt="">{
<img src="" alt="">                this.f = f;
<img src="" alt="">            }
<img src="" alt=""><br><img src="" alt="">            public void run()
<img src="" alt=""><img src="" alt="">            <img src="" alt="">{
<img src="" alt="">                doOnChange(f);
<img src="" alt="">            }
<img src="" alt="">      }
<img src="" alt=""><br><img src="" alt="">      MyThread mt = new MyThread(file);
<img src="" alt="">      mt.start();
<img src="" alt="">  }
<img src="" alt="">
<img src="" alt="">  public  void run() 
<img src="" alt=""><img src="" alt="">  <img src="" alt="">{<br><img src="" alt=""><img src="" alt="">    while(!interrupted) <img src="" alt="">{
<img src="" alt=""><img src="" alt="">      try <img src="" alt="">{
<img src="" alt="">        Thread.currentThread().sleep(delay);
<img src="" alt=""><img src="" alt="">      } catch(InterruptedException e) <img src="" alt="">{
<img src="" alt="">    // no interruption expected
<img src="" alt="">      }
<img src="" alt="">      checkAndConfigure();
<img src="" alt="">    }
<img src="" alt="">  }
<img src="" alt="">}
<img src="" alt=""></p>
<pre><code>FileWatchdog是个抽象类，本身是线程的子类；在构造函数中设置为守护线程；
此类用hashmap维护着一个文件和最新修改时间值对，checkAndConfigure()方法用来检测哪些文件的修改时间更新了，如果发现文件更新了则调用doOnChange方法来完成监测逻辑；doOnChange方法是我们需要实现的；看下面关于一个黑名单服务的监测服务：
</code></pre><p> 1<img src="" alt="">package com.ikon.thread.daemon;
 2<img src="" alt="">
 3<img src="" alt="">import java.io.File;
 4<img src="" alt="">
 5<img src="" alt=""><img src="" alt="">//<em>/</em> /<em>///</em>/<em>
 6<img src="" alt=""> /</em> 黑名单服务
 7<img src="" alt=""> /<em> @author ikon99999
 8<img src="" alt=""> /</em> 2011-3-21
 9<img src="" alt=""> /<em>/
10<img src="" alt=""><img src="" alt="">public class BlacklistService <img src="" alt="">{
11<img src="" alt="">    private File configFile = new File(&quot;c:/blacklist.txt&quot;);
12<img src="" alt=""><br>13<img src="" alt=""><img src="" alt="">    public void init() throws Exception<img src="" alt="">{
14<img src="" alt="">        loadConfig();
15<img src="" alt="">        ConfigWatchDog dog = new ConfigWatchDog();
16<img src="" alt="">        dog.setName(&quot;daemon_demo_config_watchdog&quot;);//a
17<img src="" alt="">        dog.addFile(configFile);//b
18<img src="" alt="">        dog.start();//c
19<img src="" alt="">    }
20<img src="" alt=""><br>21<img src="" alt=""><img src="" alt="">    public void loadConfig()<img src="" alt="">{
22<img src="" alt=""><img src="" alt="">        try<img src="" alt="">{
23<img src="" alt="">            Thread.sleep(1/</em>1000);//d
24<img src="" alt=""><br>25<img src="" alt="">            System.out.println(&quot;加载黑名单&quot;);
26<img src="" alt=""><img src="" alt="">        }catch(InterruptedException ex)<img src="" alt="">{
27<img src="" alt="">            System.out.println(&quot;加载配置文件失败！&quot;);
28<img src="" alt="">        }
29<img src="" alt="">    }
30<img src="" alt=""><br>31<img src="" alt=""><img src="" alt="">    public File getConfigFile() <img src="" alt="">{
32<img src="" alt="">        return configFile;
33<img src="" alt="">    }
34<img src="" alt="">
35<img src="" alt=""><img src="" alt="">    public void setConfigFile(File configFile) <img src="" alt="">{
36<img src="" alt="">        this.configFile = configFile;
37<img src="" alt="">    }
38<img src="" alt="">
39<img src="" alt="">
40<img src="" alt=""><img src="" alt="">    private class ConfigWatchDog extends FileWatchdog<img src="" alt="">{
41<img src="" alt=""><br>42<img src="" alt="">        @Override
43<img src="" alt=""><img src="" alt="">        protected void doOnChange(File file) <img src="" alt="">{
44<img src="" alt="">            System.out.println(&quot;文件&quot;+file.getName()+&quot;发生改变，重新加载&quot;);
45<img src="" alt="">            loadConfig();
46<img src="" alt="">        }
47<img src="" alt=""><br>48<img src="" alt="">    }
49<img src="" alt=""><br>50<img src="" alt=""><img src="" alt="">    public static void main(String[] args) throws Exception <img src="" alt="">{
51<img src="" alt="">        BlacklistService service = new BlacklistService();
52<img src="" alt="">        service.init();
53<img src="" alt=""><br>54<img src="" alt="">        Thread.sleep(60/<em>60/</em>1000);//e
55<img src="" alt="">    }
56<img src="" alt="">}
57<img src="" alt="">
        ConfigWatchDog内部类实现了doOnChange(File file)方法，当文件被修改后，watchdog调用doOnChange方法完成重新加载操作；
        在blackservice的init方法中初始化watchdog线程；
        d：模拟文件加载耗时
        e：主要是防止主线程退出；
        其实上面的FileWatchdog就是取自log4j；</p>
<p><a href="http://www.blogjava.net/RequireRegister.aspx" target="_blank">新用户注册</a>  <a href="">刷新评论列表</a>  </p>
<p><a href=""></a> <a href="http://job.cnblogs.com/">找优秀程序员，就在博客园</a>
<a href="http://job.cnblogs.com/offer/12368/" target="_blank">网易有道诚聘CRM研发工程师</a>
<a href="http://job.cnblogs.com/offer/11576/" target="_blank">锦江国际诚聘Java高级软件工程师</a>
<a href="http://job.cnblogs.com/offer/12493/" target="_blank">福州几维网络诚聘Java服务端程序员</a>
IT新闻：
· <a href="http://news.cnblogs.com/n/101664/" target="_blank">开放，开放，开放 —— 垄断</a>
· <a href="http://news.cnblogs.com/n/101663/" target="_blank">GNOME讨论放弃支持非Linux操作系统</a>
· <a href="http://news.cnblogs.com/n/101662/" target="_blank">Chrome 13将隐藏地址栏</a>
· <a href="http://news.cnblogs.com/n/101661/" target="_blank">联想：USB 3.0将在2012年成为主流</a>
· <a href="http://news.cnblogs.com/n/101659/" target="_blank">意法半导体 CEO ：诺基亚 Windows Phone 将采用 U8500 双核芯片</a>   <a href="http://www.cnblogs.com/" target="_blank">博客园</a>  <a href="http://home.cnblogs.com/q/" target="_blank">博问</a>  <a href="http://news.cnblogs.com/" target="_blank">IT新闻</a>  <a href="http://job.cnblogs.com/cate-java_programmer/" target="_blank">Java程序员招聘</a> 标题  请输入标题 姓名  请输入你的姓名 主页 请输入验证码 验证码 /*  <img src="" alt=""> 内容(请不要发表任何与政治相关的内容) 请输入评论内容 Remember Me?   <a href="http://www.blogjava.net/login.aspx?ReturnURL=http://www.blogjava.net/ikon/archive/2011/03/22/346738.html&amp;SourceURL=/ikon/archive/2011/03/22/346738.html" target="_blank">登录</a>       [使用Ctrl+Enter键可以直接提交]    推荐职位：
· <a href="http://job.cnblogs.com/offer/5914/" target="_blank">北京.NET 研发工程师 (北京捷报数据)</a>
· <a href="http://job.cnblogs.com/offer/12527/" target="_blank">(北京).NET软件开发工程师(北京龙达)</a>
· <a href="http://job.cnblogs.com/offer/11584/" target="_blank">厦门高级.NET软件工程师(服务于美国Amazon)</a>
· <a href="http://job.cnblogs.com/offer/10723/" target="_blank">高级Web页面前端开发工程师(新蛋中国)</a>
· <a href="http://job.cnblogs.com/offer/12493/" target="_blank">厦门Java服务端程序员(福州几维网络)</a>
· <a href="http://job.cnblogs.com/offer/9051/" target="_blank">.NET 高级软件开发工程师 (新蛋中国)</a>
· <a href="http://job.cnblogs.com/offer/12439/" target="_blank">北京ASP.NET 工程师（月薪12k）(北京盛安德)</a>
· <a href="http://job.cnblogs.com/offer/12492/" target="_blank">厦门C/#游戏客户端程序员 (福州几维网络)</a></p>
<p>博客园首页随笔：
· <a href="http://www.cnblogs.com/kqingchao/archive/2011/05/20/character-encoding-2.html" target="_blank">字符编码浅谈（二）</a>
· <a href="http://www.cnblogs.com/xuesong/archive/2011/05/20/2051892.html" target="_blank">Windows Phone 7编程实践—必应地图导航</a>
· <a href="http://www.cnblogs.com/ini_always/archive/2011/05/20/2050517.html" target="_blank">绕死你不偿命的UNICODE、_UNICODE、<strong>TEXT、</strong>T、_T、_TEXT、TEXT宏</a>
· <a href="http://www.cnblogs.com/leslies2/archive/2011/05/20/2051844.html" target="_blank">学习笔记：JAVA RMI远程方法调用简单实例</a>
· <a href="http://www.cnblogs.com/bobomouse/archive/2011/05/20/2051846.html" target="_blank">关于CellSet转DataTable的改进方案</a>
知识库：
· <a href="http://kb.cnblogs.com/page/101423/" target="_blank">程序员的本质</a>
· <a href="http://kb.cnblogs.com/page/101345/" target="_blank">Scrum之成败——从自身案例说起</a>
· <a href="http://kb.cnblogs.com/page/101321/" target="_blank">清除代码异味</a>
· <a href="http://kb.cnblogs.com/page/101198/" target="_blank">详解.NET程序集的加载规则</a>
· <a href="http://kb.cnblogs.com/page/101162/" target="_blank">如何通过ildasm/ilasm修改assembly的IL代码</a> 最简洁阅读版式：
<a href="http://archive.cnblogs.com/b/346738/" target="_blank">探索java多线程（连载）1 守护线程</a> 网站导航:</p>
<p><a href="http://www.cnblogs.com/" title="程序员的网上家园" target="_blank">博客园</a>   <a href="http://news.cnblogs.com/" target="_blank">IT新闻</a>   <a href="http://kb.cnblogs.com/" target="_blank">知识库</a>   <a href="http://www.cnweblog.com/" target="_blank">博客生活</a>   <a href="http://www.cnitblog.com/" target="_blank">IT博客网</a>   <a href="http://www.cppblog.com/" target="_blank">C++博客</a>   <a href="http://space.cnblogs.com/q/" title="IT问答" target="_blank">博问</a>   <a href="http://www.blogjava.net/ikon/archive/2011/03/22/346738.html?opt=admin" target="_blank">管理</a>    Powered by:
<a href="http://www.blogjava.net/" target="_blank">BlogJava</a>
Copyright © ikon</p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程--探索java多线程（连载）1守护线程-ikon-BlogJava/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程--探索java多线程（连载）1守护线程-ikon-BlogJava" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency4-并发容器/">深入浅出 Java Concurrency (4)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency4-并发容器/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-4-">深入浅出 Java Concurrency (4): 并发容器</h1>
<p>从这一节开始正式进入并发容器的部分，来看看JDK 6带来了哪些并发容器。</p>
<p>在JDK 1.4以下只有Vector和Hashtable是线程安全的集合（也称并发容器，Collections.synchronized/*系列也可以看作是线程安全的实现）。从JDK 5开始增加了线程安全的Map接口ConcurrentMap和线程安全的队列BlockingQueue（尽管Queue也是同时期引入的新的集合，但是规范并没有规定一定是线程安全的，事实上一些实现也不是线程安全的，比如PriorityQueue、ArrayDeque、LinkedList等，在Queue章节中会具体讨论这些队列的结构图和实现）。</p>
<p>在介绍ConcurrencyMap之前先来回顾下Map的体系结构。下图描述了Map的体系结构，其中蓝色字体的是JDK 5以后新增的并发容器。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency16part1ConcurrentMap1_10A52/image_2.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>针对上图有以下几点说明：</p>
<ol>
<li>Hashtable是JDK 5之前Map唯一线程安全的内置实现（Collections.synchronizedMap不算）。特别说明的是Hashtable的t是小写的（不知道为啥），Hashtable继承的是Dictionary（Hashtable是其唯一公开的子类），并<strong>不继承AbstractMap或者HashMap</strong>。尽管Hashtable和HashMap的结构非常类似，但是他们之间并没有多大联系。</li>
<li>ConcurrentHashMap是HashMap的线程安全版本，ConcurrentSkipListMap是TreeMap的线程安全版本。</li>
<li>最终可用的线程安全版本Map实现是ConcurrentHashMap/ConcurrentSkipListMap/Hashtable/Properties四个，但是Hashtable是过时的类库，因此如果可以的应该尽可能的使用ConcurrentHashMap和ConcurrentSkipListMap。</li>
</ol>
<p>回到正题来，这个小节主要介绍ConcurrentHashMap的API以及应用，下一节才开始将原理和分析。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency16part1ConcurrentMap1_10A52/image_4.png" target="_blank"><img src="&quot;ConcurrentMap API&quot;" alt="ConcurrentMap API"></a></p>
<p>除了实现Map接口里面对象的方法外，ConcurrentHashMap还实现了ConcurrentMap里面的四个方法。</p>
<p><strong>V putIfAbsent(K key,V value)</strong></p>
<p>如果不存在key对应的值，则将value以key加入Map，否则返回key对应的旧值。这个等价于清单1 的操作：</p>
<p><strong><em>清单1 putIfAbsent的等价操作</em></strong>
if (!map.containsKey(key)) 
   return map.put(key, value);
else
   return map.get(key);</p>
<p>在前面的章节中提到过，连续两个或多个原子操作的序列并不一定是原子操作。比如上面的操作即使在Hashtable中也不是原子操作。而putIfAbsent就是一个线程安全版本的操作的。</p>
<p>有些人喜欢用这种功能来实现<a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html" target="_blank"><strong>单例模式</strong></a>，例如清单2。</p>
<p><strong><em>清单2 一种单例模式的实现</em></strong>
package xylz.study.concurrency;</p>
<p>import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;</p>
<p>public class ConcurrentDemo1 {</p>
<pre><code>private static final ConcurrentMap&lt;String, ConcurrentDemo1&gt; map = new ConcurrentHashMap&lt;String, ConcurrentDemo1&gt;();
private static ConcurrentDemo1 instance;
public static ConcurrentDemo1 getInstance() {
    if (instance == null) {

        map.putIfAbsent(&quot;INSTANCE&quot;, new ConcurrentDemo1());

        instance = map.get(&quot;INSTANCE&quot;);
    }
    return instance;
}

private ConcurrentDemo1() {
}
</code></pre><p>}</p>
<p>当然这里只是一个操作的例子，实际上在<a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html" target="_blank"><strong>单例模式</strong></a>文章中有很多的实现和比较。清单2 在存在大量单例的情况下可能有用，实际情况下很少用于单例模式。但是这个方法避免了向Map中的同一个Key提交多个结果的可能，有时候在去掉重复记录上很有用（如果记录的格式比较固定的话）。</p>
<p><strong>boolean remove(Object key,Object value)</strong></p>
<p>只有目前将键的条目映射到给定值时，才移除该键的条目。这等价于清单3 的操作。</p>
<p><strong><em>清单3 remove(Object,Object)的等价操作</em></strong>
if (map.containsKey(key) &amp;&amp; map.get(key).equals(value)) {
   map.remove(key);
   return true;
}
return false;</p>
<p>由于集合类通常比较的hashCode和equals方法，而这两个方法是在Object对象里面，因此两个对象如果hashCode一致，并且覆盖了equals方法后也一致，那么这两个对象在集合类里面就是“相同”的，不管是否是同一个对象或者同一类型的对象。也就是说只要key1.hashCode()==key2.hashCode() &amp;&amp; key1.equals(key2)，那么key1和key2在集合类里面就认为是一致，哪怕他们的Class类型不一致也没关系，所以在很多集合类里面允许通过Object来类型来比较（或者定位）。比如说Map尽管添加的时候只能通过制定的类型<K,V>，但是删除的时候却允许通过一个Object来操作，而不必是K类型。</p>
<p>既然Map里面有一个remove(Object)方法，为什么ConcurrentMap还需要remove(Object,Object)方法呢？这是因为尽管Map里面的key没有变化，但是value可能已经被其他线程修改了，如果修改后的值是我们期望的，那么我们就不能拿一个key来删除此值，尽管我们的期望值是删除此key对于的旧值。</p>
<p>这种特性在原子操作章节的<a href="http://www.blogjava.net/xylz/archive/2010/07/02/325079.html" target="_blank">AtomicMarkableReference</a>和<a href="http://www.blogjava.net/xylz/archive/2010/07/02/325079.html" target="_blank">AtomicStampedReference</a>里面介绍过。</p>
<p><strong>boolean replace(K key,V oldValue,V newValue)</strong></p>
<p>只有目前将键的条目映射到给定值时，才替换该键的条目。这等价于清单4 的操作。</p>
<p><strong><em>清单4 replace(K,V,V)的等价操作</em></strong>
if (map.containsKey(key) &amp;&amp; map.get(key).equals(oldValue)) {
   map.put(key, newValue);
   return true;
}
return false;</p>
<p><strong>V replace(K key,V value)</strong></p>
<p>只有当前键存在的时候更新此键对于的值。这等价于清单5 的操作。</p>
<p><strong><em>清单5 replace(K,V)的等价操作</em></strong>
if (map.containsKey(key)) {
   return map.put(key, value);
}
return null;</p>
<p>replace(K,V,V)相比replace(K,V)而言，就是增加了匹配oldValue的操作。</p>
<p>其实这4个扩展方法，是ConcurrentMap附送的四个操作，其实我们更关心的是Map本身的操作。当然如果没有这4个方法，要完成类似的功能我们可能需要额外的锁，所以有总比没有要好。比如清单6，如果没有putIfAbsent内置的方法，我们如果要完成此操作就需要完全锁住整个Map，这样就大大降低了ConcurrentMap的并发性。这在下一节中有详细的分析和讨论。</p>
<p><strong><em>清单6 putIfAbsent的外部实现</em></strong>
public V putIfAbsent(K key, V value) {
    synchronized (map) {
        if (!map.containsKey(key)) return map.put(key, value);
        return map.get(key);
    }
}</p>
<p>参考资料：</p>
<ul>
<li><a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html" target="_blank">单例模式完全解析</a></li>
<li><a href="http://www.blogjava.net/xylz/archive/2010/07/02/325079.html" target="_blank">原子操作 part 2 数组、引用的原子操作</a></li>
</ul>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/19/326527.html](http://www.blogjava.net/xylz/archive/2010/07/19/326527.html)">[http://www.blogjava.net/xylz/archive/2010/07/19/326527.html](http://www.blogjava.net/xylz/archive/2010/07/19/326527.html)</a></p>
<p>本来想比较全面和深入的谈谈ConcurrentHashMap的，发现网上有很多对HashMap和ConcurrentHashMap分析的文章，因此本小节尽可能的分析其中的细节，少一点理论的东西，多谈谈内部设计的原理和思想。</p>
<p>要谈ConcurrentHashMap的构造，就不得不谈HashMap的构造，因此先从HashMap开始简单介绍。</p>
<hr>
<p><strong>HashMap原理</strong></p>
<p>我们从头开始设想。要将对象存放在一起，如何设计这个容器。目前只有两条路可以走，一种是采用分格技术，每一个对象存放于一个格子中，这样通过对格子的编号就能取到或者遍历对象；另一种技术就是采用串联的方式，将各个对象串联起来，这需要各个对象至少带有下一个对象的索引（或者指针）。显然第一种就是数组的概念，第二种就是链表的概念。所有的容器的实现其实都是基于这两种方式的，不管是数组还是链表，或者二者俱有。HashMap采用的就是数组的方式。</p>
<p>有了存取对象的容器后还需要以下两个条件才能完成Map所需要的条件。</p>
<ul>
<li>能够快速定位元素：Map的需求就是能够根据一个查询条件快速得到需要的结果，所以这个过程需要的就是尽可能的快。</li>
<li>能够自动扩充容量：显然对于容器而然，不需要人工的去控制容器的容量是最好的，这样对于外部使用者来说越少知道底部细节越好，不仅使用方便，也越安全。</li>
</ul>
<p>首先条件1，快速定位元素。快速定位元素属于算法和数据结构的范畴，通常情况下哈希（Hash）算法是一种简单可行的算法。所谓<strong>哈希算法</strong>，是将任意长度的二进制值映射为固定长度的较小二进制值。常见的MD2,MD4,MD5，SHA-1等都属于Hash算法的范畴。具体的算法原理和介绍可以参考相应的算法和数据结构的书籍，但是这里特别提醒一句，由于将一个较大的集合映射到一个较小的集合上，所以必然就存在多个元素映射到同一个元素上的结果，这个叫“碰撞”，后面会用到此知识，暂且不表。</p>
<p>条件2，如果满足了条件1，一个元素映射到了某个位置，现在一旦扩充了容量，也就意味着元素映射的位置需要变化。因为对于Hash算法来说，调整了映射的小集合，那么原来映射的路径肯定就不复存在，那么就需要对现有重新计算映射路径，也就是所谓的rehash过程。</p>
<p>好了有了上面的理论知识后来看HashMap是如何实现的。</p>
<p>在HashMap中首先由一个对象数组table是不可避免的，修饰符transient只是表示序列号的时候不被存储而已。size描述的是Map中元素的大小，threshold描述的是达到指定元素个数后需要扩容，loadFactor是扩容因子(loadFactor&gt;0)，也就是计算threshold的。那么元素的容量就是table.length，也就是数组的大小。换句话说，如果存取的元素大小达到了整个容量(table.length)的loadFactor倍（也就是table.length/*loadFactor个），那么就需要扩充容量了。在HashMap中每次扩容就是将扩大数组的一倍，使数组大小为原来的两倍。</p>
<p> <a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency17part2ConcurrentMap2_FF15/image_2.png" target="_blank"><img src="&quot;HashMap数据结构&quot;" alt="HashMap数据结构"></a></p>
<p>然后接下来看如何将一个元素映射到数组table中。显然要映射的key是一个无尽的超大集合，而table是一个较小的有限集合，那么一种方式就是将key编码后的hashCode值取模映射到table上，这样看起来不错。但是在Java中采用了一种更高效的办法。由于与(&amp;)是比取模(%)更高效的操作，因此Java中采用hash值与数组大小-1后取与来确定数组索引的。为什么这样做是更有效的？<a href="http://www.javaeye.com/topic/539465" target="_blank">参考资料7</a>对这一块进行非常详细的分析，这篇文章的作者非常认真，也非常仔细的分析了里面包含的思想。</p>
<p><strong><em>清单1 indexFor片段</em></strong>
static int indexFor(int h, int length) {
    return h &amp; (length-1);
}</p>
<p>前面说明，既然是大集合映射到小集合上，那么就必然存在“碰撞”，也就是不同的key映射到了相同的元素上。那么HashMap是怎么解决这个问题的？</p>
<p>在HashMap中采用了下面方式，解决了此问题。</p>
<ol>
<li>同一个索引的数组元素组成一个链表，查找允许时循环链表找到需要的元素。</li>
<li>尽可能的将元素均匀的分布在数组上。</li>
</ol>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency17part2ConcurrentMap2_FF15/image_4.png" target="_blank"><img src="&quot;Map.Entry结构&quot;" alt="Map.Entry结构"></a>对于问题1，HashMap采用了上图的一种数据结构。table中每一个元素是一个Map.Entry，其中Entry包含了四个数据，key,value,hash,next。key和value是存储的数据；hash是元素key的Hash后的表现形式（最终要映射到数组上），这里链表上所有元素的hash经过清单1 的indexFor后将得到相同的数组索引；next是指向下一个元素的索引，同一个链表上的元素就是通过next串联起来的。</p>
<p>再来看问题2 尽可能的将元素均匀的分布在数组上这个问题是怎么解决的。首先清单2 是将key的hashCode经过一系列的变换，使之更符合小数据集合的散列模型。</p>
<p><strong><em>清单2 hashCode的二次散列</em></strong>
static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).
    h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);
    return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);
}</p>
<p>至于清单2 为什么这样散列我没有找到依据，也没有什么好的参考资料。<a href="http://www.javaeye.com/topic/709945" target="_blank">参考资料1</a> 分析了此过程，认为是一种比较有效的方式，有兴趣的可以研究下。</p>
<p>第二点就是在清单1 的描述中，尽可能的与数组的长度减1的数与操作，使之分布均匀。这在<a href="http://www.javaeye.com/topic/539465" target="_blank">参考资料7</a> 中有介绍。</p>
<p>第三点就是构造数组时数组的长度是2的倍数。清单3 反映了这个过程。为什么要是2的倍数？在<a href="http://www.javaeye.com/topic/539465" target="_blank">参考资料7</a> 中分析说是使元素尽可能的分布均匀。</p>
<p><strong><em>清单3 HashMap 构造数组</em></strong>
// Find a power of 2 &gt;= initialCapacity
int capacity = 1;
while (capacity &lt; initialCapacity)
    capacity &lt;&lt;= 1;</p>
<p>this.loadFactor = loadFactor;
threshold = (int)(capacity /* loadFactor);
table = new Entry[capacity];</p>
<p>另外loadFactor的默认值0.75和capacity的默认值16是经过大量的统计分析得出的，很久以前我见过相关的数据分析，现在找不到了，有兴趣的可以查询相关资料。这里不再叙述了。</p>
<p>有了上述原理后再来分析HashMap的各种方法就不是什么问题的。</p>
<p><strong><em>清单4 HashMap的get操作</em></strong>
public V get(Object key) {
    if (key == null)
        return getForNullKey();
    int hash = hash(key.hashCode());
    for (Entry<K,V> e = table[indexFor(hash, table.length)];
         e != null;
         e = e.next) {
        Object k;
        if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k)))
            return e.value;
    }
    return null;
}</p>
<p>清单4 描述的是HashMap的get操作，在这个操作中首先判断key是否为空，因为为空的话总是映射到table的第0个元素上（可以看上面的清单2和清单1）。然后就需要查找table的索引。一旦找到对应的Map.Entry元素后就开始遍历此链表。由于不同的hash可能映射到同一个table[index]上，而相同的key却同时映射到相同的hash上，所以一个key和Entry对应的条件就是hash(key)==e.hash 并且key.equals(e.key)。从这里我们看到，Object.hashCode()只是为了将相同的元素映射到相同的链表上（Map.Entry)，而Object.equals()才是比较两个元素是否相同的关键！这就是为什么总是成对覆盖hashCode()和equals()的原因。</p>
<p><strong><em>清单5 HashMap的put操作</em></strong>
public V put(K key, V value) {
    if (key == null)
        return putForNullKey(value);
    int hash = hash(key.hashCode());
    int i = indexFor(hash, table.length);
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        Object k;
        if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }</p>
<pre><code>modCount++;
addEntry(hash, key, value, i);
return null;
</code></pre><p>}
void addEntry(int hash, K key, V value, int bucketIndex) {
    Entry<K,V> e = table[bucketIndex];
        table[bucketIndex] = new Entry<K,V>(hash, key, value, e);
        if (size++ &gt;= threshold)
            resize(2 /* table.length);
}</p>
<p>清单5 描述的是HashMap的put操作。对比get操作，可以发现，put实际上是先查找，一旦找到key对应的Entry就直接修改Entry的value值，否则就增加一个元素。增加的元素是在链表的头部，也就是占据table中的元素，如果table中对应索引原来有元素的话就将整个链表添加到新增加的元素的后面。也就是说新增加的元素再次查找的话是优于在它之前添加的同一个链表上的元素。这里涉及到就是扩容，也就是一旦元素的个数达到了扩容因子规定的数量(threhold=table.length/*loadFactor)，就将数组扩大一倍。</p>
<p><strong><em>清单6 HashMap扩容过程</em></strong>
void resize(int newCapacity) {
    Entry[] oldTable = table;
    int oldCapacity = oldTable.length;
    if (oldCapacity == MAXIMUM_CAPACITY) {
        threshold = Integer.MAX_VALUE;
        return;
    }</p>
<pre><code>Entry[] newTable = new Entry[newCapacity];
transfer(newTable);
table = newTable;
threshold = (int)(newCapacity /* loadFactor);
</code></pre><p>}</p>
<p>void transfer(Entry[] newTable) {
    Entry[] src = table;
    int newCapacity = newTable.length;
    for (int j = 0; j &lt; src.length; j++) {
        Entry<K,V> e = src[j];
        if (e != null) {
            src[j] = null;
            do {
                Entry<K,V> next = e.next;
                int i = indexFor(e.hash, newCapacity);
                e.next = newTable[i];
                newTable[i] = e;
                e = next;
            } while (e != null);
        }
    }
}</p>
<p>清单6 描述的是HashMap扩容的过程。可以看到扩充过程会导致元素数据的所有元素进行重新hash计算，这个过程也叫rehash。显然这是一个非常耗时的过程，否则扩容都会导致所有元素重新计算hash。因此尽可能的选择合适的初始化大小是有效提高HashMap效率的关键。太大了会导致过多的浪费空间，太小了就可能会导致繁重的rehash过程。在这个过程中loadFactor也可以考虑。</p>
<p>举个例子来说，如果要存储1000个元素，采用默认扩容因子0.75，那么1024显然是不够的，因为1000&gt;0.75/*1024了，所以选择2048是必须的，显然浪费了1048个空间。如果确定最多只有1000个元素，那么扩容因子为1，那么1024是不错的选择。另外需要强调的一点是扩容因此越大，从统计学角度讲意味着链表的长度就也大，也就是在查找元素的时候就需要更多次的循环。所以凡事必然是一个平衡的过程。</p>
<p>这里可能有人要问题，一旦我将Map的容量扩大后（也就是数组的大小），这个容量还能减小么？比如说刚开始Map中可能有10000个元素，运行一旦时间以后Map的大小永远不会超过10个，那么Map的容量能减小到10个或者16个么？答案就是不能，这个capacity一旦扩大后就不能减小了，只能通过构造一个新的Map来控制capacity了。</p>
<p>HashMap的几个内部迭代器也是非常重要的，这里限于篇幅就不再展开了，有兴趣的可以自己研究下。</p>
<p>Hashtable的原理和HashMap的原理几乎一样，所以就不讨论了。另外LinkedHashMap是在Map.Entry的基础上增加了before/after两个双向索引，用来将所有Map.Entry串联起来，这样就可以遍历或者做LRU Cache等。这里也不再展开讨论了。</p>
<p><a href="http://memcached.org/" target="_blank">memcached</a> 内部数据结构就是采用了HashMap类似的思想来实现的，有兴趣的可以参考资料8,9，10。</p>
<p>为了不使这篇文章过长，因此将ConcurrentHashMap的原理放到下篇讲。需要说明的是，尽管ConcurrentHashMap与HashMap的名称有些渊源，而且实现原理有些相似，但是为了更好的支持并发，ConcurrentHashMap在内部也有一些比较大的调整，这个在下篇会具体介绍。</p>
<p>参考资料：</p>
<ol>
<li><a href="http://www.javaeye.com/topic/709945" target="_blank">HashMap hash方法分析</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-lo-hash/" target="_blank">通过分析 JDK 源代码研究 Hash 存储机制</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-jtp05273/" target="_blank">Java 理论与实践: 哈希</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-jtp08223/" target="_blank">Java 理论与实践: 构建一个更好的 HashMap</a></li>
<li><a href="http://yk94wo.blog.sohu.com/155835132.html" target="_blank">jdk1.6 ConcurrentHashMap</a></li>
<li><a href="http://www.javaeye.com/topic/344876" target="_blank">ConcurrentHashMap之实现细节</a></li>
<li><a href="http://www.javaeye.com/topic/539465" target="_blank">深入理解HashMap</a></li>
<li><a href="http://www.lampchina.net/article/htmls/201005/Mjg1MTYy.html" target="_blank">memcached-数据结构</a></li>
<li><a href="http://www.cublog.cn/u/20146/showart_1820089.html" target="_blank">memcached存储管理 数据结构</a></li>
<li><a href="http://memcached.org/" target="_blank">memcached</a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/20/326584.html](http://www.blogjava.net/xylz/archive/2010/07/20/326584.html)">[http://www.blogjava.net/xylz/archive/2010/07/20/326584.html](http://www.blogjava.net/xylz/archive/2010/07/20/326584.html)</a> </li>
</ol>
<p>在上一篇中介绍了HashMap的原理，这一节是ConcurrentMap的最后一节，所以会完整的介绍ConcurrentHashMap的实现。</p>
<p><strong>ConcurrentHashMap原理</strong></p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2010/07/14/326080.html" target="_blank">读写锁章节部分</a>介绍过一种是用读写锁实现Map的方法。此种方法看起来可以实现Map响应的功能，而且吞吐量也应该不错。但是通过前面对<a href="http://www.blogjava.net/xylz/archive/2010/07/15/326152.html" target="_blank">读写锁原理</a>的分析后知道，读写锁的适合场景是读操作&gt;&gt;写操作，也就是读操作应该占据大部分操作，另外读写锁存在一个很严重的问题是读写操作不能同时发生。要想解决读写同时进行问题（至少不同元素的读写分离），那么就只能将锁拆分，不同的元素拥有不同的锁，这种技术就是“锁分离”技术。</p>
<p>默认情况下ConcurrentHashMap是用了16个类似HashMap 的结构，其中每一个HashMap拥有一个独占锁。也就是说最终的效果就是通过某种Hash算法，将任何一个元素均匀的映射到某个HashMap的Map.Entry上面，而对某个一个元素的操作就集中在其分布的HashMap上，与其它HashMap无关。这样就支持最多16个并发的写操作。</p>
<p> <a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency18part3ConcurrentMap3_693/image_8.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>上图就是ConcurrentHashMap的类图。参考上面的说明和HashMap的原理分析，可以看到ConcurrentHashMap将整个对象列表分为segmentMask+1个片段（Segment）。其中每一个片段是一个类似于HashMap的结构，它有一个HashEntry的数组，数组的每一项又是一个链表，通过HashEntry的next引用串联起来。</p>
<p>这个类图上面的数据结构的定义非常有学问，接下来会一个个有针对性的分析。</p>
<p>首先如何从ConcurrentHashMap定位到HashEntry。在HashMap的原理分析部分说过，对于一个Hash的数据结构来说，为了减少浪费的空间和快速定位数据，那么就需要数据在Hash上的分布比较均匀。对于一次Map的查找来说，首先就需要定位到Segment，然后从过Segment定位到HashEntry链表，最后才是通过遍历链表得到需要的元素。</p>
<p>在不讨论并发的前提下先来讨论如何定位到HashEntry的。在ConcurrentHashMap中是通过hash(key.hashCode())和segmentFor(hash)来得到Segment的。清单1 描述了如何定位Segment的过程。其中hash(int)是将key的hashCode进行二次编码，使之能够在segmentMask+1个Segment上均匀分布（默认是16个）。可以看到的是这里和HashMap还是有点不同的，这里采用的算法叫Wang/Jenkins hash，有兴趣的可以<a href="http://tech.puredanger.com/2007/07/25/hash/" target="_blank">参考资料1</a>和<a href="http://www.goworkday.com/2010/03/19/single-word-wangjenkins-hash-concurrenthashmap/" target="_blank">参考资料2</a>。总之它的目的就是使元素能够均匀的分布在不同的Segment上，这样才能够支持最多segmentMask+1个并发，这里segmentMask+1是segments的大小。</p>
<p><strong><em>清单1 定位Segment</em></strong>
private static int hash(int h) {
    // Spread bits to regularize both segment and index locations,
    // using variant of single-word Wang/Jenkins hash.
    h += (h &lt;&lt;  15) ^ 0xffffcd7d;
    h ^= (h &gt;&gt;&gt; 10);
    h += (h &lt;&lt;   3);
    h ^= (h &gt;&gt;&gt;  6);
    h += (h &lt;&lt;   2) + (h &lt;&lt; 14);
    return h ^ (h &gt;&gt;&gt; 16);
}
final Segment<K,V> segmentFor(int hash) {
    return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];
}</p>
<p>显然在不能够对Segment扩容的情况下，segments的大小就应该是固定的。所以在ConcurrentHashMap中segments/segmentMask/segmentShift都是常量，一旦初始化后就不能被再次修改，其中segmentShift是查找Segment的一个常量偏移量。</p>
<p>有了Segment以后再定位HashEntry就和HashMap中定位HashEntry一样了，先将hash值与Segment中HashEntry的大小减1进行与操作定位到HashEntry链表，然后遍历链表就可以完成相应的操作了。</p>
<p>能够定位元素以后ConcurrentHashMap就已经具有了HashMap的功能了，现在要解决的就是如何并发的问题。要解决并发问题，加锁是必不可免的。再回头看Segment的类图，可以看到Segment除了有一个volatile类型的元素大小count外，Segment还是集成自ReentrantLock的。另外在前面的原子操作和锁机制中介绍过，要想最大限度的支持并发，那么能够利用的思路就是尽量读操作不加锁，写操作不加锁。如果是读操作不加锁，写操作加锁，对于竞争资源来说就需要定义为<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">volatile</a>类型的。<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">volatile</a>类型能够保证<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">happens-before法则</a>，所以volatile能够近似保证正确性的情况下最大程度的降低加锁带来的影响，同时还与写操作的锁不产生冲突。</p>
<p>同时为了防止在遍历HashEntry的时候被破坏，那么对于HashEntry的数据结构来说，除了value之外其他属性就应该是常量，否则不可避免的会得到ConcurrentModificationException。这就是为什么HashEntry数据结构中key,hash,next是常量的原因(final类型）。</p>
<p>有了上面的分析和条件后再来看Segment的get/put/remove就容易多了。</p>
<p><strong>get操作</strong></p>
<hr>
<p><strong><em>清单2 Segment定位元素</em></strong>
V get(Object key, int hash) {
    if (count != 0) { // read-volatile
        HashEntry<K,V> e = getFirst(hash);
        while (e != null) {
            if (e.hash == hash &amp;&amp; key.equals(e.key)) {
                V v = e.value;
                if (v != null)
                    return v;
                return readValueUnderLock(e); // recheck
            }
            e = e.next;
        }
    }
    return null;
}
HashEntry<K,V> getFirst(int hash) {
    HashEntry<K,V>[] tab = table;
    return tab[hash &amp; (tab.length - 1)];
}</p>
<p>V readValueUnderLock(HashEntry<K,V> e) {
    lock();
    try {
        return e.value;
    } finally {
        unlock();
    }
}</p>
<p>清单2 描述的是Segment如何定位元素。首先判断Segment的大小count&gt;0，Segment的大小描述的是HashEntry不为空(key不为空)的个数。如果Segment中存在元素那么就通过getFirst定位到指定的HashEntry链表的头节点上，然后遍历此节点，一旦找到key对应的元素后就返回其对应的值。但是在清单2 中可以看到拿到HashEntry的value后还进行了一次判断操作，如果为空还需要加锁再读取一次（readValueUnderLock）。为什么会有这样的操作？尽管ConcurrentHashMap不允许将value为null的值加入，但现在仍然能够读到一个为空的value就意味着此值对当前线程还不可见（这是因为HashEntry还没有完全构造完成就赋值导致的，后面还会谈到此机制）。</p>
<p><strong>put操作</strong></p>
<hr>
<p>清单3 描述的是Segment的put操作。首先就需要加锁了，修改一个竞争资源肯定是要加锁的，这个毫无疑问。需要说明的是Segment集成的是ReentrantLock，所以这里加的锁也就是独占锁，也就是说同一个Segment在同一时刻只有能一个put操作。</p>
<p>接下来来就是检查是否需要扩容，这和HashMap一样，如果需要的话就扩大一倍，同时进行rehash操作。</p>
<p>查找元素就和get操作是一样的，得到元素就直接修改其值就好了。这里onlyIfAbsent只是为了实现ConcurrentMap的putIfAbsent操作而已。需要说明以下几点：</p>
<ul>
<li>如果找到key对于的HashEntry后直接修改就好了，如果找不到那么就需要构造一个新的HashEntry出来加到hash对于的HashEntry的头部，同时就的头部就加到新的头部后面。这是因为HashEntry的next是final类型的，所以只能修改头节点才能加元素加入链表中。</li>
<li>如果增加了新的操作后，就需要将count+1写回去。前面说过count是volatile类型，而读取操作没有加锁，所以只能把元素真正写回Segment中的时候才能修改count值，这个要放到整个操作的最后。</li>
<li>在将新的HashEntry写入table中时是通过构造函数来设置value值的，这意味对table的赋值可能在设置value之前，也就是说得到了一个半构造完的HashEntry。这就是重排序可能引起的问题。所以在读取操作中，一旦读到了一个value为空的value是就需要加锁重新读取一次。为什么要加锁？加锁意味着前一个写操作的锁释放，也就是前一个锁的数据已经完成写完了了，根据happens-before法则，前一个写操作的结果对当前读线程就可见了。当然在JDK 6.0以后不一定存在此问题。</li>
<li>在Segment中table变量是volatile类型，多次读取volatile类型的开销要不非volatile开销要大，而且编译器也无法优化，所以在put操作中首先建立一个临时变量tab指向table，多次读写tab的效率要比volatile类型的table要高，JVM也能够对此进行优化。</li>
</ul>
<p><strong><em>清单3 Segment的put操作</em></strong>
V put(K key, int hash, V value, boolean onlyIfAbsent) {
    lock();
    try {
        int c = count;
        if (c++ &gt; threshold) // ensure capacity
            rehash();
        HashEntry<K,V>[] tab = table;
        int index = hash &amp; (tab.length - 1);
        HashEntry<K,V> first = tab[index];
        HashEntry<K,V> e = first;
        while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key)))
            e = e.next;</p>
<pre><code>    V oldValue;
    if (e != null) {
        oldValue = e.value;
        if (!onlyIfAbsent)
            e.value = value;
    }
    else {
        oldValue = null;
        ++modCount;
        tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value);
        count = c; // write-volatile
    }
    return oldValue;
} finally {
    unlock();
}
</code></pre><p>}</p>
<p><strong>remove 操作</strong></p>
<p>清单4 描述了Segment删除一个元素的过程。同put一样，remove也需要加锁，这是因为对table可能会有变更。由于HashEntry的next节点是final类型的，所以一旦删除链表中间一个元素，就需要将删除之前或者之后的元素重新加入新的链表。而Segment采用的是将删除元素之前的元素一个个重新加入删除之后的元素之前（也就是链表头结点）来完成新链表的构造。</p>
<p><strong><em>清单4 Segment的remove操作</em></strong>
V remove(Object key, int hash, Object value) {
    lock();
    try {
        int c = count - 1;
        HashEntry<K,V>[] tab = table;
        int index = hash &amp; (tab.length - 1);
        HashEntry<K,V> first = tab[index];
        HashEntry<K,V> e = first;
        while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key)))
            e = e.next;</p>
<pre><code>    V oldValue = null;
    if (e != null) {
        V v = e.value;
        if (value == null || value.equals(v)) {
            oldValue = v;
            // All entries following removed node can stay
            // in list, but all preceding ones need to be
            // cloned.
            ++modCount;
            HashEntry&lt;K,V&gt; newFirst = e.next;
            for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next)
                newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash,
                                              newFirst, p.value);
            tab[index] = newFirst;
            count = c; // write-volatile
        }
    }
    return oldValue;
} finally {
    unlock();
}
</code></pre><p>}</p>
<p>下面的示意图描述了如何删除一个已经存在的元素的。假设我们要删除B3元素。首先定位到B3所在的Segment，然后再定位到Segment的table中的B1元素，也就是Bx所在的链表。然后遍历链表找到B3，找到之后就从头结点B1开始构建新的节点B1（蓝色）加到B4的前面，继续B1后面的节点B2构造B2（蓝色），加到由蓝色的B1和B4构成的新的链表。继续下去，直到遇到B3后终止，这样就构造出来一个新的链表B2（蓝色）-&gt;B1（蓝色）-&gt;B4-&gt;B5，然后将此链表的头结点B2（蓝色）设置到Segment的table中。这样就完成了元素B3的删除操作。需要说明的是，尽管就的链表仍然存在(B1-&gt;B2-&gt;B3-&gt;B4-&gt;B5)，但是由于没有引用指向此链表，所以此链表中无引用的（B1-&gt;B2-&gt;B3）最终会被GC回收掉。这样做的一个好处是，如果某个读操作在删除时已经定位到了旧的链表上，那么此操作仍然将能读到数据，只不过读取到的是旧数据而已，这在多线程里面是没有问题的。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency18part3ConcurrentMap3_693/image_10.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency18part3ConcurrentMap3_693/image_12.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>除了对单个元素操作外，还有对全部的Segment的操作，比如size()操作等。</p>
<p><strong>size操作</strong></p>
<p>size操作涉及到统计所有Segment的大小，这样就会遍历所有的Segment，如果每次加锁就会导致整个Map都被锁住了，任何需要锁的操作都将无法进行。这里用到了一个比较巧妙的方案解决此问题。</p>
<p>在Segment中有一个变量modCount，用来记录Segment结构变更的次数，结构变更包括增加元素和删除元素，每增加一个元素操作就+1，每进行一次删除操作+1，每进行一次清空操作(clear)就+1。也就是说每次涉及到元素个数变更的操作modCount都会+1，而且一直是增大的，不会减小。</p>
<p>遍历两次ConcurrentHashMap中的segments，每次遍历是记录每一个Segment的modCount，比较两次遍历的modCount值的和是否相同，如果相同就返回在遍历过程中获取的Segment的count的和，也就是所有元素的个数。如果不相同就重复再做一次。重复一次还不相同就将所有Segment锁住，一个一个的获取其大小(count)，最后将这些count加起来得到总的大小。当然了最后需要将锁一一释放。清单5 描述了这个过程。</p>
<p>这里有一个比较高级的话题是为什么在读取modCount的时候总是先要读取count一下。为什么不是先读取modCount然后再读取count的呢？也就是说下面的两条语句能否交换下顺序？
sum += segments[i].count;
mcsum += mc[i] = segments[i].modCount;</p>
<p>答案是不能！为什么？这是因为modCount总是在加锁的情况下才发生变化，所以不会发生多线程同时修改的情况，也就是没必要时volatile类型。另外总是在count修改的情况下修改modCount，而count是一个volatile变量。于是这里就充分利用了volatile的特性。</p>
<p>根据<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">happens-before法则</a>，第（3）条：对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。也就是说一个操作C在volatile字段的写操作之后，那么volatile写操作之前的所有操作都对此操作C可见。所以修改modCount总是在修改count之前，也就是说如果读取到了一个count的值，那么在count变化之前的modCount也就能够读取到，换句话说就是如果看到了count值的变化，那么就一定看到了modCount值的变化。而如果上面两条语句交换下顺序就无法保证这个结果一定存在了。</p>
<p>在ConcurrentHashMap.containsValue中，可以看到每次遍历segments时都会执行int c = segments[i].count;，但是接下来的语句中又不用此变量c，尽管如此JVM仍然不能将此语句优化掉，因为这是一个volatile字段的读取操作，它保证了一些列操作的happens-before顺序，所以是至关重要的。在这里可以看到：
ConcurrentHashMap将volatile发挥到了极致！</p>
<p>另外isEmpty操作于size操作类似，不再累述。</p>
<p><strong><em>清单5 ConcurrentHashMap的size操作</em></strong>
public int size() {
    final Segment<K,V>[] segments = this.segments;
    long sum = 0;
    long check = 0;
    int[] mc = new int[segments.length];
    // Try a few times to get accurate count. On failure due to
    // continuous async changes in table, resort to locking.
    for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) {
        check = 0;
        sum = 0;
        int mcsum = 0;
        for (int i = 0; i &lt; segments.length; ++i) {
            sum += segments[i].count;
            mcsum += mc[i] = segments[i].modCount;
        }
        if (mcsum != 0) {
            for (int i = 0; i &lt; segments.length; ++i) {
                check += segments[i].count;
                if (mc[i] != segments[i].modCount) {
                    check = -1; // force retry
                    break;
                }
            }
        }
        if (check == sum)
            break;
    }
    if (check != sum) { // Resort to locking all segments
        sum = 0;
        for (int i = 0; i &lt; segments.length; ++i)
            segments[i].lock();
        for (int i = 0; i &lt; segments.length; ++i)
            sum += segments[i].count;
        for (int i = 0; i &lt; segments.length; ++i)
            segments[i].unlock();
    }
    if (sum &gt; Integer.MAX_VALUE)
        return Integer.MAX_VALUE;
    else
        return (int)sum;
}</p>
<p><strong>ConcurrentSkipListMap/Set</strong></p>
<p>本来打算介绍下ConcurrentSkipListMap的，结果打开源码一看，彻底放弃了。那里面的数据结构和算法我估计研究一周也未必能够完全弄懂。很久以前我看TreeMap的时候就头大，想想那些复杂的“红黑二叉树”我头都大了。这些都归咎于从前没有好好学习《数据结构和算法》，现在再回头看这些复杂的算法感觉非常头疼，为了减少脑细胞的死亡，暂且还是不要惹这些“玩意儿”。有兴趣的可以看看<a href="http://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html?ca=drs-" target="_blank">参考资料4</a> 中对TreeMap的介绍。</p>
<p>参考资料：</p>
<ol>
<li><a href="http://tech.puredanger.com/2007/07/25/hash/" target="_blank">Hash this</a></li>
<li><a href="http://www.goworkday.com/2010/03/19/single-word-wangjenkins-hash-concurrenthashmap/" target="_blank">Single-word Wang/Jenkins Hash in ConcurrentHashMap</a></li>
<li><a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">指令重排序与happens-before法则</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html?ca=drs-" target="_blank">通过分析 JDK 源代码研究 TreeMap 红黑树算法实现</a></li>
</ol>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/20/326661.html](http://www.blogjava.net/xylz/archive/2010/07/20/326661.html)">[http://www.blogjava.net/xylz/archive/2010/07/20/326661.html](http://www.blogjava.net/xylz/archive/2010/07/20/326661.html)</a></p>
<p>Queue是JDK 5以后引入的新的集合类，它属于Java Collections Framework的成员，在Collection集合中和List/Set是同一级别的接口。通常来讲Queue描述的是一种FIFO的队列，当然不全都是，比如PriorityQueue是按照优先级的顺序（或者说是自然顺序，借助于Comparator接口）。</p>
<p>下图描述了Java Collections Framework中Queue的整个家族体系。</p>
<p>对于Queue而言是在Collection的基础上增加了offer/remove/poll/element/peek方法，另外重新定义了add方法。对于这六个方法，有不同的定义。</p>
<hr>
<p><strong>抛出异常</strong></p>
<p><strong>返回特殊值</strong></p>
<p><strong>操作描述</strong> 插入</p>
<p>add(e)</p>
<p>offer(e)</p>
<p>将元素加入到队列尾部 移除</p>
<p>remove()</p>
<p>poll()</p>
<p>移除队列头部的元素 检查</p>
<p>element()</p>
<p>peek()</p>
<p>返回队列头部的元素而不移除此元素</p>
<p>特别说明的是对于Queue而言，规范并没有规定是线程安全的，为了解决这个问题，引入了可阻塞的队列BlockingQueue。对于BlockingQueue而言所有操作的是线程安全的，并且队列的操作可以被阻塞，直到满足某种条件。Queue的另一个子接口Deque描述的是一个双向的队列。与Queue不同的是，Deque允许在队列的头部增加元素和在队列的尾部删除元素。也就是说Deque是一个双向队列。二者功能都有的队列就是BlockingDeque，这种阻塞队列允许在队列的头和尾部分别操作元素，应该说是Queue中功能最强大的实现。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/ead4e8800e0c_FD45/image_4.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>在JDK 5之前LinkedList就已经存在，而且本身实现都是一种双向队列。所以到了JDK 5以后就将LinkedList同时实现Deque接口，这样LinkedList就又属于Queue的一部分了。</p>
<p>通常情况下Queue都是靠链表结构实现的，但是链表意味着有一些而外的引用开销，如果是双向链表开销就更大了。所以为了节省内存，一种方式就是使用固定大小的数组来实现队列。在这种情况下队列的大小是固定，元素的遍历通过数组的索引进行，很显然这是一种双向链表的模型。ArrayDeque就是这样一种实现。</p>
<p>另外ArrayBlockingQueue也是一种数组实现的队列，但是却没有改造成双向，仅仅实现了BlockingQueue的模型。理论上和ArrayDeque一样也应该容易改造成双向的实现。</p>
<p>PriorityQueue和PriorityBlockingQueue实现了一种排序的队列模型。这很类似与SortedSet，通过队列的Comparator接口或者Comparable元素来排序元素。这种情况下元素在队列中的出入就不是按照FIFO的形式，而是根据比较后的自然顺序来进行。</p>
<p>CocurrentLinkedQueue是一种线程安全却非阻塞的FIFO队列，这种队列通常实现起来比较简单，但是却很有效。在接下来的章节会详细的描述它。</p>
<p>SynchronousQueue是一种特别的BlockingQueue，它只是把一个add/offer操作的元素直接移交给remove/take操作。也就是说它本身不会缓存任何元素，所以严格意义上说来讲并不是一种真正的队列。此队列维护一个线程列表，这些线程等待从队列中加入元素或者移除元素。简单的说，至少有一个remove/take操作时add/offer操作才能成功，同样至少有一个add/offer操作时remove/take操作才能成功。这是一种双向等待的队列模型，出队列等待加入等列，而入队列又等待出队列。这种队列的好处在于能够最大线程的保持吞吐量却又是线程安全的。所以对于一个需要快速处理的任务队列，SynchronousQueue是一个不错的选择。</p>
<p>BlockingQueue还有一种实现DelayQueue，这种实现允许每一个元素(Delayed)带有一个延时时间，当调用take/poll的时候会检测队列头元素这个时间是否&lt;=0，如果满足就是说已经超时了，那么此元素就可以被移除了，否则就会等待。特别说明的是这个头元素应该是最先被超时的元素（这个时间是绝对时间）。这个类设计很巧妙，被用于ScheduledFutureTask来进行定时操作。希望后面会开辟一个章节讲讲这里面的想法。实在不行在讲线程池部分肯定会提到这个。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/21/326723.html](http://www.blogjava.net/xylz/archive/2010/07/21/326723.html)">[http://www.blogjava.net/xylz/archive/2010/07/21/326723.html](http://www.blogjava.net/xylz/archive/2010/07/21/326723.html)</a> </p>
<p>ConcurrentLinkedQueue是Queue的一个线程安全实现。先来看一段文档说明。</p>
<p>一个基于链接节点的无界线程安全队列。此队列按照 FIFO（先进先出）原则对元素进行排序。队列的头部 是队列中时间最长的元素。队列的尾部 是队列中时间最短的元素。新的元素插入到队列的尾部，队列获取操作从队列头部获得元素。当多个线程共享访问一个公共 collection 时，ConcurrentLinkedQueue 是一个恰当的选择。此队列不允许使用 null 元素。</p>
<p>由于ConcurrentLinkedQueue只是简单的实现了一个队列Queue，因此从API的角度讲，没有多少值的介绍，使用起来也很简单，和前面遇到的所有FIFO队列都类似。出队列只能操作头节点，入队列只能操作尾节点，任意节点操作就需要遍历完整的队列。</p>
<p>重点放在解释ConcurrentLinkedQueue的原理和实现上。</p>
<p>在继续探讨之前，结合前面线程安全的相关知识，我来分析设计一个线程安全的队列哪几种方法。</p>
<p>第一种：使用synchronized同步队列，就像Vector或者Collections.synchronizedList/Collection那样。显然这不是一个好的并发队列，这会导致吞吐量急剧下降。</p>
<p>第二种：使用Lock。一种好的实现方式是使用ReentrantReadWriteLock来代替ReentrantLock提高读取的吞吐量。但是显然ReentrantReadWriteLock的实现更为复杂，而且更容易导致出现问题，另外也不是一种通用的实现方式，因为ReentrantReadWriteLock适合哪种读取量远远大于写入量的场合。当然了ReentrantLock是一种很好的实现，结合Condition能够很方便的实现阻塞功能，这在后面介绍BlockingQueue的时候会具体分析。</p>
<p>第三种：使用CAS操作。尽管Lock的实现也用到了CAS操作，但是毕竟是间接操作，而且会导致线程挂起。一个好的并发队列就是采用某种非阻塞算法来取得最大的吞吐量。</p>
<p>ConcurrentLinkedQueue采用的就是第三种策略。它采用了<a href="http://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf" target="_blank">参考资料1</a> 中的算法。</p>
<p>在锁机制中谈到过，要使用非阻塞算法来完成队列操作，那么就需要一种“循环尝试”的动作，就是循环操作队列，直到成功为止，失败就会再次尝试。这在前面的章节中多次介绍过。</p>
<p>针对各种功能深入分析。</p>
<p>在开始之前先介绍下ConcurrentLinkedQueue的数据结构。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency20part5ConcurrentLinkedQu_C9AC/image_2.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>在上面的数据结构中，ConcurrentLinkedQueue只有头结点、尾节点两个元素，而对于一个节点Node而言除了保存队列元素item外，还有一个指向下一个节点的引用next。 看起来整个数据结构还是比较简单的。但是也有几点是需要说明：</p>
<ol>
<li>所有结构（head/tail/item/next）都是volatile类型。 这是因为ConcurrentLinkedQueue是非阻塞的，所以只有volatile才能使变量的写操作对后续读操作是可见的（这个是有happens-before法则保证的）。同样也不会导致指令的重排序。</li>
<li>所有结构的操作都带有原子操作，这是由AtomicReferenceFieldUpdater保证的，这在原子操作中介绍过。它能保证需要的时候对变量的修改操作是原子的。</li>
<li>由于队列中任何一个节点（Node）只有下一个节点的引用，所以这个队列是单向的，根据FIFO特性，也就是说出队列在头部(head)，入队列在尾部(tail)。头部保存有进入队列最长时间的元素，尾部是最近进入的元素。</li>
<li>没有对队列长度进行计数，所以队列的长度是无限的，同时获取队列的长度的时间不是固定的，这需要遍历整个队列，并且这个计数也可能是不精确的。</li>
<li>初始情况下队列头和队列尾都指向一个空节点，但是非null，这是为了方便操作，不需要每次去判断head/tail是否为空。但是head却不作为存取元素的节点，tail在不等于head情况下保存一个节点元素。也就是说head.item这个应该一直是空，但是tail.item却不一定是空（如果head!=tail，那么tail.item!=null）。</li>
</ol>
<p>对于第5点，可以从ConcurrentLinkedQueue的初始化中看到。这种头结点也叫“伪节点”，也就是说它不是真正的节点，只是一标识，就像c中的字符数组后面的\0以后，只是用来标识结束，并不是真正字符数组的一部分。
private transient volatile Node<E> head = new Node<E>(null, null);
private transient volatile Node<E> tail = head;</p>
<p>有了上述5点再来解释相关API操作就容易多了。</p>
<p>在上一节中列出了add/offer/remove/poll/element/peek等价方法的区别，所以这里就不再重复了。</p>
<p><strong><em>清单1 入队列操作</em></strong>
public boolean offer(E e) {
    if (e == null) throw new NullPointerException();
    Node<E> n = new Node<E>(e, null);
    for (;;) {
        Node<E> t = tail;
        Node<E> s = t.getNext();
        if (t == tail) {
            if (s == null) {
                if (t.casNext(s, n)) {
                    casTail(t, n);
                    return true;
                }
            } else {
                casTail(t, s);
            }
        }
    }
}</p>
<p>清单1 描述的是入队列的过程。整个过程是这样的。</p>
<ol>
<li>获取尾节点t，以及尾节点的下一个节点s。如果尾节点没有被别人修改，也就是t==tail，进行2，否则进行1。</li>
<li>如果s不为空，也就是说此时尾节点后面还有元素，那么就需要把尾节点往后移，进行1。否则进行3。</li>
<li>修改尾节点的下一个节点为新节点，如果成功就修改尾节点，返回true。否则进行1。</li>
</ol>
<p>从操作3中可以看到是先修改尾节点的下一个节点，然后才修改尾节点位置的，所以这才有操作2中为什么获取到的尾节点的下一个节点不为空的原因。</p>
<p>特别需要说明的是，对尾节点的tail的操作需要换成临时变量t和s，一方面是为了去掉volatile变量的可变性，另一方面是为了减少volatile的性能影响。</p>
<p>清单2 描述的出队列的过程，这个过程和入队列相似，有点意思。</p>
<p>头结点是为了标识队列起始，也为了减少空指针的比较，所以头结点总是一个item为null的非null节点。也就是说head!=null并且head.item==null总是成立。所以实际上获取的是head.next，一旦将头结点head设置为head.next成功就将新head的item设置为null。至于以前就的头结点h，h.item=null并且h.next为新的head，但是由于没有对h的引用，所以最终会被GC回收。这就是整个出队列的过程。</p>
<p><strong><em>清单2 出队列操作</em></strong>
public E poll() {
    for (;;) {
        Node<E> h = head;
        Node<E> t = tail;
        Node<E> first = h.getNext();
        if (h == head) {
            if (h == t) {
                if (first == null)
                    return null;
                else
                    casTail(t, first);
            } else if (casHead(h, first)) {
                E item = first.getItem();
                if (item != null) {
                    first.setItem(null);
                    return item;
                }
                // else skip over deleted item, continue loop,
            }
        }
    }
}</p>
<p>另外对于清单3 描述的获取队列大小的过程，由于没有一个计数器来对队列大小计数，所以获取队列的大小只能通过从头到尾完整的遍历队列，显然这个代价是很大的。所以通常情况下ConcurrentLinkedQueue需要和一个AtomicInteger搭配才能获取队列大小。后面介绍的BlockingQueue正是使用了这种思想。</p>
<p><strong>清单3 遍历队列大小</strong>
public int size() {
    int count = 0;
    for (Node<E> p = first(); p != null; p = p.getNext()) {
        if (p.getItem() != null) {
            // Collections.size() spec says to max out
            if (++count == Integer.MAX_VALUE)
                break;
        }
    }
    return count;
}</p>
<p>参考资料：</p>
<ol>
<li><a href="http://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf" target="_blank">Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms</a></li>
<li><a href="http://yanxuxin.javaeye.com/blog/586943" target="_blank">多线程基础总结十一—ConcurrentLinkedQueue</a></li>
<li><a href="http://www.javaeye.com/topic/68279" target="_blank">对ConcurrentLinkedQueue进行的并发测试</a> </li>
</ol>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/23/326934.html](http://www.blogjava.net/xylz/archive/2010/07/23/326934.html)">[http://www.blogjava.net/xylz/archive/2010/07/23/326934.html](http://www.blogjava.net/xylz/archive/2010/07/23/326934.html)</a></p>
<p>在《<a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">并发容器 part 4 并发队列与Queue简介</a>》节中的类图中可以看到，对于Queue来说，BlockingQueue是主要的线程安全版本。这是一个可阻塞的版本，也就是允许添加/删除元素被阻塞，直到成功为止。</p>
<p>BlockingQueue相对于Queue而言增加了两个操作：put/take。下面是一张整理的表格。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency21part5ConcurrentLinkedQu_E370/image_4.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>看似简单的API，非常有用。这在控制队列的并发上非常有好处。既然加入队列和移除队列能够被阻塞，这在实现生产者-消费者模型上就简单多了。</p>
<p>清单1 是生产者-消费者模型的一个例子。这个例子是一个真实的场景。服务端（ICE服务）接受客户端的请求(accept)，请求计算此人的好友生日，然后将计算的结果存取缓存中（Memcache）中。在这个例子中采用了ExecutorService实现多线程的功能，尽可能的提高吞吐量，这个在后面线程池的部分会详细说明。目前就可以理解为new Thread(r).start()就可以了。另外这里阻塞队列使用的是LinkedBlockingQueue。</p>
<p><strong><em>清单1 一个生产者-消费者例子</em></strong>
package xylz.study.concurrency;</p>
<p>import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.LinkedBlockingDeque;</p>
<p>public class BirthdayService {</p>
<pre><code>final int workerNumber;

final Worker[] workers;

final ExecutorService threadPool;

static volatile boolean running = true;

public BirthdayService(int workerNumber, int capacity) {
    if (workerNumber &lt;= 0) throw new IllegalArgumentException();
    this.workerNumber = workerNumber;
    workers = new Worker[workerNumber];
    for (int i = 0; i &lt; workerNumber; i++) {
        workers[i] = new Worker(capacity);
    }
    //
    boolean b = running;// kill the resorting
    threadPool = Executors.newFixedThreadPool(workerNumber);
    for (Worker w : workers) {
        threadPool.submit(w);
    }
}

Worker getWorker(int id) {
    return workers[id % workerNumber];

}

class Worker implements Runnable {

    final BlockingQueue&lt;Integer&gt; queue;

    public Worker(int capacity) {
        queue = new LinkedBlockingQueue&lt;Integer&gt;(capacity);
    }

    public void run() {
        while (true) {
            try {
                consume(queue.take());
            } catch (InterruptedException e) {
                return;
            }
        }
    }

    void put(int id) {
        try {
            queue.put(id);
        } catch (InterruptedException e) {
            return;
        }
    }
}

public void accept(int id) {
    //accept client request
    getWorker(id).put(id);
}

protected void consume(int id) {
    //do the work
    //get the list of friends and save the birthday to cache
}
</code></pre><p>}</p>
<p>在清单1 中可以看到不管是put()还是get()，都抛出了一个InterruptedException。我们就从这里开始，为什么会抛出这个异常。</p>
<p><a href="http://www.blogjava.net/xylz/archive/2010/07/23/326934.html" target="_blank">上一节</a>中提到实现一个并发队列有三种方式。显然只有第二种 Lock 才能实现阻塞队列。在锁机制中提到过，Lock结合Condition就可以实现线程的阻塞，这在锁机制部分的很多工具中都详细介绍过，而接下来要介绍的LinkedBlockingQueue就是采用这种方式。</p>
<p><strong>LinkedBlockingQueue 原理</strong></p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency21part5ConcurrentLinkedQu_E370/image8_1.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>对比<a href="http://www.blogjava.net/xylz/archive/2010/07/23/326934.html" target="_blank">ConcurrentLinkedQueue的结构图</a>，LinkedBlockingQueue多了两个ReentrantLock和两个Condition以及用于计数的AtomicInteger，显然这会导致LinkedBlockingQueue的实现有点复杂。对照此结构，有以下几点说明：</p>
<ol>
<li>但是整体上讲，LinkedBlockingQueue和ConcurrentLinkedQueue的结构类似，都是采用头尾节点，每个节点指向下一个节点的结构，这表示它们在操作上应该类似。</li>
<li>LinkedBlockingQueue引入了原子计数器count，这意味着获取队列大小size()已经是常量时间了，不再需要遍历队列。每次队列长度有变更时只需要修改count即可。</li>
<li>有了修改Node指向有了锁，所以不需要volatile特性了。既然有了锁Node的item为什么需要volatile在后面会详细分析，暂且不表。</li>
<li>引入了两个锁，一个入队列锁，一个出队列锁。当然同时有一个队列不满的Condition和一个队列不空的Condition。其实参照锁机制前面介绍过的生产者-消费者模型就知道，入队列就代表生产者，出队列就代表消费者。为什么需要两个锁？一个锁行不行？其实一个锁完全可以，但是一个锁意味着入队列和出队列同时只能有一个在进行，另一个必须等待其释放锁。而从ConcurrentLinkedQueue的实现原理来看，事实上head和last (ConcurrentLinkedQueue中是tail)是分离的，互相独立的，这意味着入队列实际上是不会修改出队列的数据的，同时出队列也不会修改入队列，也就是说这两个操作是互不干扰的。更通俗的将，这个锁相当于两个写入锁，入队列是一种写操作，操作head，出队列是一种写操作，操作tail。可见它们是无关的。但是并非完全无关，后面详细分析。</li>
</ol>
<p>在没有揭示入队列和出队列过程前，暂且猜测下实现原理。</p>
<p>根据前面学到的锁机制原理结合ConcurrentLinkedQueue的原理，入队列的阻塞过程大概是这样的：</p>
<ol>
<li>获取入队列的锁putLock，检测队列大小，如果队列已满，那么就挂起线程，等待队列不满信号notFull的唤醒。</li>
<li>将元素加入到队列尾部，同时修改队列尾部引用last。</li>
<li>队列大小加1。</li>
<li>释放锁putLock。</li>
<li>唤醒notEmpty线程（如果有挂起的出队列线程），告诉消费者，已经有了新的产品。</li>
</ol>
<p>对比入队列，出队列的阻塞过程大概是这样的：</p>
<ol>
<li>获取出队列的锁takeLock，检测队列大小，如果队列为空，那么就挂起线程，等待队列不为空notEmpty的唤醒。</li>
<li>将元素从头部移除，同时修改队列头部引用head。</li>
<li>队列大小减1。</li>
<li>释放锁takeLock。</li>
<li>唤醒notFull线程（如果有挂起的入队列线程），告诉生产者，现在还有空闲的空间。</li>
</ol>
<p>下面来验证上面的过程。</p>
<p><strong>入队列过程（put/offer）</strong></p>
<p><strong><em>清单2 阻塞的入队列过程</em></strong>
public void put(E e) throws InterruptedException {
    if (e == null) throw new NullPointerException();
    int c = -1;
    final ReentrantLock putLock = this.putLock;
    final AtomicInteger count = this.count;
    putLock.lockInterruptibly();
    try {
        try {
            while (count.get() == capacity)
                notFull.await();
        } catch (InterruptedException ie) {
            notFull.signal(); // propagate to a non-interrupted thread
            throw ie;
        }
        insert(e);
        c = count.getAndIncrement();
        if (c + 1 &lt; capacity)
            notFull.signal();
    } finally {
        putLock.unlock();
    }
    if (c == 0)
        signalNotEmpty();
}</p>
<p>清单2 描述的是入队列的阻塞过程。可以看到和上面描述的入队列的过程基本相同。但是也有以下几个问题：</p>
<ol>
<li>如果在入队列的时候线程被中断，那么就需要发出一个notFull的信号，表示下一个入队列的线程能够被唤醒（如果阻塞的话）。</li>
<li>入队列成功后如果队列不满需要补一个notFull的信号。为什么？队列不满的时候其它入队列的阻塞线程难道不知道么？有可能。这是因为为了减少上下文切换的次数，每次唤醒一个线程（不管是入队列还是出队列）都是只随机唤醒一个(notify)，而不是唤醒所有的（notifyall()）。这会导致其它阻塞的入队列线程不能够即使处理队列不满的情况。</li>
<li>如果队列不为空并且可能有一个元素的话就唤醒一个出队列线程。这么做说明之前队列一定为空，因为在加入队列之后队列最多只能为1，那么说明未加入之前是0，那么就可能有被阻塞的出队列线程，所以就唤醒一个出队列线程。特别说明的是为什么使用一个临时变量c，而不用count。这是因为读取一个count的开销比读取一个临时一个变量大，而此处c又能够完成确认队列最多只有一个元素的判断。首先c默认为-1，如果加入队列后获取原子计数器的结果为0，说明之前队列为空，不可能消费（出队列），也不可能入队列，因为此时锁还在当前线程上，那么加入一个后队列就不为空了，所以就可以安全的唤醒一个消费（出对立）线程。</li>
<li>入队列的过程允许被中断，所以总是抛出InterruptedException 异常。</li>
</ol>
<p>针对第2点，特别补充说明下。本来这属于锁机制中条件队列的范围，由于没有应用场景，所以当时没有提。</p>
<p>前面提高notifyall总是比notify更可靠，因为notify可能丢失通知，为什么不适用notifyall呢？</p>
<p>先解释下notify丢失通知的问题。</p>
<p><strong>notify丢失通知问题</strong></p>
<p>假设线程A因为某种条件在条件队列中等待，同时线程B因为另外一种条件在同一个条件队列中等待，也就是说线程A/B都被同一个Conditon.await()挂起，但是等待的条件不同。现在假设线程B的线程被满足，线程C执行一个notify操作，此时JVM从Conditon.await()的多个线程（A/B）中随机挑选一个唤醒，不幸的是唤醒了A。此时A的条件不满足，于是A继续挂起。而此时B仍然在傻傻的等待被唤醒的信号。也就是说本来给B的通知却被一个无关的线程持有了，真正需要通知的线程B却没有得到通知，而B仍然在等待一个已经发生过的通知。</p>
<p>如果使用notifyall，则能够避免此问题。notifyall会唤醒所有正在等待的线程，线程C发出的通知线程A同样能够收到，但是由于对于A没用，所以A继续挂起，而线程B也收到了此通知，于是线程B正常被唤醒。</p>
<p>既然notifyall能够解决单一notify丢失通知的问题，那么为什么不总是使用notifyall替换notify呢？</p>
<p>假设有N个线程在条件队列中等待，调用notifyall会唤醒所有线程，然后这N个线程竞争同一个锁，最多只有一个线程能够得到锁，于是其它线程又回到挂起状态。这意味每一次唤醒操作可能带来大量的上下文切换（如果N比较大的话），同时有大量的竞争锁的请求。这对于频繁的唤醒操作而言性能上可能是一种灾难。</p>
<p>如果说总是只有一个线程被唤醒后能够拿到锁，那么为什么不使用notify呢？所以某些情况下使用notify的性能是要高于notifyall的。</p>
<p>如果满足下面的条件，可以使用单一的notify取代notifyall操作：
相同的等待者，也就是说等待条件变量的线程操作相同，每一个从wait放回后执行相同的逻辑，同时一个条件变量的通知至多只能唤醒一个线程。</p>
<p>也就是说理论上讲在put/take中如果使用sinallAll唤醒的话，那么在清单2 中的notFull.singal就是多余的。</p>
<p><strong>出队列过程（poll/take）</strong></p>
<p>再来看出队列过程。清单3 描述了出队列的过程。可以看到这和入队列是对称的。从这里可以看到，出队列使用的是和入队列不同的锁，所以入队列、出队列这两个操作才能并行进行。</p>
<p><strong><em>清单3 阻塞的出队列过程</em></strong>
public E take() throws InterruptedException {
    E x;
    int c = -1;
    final AtomicInteger count = this.count;
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lockInterruptibly();
    try {
        try {
            while (count.get() == 0)
                notEmpty.await();
        } catch (InterruptedException ie) {
            notEmpty.signal(); // propagate to a non-interrupted thread
            throw ie;
        }</p>
<pre><code>    x = extract();
    c = count.getAndDecrement();
    if (c &gt; 1)
        notEmpty.signal();
} finally {
    takeLock.unlock();
}
if (c == capacity)
    signalNotFull();
return x;
</code></pre><p>}</p>
<p><strong>为什么有异常？</strong></p>
<p>有了入队列、出队列的过程后再来回答前面的几个问题。</p>
<p>为什么总是抛出InterruptedException 异常？ 这是很大一块内容，其实是Java对线程中断的处理问题，希望能够在系列文章的最后能够对此开辟单独的篇章来谈谈。</p>
<p>在锁机制里面也是总遇到，这是因为，Java里面没有一种直接的方法中断一个挂起的线程，所以通常情况下等于一个处于WAITING状态的线程，允许设置一个中断位，一旦线程检测到这个中断位就会从WAITING状态退出，以一个InterruptedException 的异常返回。所以只要是对一个线程挂起操作都会导致InterruptedException 的可能，比如Thread.sleep()、Thread.join()、Object.wait()。尽管LockSupport.park()不会抛出一个InterruptedException 异常，但是它会将当前线程的的interrupted状态位置上，而对于Lock/Condition而言，当捕捉到interrupted状态后就认为线程应该终止任务，所以就抛出了一个InterruptedException 异常。</p>
<p><strong>又见volatile</strong></p>
<p>还有一个不容易理解的问题。<strong>为什么Node.item是volatile类型的？</strong></p>
<p>起初我不大明白，因为对于一个进入队列的Node，它的item是不变，当且仅当出队列的时候会将头结点元素的item 设置为null。尽管在remove(o)的时候也是设置为null,但是那时候是加了putLock/takeLock两个锁的，所以肯定是没有问题的。那么问题出在哪？</p>
<p>我们知道，item的值是在put/offer的时候加入的。这时候都是有putLock锁保证的，也就是说它保证使用putLock锁的读取肯定是没有问题的。那么问题就只可能出在一个不适用putLock却需要读取Node.item的地方。</p>
<p>peek操作时获取头结点的元素而不移除它。显然他不会操作尾节点，所以它不需要putLock锁，也就是说它只有takeLock锁。清单4 描述了这个过程。</p>
<p><strong><em>清单4 查询队列头元素过程</em></strong>
public E peek() {
    if (count.get() == 0)
        return null;
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lock();
    try {
        Node<E> first = head.next;
        if (first == null)
            return null;
        else
            return first.item;
    } finally {
        takeLock.unlock();
    }
}</p>
<p>清单4 描述了peek的过程，最后返回一个非null节点的结果是Node.item。这里读取了Node的item值，但是整个过程却是使用了takeLock而非putLock。换句话说putLock对Node.item的操作，peek()线程可能不可见！</p>
<p><strong><em>清单5 队列尾部加入元素</em></strong>
private void insert(E x) {
    last = last.next = new Node<E>(x);
}</p>
<p>清单5 是入队列offer/put的一部分，这里关键在于last=new Node<E>(x)可能发生重排序。Node构造函数是这样的：Node(E x) { item = x; }。在这一步里面我们可能得到以下一种情况：</p>
<ol>
<li>构建一个Node对象n；</li>
<li>将Node的n赋给last</li>
<li>初始化n，设置item=x</li>
</ol>
<p>在执行步骤2 的时候一个peek线程可能拿到了新的Node n，这时候它读取item，得到了一个null。显然这是不可靠的。</p>
<p>对item采用volatile之后，JMM保证对item=x的赋值一定在last=n之前，也就是说last得到的一个是一个已经赋值了的新节点n。这就不会导致读取空元素的问题的。</p>
<p>出对了poll/take和peek都是使用的takeLock锁，所以不会导致此问题。</p>
<p>删除操作和遍历操作由于同时获取了takeLock和putLock，所以也不会导致此问题。</p>
<p>总结：当前仅当元素加入队列时读取此元素才可能导致不一致的问题。采用volatile正式避免此问题。</p>
<p><strong>附加功能</strong></p>
<p>BlockingQueue有一个额外的功能，允许批量从队列中异常元素。这个API是：
<strong><em>int drainTo(Collection&lt;? super E&gt; c, int maxElements);</em></strong> 最多从此队列中移除给定数量的可用元素，并将这些元素添加到给定 collection 中。</p>
<p><strong><em>int drainTo(Collection&lt;? super E&gt; c);</em></strong> 移除此队列中所有可用的元素，并将它们添加到给定 collection 中。</p>
<p>清单6 描述的是最多移除指定数量元素的过程。由于批量操作只需要一次获取锁，所以效率会比每次获取锁要高。但是需要说明的，需要同时获取takeLock/putLock两把锁，因为当移除完所有元素后这会涉及到尾节点的修改（last节点仍然指向一个已经移走的节点）。</p>
<p>由于迭代操作<strong>contains()/remove()/iterator()</strong>也是获取了两个锁，所以迭代操作也是线程安全的。</p>
<p><strong><em>清单6 批量移除操作</em></strong>
public int drainTo(Collection&lt;? super E&gt; c, int maxElements) {
    if (c == null)
        throw new NullPointerException();
    if (c == this)
        throw new IllegalArgumentException();
    fullyLock();
    try {
        int n = 0;
        Node<E> p = head.next;
        while (p != null &amp;&amp; n &lt; maxElements) {
            c.add(p.item);
            p.item = null;
            p = p.next;
            ++n;
        }
        if (n != 0) {
            head.next = p;
            assert head.item == null;
            if (p == null)
                last = head;
            if (count.getAndAdd(-n) == capacity)
                notFull.signalAll();
        }
        return n;
    } finally {
        fullyUnlock();
    }
}</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/24/326988.html](http://www.blogjava.net/xylz/archive/2010/07/24/326988.html)">[http://www.blogjava.net/xylz/archive/2010/07/24/326988.html](http://www.blogjava.net/xylz/archive/2010/07/24/326988.html)</a></p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2010/07/24/326988.html" target="_blank">上一节</a>中详细分析了<strong>LinkedBlockingQueue </strong>的实现原理。实现一个可扩展的队列通常有两种方式：一种方式就像LinkedBlockingQueue一样使用链表，也就是每一个元素带有下一个元素的引用，这样的队列原生就是可扩展的；另外一种就是通过数组实现，一旦队列的大小达到数组的容量的时候就将数组扩充一倍（或者一定的系数倍），从而达到扩容的目的。常见的ArrayList就属于第二种。前面章节介绍过的HashMap确是综合使用了这两种方式。</p>
<p>对于一个Queue而言，同样可以使用数组实现。使用数组的好处在于各个元素之间原生就是通过数组的索引关联起来的，一次元素之间就是有序的，在通过索引操作数组就方便多了。当然也有它不利的一面，扩容起来比较麻烦，同时删除一个元素也比较低效。</p>
<p>ArrayBlockingQueue 就是Queue的一种数组实现。</p>
<p><strong>ArrayBlockingQueue 原理</strong></p>
<p>在没有介绍ArrayBlockingQueue原理之前可以想象下，一个数组如何实现Queue的FIFO特性。首先，数组是固定大小的，这个是毫无疑问的，那么初始化就是所有元素都为null。假设数组一段为头，另一端为尾。那么头和尾之间的元素就是FIFO队列。</p>
<ol>
<li>入队列就将尾索引往右移动一个，新元素加入尾索引的位置；</li>
<li>出队列就将头索引往尾索引方向移动一个，同时将旧头索引元素设为null，返回旧头索引的元素。</li>
<li>一旦数组已满，那么就不允许添加新元素（除非扩充容量）</li>
<li>如果尾索引移到了数组的最后（最大索引处），那么就从索引0开始，形成一个“闭合”的数组。</li>
<li>由于头索引和尾索引之间的元素都不能为空（因为为空不知道take出来的元素为空还是队列为空），所以删除一个头索引和尾索引之间的元素的话，需要移动删除索引前面或者后面的所有元素，以便填充删除索引的位置。</li>
<li>由于是阻塞队列，那么显然需要一个锁，另外由于只是一份数据（一个数组），所以只能有一个锁，也就是同时只能有一个线程操作队列。</li>
</ol>
<p>有了上述几点分析，设计一个可阻塞的数组队列就比较容易了。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency22part7BlockingQueue2_1216F/image_4.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>上图描述的ArrayBlockingQueue的数据结构。首先有一个数组E[]，用来存储所有的元素。由于ArrayBlockingQueue最终设置为一个不可扩展大小的Queue，所以这里items就是初始化就固定大小的数组（final类型）；另外有两个索引，头索引takeIndex，尾索引putIndex；一个队列的大小count；要支持阻塞就必须需要一个锁lock和两个条件（非空、非满），这三个元素都是不可变更类型的（final）。</p>
<p>由于只有一把锁，所以任何时刻对队列的操作都只有一个线程，这意味着对索引和大小的操作都是线程安全的，所以可以看到这个takeIndex/putIndex/count就不需要原子操作和volatile语义了。</p>
<p>清单1 描述的是一个可阻塞的添加元素过程。这与前面介绍的消费者、生产者模型相同。如果队列已经满了就挂起等待，否则就插入元素，同时唤醒一个队列已空的线程。对比清单2 可以看到是完全相反的两个过程。这在前面几种实现生产者-消费者模型的时候都介绍过了。</p>
<p><strong><em>清单1 可阻塞的添加元素</em></strong>
public void put(E e) throws InterruptedException {
    if (e == null) throw new NullPointerException();
    final E[] items = this.items;
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        try {
            while (count == items.length)
                notFull.await();
        } catch (InterruptedException ie) {
            notFull.signal(); // propagate to non-interrupted thread
            throw ie;
        }
        insert(e);
    } finally {
        lock.unlock();
    }
}</p>
<p> <strong><em>清单2 可阻塞的移除元素</em></strong>
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        try {
            while (count == 0)
                notEmpty.await();
        } catch (InterruptedException ie) {
            notEmpty.signal(); // propagate to non-interrupted thread
            throw ie;
        }
        E x = extract();
        return x;
    } finally {
        lock.unlock();
    }
}</p>
<p>需要注意到的是，尽管每次加入、移除一个元素使用的都是signal()通知，而不是signalAll()通知。我们参考上一节中notify替换notifyAll的原则：每一个await醒来的动作相同，每次最多唤醒一个线程来操作。显然这里符合这两种条件，因此使用signal要比使用signalAll要高效，并且是可靠的。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency22part7BlockingQueue2_1216F/image_10.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>上图描述了take()/put()的索引位置示意图。</p>
<p>一开始takeIndex/putIndex都在E/0位置，然后每加入一个元素offer/put，putIndex都增加1，也就是往后边移动一位；每移除一个元素poll/take，takeIndex都增加1，也是往后边移动一位，显然takeIndex总是在putIndex的“后边”，因为当队列中没有元素的时候takeIndex和putIndex相等，同时当前位置也没有元素，takeIndex也就是无法再往右边移动了；一旦putIndex/takeIndex移动到了最后面，也就是size-1的位置（这里size是指数组的长度），那么就移动到0，继续循环。循环的前提是数组中元素的个数小于数组的长度。整个过程就是这样的。可见putIndex同时指向头元素的下一个位置（如果队列已经满了，那么就是尾元素位置，否则就是一个元素为null的位置）。</p>
<p>比较复杂的操作时删除任意一个元素。清单3 描述的是删除任意一个元素的过程。显然删除任何一个元素需要遍历整个数组，也就是它的复杂度是O(n)，这与根据索引从ArrayList中查找一个元素的复杂度O(1)相比开销要大得多。参考声明的结构图，一旦删除的是takeIndex位置的元素，那么只需要将takeIndex往“右边”移动一位即可；如果删除的是takeIndex和putIndex之间的元素怎么办？这时候就从删除的位置i开始，将i后面的所有元素位置都往“左”移动一位，直到putIndex为止。最终的结果是删除位置的所有元素都“后退”了一个位置，同时putIndex也后退了一个位置。</p>
<p><strong><em>清单3 删除任意一个元素</em></strong>
public boolean remove(Object o) {
    if (o == null) return false;
    final E[] items = this.items;
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        int i = takeIndex;
        int k = 0;
        for (;;) {
            if (k++ &gt;= count)
                return false;
            if (o.equals(items[i])) {
                removeAt(i);
                return true;
            }
            i = inc(i);
        }</p>
<pre><code>} finally {
    lock.unlock();
}
</code></pre><p>}
void removeAt(int i) {
    final E[] items = this.items;
    // if removing front item, just advance
    if (i == takeIndex) {
        items[takeIndex] = null;
        takeIndex = inc(takeIndex);
    } else {
        // slide over all others up through putIndex.
        for (;;) {
            int nexti = inc(i);
            if (nexti != putIndex) {
                items[i] = items[nexti];
                i = nexti;
            } else {
                items[i] = null;
                putIndex = i;
                break;
            }
        }
    }
    --count;
    notFull.signal();
}</p>
<p>对于其他的操作，由于都是带着Lock的操作，所以都比较简单就不再展开了。</p>
<p>下一篇中将介绍另外两个BlockingQueue， PriorityBlockingQueue和SynchronousQueue 然后对这些常见的Queue进行一个小范围的对比。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/27/327265.html](http://www.blogjava.net/xylz/archive/2010/07/27/327265.html)">[http://www.blogjava.net/xylz/archive/2010/07/27/327265.html](http://www.blogjava.net/xylz/archive/2010/07/27/327265.html)</a> </p>
<p>在Set中有一个排序的集合SortedSet，用来保存按照自然顺序排列的对象。Queue中同样引入了一个支持排序的FIFO模型。</p>
<h3 id="-queue-http-www-blogjava-net-xylz-archive-2010-07-21-326723-html-priorityqueue-priorityblockingqueue-queue-queue-queue-priorityblockingqueue-priorityqueue-blocking-"><a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">并发队列与Queue简介</a> 中介绍了，PriorityQueue和PriorityBlockingQueue就是支持排序的Queue。显然一个支持阻塞的排序Queue要比一个非线程安全的Queue实现起来要复杂的多，因此下面只介绍PriorityBlockingQueue，至于PriorityQueue只需要去掉Blocking功能就基本相同了。</h3>
<p><strong>排序的BlockingQueue — PriorityBlockingQueue</strong></p>
<p>先简单介绍下PriorityQueue，因为PriorityBlockingQueue内部就是通过PriorityQueue适配实现的，只不过通过锁进行同步和阻塞而已。</p>
<p>PriorityQueue是一个数组实现的，是一个二叉树的实现，这个二叉树的任意一个节点都比其子节点要小，这样顶点就是最小的节点。每一个元素或者节点要么本身是可比较的（Comparable），或者队列本身带有一个比较器（Comparator&lt;? super E&gt;），所有元素就是靠比较自身的大小来确定顺序的。而数组中顶点就是数组的第0个元素，因此出队列的话总是取第0个元素。对于第0个元素，其子节点是第1个元素和第2个元素，对于第1个元素，其子元素又是第3/4个元素，以此类推，第i个元素的父节点就是(i-1)/2。这样任意一个元素加入队列就从其父节点(i-1)/2开始比较，一旦新节点比父节点小就交换两个节点，然后继续比较新节点与其新的父节点。知道所有节点都是按照父节点一定比子节点小的顺序排列。这是一个有点复杂的算法，此处不再讨论更多的细节。不管是删除还是查找，我们只需要了解的顶点（索引为0的元素）总是最小的。</p>
<p>特别需要说明的是PriorityQueue是一个无界的队列，也就是说一旦元素的个数达到了数组的大小，那么就将数组扩大50%，这样这个数组就是无穷大的。当然了如果达到了整数的最大值就会得到一个OutOfMemoryError，这个是由逻辑保证的。</p>
<p>对于PriorityBlockingQueue而言，由于是无界的，因此就只有非空的信号，也就是说只有take()才能阻塞，put是永远不会阻塞（除非达到Integer.MAX_VALUE直到抛出一个OutOfMemoryError异常）。</p>
<p>只有take()操作的时候才可能因为队列为空而挂起。同时其它需要操作队列变化和大小的只需要使用独占锁ReentrantLock就可以了，非常方便。需要说明的是PriorityBlockingQueue采用了一个公平的锁。</p>
<p>总的来说PriorityBlockingQueue 不是一个FIFO的队列，而是一个有序的队列，这个队列总是取“自然顺序”最小的对象，同时又是一个只能出队列阻塞的BlockingQueue，对于入队列却不是阻塞的。所有操作都是线程安全的。</p>
<p><strong>直接交换的BlockingQueue — SynchronousQueue</strong></p>
<p>这是一个很有意思的阻塞队列，其中每个插入操作必须等待另一个线程的移除操作，同样任何一个移除操作都等待另一个线程的插入操作。因此此队列内部其实没有任何一个元素，或者说容量是0，严格说并不是一种容器。由于队列没有容量，因此不能调用peek操作，因为只有移除元素时才有元素。</p>
<p>一个没有容量的并发队列有什么用了？或者说存在的意义是什么？</p>
<p>SynchronousQueue 的实现非常复杂，当然了如果真要去分析还是能够得到一些经验的，但是前面分析了过多的结构后，发现越来越陷于数据结构与算法里面了。我的初衷是通过研究并发实现的原理来更好的利用并发来最大限度的利用可用资源。所以在后面的章节中尽可能的少研究数据结构和算法，但是为了弄清楚里面的原理，必不可免的会涉及到一些这方面的知识，希望后面能够适可而止。</p>
<p>再回到话题。SynchronousQueue 内部没有容量，但是由于一个插入操作总是对应一个移除操作，反过来同样需要满足。那么一个元素就不会再SynchronousQueue 里面长时间停留，一旦有了插入线程和移除线程，元素很快就从插入线程移交给移除线程。也就是说这更像是一种信道（管道），资源从一个方向快速传递到另一方向。</p>
<p>需要特别说明的是，尽管元素在SynchronousQueue 内部不会“停留”，但是并不意味之SynchronousQueue 内部没有队列。实际上SynchronousQueue 维护者线程队列，也就是插入线程或者移除线程在不同时存在的时候就会有线程队列。既然有队列，同样就有公平性和非公平性特性，公平性保证正在等待的插入线程或者移除线程以FIFO的顺序传递资源。</p>
<p>显然这是一种快速传递元素的方式，也就是说在这种情况下元素总是以最快的方式从插入着（生产者）传递给移除着（消费者），这在多任务队列中是最快处理任务的方式。在线程池的相关章节中还会更多的提到此特性。</p>
<p>事实上在《<a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">并发队列与Queue简介</a>》中介绍了还有一种BlockingQueue的实现DelayQueue，它描述的是一种延时队列。这个队列的特性是，队列中的元素都要延迟时间（超时时间），只有一个元素达到了延时时间才能出队列，也就是说每次从队列中获取的元素总是最先到达延时的元素。这种队列的场景就是计划任务。比如以前要完成计划任务，很有可能是使用Timer/TimerTask，这是一种循环检测的方式，也就是在循环里面遍历所有元素总是检测元素是否满足条件，一旦满足条件就执行相关任务。显然这中方式浪费了很多的检测工作，因为大多数时间总是在进行无谓的检测。而DelayQueue 却能避免这种无谓的检测。在线程池的计划任务部分还有更加详细的讨论此队列实现。</p>
<p>下面就对常见的BlockingQueue进行小节下，这里不包括双向的队列，尽管ConcurrentLinkedQueue不是可阻塞的Queue，但是这里还是将其放在一起进行对比。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency23part8BlockingQueue3_1086D/image_2.png" target="_blank"><img src="&quot;并发队列比较&quot;" alt="并发队列比较"></a></p>
<p>如果不需要阻塞队列，优先选择ConcurrentLinkedQueue；如果需要阻塞队列，队列大小固定优先选择ArrayBlockingQueue，队列大小不固定优先选择LinkedBlockingQueue；如果需要对队列进行排序，选择PriorityBlockingQueue；如果需要一个快速交换的队列，选择SynchronousQueue；如果需要对队列中的元素进行延时操作，则选择DelayQueue。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/30/327582.html](http://www.blogjava.net/xylz/archive/2010/07/30/327582.html)">[http://www.blogjava.net/xylz/archive/2010/07/30/327582.html](http://www.blogjava.net/xylz/archive/2010/07/30/327582.html)</a> </p>
<p>有一段时间没有更新了。接着上节继续吧。</p>
<p>Queue除了前面介绍的实现外，还有一种双向的Queue实现Deque。这种队列允许在队列头和尾部进行入队出队操作，因此在功能上比Queue显然要更复杂。下图描述的是Deque的完整体系图。需要说明的是LinkedList也已经加入了Deque的一部分（LinkedList是从jdk1.2 开始就存在数据结构）。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency24part9Deque_1425C/image_2.png" target="_blank"><img src="&quot;Deque体系结构&quot;" alt="Deque体系结构"></a></p>
<p>Deque在Queue的基础上增加了更多的操作方法。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency24part9Deque_1425C/image_4.png" target="_blank"><img src="&quot;Deque操作方法&quot;" alt="Deque操作方法"></a></p>
<p>从上图可以看到，Deque不仅具有FIFO的Queue实现，也有FILO的实现，也就是不仅可以实现队列，也可以实现一个堆栈。</p>
<p>同时在Deque的体系结构图中可以看到，实现一个Deque可以使用数组（ArrayDeque），同时也可以使用链表（LinkedList），还可以同实现一个支持阻塞的线程安全版本队列LinkedBlockingDeque。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency24part9Deque_1425C/image_6.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>对于数组实现的Deque来说，数据结构上比较简单，只需要一个存储数据的数组以及头尾两个索引即可。由于数组是固定长度的，所以很容易就得到数组的头和尾，那么对于数组的操作只需要移动头和尾的索引即可。</p>
<p>特别说明的是ArrayDeque并不是一个固定大小的队列，每次队列满了以后就将队列容量扩大一倍（doubleCapacity()），因此加入一个元素总是能成功，而且也不会抛出一个异常。也就是说ArrayDeque是一个没有容量限制的队列。</p>
<p>同样继续性能的考虑，使用System.arraycopy复制一个数组比循环设置要高效得多。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency24part9Deque_1425C/image_8.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>对于LinkedList本身而言，数据结构就更简单了，除了一个size用来记录大小外，只有head一个元素Entry。对比Map和Queue的其它数据结构可以看到这里的Entry有两个引用，是双向的队列。</p>
<p>在示意图中，LinkedList总是有一个“傀儡”节点，用来描述队列“头部”，但是并不表示头部元素，它是一个执行null的空节点。</p>
<p>队列一开始只有head一个空元素，然后从尾部加入E1(add/addLast)，head和E1之间建立双向链接。然后继续从尾部加入E2，E2就在head和E1之间建立双向链接。最后从队列的头部加入E3(push/addFirst)，于是E3就在E1和head之间链接双向链接。</p>
<p>双向链表的数据结构比较简单，操作起来也比较容易，从事从“傀儡”节点开始，“傀儡”节点的下一个元素就是队列的头部，前一个元素是队列的尾部，换句话说，“傀儡”节点在头部和尾部之间建立了一个通道，是整个队列形成一个循环，这样就可以从任意一个节点的任意一个方向能遍历完整的队列。</p>
<p>同样LinkedList也是一个没有容量限制的队列，因此入队列（不管是从头部还是尾部）总能成功。</p>
<p>上面描述的ArrayDeque和LinkedList是两种不同方式的实现，通常在遍历和节省内存上ArrayDeque更高效（索引更快，另外不需要Entry对象），但是在队列扩容下LinkedList更灵活，因为不需要复制原始的队列，某些情况下可能更高效。</p>
<p>同样需要注意的上述两个实现都不是线程安全的，因此只适合在单线程环境下使用，下面章节要介绍的LinkedBlockingDeque就是线程安全的可阻塞的Deque。事实上也应该是功能最强大的Queue实现，当然了实现起来也许会复杂一点。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/08/12/328587.html](http://www.blogjava.net/xylz/archive/2010/08/12/328587.html)">[http://www.blogjava.net/xylz/archive/2010/08/12/328587.html](http://www.blogjava.net/xylz/archive/2010/08/12/328587.html)</a> </p>
<p>这个小节介绍Queue的最后一个工具，也是最强大的一个工具。从名称上就可以看到此工具的特点：双向并发阻塞队列。所谓双向是指可以从队列的头和尾同时操作，并发只是线程安全的实现，阻塞允许在入队出队不满足条件时挂起线程，这里说的队列是指支持FIFO/FILO实现的链表。</p>
<p>首先看下LinkedBlockingDeque的数据结构。通常情况下从数据结构上就能看出这种实现的优缺点，这样就知道如何更好的使用工具了。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency25part10BlockingDeque_CB65/image_2.png" target="_blank"><img src="&quot;LinkedBlockingDeque类图&quot;" alt="LinkedBlockingDeque类图"></a></p>
<p>从数据结构和功能需求上可以得到以下结论：</p>
<ol>
<li>要想支持阻塞功能，队列的容量一定是固定的，否则无法在入队的时候挂起线程。也就是capacity是final类型的。</li>
<li>既然是双向链表，每一个结点就需要前后两个引用，这样才能将所有元素串联起来，支持双向遍历。也即需要prev/next两个引用。</li>
<li>双向链表需要头尾同时操作，所以需要first/last两个节点，当然可以参考LinkedList那样采用一个节点的双向来完成，那样实现起来就稍微麻烦点。</li>
<li>既然要支持阻塞功能，就需要锁和条件变量来挂起线程。这里使用一个锁两个条件变量来完成此功能。</li>
</ol>
<p>有了上面的结论再来研究LinkedBlockingDeque的优缺点。</p>
<p>优点当然是功能足够强大，同时由于采用一个独占锁，因此实现起来也比较简单。所有对队列的操作都加锁就可以完成。同时独占锁也能够很好的支持双向阻塞的特性。</p>
<p>凡事有利必有弊。缺点就是由于独占锁，所以不能同时进行两个操作，这样性能上就大打折扣。从性能的角度讲LinkedBlockingDeque要比LinkedBlockingQueue要低很多，比CocurrentLinkedQueue就低更多了，这在高并发情况下就比较明显了。</p>
<p>前面分析足够多的Queue实现后，LinkedBlockingDeque的原理和实现就不值得一提了，无非是在独占锁下对一个链表的普通操作。</p>
<p>有趣的是此类支持序列化，但是Node并不支持序列化，因此fist/last就不能序列化，那么如何完成序列化/反序列化过程呢？</p>
<p><strong><em>清单1 LinkedBlockingDeque的序列化、反序列化</em></strong>
private void writeObject(java.io.ObjectOutputStream s)
    throws java.io.IOException {
    lock.lock();
    try {
        // Write out capacity and any hidden stuff
        s.defaultWriteObject();
        // Write out all elements in the proper order.
        for (Node<E> p = first; p != null; p = p.next)
            s.writeObject(p.item);
        // Use trailing null as sentinel
        s.writeObject(null);
    } finally {
        lock.unlock();
    }
}</p>
<p>private void readObject(java.io.ObjectInputStream s)
    throws java.io.IOException, ClassNotFoundException {
    s.defaultReadObject();
    count = 0;
    first = null;
    last = null;
    // Read in all elements and place in queue
    for (;;) {
        E item = (E)s.readObject();
        if (item == null)
            break;
        add(item);
    }
}</p>
<p>清单1 描述的是LinkedBlockingDeque序列化/反序列化的过程。序列化时将真正的元素写入输出流，最后还写入了一个null。读取的时候将所有对象列表读出来，如果读取到一个null就表示结束。这就是为什么写入的时候写入一个null的原因，因为没有将count写入流，所以就靠null来表示结束，省一个整数空间。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/08/18/329227.html](http://www.blogjava.net/xylz/archive/2010/08/18/329227.html)">[http://www.blogjava.net/xylz/archive/2010/08/18/329227.html](http://www.blogjava.net/xylz/archive/2010/08/18/329227.html)</a> </p>
<p>可以在对中对元素进行配对和交换的线程的同步点。每个线程将条目上的某个方法呈现给 </p>
<p>exchange
 方法，与伙伴线程进行匹配，并且在返回时接收其伙伴的对象。Exchanger 可能被视为 </p>
<p>SynchronousQueue
 的双向形式。</p>
<p>换句话说Exchanger提供的是一个交换服务，允许原子性的交换两个（多个）对象，但同时只有一对才会成功。先看一个简单的实例模型。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-26--part-11--BlockingD_12273/Exchanger_2.png" target="_blank"><img src="&quot;Exchanger&quot;" alt="Exchanger"></a></p>
<p>在上面的模型中，我们假定一个空的栈（Stack），栈顶（Top）当然是没有元素的。同时我们假定一个数据结构Node，包含一个要交换的元素E和一个要填充的“洞”Node。这时线程T1携带节点node1进入栈（cas_push)，当然这是CAS操作，这样栈顶就不为空了。线程T2携带节点node2进入栈，发现栈里面已经有元素了node1，同时发现node1的hold（Node）为空，于是将自己（node2）填充到node1的hold中（cas_fill）。然后将元素node1从栈中弹出（cas_take）。这样线程T1就得到了node1.hold.item也就是node2的元素e2，线程T2就得到了node1.item也就是e1，从而达到了交换的目的。</p>
<p>算法描述就是下图展示的内容。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-26--part-11--BlockingD_12273/image_4.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>JDK 5就是采用类似的思想实现的Exchanger。JDK 6以后为了支持多线程多对象同时Exchanger了就进行了改造（为了支持更好的并发），采用ConcurrentHashMap的思想，将Stack分割成很多的片段（或者说插槽Slot），线程Id（Thread.getId()）hash相同的落在同一个Slot上，这样在默认32个Slot上就有很好的吞吐量。当然会根据机器CPU内核的数量有一定的优化，有兴趣的可以去了解下Exchanger的源码。</p>
<p>至于Exchanger的使用，在JDK文档上有个例子，讲述的是两个线程交换数据缓冲区的例子（实际上仍然可以认为是生产者/消费者模型）。
class FillAndEmpty {
   Exchanger<DataBuffer> exchanger = new Exchanger<DataBuffer>();
   DataBuffer initialEmptyBuffer = <img src="" alt=""> a made-up type
   DataBuffer initialFullBuffer = <img src="" alt="">
   class FillingLoop implements Runnable {
     public void run() {
       DataBuffer currentBuffer = initialEmptyBuffer;
       try {
         while (currentBuffer != null) {
           addToBuffer(currentBuffer);
           if (currentBuffer.isFull())
             currentBuffer = exchanger.exchange(currentBuffer);
         }
       } catch (InterruptedException ex) { <img src="" alt=""> handle <img src="" alt=""> }
     }
   }
   class EmptyingLoop implements Runnable {
     public void run() {
       DataBuffer currentBuffer = initialFullBuffer;
       try {
         while (currentBuffer != null) {
           takeFromBuffer(currentBuffer);
           if (currentBuffer.isEmpty())
             currentBuffer = exchanger.exchange(currentBuffer);
         }
       } catch (InterruptedException ex) { <img src="" alt=""> handle <img src="" alt="">}
     }
   }
   void start() {
     new Thread(new FillingLoop()).start();
     new Thread(new EmptyingLoop()).start();
   }
  }</p>
<p>Exchanger实现的是一种数据分片的思想，这在大数据情况下将数据分成一定的片段并且多线程执行的情况下有一定的使用价值。</p>
<p>最近一直推托工作忙，更新频度越来越低了，好在现在的工作还有点个人时间，以后争取多更新下吧，至少也要把这个专辑写完。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/11/22/338733.html](http://www.blogjava.net/xylz/archive/2010/11/22/338733.html)">[http://www.blogjava.net/xylz/archive/2010/11/22/338733.html](http://www.blogjava.net/xylz/archive/2010/11/22/338733.html)</a> </p>
<p>本小节是《并发容器》的最后一部分，这一个小节描述的是针对List/Set接口的一个线程版本。</p>
<p>在《<a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">并发队列与Queue简介</a>》中介绍了并发容器的一个概括，主要描述的是Queue的实现。其中特别提到一点LinkedList是List/Queue的实现，但是LinkedList确实非线程安全的。不管BlockingQueue还是ConcurrentMap的实现，我们发现都是针对链表的实现，当然尽可能的使用CAS或者Lock的特性，同时都有通过锁部分容器来提供并发的特性。而对于List或者Set而言，增、删操作其实都是针对整个容器，因此每次操作都不可避免的需要锁定整个容器空间，性能肯定会大打折扣。要实现一个线程安全的List/Set，只需要在修改操作的时候进行同步即可，比如使用java.util.Collections.synchronizedList(List<T>)或者java.util.Collections.synchronizedSet(Set<T>)。当然也可以使用Lock来实现线程安全的List/Set。</p>
<p>通常情况下我们的高并发都发生在“多读少写”的情况，因此如果能够实现一种更优秀的算法这对生产环境还是很有好处的。ReadWriteLock当然是一种实现。CopyOnWriteArrayList/CopyOnWriteArraySet确实另外一种思路。</p>
<p>CopyOnWriteArrayList/CopyOnWriteArraySet的基本思想是一旦对容器有修改，那么就“复制”一份新的集合，在新的集合上修改，然后将新集合复制给旧的引用。当然了这部分少不了要加锁。显然对于CopyOnWriteArrayList/CopyOnWriteArraySet来说最大的好处就是“读”操作不需要锁了。</p>
<p>我们来看看源码。
//<em>/</em> The array, accessed only via getArray/setArray. /*/
private volatile transient Object[] array;
public E get(int index) {
    return (E)(getArray()[index]);
}
private static int indexOf(Object o, Object[] elements,
                           int index, int fence) {
    if (o == null) {
        for (int i = index; i &lt; fence; i++)
            if (elements[i] == null)
                return i;
    } else {
        for (int i = index; i &lt; fence; i++)
            if (o.equals(elements[i]))
                return i;
    }
    return -1;
}
public Iterator<E> iterator() {
    return new COWIterator<E>(getArray(), 0);
}
    public void clear() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        setArray(new Object[0]);
    } finally {
        lock.unlock();
    }
    }</p>
<p>对于上述代码，有几点说明：</p>
<ol>
<li>List仍然是基于数组的实现，因为只有数组是最快的。</li>
<li>为了保证无锁的读操作能够看到写操作的变化，因此数组array是volatile类型的。</li>
<li>get/indexOf/iterator等操作都是无锁的，同时也可以看到所操作的都是某一时刻array的镜像（这得益于数组是不可变化的）</li>
<li>add/set/remove/clear等元素变化的都是需要加锁的，这里使用的是ReentrantLock。</li>
</ol>
<p>这里有一段有意思的代码片段。
    public E set(int index, E element) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        Object[] elements = getArray();
        Object oldValue = elements[index];
        if (oldValue != element) {
        int len = elements.length;
        Object[] newElements = Arrays.copyOf(elements, len);
        newElements[index] = element;
        setArray(newElements);
        } else {
        // Not quite a no-op; ensures volatile write semantics
        setArray(elements);
        }
        return (E)oldValue;
    } finally {
        lock.unlock();
    }
    }
final void setArray(Object[] a) {
    array = a;
}</p>
<p>对于set操作，如果元素有变化，修改后setArray(newElements);将新数组赋值还好理解。那么如果一个元素没有变化，也就是上述代码的else部分，为什么还需要进行一个无谓的setArray操作？毕竟setArray操作没有改变任何数据。</p>
<p>对于这个问题也是很有意思，有一封邮件讨论了此问题（<a href="http://cs.oswego.edu/pipermail/concurrency-interest/2010-February/006886.html" target="_blank">1</a>、<a href="http://cs.oswego.edu/pipermail/concurrency-interest/2010-February/006887.html" target="_blank">2</a>、<a href="http://cs.oswego.edu/pipermail/concurrency-interest/2010-February/006888.html" target="_blank">3</a>）。
大致的意思是，尽管没有改变任何数据，但是为了保持“volatile”的语义，任何一个读操作都应该是一个写操作的结果，也就是读操作看到的数据一定是某个写操作的结果（尽管写操作没有改变数据本身）。所以这里即使不设置也没有问题，仅仅是为了一个语义上的补充（个人理解）。</p>
<p>这里还有一个有意思的讨论，说什么addIfAbsent在元素没有变化的时候为什么没有setArray操作？这个要看怎么理解addIfAbsent的语义了。如果说addIfAbsent语义是”写“或者”不写“操作，而把”不写“操作当作一次”读“操作的话，那么”读“操作就不需要保持volatile语义了。</p>
<p>对于CopyOnWriteArraySet而言就简单多了，只是持有一个CopyOnWriteArrayList，仅仅在add/addAll的时候检测元素是否存在，如果存在就不加入集合中。
private final CopyOnWriteArrayList<E> al;
//<em>/</em>
/<em> Creates an empty set.
/</em>/
public CopyOnWriteArraySet() {
    al = new CopyOnWriteArrayList<E>();
}
public boolean add(E e) {
    return al.addIfAbsent(e);
}</p>
<p>在使用上CopyOnWriteArrayList/CopyOnWriteArraySet就简单多了，和List/Set基本相同，这里就不再介绍了。</p>
<p>整个并发容器结束了，接下来好好规划下线程池部分，然后进入最后一部分的梳理。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/11/23/338853.html](http://www.blogjava.net/xylz/archive/2010/11/23/338853.html)">[http://www.blogjava.net/xylz/archive/2010/11/23/338853.html](http://www.blogjava.net/xylz/archive/2010/11/23/338853.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency4-并发容器/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency4-并发容器" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency3-锁机制/">深入浅出 Java Concurrency (3)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency3-锁机制/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-3-">深入浅出 Java Concurrency (3): 锁机制</h1>
<p>前面的章节主要谈谈原子操作，至于与原子操作一些相关的问题或者说陷阱就放到最后的总结篇来整体说明。从这一章开始花少量的篇幅谈谈锁机制。</p>
<p><a href="http://www.blogjava.net/xylz/archive/2010/07/04/325206.html" target="_blank">上一个章节</a>中谈到了锁机制，并且针对于原子操作谈了一些相关的概念和设计思想。接下来的文章中，尽可能的深入研究锁机制，并且理解里面的原理和实际应用场合。</p>
<p>尽管synchronized在语法上已经足够简单了，在JDK 5之前只能借助此实现，但是由于是独占锁，性能却不高，因此JDK 5以后就开始借助于JNI来完成更高级的锁实现。</p>
<p>JDK 5中的锁是接口<strong>java.util.concurrent.locks.Lock</strong>。另外<strong>java.util.concurrent.locks.ReadWriteLock</strong>提供了一对可供读写并发的锁。根据前面的规则，我们从<strong>java.util.concurrent.locks.Lock</strong>的API开始。</p>
<p><strong>void lock();</strong></p>
<p>获取锁。</p>
<p>如果锁不可用，出于线程调度目的，将禁用当前线程，并且在获得锁之前，该线程将一直处于休眠状态。</p>
<p><strong>void lockInterruptibly() throws InterruptedException;</strong></p>
<p>如果当前线程未被中断，则获取锁。</p>
<p>如果锁可用，则获取锁，并立即返回。</p>
<p>如果锁不可用，出于线程调度目的，将禁用当前线程，并且在发生以下两种情况之一以前，该线程将一直处于休眠状态：</p>
<ul>
<li>锁由当前线程获得；或者</li>
<li>其他某个线程<a href="http://www.blogjava.net/xylz/java/lang/Thread.html#interrupt(" target="_blank">中断</a>)当前线程，并且支持对锁获取的中断。</li>
</ul>
<p>如果当前线程：</p>
<ul>
<li>在进入此方法时已经设置了该线程的中断状态；或者</li>
<li>在获取锁时被<a href="http://www.blogjava.net/xylz/java/lang/Thread.html#interrupt(" target="_blank">中断</a>)，并且支持对锁获取的中断，
则将抛出 </li>
</ul>
<p>InterruptedException
，并清除当前线程的已中断状态。</p>
<p><strong>Condition newCondition();</strong></p>
<p>返回绑定到此 </p>
<p>Lock
 实例的新 </p>
<p>Condition
 实例。下一小节中会重点谈Condition，此处不做过多的介绍。</p>
<p><strong>boolean tryLock();</strong></p>
<p>仅在调用时锁为空闲状态才获取该锁。</p>
<p>如果锁可用，则获取锁，并立即返回值 </p>
<p>true
。如果锁不可用，则此方法将立即返回值 </p>
<p>false
。</p>
<p>通常对于那些不是必须获取锁的操作可能有用。</p>
<p><strong>boolean tryLock(long time, TimeUnit unit) throws InterruptedException;</strong></p>
<p>如果锁在给定的等待时间内空闲，并且当前线程未被中断，则获取锁。</p>
<p>如果锁可用，则此方法将立即返回值 </p>
<p>true
。如果锁不可用，出于线程调度目的，将禁用当前线程，并且在发生以下三种情况之一前，该线程将一直处于休眠状态：</p>
<ul>
<li>锁由当前线程获得；或者</li>
<li>其他某个线程中断当前线程，并且支持对锁获取的中断；或者</li>
<li>已超过指定的等待时间</li>
</ul>
<p>如果获得了锁，则返回值 </p>
<p>true
。</p>
<p>如果当前线程：</p>
<ul>
<li>在进入此方法时已经设置了该线程的中断状态；或者</li>
<li>在获取锁时被中断，并且支持对锁获取的中断，
则将抛出 </li>
</ul>
<p>InterruptedException
，并会清除当前线程的已中断状态。</p>
<p>如果超过了指定的等待时间，则将返回值 </p>
<p>false
。如果 time 小于等于 0，该方法将完全不等待。</p>
<p><strong>void unlock();</strong></p>
<p>释放锁。对应于lock()、tryLock()、tryLock(xx)、lockInterruptibly()等操作，如果成功的话应该对应着一个unlock()，这样可以避免死锁或者资源浪费。</p>
<p>相对于比较空洞的API，来看一个实际的例子。下面的代码实现了一个类似于AtomicInteger的操作。
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;</p>
<p>public class AtomicIntegerWithLock {</p>
<pre><code>private int value;

private Lock lock = new ReentrantLock();

public AtomicIntegerWithLock() {
    super();
}

public AtomicIntegerWithLock(int value) {
    this.value = value;
}

public final int get() {
    lock.lock();
    try {
        return value;
    } finally {
        lock.unlock();
    }
}

public final void set(int newValue) {
    lock.lock();
    try {
        value = newValue;
    } finally {
        lock.unlock();
    }

}

public final int getAndSet(int newValue) {
    lock.lock();
    try {
        int ret = value;
        value = newValue;
        return ret;
    } finally {
        lock.unlock();
    }
}

public final boolean compareAndSet(int expect, int update) {
    lock.lock();
    try {
        if (value == expect) {
            value = update;
            return true;
        }
        return false;
    } finally {
        lock.unlock();
    }
}

public final int getAndIncrement() {
    lock.lock();
    try {
        return value++;
    } finally {
        lock.unlock();
    }
}

public final int getAndDecrement() {
    lock.lock();
    try {
        return value--;
    } finally {
        lock.unlock();
    }
}

public final int incrementAndGet() {
    lock.lock();
    try {
        return ++value;
    } finally {
        lock.unlock();
    }
}

public final int decrementAndGet() {
    lock.lock();
    try {
        return --value;
    } finally {
        lock.unlock();
    }
}

public String toString() {
    return Integer.toString(get());
}
</code></pre><p>}</p>
<p>类<strong>AtomicIntegerWithLock</strong>是线程安全的，此结构中大量使用了Lock对象的lock/unlock方法对。同样可以看到的是对于自增和自减操作使用了++/--。之所以能够保证线程安全，是因为Lock对象的lock()方法保证了只有一个线程能够只有此锁。需要说明的是对于任何一个lock()方法，都需要一个unlock()方法与之对于，通常情况下为了保证unlock方法总是能够得到执行，unlock方法被置于finally块中。另外这里使用了<strong>java.util.concurrent.locks.ReentrantLock.ReentrantLock</strong>对象，下一个小节中会具体描述此类作为Lock的唯一实现是如何设计和实现的。</p>
<p>尽管synchronized实现Lock的相同语义，并且在语法上比Lock要简单多，但是前者却比后者的开销要大得多。做一个简单的测试。
public static void main(String[] args) throws Exception{
     final int max = 10;
     final int loopCount = 100000;
     long costTime = 0;
     for (int m = 0; m &lt; max; m++) {
         long start1 = System.nanoTime();
         final AtomicIntegerWithLock value1 = new AtomicIntegerWithLock(0);
         Thread[] ts = new Thread[max];
         for(int i=0;i&lt;max;i++) {
             ts[i] = new Thread() {
                 public void run() {
                     for (int i = 0; i &lt; loopCount; i++) {
                         value1.incrementAndGet();
                     }
                 }
             };
         }
         for(Thread t:ts) {
             t.start();
         }
         for(Thread t:ts) {
             t.join();
         }
         long end1 = System.nanoTime();
         costTime += (end1-start1);
     }
     System.out.println(&quot;cost1: &quot; + (costTime));
     //
     System.out.println();
     costTime = 0;
     //
     final Object lock = new Object();
     for (int m = 0; m &lt; max; m++) {
         staticValue=0;
         long start1 = System.nanoTime();
         Thread[] ts = new Thread[max];
         for(int i=0;i&lt;max;i++) {
             ts[i] = new Thread() {
                 public void run() {
                     for (int i = 0; i &lt; loopCount; i++) {
                         synchronized(lock) {
                             ++staticValue;
                         }
                     }
                 }
             };
         }
         for(Thread t:ts) {
             t.start();
         }
         for(Thread t:ts) {
             t.join();
         }
         long end1 = System.nanoTime();
         costTime += (end1-start1);
     }
     //
     System.out.println(&quot;cost2: &quot; + (costTime));
}</p>
<p>static int staticValue = 0;</p>
<p>在这个例子中每次启动10个线程，每个线程计算100000次自增操作，重复测试10次，下面是某此测试的结果：</p>
<p>cost1: 624071136</p>
<p>cost2: 2057847833</p>
<p>尽管上面的例子不是非常正式的测试案例，但上面的例子在于说明，Lock的性能比synchronized的要好得多。如果可以的话总是使用Lock替代synchronized是一个明智的选择。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/05/325274.html](http://www.blogjava.net/xylz/archive/2010/07/05/325274.html)">[http://www.blogjava.net/xylz/archive/2010/07/05/325274.html](http://www.blogjava.net/xylz/archive/2010/07/05/325274.html)</a> </p>
<p>在理解J.U.C原理以及锁机制之前，我们来介绍J.U.C框架最核心也是最复杂的一个基础类：<strong>java.util.concurrent.locks.AbstractQueuedSynchronizer</strong>。</p>
<p><strong>AQS</strong></p>
<p>AbstractQueuedSynchronizer，简称AQS，是J.U.C最复杂的一个类，导致绝大多数讲解并发原理或者实战的时候都不会提到此类。但是虚心的作者愿意借助自己有限的能力和精力来探讨一二（参考资源中也有一些作者做了部分的分析。）。</p>
<p>首先从理论知识开始，在了解了相关原理后会针对源码进行一些分析，最后加上一些实战来描述。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency72_93BD/image_2.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>上面的继承体系中，AbstractQueuedSynchronizer是CountDownLatch/FutureTask/ReentrantLock/RenntrantReadWriteLock/Semaphore的基础，因此AbstractQueuedSynchronizer是Lock/Executor实现的前提。公平锁、不公平锁、Condition、CountDownLatch、Semaphore等放到后面的篇幅中说明。</p>
<p>完整的设计原理可以参考Doug Lea的论文 <a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf" target="_blank"><em>The java</em>.<em>util</em>.<em>concurrent Synchronizer Framework</em></a> ，这里做一些简要的分析。</p>
<p>基本的思想是表现为一个同步器，支持下面两个操作：</p>
<p>获取锁：首先判断当前状态是否允许获取锁，如果是就获取锁，否则就阻塞操作或者获取失败，也就是说如果是独占锁就可能阻塞，如果是共享锁就可能失败。另外如果是阻塞线程，那么线程就需要进入阻塞队列。当状态位允许获取锁时就修改状态，并且如果进了队列就从队列中移除。
while(synchronization state does not allow acquire){</p>
<pre><code>enqueue current thread if not already queued;

possibly block current thread;
</code></pre><p>}</p>
<p>dequeue current thread if it was queued;</p>
<p>释放锁:这个过程就是修改状态位，如果有线程因为状态位阻塞的话就唤醒队列中的一个或者更多线程。</p>
<p>update synchronization state;</p>
<p>if(state may permit a blocked thread to acquire)</p>
<pre><code>unlock one or more queued threads;
</code></pre><p>要支持上面两个操作就必须有下面的条件：</p>
<ul>
<li>原子性操作同步器的状态位</li>
<li>阻塞和唤醒线程</li>
<li>一个有序的队列</li>
</ul>
<p>目标明确，要解决的问题也清晰了，那么剩下的就是解决上面三个问题。</p>
<p><strong>状态位的原子操作</strong></p>
<p>这里使用一个32位的整数来描述状态位，前面章节的原子操作的理论知识整好派上用场，在这里依然使用CAS操作来解决这个问题。事实上这里还有一个64位版本的同步器（AbstractQueuedLongSynchronizer），这里暂且不谈。</p>
<p><strong>阻塞和唤醒线程</strong></p>
<p>标准的JAVA API里面是无法挂起（阻塞）一个线程，然后在将来某个时刻再唤醒它的。JDK 1.0的API里面有Thread.suspend和Thread.resume，并且一直延续了下来。但是这些都是过时的API，而且也是不推荐的做法。</p>
<p>在JDK 5.0以后利用JNI在LockSupport类中实现了此特性。
LockSupport.park()
LockSupport.park(Object)
LockSupport.parkNanos(Object, long)
LockSupport.parkNanos(long)
LockSupport.parkUntil(Object, long)
LockSupport.parkUntil(long)
LockSupport.unpark(Thread)</p>
<p>上面的API中park()是在当前线程中调用，导致线程阻塞，带参数的Object是挂起的对象，这样监视的时候就能够知道此线程是因为什么资源而阻塞的。由于park()立即返回，所以通常情况下需要在循环中去检测竞争资源来决定是否进行下一次阻塞。park()返回的原因有三：</p>
<ul>
<li>其他某个线程调用将当前线程作为目标调用 <a href="http://www.blogjava.net/xylz/java/util/concurrent/locks/LockSupport.html#unpark(java.lang.Thread">
unpark
</a>)；</li>
<li>其他某个线程<a href="http://www.blogjava.net/xylz/java/lang/Thread.html#interrupt(" target="_blank">中断</a>)当前线程；</li>
<li>该调用不合逻辑地（即毫无理由地）返回。</li>
</ul>
<p>其实第三条就决定了需要循环检测了，类似于通常写的while(checkCondition()){Thread.sleep(time);}类似的功能。</p>
<p><strong>有序队列</strong></p>
<p>在AQS中采用CHL列表来解决有序的队列的问题。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency72_93BD/image_6.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>AQS采用的CHL模型采用下面的算法完成FIFO的入队列和出队列过程。</p>
<p>对于入队列(<em>enqueue)：</em>采用CAS操作，每次比较尾结点是否一致，然后插入的到尾结点中。
do {</p>
<pre><code>    pred = tail;
</code></pre><p>}while ( !compareAndSet(pred,tail,node) );</p>
<p>对于出队列(<em>dequeue</em>):由于每一个节点也缓存了一个状态，决定是否出队列，因此当不满足条件时就需要自旋等待，一旦满足条件就将头结点设置为下一个节点。</p>
<p>while (pred.status != RELEASED) ;</p>
<p>head  = node;</p>
<p>实际上这里自旋等待也是使用LockSupport.park()来实现的。</p>
<p>AQS里面有三个核心字段：
private volatile int state;</p>
<p>private transient volatile Node head;</p>
<p>private transient volatile Node tail;</p>
<p>其中state描述的有多少个线程取得了锁，对于互斥锁来说state&lt;=1。head/tail加上CAS操作就构成了一个CHL的FIFO队列。下面是Node节点的属性。</p>
<p><strong><em>volatile int waitStatus;</em></strong> 节点的等待状态，一个节点可能位于以下几种状态：</p>
<ul>
<li>CANCELLED = 1： 节点操作因为超时或者对应的线程被interrupt。节点不应该留在此状态，一旦达到此状态将从CHL队列中踢出。</li>
<li>SIGNAL = -1： 节点的继任节点是（或者将要成为）BLOCKED状态（例如通过LockSupport.park()操作），因此一个节点一旦被释放（解锁）或者取消就需要唤醒（LockSupport.unpack()）它的继任节点。</li>
<li>CONDITION = -2：表明节点对应的线程因为不满足一个条件（Condition）而被阻塞。</li>
<li>0： 正常状态，新生的非CONDITION节点都是此状态。</li>
<li>非负值标识节点不需要被通知（唤醒）。</li>
</ul>
<p><strong><em>volatile Node prev;</em></strong>此节点的前一个节点。节点的waitStatus依赖于前一个节点的状态。</p>
<p><strong><em>volatile Node next;</em></strong>此节点的后一个节点。后一个节点是否被唤醒（uppark()）依赖于当前节点是否被释放。</p>
<p><strong><em>volatile Thread thread;</em></strong>节点绑定的线程。</p>
<p><strong><em>Node nextWaiter;</em></strong>下一个等待条件（Condition）的节点，由于Condition是独占模式，因此这里有一个简单的队列来描述Condition上的线程节点。</p>
<p><strong>AQS 在J.U.C里面是一个非常核心的工具，而且也非常复杂，里面考虑到了非常多的逻辑实现，所以在后面的章节中总是不断的尝试介绍AQS的特性和实现。</strong></p>
<p>这一个小节主要介绍了一些理论背景和相关的数据结构，在下一个小节中将根据以上知识来了解Lock.lock/unlock是如何实现的。</p>
<p>参考资料：</p>
<p>（1）<a href="http://www.cnblogs.com/MichaelPeng/archive/2010/02/12/1667947.html" target="_blank">ReentrantLock代码剖析之ReentrantLock.lock</a> <a href="http://www.cnblogs.com/MichaelPeng/archive/2010/02/17/1668986.html" target="_blank">ReentrantLock代码剖析之ReentrantLock.unlock</a> <a href="http://www.cnblogs.com/MichaelPeng/archive/2010/02/18/1669150.html" target="_blank">ReentrantLock代码剖析之ReentrantLock.lockInterruptibly</a></p>
<p>（2）<a href="http://wagtto.javaeye.com/blog/607848" target="_blank">java多线程--java.util.concurrent.locks.AbstractQueuedSynchronizer解析(只包含多线程同步示例)</a></p>
<p>（3）<a href="http://www.ibm.com/developerworks/cn/java/j-jtp05236.html" target="_blank">处理 InterruptedException</a></p>
<p>（4）<a href="http://hi.baidu.com/gefforey520/blog/item/6f64eb442300a446500ffe3f.html" target="_blank">AbstractQueuedSynchronizer源码解析之ReentrantLock(一)</a>  <a href="http://hi.baidu.com/gefforey520/blog/item/ce633582511217a80df4d26c.html" target="_blank">AbstractQueuedSynchronizer源码解析之ReentrantLock(二)</a></p>
<p>（5）<a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf" target="_blank"><em>The java</em>.<em>util</em>.<em>concurrent Synchronizer Framework</em></a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/06/325390.html](http://www.blogjava.net/xylz/archive/2010/07/06/325390.html)">[http://www.blogjava.net/xylz/archive/2010/07/06/325390.html](http://www.blogjava.net/xylz/archive/2010/07/06/325390.html)</a> </p>
<p>接上篇，这篇从Lock.lock/unlock开始。特别说明在没有特殊情况下所有程序、API、文档都是基于JDK 6.0的。</p>
<p><strong>public void java.util.concurrent.locks.ReentrantLock.lock()</strong>
<em>获取锁。</em></p>
<p><em>如果该锁没有被另一个线程保持，则获取该锁并立即返回，将锁的保持计数设置为 1。</em></p>
<p><em>如果当前线程已经保持该锁，则将保持计数加 1，并且该方法立即返回。</em></p>
<p><em>如果该锁被另一个线程保持，则出于线程调度的目的，禁用当前线程，并且在获得锁之前，该线程将一直处于休眠状态，此时锁保持计数被设置为 1。</em></p>
<p>从上面的文档可以看出ReentrantLock是可重入锁的实现。而内部是委托java.util.concurrent.locks.ReentrantLock.Sync.lock()实现的。java.util.concurrent.locks.ReentrantLock.Sync是抽象类，有java.util.concurrent.locks.ReentrantLock.FairSync和java.util.concurrent.locks.ReentrantLock.NonfairSync两个实现，也就是常说的公平锁和不公平锁。</p>
<p><strong>公平锁和非公平锁</strong>
如果获取一个锁是按照请求的顺序得到的，那么就是公平锁，否则就是非公平锁。</p>
<p>在没有深入了解内部机制及实现之前，先了解下为什么会存在公平锁和非公平锁。公平锁保证一个阻塞的线程最终能够获得锁，因为是有序的，所以总是可以按照请求的顺序获得锁。不公平锁意味着后请求锁的线程可能在其前面排列的休眠线程恢复前拿到锁，这样就有可能提高并发的性能。这是因为通常情况下挂起的线程重新开始与它真正开始运行，二者之间会产生严重的延时。因此非公平锁就可以利用这段时间完成操作。这是非公平锁在某些时候比公平锁性能要好的原因之一。</p>
<p>二者在实现上的区别会在后面介绍，我们先从公平锁（FairSync）开始。</p>
<p>前面说过<strong>java.util.concurrent.locks.AbstractQueuedSynchronizer （AQS)</strong>是Lock的基础，对于一个FairSync而言，lock()就直接调用AQS的acquire(int arg);
<strong>public final void acquire(int arg)</strong> <em>以独占模式获取对象，忽略中断。通过至少调用一次 </em><a href="http://www.blogjava.net/xylz/java/util/concurrent/locks/AbstractQueuedSynchronizer.html#tryAcquire(int">
<em>tryAcquire(int)</em>
</a>)<em> 来实现此方法，并在成功时返回。否则在成功之前，一直调用 </em><a href="http://www.blogjava.net/xylz/java/util/concurrent/locks/AbstractQueuedSynchronizer.html#tryAcquire(int">
<em>tryAcquire(int)</em>
</a>)<em> 将线程加入队列，线程可能重复被阻塞或不被阻塞。</em></p>
<p>在介绍实现之前先要补充上一节的知识，对于一个AQS的实现而言，通常情况下需要实现以下方法来描述如何锁定线程。</p>
<ul>
<li><strong>tryAcquire(int)</strong> 
试图在独占模式下获取对象状态。此方法应该查询是否允许它在独占模式下获取对象状态，如果允许，则获取它。</li>
</ul>
<p>此方法总是由执行 acquire 的线程来调用。如果此方法报告失败，则 acquire 方法可以将线程加入队列（如果还没有将它加入队列），直到获得其他某个线程释放了该线程的信号。也就是说此方法是一种尝试性方法，如果成功获取锁那最好，如果没有成功也没有关系，直接返回false。</p>
<ul>
<li><strong>tryRelease(int)</strong> 
试图设置状态来反映独占模式下的一个释放。 此方法总是由正在执行释放的线程调用。释放锁可能失败或者抛出异常，这个在后面会具体分析。</li>
<li><strong>tryAcquireShared(int)</strong> 试图在共享模式下获取对象状态。</li>
<li><strong>tryReleaseShared(int)</strong> 试图设置状态来反映共享模式下的一个释放。</li>
<li><strong>isHeldExclusively()</strong> 如果对于当前（正调用的）线程，同步是以独占方式进行的，则返回         true    。</li>
</ul>
<p>除了tryAcquire(int)外，其它方法会在后面具体介绍。首先对于ReentrantLock而言，不管是公平锁还是非公平锁，都是独占锁，也就是说同时能够有一个线程持有锁。因此对于acquire(int arg)而言，arg==1。在AQS中acquire的实现如下：</p>
<p>public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;&amp;
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}</p>
<p>这个看起来比较复杂，我们分解以下4个步骤。</p>
<ol>
<li>如果tryAcquire(arg)成功，那就没有问题，已经拿到锁，整个lock()过程就结束了。如果失败进行操作2。</li>
<li>创建一个独占节点（Node）并且此节点加入CHL队列末尾。进行操作3。</li>
<li>自旋尝试获取锁，失败根据前一个节点来决定是否挂起（park()），直到成功获取到锁。进行操作4。</li>
<li>如果当前线程已经中断过，那么就中断当前线程（清除中断位）。</li>
</ol>
<p>这是一个比较复杂的过程，我们按部就班一个一个分析。</p>
<p><strong>tryAcquire(acquires)</strong></p>
<p>对于公平锁而言，它的实现方式如下：
    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (isFirst(current) &amp;&amp;
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            setState(nextc);
            return true;
        }
        return false;
    }
}</p>
<p>在这段代码中，前面说明对于AQS存在一个state来描述当前有多少线程持有锁。由于AQS支持共享锁（例如读写锁，后面会继续讲），所以这里state&gt;=0，但是由于ReentrantLock是独占锁，所以这里不妨理解为0&lt;=state，acquires=1。isFirst(current)是一个很复杂的逻辑，包括踢出无用的节点等复杂过程，这里暂且不提，大体上的意思是说判断AQS是否为空或者当前线程是否在队列头（为了区分公平与非公平锁）。</p>
<ol>
<li>如果当前锁有其它线程持有，c!=0，进行操作2。否则，如果当前线程在AQS队列头部，则尝试将AQS状态state设为acquires（等于1），成功后将AQS独占线程设为当前线程返回true，否则进行2。这里可以看到compareAndSetState就是使用了CAS操作。</li>
<li>判断当前线程与AQS的独占线程是否相同，如果相同，那么就将当前状态位加1（这里+1后结果为负数后面会讲，这里暂且不理它），修改状态位，返回true，否则进行3。这里之所以不是将当前状态位设置为1，而是修改为旧值+1呢？这是因为ReentrantLock是可重入锁，同一个线程每持有一次就+1。</li>
<li>返回false。</li>
</ol>
<p>比较非公平锁的tryAcquire实现java.util.concurrent.locks.ReentrantLock.Sync.nonfairTryAcquire(int)，公平锁多了一个判断当前节点是否在队列头，这个就保证了是否按照请求锁的顺序来决定获取锁的顺序（同一个线程的多次获取锁除外）。</p>
<p>现在再回头看公平锁和非公平锁的lock()方法。公平锁只有一句acquire(1)；而非公平锁的调用如下：
final void lock() {
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
}</p>
<p>很显然，非公平锁在第一次获取锁，或者其它线程释放锁后（可能等待），优先采用compareAndSetState(0,1)然后设置AQS独占线程而持有锁，这样有时候比acquire(1)顺序检查锁持有而要高效。即使在重入锁上，也就是compareAndSetState(0,1)失败，但是是当前线程持有锁上，非公平锁也没有问题。</p>
<p><strong>addWaiter(mode)</strong></p>
<p>tryAcquire失败就意味着入队列了。此时AQS的队列中节点Node就开始发挥作用了。一般情况下AQS支持独占锁和共享锁，而独占锁在Node中就意味着条件（Condition）队列为空（上一篇中介绍过相关概念）。在java.util.concurrent.locks.AbstractQueuedSynchronizer.Node中有两个常量，
static final Node EXCLUSIVE = null; //独占节点模式</p>
<p>static final Node SHARED = new Node(); //共享节点模式</p>
<p>addWaiter(mode)中的mode就是节点模式，也就是共享锁还是独占锁模式。</p>
<p>前面一再强调ReentrantLock是独占锁模式。
private Node addWaiter(Node mode) {
     Node node = new Node(Thread.currentThread(), mode);
     // Try the fast path of enq; backup to full enq on failure
     Node pred = tail;
     if (pred != null) {
         node.prev = pred;
         if (compareAndSetTail(pred, node)) {
             pred.next = node;
             return node;
         }
     }
     enq(node);
     return node;
}</p>
<p>上面是节点如队列的一部分。当前仅当队列不为空并且将新节点插入尾部成功后直接返回新节点。否则进入enq(Node)进行操作。</p>
<p>private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            Node h = new Node(); // Dummy header
            h.next = node;
            node.prev = h;
            if (compareAndSetHead(h)) {
                tail = node;
                return h;
            }
        }
        else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}</p>
<p>enq(Node)去队列操作实现了CHL队列的算法，如果为空就创建头结点，然后同时比较节点尾部是否是改变来决定CAS操作是否成功，当且仅当成功后才将为不节点的下一个节点指向为新节点。可以看到这里仍然是CAS操作。</p>
<p><strong>acquireQueued(node,arg)</strong></p>
<p>自旋请求锁，如果可能的话挂起线程，直到得到锁，返回当前线程是否中断过（如果park()过并且中断过的话有一个interrupted中断位）。
final boolean acquireQueued(final Node node, int arg) {
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } catch (RuntimeException ex) {
        cancelAcquire(node);
        throw ex;
    }
}</p>
<p>下面的分析就需要用到上节节点的状态描述了。acquireQueued过程是这样的：</p>
<ol>
<li>如果当前节点是AQS队列的头结点（如果第一个节点是DUMP节点也就是傀儡节点，那么第二个节点实际上就是头结点了），就尝试在此获取锁tryAcquire(arg)。如果成功就将头结点设置为当前节点（不管第一个结点是否是DUMP节点），返回中断位。否则进行2。</li>
<li>检测当前节点是否应该park()，如果应该park()就挂起当前线程并且返回当前线程中断位。进行操作1。</li>
</ol>
<p>一个节点是否该park()是关键，这是由方法java.util.concurrent.locks.AbstractQueuedSynchronizer.shouldParkAfterFailedAcquire(Node, Node)实现的。
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int s = pred.waitStatus;
    if (s &lt; 0) return true;
    if (s &gt; 0) {
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &gt; 0);
        pred.next = node;
    } else compareAndSetWaitStatus(pred, 0, Node.SIGNAL);
    return false;
}</p>
<ol>
<li>如果前一个节点的等待状态waitStatus&lt;0，也就是前面的节点还没有获得到锁，那么返回true，表示当前节点（线程）就应该park()了。否则进行2。</li>
<li>如果前一个节点的等待状态waitStatus&gt;0，也就是前一个节点被CANCELLED了，那么就将前一个节点去掉，递归此操作直到所有前一个节点的waitStatus&lt;=0，进行4。否则进行3。</li>
<li>前一个节点等待状态waitStatus=0，修改前一个节点状态位为SINGAL，表示后面有节点等待你处理，需要根据它的等待状态来决定是否该park()。进行4。</li>
<li>返回false，表示线程不应该park()。</li>
</ol>
<p><strong>selfInterrupt()</strong>
private static void selfInterrupt() {
    Thread.currentThread().interrupt();
}</p>
<p>如果线程曾经中断过（或者阻塞过）（比如手动interrupt()或者超时等等，那么就再中断一次，中断两次的意思就是清除中断位）。</p>
<p>大体上整个Lock.lock()就这样一个流程。除了lock()方法外，还有lockInterruptibly()/tryLock()/unlock()/newCondition()等，在接下来的章节中会一一介绍。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/07/325410.html](http://www.blogjava.net/xylz/archive/2010/07/07/325410.html)">[http://www.blogjava.net/xylz/archive/2010/07/07/325410.html](http://www.blogjava.net/xylz/archive/2010/07/07/325410.html)</a> </p>
<p>本小节介绍锁释放Lock.unlock()。</p>
<p><strong>Release/TryRelease</strong></p>
<p>unlock操作实际上就调用了<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>的release操作，释放持有的锁。
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null &amp;&amp; h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}</p>
<p>前面提到过<strong><em>tryRelease(arg)</em></strong>操作，此操作里面总是尝试去释放锁，如果成功，说明锁确实被当前线程持有，那么就看<strong>AQS</strong>队列中的头结点是否为空并且能否被唤醒，如果可以的话就唤醒继任节点（下一个非CANCELLED节点，下面会具体分析）。</p>
<p>对于独占锁而言，java.util.concurrent.locks.ReentrantLock.Sync.tryRelease(int)展示了如何尝试释放锁(<strong><em>tryRelease</em></strong>)操作。
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}</p>
<p>整个<strong><em>tryRelease</em></strong>操作是这样的：</p>
<ol>
<li>判断持有锁的线程是否是当前线程，如果不是就抛出IllegalMonitorStateExeception()，因为一个线程是不能释放另一个线程持有的锁（否则锁就失去了意义）。否则进行2。</li>
<li>将AQS状态位减少要释放的次数（对于独占锁而言总是1），如果剩余的状态位0（也就是没有线程持有锁），那么当前线程就是最后一个持有锁的线程，清空AQS持有锁的独占线程。进行3。</li>
<li>将剩余的状态位写回AQS，如果没有线程持有锁就返回true，否则就是false。</li>
</ol>
<p>参考上一节的分析就可以知道，这里c==0决定了是否完全释放了锁。由于<strong><em>ReentrantLock</em></strong>是可重入锁，因此同一个线程可能多重持有锁，那么当且仅当最后一个持有锁的线程释放锁是才能将AQS中持有锁的独占线程清空，这样接下来的操作才需要唤醒下一个需要锁的<strong>AQS</strong>节点（Node），否则就只是减少锁持有的计数器，并不能改变其他操作。</p>
<p>当<strong><em>tryRelease</em></strong>操作成功后（也就是完全释放了锁），release操作才能检查是否需要唤醒下一个继任节点。这里的前提是<strong>AQS</strong>队列的头结点需要锁(<em>waitStatus!=0</em>)，如果头结点需要锁，就开始检测下一个继任节点是否需要锁操作。</p>
<p>在上一节中说道<strong><em>acquireQueued</em></strong>操作完成后（拿到了锁），会将当前持有锁的节点设为头结点，所以一旦头结点释放锁，那么就需要寻找头结点的下一个需要锁的继任节点，并唤醒它。
private void unparkSuccessor(Node node) {
        //此时node是需要是需要释放锁的头结点</p>
<pre><code>    //清空头结点的waitStatus，也就是不再需要锁了
    compareAndSetWaitStatus(node, Node.SIGNAL, 0);

    //从头结点的下一个节点开始寻找继任节点，当且仅当继任节点的waitStatus&lt;=0才是有效继任节点，否则将这些waitStatus&gt;0（也就是CANCELLED的节点）从AQS队列中剔除  
   //这里并没有从head-&gt;tail开始寻找，而是从tail-&gt;head寻找最后一个有效节点。
   //解释在这里 http://www.blogjava.net/xylz/archive/2010/07/08/325540.html/#377512

    Node s = node.next;
    if (s == null || s.waitStatus &gt; 0) {
        s = null;
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }

    //如果找到一个有效的继任节点，就唤醒此节点线程
    if (s != null)
        LockSupport.unpark(s.thread);
}
</code></pre><p>这里再一次把<strong><em>acquireQueued</em></strong>的过程找出来。对比<strong><em>unparkSuccessor</em></strong>，一旦头节点的继任节点被唤醒，那么继任节点就会尝试去获取锁（在<strong><em>acquireQueued</em></strong>中node就是有效的继任节点，p就是唤醒它的头结点），如果成功就会将头结点设置为自身，并且将头结点的前任节点清空，这样前任节点（已经过时了）就可以被GC释放了。</p>
<p>final boolean acquireQueued(final Node node, int arg) {
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } catch (RuntimeException ex) {
        cancelAcquire(node);
        throw ex;
    }
}</p>
<p>在<strong><em>setHead</em></strong>中，将头结点的前任节点清空并且将头结点的线程清空就是为了更好的GC，防止内存泄露。</p>
<p>private void setHead(Node node) {
    head = node;
    node.thread = null;
    node.prev = null;
}</p>
<p>对比lock()操作，unlock()操作还是比较简单的，主要就是释放响应的资源，并且唤醒<strong>AQS</strong>队列中有效的继任节点。这样所就按照请求的顺序去尝试获取锁了。</p>
<p>整个lock()/unlock()过程完成了，我们再回头看公平锁(FairSync)和非公平锁(NonfairSync)。</p>
<p>公平锁和非公平锁只是在获取锁的时候有差别，其它都是一样的。
final void lock() {
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
}</p>
<p>在上面非公平锁的代码中总是优先尝试当前是否有线程持有锁，一旦没有任何线程持有锁，那么非公平锁就霸道的尝试将锁“占为己有”。如果在抢占锁的时候失败就和公平锁一样老老实实的去排队。</p>
<p>也即是说公平锁和非公平锁只是在入<strong>AQS</strong>的<strong>CLH</strong>队列之前有所差别，一旦进入了队列，所有线程都是按照队列中先来后到的顺序请求锁。</p>
<p><strong>Condition</strong></p>
<p>条件变量很大一个程度上是为了解决Object.wait/notify/notifyAll难以使用的问题。</p>
<p>条件（也称为<em>条件队列</em> 或<em>条件变量</em>）为线程提供了一个含义，以便在某个状态条件现在可能为 true 的另一个线程通知它之前，一直挂起该线程（即让其“等待”）。因为访问此共享状态信息发生在不同的线程中，所以它必须受保护，因此要将某种形式的锁与该条件相关联。等待提供一个条件的主要属性是：<em>以原子方式</em> 释放相关的锁，并挂起当前线程，就像 </p>
<p>Object.wait
 做的那样。</p>
<p>上述API说明表明条件变量需要与锁绑定，而且多个Condition需要绑定到同一锁上。前面的<strong>Lock</strong>中提到，获取一个条件变量的方法是<strong>Lock.newCondition()</strong>。
void await() throws InterruptedException;
void awaitUninterruptibly();
long awaitNanos(long nanosTimeout) throws InterruptedException;
boolean await(long time, TimeUnit unit) throws InterruptedException;
boolean awaitUntil(Date deadline) throws InterruptedException;
void signal();
void signalAll();</p>
<p>以上是<strong>Condition</strong>接口定义的方法，<em>await/**对应于</em>Object.wait<em>，</em>signal<em>对应于</em>Object.notify<em>，</em>signalAll<em>对应于</em>Object.notifyAll<em>。特别说明的是<strong>Condition</strong>的接口改变名称就是为了避免与Object中的</em>wait/notify/notifyAll<em>的语义和使用上混淆，因为Condition同样有</em>wait/notify/notifyAll*方法。</p>
<p>每一个<strong>Lock</strong>可以有任意数据的<strong>Condition</strong>对象，<strong>Condition</strong>是与<strong>Lock</strong>绑定的，所以就有<strong>Lock</strong>的公平性特性：如果是公平锁，线程为按照FIFO的顺序从<em>Condition.await</em>中释放，如果是非公平锁，那么后续的锁竞争就不保证FIFO顺序了。</p>
<p>一个使用Condition实现生产者消费者的模型例子如下。
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;</p>
<p>public class ProductQueue<T> {</p>
<pre><code>private final T[] items;

private final Lock lock = new ReentrantLock();

private Condition notFull = lock.newCondition();

private Condition notEmpty = lock.newCondition();

//
private int head, tail, count;

public ProductQueue(int maxSize) {
    items = (T[]) new Object[maxSize];
}

public ProductQueue() {
    this(10);
}

public void put(T t) throws InterruptedException {
    lock.lock();
    try {
        while (count == getCapacity()) {
            notFull.await();
        }
        items[tail] = t;
        if (++tail == getCapacity()) {
            tail = 0;
        }
        ++count;
        notEmpty.signalAll();
    } finally {
        lock.unlock();
    }
}

public T take() throws InterruptedException {
    lock.lock();
    try {
        while (count == 0) {
            notEmpty.await();
        }
        T ret = items[head];
        items[head] = null;//GC
        //
        if (++head == getCapacity()) {
            head = 0;
        }
        --count;
        notFull.signalAll();
        return ret;
    } finally {
        lock.unlock();
    }
}

public int getCapacity() {
    return items.length;
}

public int size() {
    lock.lock();
    try {
        return count;
    } finally {
        lock.unlock();
    }
}
</code></pre><p>}</p>
<p>在这个例子中消费<em>take()</em>需要 队列不为空，如果为空就挂起（<em>await()</em>），直到收到<em>notEmpty</em>的信号；生产<em>put()</em>需要队列不满，如果满了就挂起（<em>await()</em>），直到收到<em>notFull</em>的信号。</p>
<p>可能有人会问题，如果一个线程<em>lock()</em>对象后被挂起还没有<em>unlock</em>，那么另外一个线程就拿不到锁了（<em>lock()</em>操作会挂起），那么就无法通知(<em>notify</em>)前一个线程，这样岂不是“死锁”了？</p>
<p><strong>await/* 操作</strong></p>
<p>上一节中说过多次<em>ReentrantLock</em>是独占锁，一个线程拿到锁后如果不释放，那么另外一个线程肯定是拿不到锁，所以在<em>lock.lock()</em>和<em>lock.unlock()</em>之间可能有一次释放锁的操作（同样也必然还有一次获取锁的操作）。我们再回头看代码，不管<em>take()</em>还是<em>put()</em>，在进入<em>lock.lock()</em>后唯一可能释放锁的操作就是<em>await()</em>了。也就是说<em>await()</em>操作实际上就是释放锁，然后挂起线程，一旦条件满足就被唤醒，再次获取锁！
public final void await() throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    Node node = addConditionWaiter();
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null)
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}</p>
<p>上面是<em>await()</em>的代码片段。上一节中说过，<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>在获取锁的时候需要有一个<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>CHL</strong></a>的FIFO队列，所以对于一个<em>Condition.await()</em>而言，如果释放了锁，要想再一次获取锁那么就需要进入队列，等待被通知获取锁。完整的await()操作是安装如下步骤进行的：</p>
<ol>
<li>将当前线程加入<em>Condition</em>锁队列。特别说明的是，这里不同于<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>的队列，这里进入的是<em>Condition</em>的FIFO队列。后面会具体谈到此结构。进行2。</li>
<li>释放锁。这里可以看到将锁释放了，否则别的线程就无法拿到锁而发生死锁。进行3。</li>
<li>自旋(while)挂起，直到被唤醒或者超时或者CACELLED等。进行4。</li>
<li>获取锁(<em>acquireQueued</em>)。并将自己从<em>Condition</em>的FIFO队列中释放，表明自己不再需要锁（我已经拿到锁了）。</li>
</ol>
<p>这里再回头介绍<em>Condition</em>的数据结构。我们知道一个<em>Condition</em>可以在多个地方被<em>await/</em>()<em>，那么就需要一个FIFO的结构将这些</em>Condition<em>串联起来，然后根据需要唤醒一个或者多个（通常是所有）。所以在</em>Condition*内部就需要一个FIFO的队列。
private transient Node firstWaiter;
private transient Node lastWaiter;</p>
<p>上面的两个节点就是描述一个FIFO的队列。我们再结合<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">前面</a>提到的<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">节点（Node）数据结构</a>。我们就发现<em>Node.nextWaiter</em>就派上用场了！<em>nextWaiter</em>就是将一系列的<em>Condition.await/*</em>串联起来组成一个FIFO的队列。</p>
<p><strong>signal/signalAll 操作</strong></p>
<p><em>await/</em>()<em>清楚了，现在再来看</em>signal/signalAll<em>就容易多了。按照</em>signal/signalAll<em>的需求，就是要将</em>Condition.await/<em>()</em>中FIFO队列中第一个<strong>Node</strong>唤醒（或者全部<strong>Node</strong>）唤醒。尽管所有<strong>Node</strong>可能都被唤醒，但是要知道的是仍然只有一个线程能够拿到锁，其它没有拿到锁的线程仍然需要自旋等待，就上上面提到的第4步(acquireQueued)。
private void doSignal(Node first) {
    do {
        if ( (firstWaiter = first.nextWaiter) == null)
            lastWaiter = null;
        first.nextWaiter = null;
    } while (!transferForSignal(first) &amp;&amp;
             (first = firstWaiter) != null);
}</p>
<p>private void doSignalAll(Node first) {
    lastWaiter = firstWaiter  = null;
    do {
        Node next = first.nextWaiter;
        first.nextWaiter = null;
        transferForSignal(first);
        first = next;
    } while (first != null);
}</p>
<p>上面的代码很容易看出来，<em>signal</em>就是唤醒<strong>Condition</strong>队列中的第一个非CANCELLED节点线程，而signalAll就是唤醒所有非CANCELLED节点线程。当然了遇到CANCELLED线程就需要将其从FIFO队列中剔除。</p>
<p>final boolean transferForSignal(Node node) {
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;</p>
<pre><code>Node p = enq(node);
int c = p.waitStatus;
if (c &gt; 0 || !compareAndSetWaitStatus(p, c, Node.SIGNAL))
    LockSupport.unpark(node.thread);
return true;
</code></pre><p>}</p>
<p>上面就是唤醒一个<em>await/</em>()<em>线程的过程，根据前面的小节介绍的，如果要</em>unpark<em>线程，并使线程拿到锁，那么就需要线程节点进入<strong>AQS</strong>的队列。所以可以看到在</em>LockSupport.unpark<em>之前调用了</em>enq(node)<em>操作，将当前节点加入到<em>*AQS</em></em>队列。</p>
<p>整个锁机制的原理就介绍完了，从下一节开始就进入了锁机制的应用了。</p>
<p>此小节介绍几个与锁有关的有用工具。</p>
<p><strong>闭锁（Latch）</strong></p>
<p>闭锁（Latch）：一种同步方法，可以延迟线程的进度直到线程到达某个终点状态。通俗的讲就是，一个闭锁相当于一扇大门，在大门打开之前所有线程都被阻断，一旦大门打开所有线程都将通过，但是一旦大门打开，所有线程都通过了，那么这个闭锁的状态就失效了，门的状态也就不能变了，只能是打开状态。也就是说闭锁的状态是一次性的，它确保在闭锁打开之前所有特定的活动都需要在闭锁打开之后才能完成。</p>
<p><strong>CountDownLatch</strong>是JDK 5+里面闭锁的一个实现，允许一个或者多个线程等待某个事件的发生。<strong>CountDownLatch</strong>有一个正数计数器，<em>countDown</em>方法对计数器做减操作，<em>await</em>方法等待计数器达到0。所有<em>await</em>的线程都会阻塞直到计数器为0或者等待线程中断或者超时。</p>
<p><strong>CountDownLatch</strong>的API如下。</p>
<ul>
<li>public void await() throws InterruptedException</li>
<li>public boolean await(long timeout, TimeUnit unit) throws InterruptedException</li>
<li>public void countDown()</li>
<li>public long getCount()</li>
</ul>
<p>其中<em>getCount()</em>描述的是当前计数，通常用于调试目的。</p>
<p>下面的例子中描述了闭锁的两种常见的用法。
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.CountDownLatch;</p>
<p>public class PerformanceTestTool {</p>
<pre><code>public long timecost(final int times, final Runnable task) throws InterruptedException {
    if (times &lt;= 0) throw new IllegalArgumentException();
    final CountDownLatch startLatch = new CountDownLatch(1);
    final CountDownLatch overLatch = new CountDownLatch(times);
    for (int i = 0; i &lt; times; i++) {
        new Thread(new Runnable() {
            public void run() {
                try {
                    startLatch.await();
                    //
                    task.run();
                } catch (InterruptedException ex) {
                    Thread.currentThread().interrupt();
                } finally {
                    overLatch.countDown();
                }
            }
        }).start();
    }
    //
    long start = System.nanoTime();
    startLatch.countDown();
    overLatch.await();
    return System.nanoTime() - start;
}
</code></pre><p>}</p>
<p>在上面的例子中使用了两个闭锁，第一个闭锁确保在所有线程开始执行任务前，所有准备工作都已经完成，一旦准备工作完成了就调用<em>startLatch.countDown()</em>打开闭锁，所有线程开始执行。第二个闭锁在于确保所有任务执行完成后主线程才能继续进行，这样保证了主线程等待所有任务线程执行完成后才能得到需要的结果。在第二个闭锁当中，初始化了一个N次的计数器，每个任务执行完成后都会将计数器减一，所有任务完成后计数器就变为了0，这样主线程闭锁overLatch拿到此信号后就可以继续往下执行了。</p>
<p>根据前面的<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">happend-before法则</a>可以知道闭锁有以下特性：
**内存一致性效果：线程中调用 </p>
<p>countDown()
 之前的操作 <strong><a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">happen-before</a><strong>**</strong></strong> 紧跟在从另一个线程中对应 </p>
<p>await()
 成功返回的操作。**</p>
<p>在上面的例子中第二个闭锁相当于把一个任务拆分成N份，每一份独立完成任务，主线程等待所有任务完成后才能继续执行。这个特性在后面的线程池框架中会用到，其实<strong>FutureTask</strong>就可以看成一个闭锁。后面的章节还会具体分析<strong>FutureTask</strong>的。</p>
<p>同样基于探索精神，仍然需要“窥探”下<strong>CountDownLatch</strong>里面到底是如何实现<em>await/**和</em>countDown*的。</p>
<p>首先，研究下<em>await()</em>方法。内部直接调用了<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>的<em>acquireSharedInterruptibly(1)</em>。
public final void acquireSharedInterruptibly(int arg) throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    if (tryAcquireShared(arg) &lt; 0)
        doAcquireSharedInterruptibly(arg);
}</p>
<p>前面一直提到的都是独占锁（排它锁、互斥锁），现在就用到了另外一种锁，共享锁。</p>
<p>所谓共享锁是说所有共享锁的线程共享同一个资源，一旦任意一个线程拿到共享资源，那么所有线程就都拥有的同一份资源。也就是通常情况下共享锁只是一个标志，所有线程都等待这个标识是否满足，一旦满足所有线程都被激活（相当于所有线程都拿到锁一样）。这里的闭锁<strong>CountDownLatch</strong>就是基于共享锁的实现。</p>
<p>闭锁中关于<strong>AQS</strong>的<em>tryAcquireShared</em>的实现是如下代码（<strong>java.util.concurrent.CountDownLatch.Sync.tryAcquireShared</strong>）：
public int tryAcquireShared(int acquires) {
    return getState() == 0? 1 : -1;
}</p>
<p>在这份逻辑中，对于闭锁而言第一次await时tryAcquireShared应该总是-1，因为对于闭锁<strong>CountDownLatch</strong>而言<em>state</em>的值就是初始化的<em>count</em>值。这也就解释了为什么在<em>countDown</em>调用之前闭锁的<em>count</em>总是&gt;0。</p>
<p>private void doAcquireSharedInterruptibly(int arg)
    throws InterruptedException {
    final Node node = addWaiter(Node.SHARED);
    try {
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                if (r &gt;= 0) {
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                break;
        }
    } catch (RuntimeException ex) {
        cancelAcquire(node);
        throw ex;
    }
    // Arrive here only if interrupted
    cancelAcquire(node);
    throw new InterruptedException();
}</p>
<p>上面的逻辑展示了如何通过<em>await</em>将所有线程串联并挂起，直到被唤醒或者条件满足或者被中断。整个过程是这样的：</p>
<ol>
<li>将当前线程节点以共享模式加入<strong>AQS</strong>的<strong>CLH</strong>队列中（相关概念参考<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">这里</a>和<a href="http://www.blogjava.net/xylz/archive/2010/07/07/325410.html" target="_blank">这里</a>）。进行2。</li>
<li>检查当前节点的前任节点，如果是头结点并且当前闭锁计数为0就将当前节点设置为头结点，唤醒继任节点，返回（结束线程阻塞）。否则进行3。</li>
<li>检查线程是否该阻塞，如果应该就阻塞(park)，直到被唤醒（unpark）。重复2。</li>
<li>如果2、3有异常就抛出异常（结束线程阻塞）。</li>
</ol>
<p>这里有一点值得说明下，设置头结点并唤醒继任节点<em>setHeadAndPropagate</em>。由于前面<em>tryAcquireShared</em>总是返回1或者-1，而进入<em>setHeadAndPropagate</em>时总是<em>propagate&gt;=0</em>，所以这里<em>propagate==1</em>。后面唤醒继任节点操作就非常熟悉了。
private void setHeadAndPropagate(Node node, int propagate) {
    setHead(node);
    if (propagate &gt; 0 &amp;&amp; node.waitStatus != 0) {
        Node s = node.next;
        if (s == null || s.isShared())
            unparkSuccessor(node);
    }
}</p>
<p>从上面的所有逻辑可以看出<em>countDown</em>应该就是在条件满足（计数为0）时唤醒头结点（时间最长的一个节点），然后头结点就会根据FIFO队列唤醒整个节点列表（如果有的话）。</p>
<p>从<strong>CountDownLatch</strong>的<em>countDown</em>代码中看到，直接调用的是<strong>AQS</strong>的<em>releaseShared(1)</em>，参考前面的知识，这就印证了上面的说法。</p>
<p><strong><em>tryReleaseShared</em></strong>中正是采用CAS操作减少计数（每次减-1）。
public boolean tryReleaseShared(int releases) {
    for (;;) {
        int c = getState();
        if (c == 0)
            return false;
        int nextc = c-1;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}</p>
<p>整个<strong>CountDownLatch</strong>就是这个样子的。其实有了前面原子操作和<strong>AQS</strong>的原理及实现，分析<strong>CountDownLatch</strong>还是比较容易的。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/09/325612.html](http://www.blogjava.net/xylz/archive/2010/07/09/325612.html)">[http://www.blogjava.net/xylz/archive/2010/07/09/325612.html](http://www.blogjava.net/xylz/archive/2010/07/09/325612.html)</a> </p>
<p>如果说<a href="http://www.blogjava.net/xylz/archive/2010/07/09/325612.html" target="_blank">CountDownLatch</a>是一次性的，那么<strong>CyclicBarrier</strong>正好可以循环使用。它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。所谓屏障点就是一组任务执行完毕的时刻。</p>
<p><strong><em>清单1 一个使用CyclicBarrier的例子</em></strong>
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.BrokenBarrierException;
import java.util.concurrent.CyclicBarrier;</p>
<p>public class CyclicBarrierDemo {</p>
<pre><code>final CyclicBarrier barrier;

final int MAX_TASK;

public CyclicBarrierDemo(int cnt) {
    barrier = new CyclicBarrier(cnt + 1);
    MAX_TASK = cnt;
}

public void doWork(final Runnable work) {
    new Thread() {

        public void run() {
            work.run();
            try {
                int index = barrier.await();
                doWithIndex(index);
            } catch (InterruptedException e) {
                return;
            } catch (BrokenBarrierException e) {
                return;
            }
        }
    }.start();
}

private void doWithIndex(int index) {
    if (index == MAX_TASK / 3) {
        System.out.println(&quot;Left 30%.&quot;);
    } else if (index == MAX_TASK / 2) {
        System.out.println(&quot;Left 50%&quot;);
    } else if (index == 0) {
        System.out.println(&quot;run over&quot;);
    }
}

public void waitForNext() {
    try {
        doWithIndex(barrier.await());
    } catch (InterruptedException e) {
        return;
    } catch (BrokenBarrierException e) {
        return;
    }
}

public static void main(String[] args) {
    final int count = 10;
    CyclicBarrierDemo demo = new CyclicBarrierDemo(count);
    for (int i = 0; i &lt; 100; i++) {
        demo.doWork(new Runnable() {

            public void run() {
                //do something
                try {
                    Thread.sleep(1000L);
                } catch (Exception e) {
                    return;
                }
            }
        });
        if ((i + 1) % count == 0) {
            demo.waitForNext();
        }
    }
}
</code></pre><p>}</p>
<p>清单1描述的是一个周期性处理任务的例子，在这个例子中有一对的任务（100个），希望每10个为一组进行处理，当前仅当上一组任务处理完成后才能进行下一组，另外在每一组任务中，当任务剩下50%，30%以及所有任务执行完成时向观察者发出通知。</p>
<p>在这个例子中，CyclicBarrierDemo 构建了一个count+1的任务组（其中一个任务时为了外界方便挂起主线程）。每一个子任务里，人物本身执行完毕后都需要等待同组内其它任务执行完成后才能继续。同时在剩下任务50%、30%已经0时执行特殊的其他任务（发通知）。</p>
<p>很显然CyclicBarrier有以下几个特点：</p>
<ul>
<li>await()方法将挂起线程，直到同组的其它线程执行完毕才能继续</li>
<li>await()方法返回线程执行完毕的索引，注意，索引时从任务数-1开始的，也就是第一个执行完成的任务索引为parties-1,最后一个为0，这个parties为总任务数，清单中是cnt+1</li>
<li>CyclicBarrier 是可循环的，显然名称说明了这点。在清单1中，每一组任务执行完毕就能够执行下一组任务。</li>
</ul>
<p>另外除了CyclicBarrier除了以上特点外，还有以下几个特点：</p>
<ul>
<li>如果屏障操作不依赖于挂起的线程，那么任何线程都可以执行屏障操作。在清单1中可以看到并没有指定那个线程执行50%、30%、0%的操作，而是一组线程（cnt+1）个中任何一个线程只要到达了屏障点都可以执行相应的操作</li>
<li>CyclicBarrier 的构造函数允许携带一个任务，这个任务将在0%屏障点执行，它将在await()==0后执行。</li>
<li>CyclicBarrier 如果在await时因为中断、失败、超时等原因提前离开了屏障点，那么任务组中的其他任务将立即被中断，以InterruptedException异常离开线程。</li>
<li>所有await()之前的操作都将在屏障点之前运行，也就是CyclicBarrier 的内存一致性效果</li>
</ul>
<p>CyclicBarrier 的所有API如下：</p>
<ul>
<li><em>public CyclicBarrier(int parties)</em> 创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，但它不会在启动 barrier 时执行预定义的操作。</li>
<li><em>public CyclicBarrier(int parties, Runnable barrierAction)</em> 创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，并在启动 barrier 时执行给定的屏障操作，该操作由最后一个进入 barrier 的线程执行。</li>
<li><em>public int await() throws InterruptedException, BrokenBarrierException</em> 在所有参与者都已经在此 barrier 上调用 await 方法之前，将一直等待。</li>
<li><em>public int await(long timeout,TimeUnit unit) throws InterruptedException, BrokenBarrierException,TimeoutException</em> 在所有参与者都已经在此屏障上调用 await 方法之前将一直等待,或者超出了指定的等待时间。</li>
<li><em>public int getNumberWaiting() </em>返回当前在屏障处等待的参与者数目。此方法主要用于调试和断言。</li>
<li><em>public int getParties()</em> 返回要求启动此 barrier 的参与者数目。</li>
<li><em>public boolean isBroken()</em> 查询此屏障是否处于损坏状态。</li>
<li><em>public void reset()</em> 将屏障重置为其初始状态。</li>
</ul>
<p>针对以上API，下面来探讨下CyclicBarrier 的实现原理，以及为什么有这样的API。</p>
<p><strong><em>清单2 CyclicBarrier.await/</em>()的实现片段*</strong>
    private int dowait(boolean timed, long nanos)
    throws InterruptedException, BrokenBarrierException,
           TimeoutException {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        final Generation g = generation;
        if (g.broken)
            throw new BrokenBarrierException();</p>
<pre><code>    if (Thread.interrupted()) {
        breakBarrier();
        throw new InterruptedException();
    }

   int index = --count;
   if (index == 0) {  // tripped
       boolean ranAction = false;
       try {
           final Runnable command = barrierCommand;
           if (command != null)
               command.run();
           ranAction = true;
           nextGeneration();
           return 0;
       } finally {
           if (!ranAction)
               breakBarrier();
       }
   }

    // loop until tripped, broken, interrupted, or timed out
    for (;;) {
        try {
            if (!timed)
                trip.await();
            else if (nanos &gt; 0L)
                nanos = trip.awaitNanos(nanos);
        } catch (InterruptedException ie) {
            if (g == generation &amp;&amp; ! g.broken) {
                breakBarrier();
                throw ie;
            } else {
                Thread.currentThread().interrupt();
            }
        }

        if (g.broken)
            throw new BrokenBarrierException();

        if (g != generation)
            return index;

        if (timed &amp;&amp; nanos &lt;= 0L) {
            breakBarrier();
            throw new TimeoutException();
        }
    }
} finally {
    lock.unlock();
}
</code></pre><p>}</p>
<p>清单2有点复杂，这里一点一点的剖析，并且还原到最原始的状态。</p>
<p>利用前面学到的知识，我们知道要想让线程等待其他线程执行完毕，那么已经执行完毕的线程（进入await/*()方法）就需要park()，直到超时或者被中断，或者被其它线程唤醒。</p>
<p>前面说过CyclicBarrier 的特点是要么大家都正常执行完毕，要么大家都异常被中断，不会其中有一个被中断而其它正常执行完毕的现象存在。这种特点叫all-or-none。类似的概念是原子操作中的要么大家都执行完，要么一个操作都不执行完。当前这其实是两个概念了。要完成这样的特点就必须有一个状态来描述曾经是否有过线程被中断（broken)了，这样后面执行完的线程就该知道是否需要继续等待了。而在CyclicBarrier 中Generation 就是为了完成这件事情的。Generation的定义非常简单，整个结构就只有一个变量<em>boolean broken = false;，</em>定义是否发生了broken操作。</p>
<p>由于有竞争资源的存在（broken/index），所以毫无疑问需要一把锁lock。拿到锁后整个过程是这样的：</p>
<ol>
<li>检查是否存在中断位(broken)，如果存在就立即以BrokenBarrierException异常返回。此异常描述的是线程进入屏障被破坏的等待状态。否则进行2。</li>
<li>检查当前线程是否被中断，如果是那么就设置中断位（使其它将要进入等待的线程知道），另外唤醒已经等待的线程，同时以InterruptedException异常返回，表示线程要处理中断。否则进行3。</li>
<li>将剩余任务数减1，如果此时剩下的任务数为0，也就是达到了公共屏障点，那么就执行屏障点任务（如果有的话），同时创建新的Generation（在这个过程中会唤醒其它所有线程，因此当前线程是屏障点线程，那么其它线程就都应该在等待状态）。否则进行4。</li>
<li>到这里说明还没有到达屏障点，那么此时线程就应该park()。很显然在下面的for循环中就是要park线程。这里park线程采用的是Condition.await()方法。也就是trip.await/<em>()。为什么需要Condition？因为所有的await/</em>()其实等待的都是一个条件，一旦条件满足就应该都被唤醒，所以Condition整好满足这个特点。所以到这里就会明白为什么在步骤3中到达屏障点时创建新的Generation的时候是一定要唤醒其它线程的原因了。</li>
</ol>
<p>上面4个步骤其实只是描述主体结构，事实上整个过程中有非常多的逻辑来处理异常引发的问题，比如执行屏障点任务引发的异常，park线程超时引发的中断异常和超时异常等等。所以对于await()而言，异常的处理比业务逻辑的处理更复杂，这就解释了为什么await()的时候可能引发<em>InterruptedException,BrokenBarrierException,TimeoutException</em> 三种异常。</p>
<p><strong><em>清单3 生成下一个循环周期并唤醒其它线程</em></strong>
private void nextGeneration() {
     trip.signalAll();
     count = parties;
     generation = new Generation();
}</p>
<p>清单3 描述了如何生成下一个循环周期的过程，在这个过程中当然需要使用Condition.signalAll()唤醒所有已经执行完成并且正在等待的线程。另外这里count描述的是还有多少线程需要执行，是为了线程执行完毕索引计数。</p>
<p>isBroken() 方法描述的就是generation.broken，也即线程组是否发生了异常。这里再一次解释下为什么要有这个状态的存在。</p>
<p>如果一个将要位于屏障点或者已经位于屏障点的而执行屏障点任务的线程发生了异常，那么即使唤醒了其它等待的线程，其它等待的线程也会因为循环等待而“死去”，因为再也没有一个线程来唤醒这些第二次进行park的线程了。还有一个意图是，如果屏障点都已经损坏了，那么其它将要等待屏障点的再线程挂起就没有意义了。
<em><a href="http://www.imxylz.info/p/336.html" target="_blank">写到这里的时候非常不幸，用了4年多了台灯终于“寿终正寝了”。</a></em></p>
<p>其实CyclicBarrier 还有一个reset方法，描述的是手动立即将所有线程中断，恢复屏障点，进行下一组任务的执行。也就是与重新创建一个新的屏障点相比，可能维护的代价要小一些（减少同步，减少上一个CyclicBarrier 的管理等等）。</p>
<p>本来是想和Semaphore 一起将的，最后发现铺开后就有点长了，而且也不利于理解和吸收，所以放到下一篇吧。</p>
<p><strong>参考资料：</strong></p>
<ol>
<li><a href="http://blog.sina.com.cn/s/blog_5ce5700e0100e44l.html" target="_blank">使用 CyclicBarrier 做线程间同步</a></li>
<li><a href="http://spring21.javaeye.com/blog/363149" target="_blank">CyclicBarrier And CountDownLatch Tutorial</a></li>
<li><a href="http://www.blogjava.net/kissyan4916/articles/307091.html" target="_blank">线程—CyclicBarrier</a></li>
<li><a href="http://www.javaeye.com/topic/657295" target="_blank">Java线程学习笔记（十）CountDownLatch 和CyclicBarrier</a></li>
<li><a href="http://www.jspcn.net/htmlnews/11500653090781610.html" target="_blank">关于多线程同步的初步教程－－Barrier的设计及使用</a></li>
<li><a href="http://tech.puredanger.com/2007/11/11/thread-coord/" target="_blank">Thread coordination with CountDownLatch and CyclicBarrier</a></li>
<li><a href="http://flysnow.javaeye.com/blog/711162" target="_blank">如何充分利用多核CPU，计算很大的List中所有整数的和</a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/12/325913.html](http://www.blogjava.net/xylz/archive/2010/07/12/325913.html)">[http://www.blogjava.net/xylz/archive/2010/07/12/325913.html](http://www.blogjava.net/xylz/archive/2010/07/12/325913.html)</a> </li>
</ol>
<p>Semaphore 是一个计数信号量。从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 </p>
<p>acquire()
，然后再获取该许可。每个 </p>
<p>release()
 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，</p>
<p>Semaphore
 只对可用许可的号码进行计数，并采取相应的行动。</p>
<p>说白了，Semaphore是一个计数器，在计数器不为0的时候对线程就放行，一旦达到0，那么所有请求资源的新线程都会被阻塞，包括增加请求到许可的线程，也就是说Semaphore不是可重入的。每一次请求一个许可都会导致计数器减少1，同样每次释放一个许可都会导致计数器增加1，一旦达到了0，新的许可请求线程将被挂起。</p>
<p>缓存池整好使用此思想来实现的，比如链接池、对象池等。</p>
<p><strong><em>清单1 对象池</em></strong>
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.Semaphore;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;</p>
<p>public class ObjectCache<T> {</p>
<pre><code>public interface ObjectFactory&lt;T&gt; {

    T makeObject();
}

class Node {

    T obj;

    Node next;
}

final int capacity;

final ObjectFactory&lt;T&gt; factory;

final Lock lock = new ReentrantLock();

final Semaphore semaphore;

private Node head;

private Node tail;

public ObjectCache(int capacity, ObjectFactory&lt;T&gt; factory) {
    this.capacity = capacity;
    this.factory = factory;
    this.semaphore = new Semaphore(this.capacity);
    this.head = null;
    this.tail = null;
}

public T getObject() throws InterruptedException {
    semaphore.acquire();
    return getNextObject();
}

private T getNextObject() {
    lock.lock();
    try {
        if (head == null) {
            return factory.makeObject();
        } else {
            Node ret = head;
            head = head.next;
            if (head == null) tail = null;
            ret.next = null;//help GC
            return ret.obj;
        }
    } finally {
        lock.unlock();
    }
}

private void returnObjectToPool(T t) {
    lock.lock();
    try {
        Node node = new Node();
        node.obj = t;
        if (tail == null) {
            head = tail = node;
        } else {
            tail.next = node;
            tail = node;
        }

    } finally {
        lock.unlock();
    }
}

public void returnObject(T t) {
    returnObjectToPool(t);
    semaphore.release();
}
</code></pre><p>}</p>
<p>清单1描述了一个基于信号量Semaphore的对象池实现。此对象池最多支持capacity个对象，这在构造函数中传入。对象池有一个基于FIFO的队列，每次从对象池的头结点开始取对象，如果头结点为空就直接构造一个新的对象返回。否则将头结点对象取出，并且头结点往后移动。特别要说明的如果对象的个数用完了，那么新的线程将被阻塞，直到有对象被返回回来。返还对象时将对象加入FIFO的尾节点并且释放一个空闲的信号量，表示对象池中增加一个可用对象。</p>
<p>实际上对象池、线程池的原理大致上就是这样的，只不过真正的对象池、线程池要处理比较复杂的逻辑，所以实现起来还需要做很多的工作，例如超时机制，自动回收机制，对象的有效期等等问题。</p>
<p>这里特别说明的是信号量只是在信号不够的时候挂起线程，但是并不能保证信号量足够的时候获取对象和返还对象是线程安全的，所以在清单1中仍然需要锁Lock来保证并发的正确性。</p>
<p>将信号量初始化为 1，使得它在使用时最多只有一个可用的许可，从而可用作一个相互排斥的锁。这通常也称为<em>二进制信号量</em>，因为它只能有两种状态：一个可用的许可，或零个可用的许可。按此方式使用时，二进制信号量具有某种属性（与很多 </p>
<p>Lock
 实现不同），即可以由线程释放“锁”，而不是由所有者（因为信号量没有所有权的概念）。在某些专门的上下文（如死锁恢复）中这会很有用。</p>
<p>上面这段话的意思是说当某个线程A持有信号量数为1的信号量时，其它线程只能等待此线程释放资源才能继续，这时候持有信号量的线程A就相当于持有了“锁”，其它线程的继续就需要这把锁，于是线程A的释放才能决定其它线程的运行，相当于扮演了“锁”的角色。</p>
<p>另外同公平锁非公平锁一样，信号量也有公平性。如果一个信号量是公平的表示线程在获取信号量时按FIFO的顺序得到许可，也就是按照请求的顺序得到释放。这里特别说明的是：所谓请求的顺序是指在请求信号量而进入FIFO队列的顺序，有可能某个线程先请求信号而后进去请求队列，那么次线程获取信号量的顺序就会晚于其后请求但是先进入请求队列的线程。这个在公平锁和非公平锁中谈过很多。</p>
<p>除了acquire以外，Semaphore还有几种类似的acquire方法，这些方法可以更好的处理中断和超时或者异步等特性，可以参考JDK API。</p>
<p>按照同样的学习原则，下面对主要的实现进行分析。Semaphore的acquire方法实际上访问的是<strong>AQS</strong>的<em>acquireSharedInterruptibly(arg)</em>方法。这个可以参考<a href="http://www.blogjava.net/xylz/archive/2010/07/09/325612.html" target="_blank"><strong>CountDownLatch</strong></a>一节或者<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>一节。</p>
<p>所以Semaphore的await实现也是比较简单的。与CountDownLatch不同的是，Semaphore区分公平信号和非公平信号。</p>
<p><strong><em>清单2 公平信号获取方法</em></strong>
protected int tryAcquireShared(int acquires) {
    Thread current = Thread.currentThread();
    for (;;) {
        Thread first = getFirstQueuedThread();
        if (first != null &amp;&amp; first != current)
            return -1;
        int available = getState();
        int remaining = available - acquires;
        if (remaining &lt; 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}</p>
<p><strong><em>清单3 非公平信号获取方法</em></strong></p>
<p>protected int tryAcquireShared(int acquires) {
    return nonfairTryAcquireShared(acquires);
}</p>
<p>final int nonfairTryAcquireShared(int acquires) {
    for (;;) {
        int available = getState();
        int remaining = available - acquires;
        if (remaining &lt; 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}</p>
<p>对比清单2和清单3可以看到，公平信号和非公平信号在于第一次尝试能否获取信号时，公平信号量总是将当前线程进入AQS的CLH队列进行排队（因为第一次尝试时队列的头结点线程很有可能不是当前线程，当然不排除同一个线程第二次进入信号量），从而根据AQS的CLH队列的顺序FIFO依次获取信号量；而对于非公平信号量，第一次立即尝试能否拿到信号量，一旦信号量的剩余数available大于请求数（acquires通常为1），那么线程就立即得到了释放，而不需要进行AQS队列进行排队。只有remaining&lt;0的时候（也就是信号量不够的时候）才会进入AQS队列。</p>
<p>所以非公平信号量的吞吐量总是要比公平信号量的吞吐量要大，但是需要强调的是非公平信号量和非公平锁一样存在“饥渴死”的现象，也就是说活跃线程可能总是拿到信号量，而非活跃线程可能难以拿到信号量。而对于公平信号量由于总是靠请求的线程的顺序来获取信号量，所以不存在此问题。</p>
<p> <strong>参考资料：</strong></p>
<ol>
<li><a href="http://blog.csdn.net/java2000_net/archive/2009/03/17/3997449.aspx" target="_blank">信号量(Semaphore)在生产者和消费者模式的使用</a></li>
<li><a href="http://stackoverflow.com/questions/771347/what-is-mutex-and-semaphore-in-java-what-is-the-main-difference" target="_blank">What is mutex and semaphore in Java ? What is the main difference ?</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-5things5.html" target="_blank">关于 java.util.concurrent 您不知道的 5 件事，第 2 部分</a></li>
<li><a href="http://tutorials.jenkov.com/java-concurrency/semaphores.html" target="_blank">Semahores</a></li>
</ol>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/13/326021.html](http://www.blogjava.net/xylz/archive/2010/07/13/326021.html)">[http://www.blogjava.net/xylz/archive/2010/07/13/326021.html](http://www.blogjava.net/xylz/archive/2010/07/13/326021.html)</a></p>
<p>从这一节开始介绍锁里面的最后一个工具：读写锁(ReadWriteLock)。</p>
<p>ReentrantLock 实现了标准的互斥操作，也就是一次只能有一个线程持有锁，也即所谓独占锁的概念。前面的章节中一直在强调这个特点。显然这个特点在一定程度上面减低了吞吐量，实际上独占锁是一种保守的锁策略，在这种情况下任何“读/读”，“写/读”，“写/写”操作都不能同时发生。但是同样需要强调的一个概念是，锁是有一定的开销的，当并发比较大的时候，锁的开销就比较客观了。所以如果可能的话就尽量少用锁，非要用锁的话就尝试看能否改造为读写锁。</p>
<p>ReadWriteLock描述的是：一个资源能够被多个读线程访问，或者被一个写线程访问，但是不能同时存在读写线程。也就是说读写锁使用的场合是一个共享资源被大量读取操作，而只有少量的写操作（修改数据）。清单1描述了ReadWriteLock的API。</p>
<p> <strong><em>清单1 ReadWriteLock 接口</em></strong>
public interface ReadWriteLock {
    Lock readLock();
    Lock writeLock();
}</p>
<p>清单1描述的ReadWriteLock结构，这里需要说明的是ReadWriteLock并不是Lock的子接口，只不过ReadWriteLock借助Lock来实现读写两个视角。在ReadWriteLock中每次读取共享数据就需要读取锁，当需要修改共享数据时就需要写入锁。看起来好像是两个锁，但其实不尽然，在下一节中的分析中会解释这点奥秘。</p>
<p>在JDK 6里面ReadWriteLock的实现是ReentrantReadWriteLock。</p>
<p><strong><em>清单2 SimpleConcurrentMap</em></strong>
package xylz.study.concurrency.lock;</p>
<p>import java.util.ArrayList;
import java.util.Collection;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;</p>
<p>public class SimpleConcurrentMap<K, V> implements Map<K, V> {</p>
<pre><code>final ReadWriteLock lock = new ReentrantReadWriteLock();

final Lock r = lock.readLock();

final Lock w = lock.writeLock();

final Map&lt;K, V&gt; map;

public SimpleConcurrentMap(Map&lt;K, V&gt; map) {
    this.map = map;
    if (map == null) throw new NullPointerException();
}

public void clear() {
    w.lock();
    try {
        map.clear();
    } finally {
        w.unlock();
    }
}

public boolean containsKey(Object key) {
    r.lock();
    try {
        return map.containsKey(key);
    } finally {
        r.unlock();
    }
}

public boolean containsValue(Object value) {
    r.lock();
    try {
        return map.containsValue(value);
    } finally {
        r.unlock();
    }
}

public Set&lt;java.util.Map.Entry&lt;K, V&gt;&gt; entrySet() {
    throw new UnsupportedOperationException();
}

public V get(Object key) {
    r.lock();
    try {
        return map.get(key);
    } finally {
        r.unlock();
    }
}

public boolean isEmpty() {
    r.lock();
    try {
        return map.isEmpty();
    } finally {
        r.unlock();
    }
}

public Set&lt;K&gt; keySet() {
    r.lock();
    try {
        return new HashSet&lt;K&gt;(map.keySet());
    } finally {
        r.unlock();
    }
}

public V put(K key, V value) {
    w.lock();
    try {
        return map.put(key, value);
    } finally {
        w.unlock();
    }
}

public void putAll(Map&lt;? extends K, ? extends V&gt; m) {
    w.lock();
    try {
        map.putAll(m);
    } finally {
        w.unlock();
    }
}

public V remove(Object key) {
    w.lock();
    try {
        return map.remove(key);
    } finally {
        w.unlock();
    }
}

public int size() {
    r.lock();
    try {
        return map.size();
    } finally {
        r.unlock();
    }
}

public Collection&lt;V&gt; values() {
    r.lock();
    try {
        return new ArrayList&lt;V&gt;(map.values());
    } finally {
        r.unlock();
    }
}
</code></pre><p>}</p>
<p>清单2描述的是用读写锁实现的一个线程安全的Map。其中需要特别说明的是并没有实现entrySet()方法，这是因为实现这个方法比较复杂，在后面章节中讲到ConcurrentHashMap的时候会具体谈这些细节。另外这里keySet()和values()也没有直接返回Map的视图，而是一个映射原有元素的新视图，其实这个entrySet()一样，是为了保护原始Map的数据逻辑，防止不正确的修改导致原始Map发生数据错误。特别说明的是在没有特别需求的情况下没有必要按照清单2写一个线程安全的Map实现，因为ConcurrentHashMap已经完成了此操作。</p>
<p>ReadWriteLock需要严格区分读写操作，如果读操作使用了写入锁，那么降低读操作的吞吐量，如果写操作使用了读取锁，那么就可能发生数据错误。</p>
<p>另外ReentrantReadWriteLock还有以下几个特性：</p>
<ul>
<li><p><strong>公平性</strong></p>
</li>
<li><p>非公平锁（默认） 这个和独占锁的非公平性一样，由于读线程之间没有锁竞争，所以读操作没有公平性和非公平性，写操作时，由于写操作可能立即获取到锁，所以会推迟一个或多个读操作或者写操作。因此非公平锁的吞吐量要高于公平锁。</p>
</li>
<li>公平锁 利用AQS的CLH队列，释放当前保持的锁（读锁或者写锁）时，优先为等待时间最长的那个写线程分配写入锁，当前前提是写线程的等待时间要比所有读线程的等待时间要长。同样一个线程持有写入锁或者有一个写线程已经在等待了，那么试图获取公平锁的（非重入）所有线程（包括读写线程）都将被阻塞，直到最先的写线程释放锁。如果读线程的等待时间比写线程的等待时间还有长，那么一旦上一个写线程释放锁，这一组读线程将获取锁。</li>
<li><p><strong>重入性</strong></p>
</li>
<li><p>读写锁允许读线程和写线程按照请求锁的顺序重新获取读取锁或者写入锁。当然了只有写线程释放了锁，读线程才能获取重入锁。</p>
</li>
<li>写线程获取写入锁后可以再次获取读取锁，但是读线程获取读取锁后却不能获取写入锁。</li>
<li>另外读写锁最多支持65535个递归写入锁和65535个递归读取锁。</li>
<li><p><strong>锁降级</strong></p>
</li>
<li><p>写线程获取写入锁后可以获取读取锁，然后释放写入锁，这样就从写入锁变成了读取锁，从而实现锁降级的特性。</p>
</li>
<li><p>锁升级</p>
</li>
<li><p>读取锁是不能直接升级为写入锁的。因为获取一个写入锁需要释放所有读取锁，所以如果有两个读取锁视图获取写入锁而都不释放读取锁时就会发生死锁。</p>
</li>
<li><p><strong>锁获取中断</strong></p>
</li>
<li><p>读取锁和写入锁都支持获取锁期间被中断。这个和独占锁一致。</p>
</li>
<li><p><strong>条件变量</strong></p>
</li>
<li><p>写入锁提供了条件变量(Condition)的支持，这个和独占锁一致，但是读取锁却不允许获取条件变量，将得到一个</p>
</li>
</ul>
<p>UnsupportedOperationException
异常。</p>
<ul>
<li><p><strong>重入数</strong></p>
</li>
<li><p>读取锁和写入锁的数量最大分别只能是65535（包括重入数）。这在下节中有介绍。</p>
</li>
</ul>
<p>上面几个特性对读写锁的理解很有帮助，而且也是必要的，另外在下一节中讲ReadWriteLock的实现会用到这些知识的。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/14/326080.html](http://www.blogjava.net/xylz/archive/2010/07/14/326080.html)">[http://www.blogjava.net/xylz/archive/2010/07/14/326080.html](http://www.blogjava.net/xylz/archive/2010/07/14/326080.html)</a> </p>
<p>这一节主要是谈谈读写锁的实现。</p>
<p>上一节中提到，ReadWriteLock看起来有两个锁：readLock/writeLock。如果真的是两个锁的话，它们之间又是如何相互影响的呢？</p>
<p>事实上在ReentrantReadWriteLock里锁的实现是靠java.util.concurrent.locks.ReentrantReadWriteLock.Sync完成的。这个类看起来比较眼熟，实际上它是AQS的一个子类，这中类似的结构在CountDownLatch、ReentrantLock、Semaphore里面都存在。同样它也有两种实现：公平锁和非公平锁，也就是java.util.concurrent.locks.ReentrantReadWriteLock.FairSync和java.util.concurrent.locks.ReentrantReadWriteLock.NonfairSync。这里暂且不提。</p>
<p>在ReentrantReadWriteLock里面的锁主体就是一个Sync，也就是上面提到的FairSync或者NonfairSync，所以说实际上只有一个锁，只是在获取读取锁和写入锁的方式上不一样，所以前面才有读写锁是独占锁的两个不同视图一说。</p>
<p>ReentrantReadWriteLock里面有两个类：ReadLock/WriteLock，这两个类都是Lock的实现。</p>
<p><strong><em>清单1 ReadLock 片段</em></strong>
public static class ReadLock implements Lock, java.io.Serializable  {
    private final Sync sync;</p>
<pre><code>protected ReadLock(ReentrantReadWriteLock lock) {
    sync = lock.sync;
}

public void lock() {
    sync.acquireShared(1);
}

public void lockInterruptibly() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

public  boolean tryLock() {
    return sync.tryReadLock();
}

public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
}

public  void unlock() {
    sync.releaseShared(1);
}

public Condition newCondition() {
    throw new UnsupportedOperationException();
}
</code></pre><p>}</p>
<p><strong><em>清单2 WriteLock 片段</em></strong></p>
<p>public static class WriteLock implements Lock, java.io.Serializable  {
    private final Sync sync;
    protected WriteLock(ReentrantReadWriteLock lock) {
        sync = lock.sync;
    }
    public void lock() {
        sync.acquire(1);
    }</p>
<pre><code>public void lockInterruptibly() throws InterruptedException {
    sync.acquireInterruptibly(1);
}

public boolean tryLock( ) {
    return sync.tryWriteLock();
}

public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireNanos(1, unit.toNanos(timeout));
}

public void unlock() {
    sync.release(1);
}

public Condition newCondition() {
    return sync.newCondition();
}

public boolean isHeldByCurrentThread() {
    return sync.isHeldExclusively();
}

public int getHoldCount() {
    return sync.getWriteHoldCount();
}
</code></pre><p>}</p>
<p>清单1描述的是读锁的实现，清单2描述的是写锁的实现。显然WriteLock就是一个独占锁，这和ReentrantLock里面的实现几乎相同，都是使用了AQS的acquire/release操作。当然了在内部处理方式上与ReentrantLock还是有一点不同的。对比清单1和清单2可以看到，ReadLock获取的是共享锁，WriteLock获取的是独占锁。</p>
<p>在AQS章节中介绍到AQS中有一个state字段（int类型，32位）用来描述有多少线程获持有锁。在独占锁的时代这个值通常是0或者1（如果是重入的就是重入的次数），在共享锁的时代就是持有锁的数量。在上一节中谈到，ReadWriteLock的读、写锁是相关但是又不一致的，所以需要两个数来描述读锁（共享锁）和写锁（独占锁）的数量。显然现在一个state就不够用了。于是在ReentrantReadWrilteLock里面将这个字段一分为二，高位16位表示共享锁的数量，低位16位表示独占锁的数量（或者重入数量）。2^16-1=65536，这就是上节中提到的为什么共享锁和独占锁的数量最大只能是65535的原因了。</p>
<p>有了上面的知识后再来分析读写锁的获取和释放就容易多了。</p>
<p><strong><em>清单3 写入锁获取片段</em></strong>
protected final boolean tryAcquire(int acquires) {
    Thread current = Thread.currentThread();
    int c = getState();
    int w = exclusiveCount(c);
    if (c != 0) {
        if (w == 0 || current != getExclusiveOwnerThread())
            return false;
        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
    }
    if ((w == 0 &amp;&amp; writerShouldBlock(current)) ||
        !compareAndSetState(c, c + acquires))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}</p>
<p>清单3 是写入锁获取的逻辑片段，整个工作流程是这样的：</p>
<ol>
<li>持有锁线程数非0（c=getState()不为0），如果写线程数（w）为0（那么读线程数就不为0）或者独占锁线程（持有锁的线程）不是当前线程就返回失败，或者写入锁的数量（其实是重入数）大于65535就抛出一个Error异常。否则进行2。</li>
<li>如果当且写线程数位0（那么读线程也应该为0，因为步骤1已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果增加写线程数失败也返回失败。否则进行3。</li>
<li>设置独占线程（写线程）为当前线程，返回true。</li>
</ol>
<p>清单3 中 exclusiveCount(c)就是获取写线程数（包括重入数），也就是state的低16位值。另外这里有一段逻辑是当前写线程是否需要阻塞writerShouldBlock(current)。清单4 和清单5 就是公平锁和非公平锁中是否需要阻塞的片段。很显然对于非公平锁而言总是不阻塞当前线程，而对于公平锁而言如果AQS队列不为空或者当前线程不是在AQS的队列头那么就阻塞线程，直到队列前面的线程处理完锁逻辑。</p>
<p><strong><em>清单4 公平读写锁写线程是否阻塞</em></strong>
final boolean writerShouldBlock(Thread current) {
    return !isFirst(current);
}</p>
<p><strong><em>清单5 非公平读写锁写线程是否阻塞</em></strong></p>
<p>final boolean writerShouldBlock(Thread current) {
    return false;
}</p>
<p>写入锁的获取逻辑清楚后，释放锁就比较简单了。清单6 描述的写入锁释放逻辑片段，其实就是检测下剩下的写入锁数量，如果是0就将独占锁线程清空（意味着没有线程获取锁），否则就是说当前是重入锁的一次释放，所以不能将独占锁线程清空。然后将剩余线程状态数写回AQS。</p>
<p><strong><em>清单6 写入锁释放逻辑片段</em></strong>
protected final boolean tryRelease(int releases) {
    int nextc = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    if (exclusiveCount(nextc) == 0) {
        setExclusiveOwnerThread(null);
        setState(nextc);
        return true;
    } else {
        setState(nextc);
        return false;
    }
}</p>
<p>清单3~6 描述的写入锁的获取释放过程。读取锁的获取和释放过程要稍微复杂些。 清单7描述的是读取锁的获取过程。</p>
<p><strong><em>清单7 读取锁获取过程片段</em></strong>
protected final int tryAcquireShared(int unused) {
    Thread current = Thread.currentThread();
    int c = getState();
    if (exclusiveCount(c) != 0 &amp;&amp;
        getExclusiveOwnerThread() != current)
        return -1;
    if (sharedCount(c) == MAX_COUNT)
        throw new Error(&quot;Maximum lock count exceeded&quot;);
    if (!readerShouldBlock(current) &amp;&amp;
        compareAndSetState(c, c + SHARED_UNIT)) {
        HoldCounter rh = cachedHoldCounter;
        if (rh == null || rh.tid != current.getId())
            cachedHoldCounter = rh = readHolds.get();
        rh.count++;
        return 1;
    }
    return fullTryAcquireShared(current);
}</p>
<p>final int fullTryAcquireShared(Thread current) {
    HoldCounter rh = cachedHoldCounter;
    if (rh == null || rh.tid != current.getId())
        rh = readHolds.get();
    for (;;) {
        int c = getState();
        int w = exclusiveCount(c);
        if ((w != 0 &amp;&amp; getExclusiveOwnerThread() != current) ||
            ((rh.count | w) == 0 &amp;&amp; readerShouldBlock(current)))
            return -1;
        if (sharedCount(c) == MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        if (compareAndSetState(c, c + SHARED_UNIT)) {
            cachedHoldCounter = rh; // cache for release
            rh.count++;
            return 1;
        }
    }
}</p>
<p>读取锁获取的过程是这样的：</p>
<ol>
<li>如果写线程持有锁（也就是独占锁数量不为0），并且独占线程不是当前线程，那么就返回失败。因为允许写入线程获取锁的同时获取读取锁。否则进行2。</li>
<li>如果读线程请求锁数量达到了65535（包括重入锁），那么就跑出一个错误Error，否则进行3。</li>
<li>如果读线程不用等待（实际上是是否需要公平锁），并且增加读取锁状态数成功，那么就返回成功，否则进行4。</li>
<li>步骤3失败的原因是CAS操作修改状态数失败，那么就需要循环不断尝试去修改状态直到成功或者锁被写入线程占有。实际上是过程3的不断尝试直到CAS计数成功或者被写入线程占有锁。</li>
</ol>
<p>在清单7 中有一个对象HoldCounter，这里暂且不提这是什么结构和为什么存在这样一个结构。</p>
<p>接下来根据清单8 我们来看如何释放一个读取锁。同样先不理HoldCounter，关键的在于for循环里面，其实就是一个不断尝试的CAS操作，直到修改状态成功。前面说过state的高16位描述的共享锁（读取锁）的数量，所以每次都需要减去2^16，这样就相当于读取锁数量减1。实际上SHARED_UNIT=1&lt;&lt;16。</p>
<p><strong><em>清单8 读取锁释放过程</em></strong>
protected final boolean tryReleaseShared(int unused) {
    HoldCounter rh = cachedHoldCounter;
    Thread current = Thread.currentThread();
    if (rh == null || rh.tid != current.getId())
        rh = readHolds.get();
    if (rh.tryDecrement() &lt;= 0)
        throw new IllegalMonitorStateException();
    for (;;) {
        int c = getState();
        int nextc = c - SHARED_UNIT;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}</p>
<p>好了，现在回头看HoldCounter到底是一个什么东西。首先我们可以看到只有在获取共享锁（读取锁）的时候加1，也只有在释放共享锁的时候减1有作用，并且在释放锁的时候抛出了一个IllegalMonitorStateException异常。而我们知道IllegalMonitorStateException通常描述的是一个线程操作一个不属于自己的监视器对象的引发的异常。也就是说这里的意思是一个线程释放了一个不属于自己或者不存在的共享锁。</p>
<p>前面的章节中一再强调，对于共享锁，其实并不是锁的概念，更像是计数器的概念。一个共享锁就相对于一次计数器操作，一次获取共享锁相当于计数器加1，释放一个共享锁就相当于计数器减1。显然只有线程持有了共享锁（也就是当前线程携带一个计数器，描述自己持有多少个共享锁或者多重共享锁），才能释放一个共享锁。否则一个没有获取共享锁的线程调用一次释放操作就会导致读写锁的state（持有锁的线程数，包括重入数）错误。</p>
<p>明白了HoldCounter的作用后我们就可以猜到它的作用其实就是当前线程持有共享锁（读取锁）的数量，包括重入的数量。那么这个数量就必须和线程绑定在一起。</p>
<p>在Java里面将一个对象和线程绑定在一起，就只有ThreadLocal才能实现了。所以毫无疑问HoldCounter就应该是绑定到线程上的一个计数器。</p>
<p><strong><em>清单9 线程持有读取锁数量的计数器</em></strong>
static final class HoldCounter {
    int count;
    final long tid = Thread.currentThread().getId();
    int tryDecrement() {
        int c = count;
        if (c &gt; 0)
            count = c - 1;
        return c;
    }
}</p>
<p>static final class ThreadLocalHoldCounter
    extends ThreadLocal<HoldCounter> {
    public HoldCounter initialValue() {
        return new HoldCounter();
    }
}</p>
<p>清单9 描述的是线程持有读取锁数量的计数器。可以看到这里使用ThreadLocal将HoldCounter绑定到当前线程上，同时HoldCounter也持有线程Id，这样在释放锁的时候才能知道ReadWriteLock里面缓存的上一个读取线程（cachedHoldCounter）是否是当前线程。这样做的好处是可以减少ThreadLocal.get()的次数，因为这也是一个耗时操作。需要说明的是这样HoldCounter绑定线程id而不绑定线程对象的原因是避免HoldCounter和ThreadLocal互相绑定而GC难以释放它们（尽管GC能够智能的发现这种引用而回收它们，但是这需要一定的代价），所以其实这样做只是为了帮助GC快速回收对象而已。</p>
<p>除了readLock()和writeLock()外，Lock对象还允许tryLock()，那么ReadLock和WriteLock的tryLock()不一样。清单10 和清单11 分别描述了读取锁的tryLock()和写入锁的tryLock()。</p>
<p>读取锁tryLock()也就是tryReadLock()成功的条件是：没有写入锁或者写入锁是当前线程，并且读线程共享锁数量没有超过65535个。</p>
<p>写入锁tryLock()也就是tryWriteLock()成功的条件是: 没有写入锁或者写入锁是当前线程，并且尝试一次修改state成功。</p>
<p><strong><em>清单10 读取锁的tryLock()</em></strong>
final boolean tryReadLock() {
    Thread current = Thread.currentThread();
    for (;;) {
        int c = getState();
        if (exclusiveCount(c) != 0 &amp;&amp;
            getExclusiveOwnerThread() != current)
            return false;
        if (sharedCount(c) == MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        if (compareAndSetState(c, c + SHARED_UNIT)) {
            HoldCounter rh = cachedHoldCounter;
            if (rh == null || rh.tid != current.getId())
                cachedHoldCounter = rh = readHolds.get();
            rh.count++;
            return true;
        }
    }
}</p>
<p><strong><em>清单11 写入锁的tryLock()</em></strong></p>
<p>final boolean tryWriteLock() {
    Thread current = Thread.currentThread();
    int c = getState();
    if (c != 0) {
        int w = exclusiveCount(c);
        if (w == 0 ||current != getExclusiveOwnerThread())
            return false;
        if (w == MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
    }
    if (!compareAndSetState(c, c + 1))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}</p>
<p>整个读写锁的逻辑大概就这么多，其实真正研究起来也不是很复杂，真正复杂的东西都在AQS里面。</p>
<p>锁部分的原理和思想都介绍完了，下一节里面会对锁机进行小节，并对线程并发也会有一些简单的小节。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/15/326152.html](http://www.blogjava.net/xylz/archive/2010/07/15/326152.html)">[http://www.blogjava.net/xylz/archive/2010/07/15/326152.html](http://www.blogjava.net/xylz/archive/2010/07/15/326152.html)</a> </p>
<p>主要谈谈锁的性能以及其它一些理论知识，内容主要的出处是《<a href="http://www.amazon.com/exec/obidos/ASIN/0321349601/ref=nosim/none0b69" target="_blank">Java Concurrency in Practice</a>》，结合自己的理解和实际应用对锁机制进行一个小小的总结。</p>
<p>首先需要强调的一点是：所有锁（包括内置锁和高级锁）都是有性能消耗的，也就是说在高并发的情况下，由于锁机制带来的上下文切换、资源同步等消耗是非常可观的。在某些极端情况下，线程在锁上的消耗可能比线程本身的消耗还要多。所以如果可能的话，在任何情况下都尽量少用锁，如果不可避免那么采用非阻塞算法是一个不错的解决方案，但是却也不是绝对的。</p>
<p><strong>内部锁</strong></p>
<p>Java语言通过synchronized关键字来保证原子性。这是因为每一个Object都有一个隐含的锁，这个也称作监视器对象。在进入synchronized之前自动获取此内部锁，而一旦离开此方式（不管通过和中方式离开此方法）都会自动释放锁。显然这是一个独占锁，每个锁请求之间是互斥的。相对于前面介绍的众多高级锁（Lock/ReadWriteLock等），synchronized的代价都比后者要高。但是synchronized的语法比较简单，而且也比较容易使用和理解，不容易写法上的错误。而我们知道Lock一旦调用了lock()方法获取到锁而未正确释放的话很有可能就死锁了。所以Lock的释放操作总是跟在finally代码块里面，这在代码结构上也是一次调整和冗余。另外前面介绍中说过Lock的实现已经将硬件资源用到了极致，所以未来可优化的空间不大，除非硬件有了更高的性能。但是synchronized只是规范的一种实现，这在不同的平台不同的硬件还有很高的提升空间，未来Java在锁上的优化也会主要在这上面。</p>
<p><strong>性能</strong></p>
<p>由于锁总是带了性能影响，所以是否使用锁和使用锁的场合就变得尤为重要。如果在一个高并发的Web请求中使用了强制的独占锁，那么就可以发现Web的吞吐量将急剧下降。</p>
<p>为了利用并发来提高性能，出发点就是：更有效的利用现有的资源，同时让程序尽可能的开拓更多可用的资源。这意味着机器尽可能的处于忙碌的状态，通常意义是说CPU忙于计算，而不是等待。当然CPU要做有用的事情，而不是进行无谓的循环。当然在实践中通常会预留一些资源出来以便应急特殊情况，这在以后的线程池并发中可以看到很多例子。</p>
<p><strong>线程阻塞</strong></p>
<p>锁机制的实现通常需要操作系统提供支持，显然这会增加开销。当锁竞争的时候，失败的线程必然会发生阻塞。JVM既能自旋等待（不断尝试，知道成功，很多CAS就是这样实现的），也能够在操作系统中挂起阻塞的线程，直到超时或者被唤醒。通常情况下这取决于上下文切换的开销以及与获取锁需要等待的时间二者之间的关系。自旋等待适合于比较短的等待，而挂起线程比较适合那些比较耗时的等待。</p>
<p>挂起一个线程可能是因为无法获取到锁，或者需要某个特定的条件，或者耗时的I/O操作。挂起一个线程需要两次额外的上下文切换以及操作系统、缓存等多资源的配合：如果线程被提前换出，那么一旦拿到锁或者条件满足，那么又需要将线程换回执行队列，这对线程而言，两次上下文切换可能比较耗时。</p>
<hr>
<p><strong>锁竞争</strong></p>
<p>影响锁竞争性的条件有两个：锁被请求的频率和每次持有锁的时间。显然当而这二者都很小的时候，锁竞争不会成为主要的瓶颈。但是如果锁使用不当，导致二者都比较大，那么很有可能CPU不能有效的处理任务，任务被大量堆积。</p>
<p>所以减少锁竞争的方式有下面三种：</p>
<ol>
<li>减少锁持有的时间</li>
<li>减少锁请求的频率</li>
<li>采用共享锁取代独占锁</li>
</ol>
<p><strong>死锁</strong></p>
<p>如果一个线程永远不释放另外一个线程需要的资源那么就会导致死锁。这有两种情况：一种情况是线程A永远不释放锁，结果B一直拿不到锁，所以线程B就“死掉”了；第二种情况下，线程A拥有线程B需要的锁Y，同时线程B拥有线程A需要的锁X，那么这时候线程A/B互相依赖对方释放锁，于是二者都“死掉”了。</p>
<p>还有一种情况为发生死锁，如果一个线程总是不能被调度，那么等待此线程结果的线程可能就死锁了。这种情况叫做线程饥饿死锁。比如说在前面介绍的非公平锁中，如果某些线程非常活跃，在高并发情况下这类线程可能总是拿到锁，那么那些活跃度低的线程可能就一直拿不到锁，这样就发生了“饥饿死”。</p>
<p>避免死锁的解决方案是：尽可能的按照锁的使用规范请求锁，另外锁的请求粒度要小（不要在不需要锁的地方占用锁，锁不用了尽快释放）；在高级锁里面总是使用tryLock或者定时机制（这个以后会讲，就是指定获取锁超时的时间，如果时间到了还没有获取到锁那么就放弃）。高级锁（Lock）里面的这两种方式可以有效的避免死锁。</p>
<p><strong>活锁</strong></p>
<p>活锁描述的是线程总是尝试某项操作却总是失败的情况。这种情况下尽管线程没有被阻塞，但是人物却总是不能被执行。比如在一个死循环里面总是尝试做某件事，结果却总是失败，现在线程将永远不能跳出这个循环。另外一种情况是在一个队列中每次从队列头取出一个任务来执行，每次都失败，然后将任务放入队列头，接下来再一次从队列头取出任务执行，仍然失败。</p>
<p>还有一种活锁方式发生在“碰撞协让”情况下：两个人过独木桥，如果在半路相撞，双方礼貌退出去然后再试一次。如果总是失败，那么这两个任务将一直无法得到执行。</p>
<p><strong>总之解决锁问题的关键就是：从简单的开始，先保证正确，然后再开始优化。</strong>
<strong>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/16/326246.html](http://www.blogjava.net/xylz/archive/2010/07/16/326246.html)">[http://www.blogjava.net/xylz/archive/2010/07/16/326246.html](http://www.blogjava.net/xylz/archive/2010/07/16/326246.html)</a> </strong></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency3-锁机制/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency3-锁机制" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/58/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/56/">56</a></li><li><a class="page-number" href="/page/57/">57</a></li><li><a class="page-number" href="/page/58/">58</a></li><li class="active"><li><span class="page-number current">59</span></li><li><a class="page-number" href="/page/60/">60</a></li><li><a class="page-number" href="/page/61/">61</a></li><li><a class="page-number" href="/page/62/">62</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/164/">164</a></li><li><a class="page-number" href="/page/165/">165</a></li><li><a class="extend next" href="/page/60/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Blog powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a> Theme <strong><a href='https://github.com/chenall/hexo-theme-chenall'>chenall</a></strong>(Some change in it)<span class="pull-right"> 更新时间: <em>2014-03-15 13:06:28</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
