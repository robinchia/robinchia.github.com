
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>The 54 Page | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="It so life">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency4-并发容器/">深入浅出 Java Concurrency (4)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency4-并发容器/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-4-">深入浅出 Java Concurrency (4): 并发容器</h1>
<p>从这一节开始正式进入并发容器的部分，来看看JDK 6带来了哪些并发容器。</p>
<p>在JDK 1.4以下只有Vector和Hashtable是线程安全的集合（也称并发容器，Collections.synchronized/*系列也可以看作是线程安全的实现）。从JDK 5开始增加了线程安全的Map接口ConcurrentMap和线程安全的队列BlockingQueue（尽管Queue也是同时期引入的新的集合，但是规范并没有规定一定是线程安全的，事实上一些实现也不是线程安全的，比如PriorityQueue、ArrayDeque、LinkedList等，在Queue章节中会具体讨论这些队列的结构图和实现）。</p>
<p>在介绍ConcurrencyMap之前先来回顾下Map的体系结构。下图描述了Map的体系结构，其中蓝色字体的是JDK 5以后新增的并发容器。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency16part1ConcurrentMap1_10A52/image_2.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>针对上图有以下几点说明：</p>
<ol>
<li>Hashtable是JDK 5之前Map唯一线程安全的内置实现（Collections.synchronizedMap不算）。特别说明的是Hashtable的t是小写的（不知道为啥），Hashtable继承的是Dictionary（Hashtable是其唯一公开的子类），并<strong>不继承AbstractMap或者HashMap</strong>。尽管Hashtable和HashMap的结构非常类似，但是他们之间并没有多大联系。</li>
<li>ConcurrentHashMap是HashMap的线程安全版本，ConcurrentSkipListMap是TreeMap的线程安全版本。</li>
<li>最终可用的线程安全版本Map实现是ConcurrentHashMap/ConcurrentSkipListMap/Hashtable/Properties四个，但是Hashtable是过时的类库，因此如果可以的应该尽可能的使用ConcurrentHashMap和ConcurrentSkipListMap。</li>
</ol>
<p>回到正题来，这个小节主要介绍ConcurrentHashMap的API以及应用，下一节才开始将原理和分析。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency16part1ConcurrentMap1_10A52/image_4.png" target="_blank"><img src="&quot;ConcurrentMap API&quot;" alt="ConcurrentMap API"></a></p>
<p>除了实现Map接口里面对象的方法外，ConcurrentHashMap还实现了ConcurrentMap里面的四个方法。</p>
<p><strong>V putIfAbsent(K key,V value)</strong></p>
<p>如果不存在key对应的值，则将value以key加入Map，否则返回key对应的旧值。这个等价于清单1 的操作：</p>
<p><strong><em>清单1 putIfAbsent的等价操作</em></strong>
if (!map.containsKey(key)) 
   return map.put(key, value);
else
   return map.get(key);</p>
<p>在前面的章节中提到过，连续两个或多个原子操作的序列并不一定是原子操作。比如上面的操作即使在Hashtable中也不是原子操作。而putIfAbsent就是一个线程安全版本的操作的。</p>
<p>有些人喜欢用这种功能来实现<a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html" target="_blank"><strong>单例模式</strong></a>，例如清单2。</p>
<p><strong><em>清单2 一种单例模式的实现</em></strong>
package xylz.study.concurrency;</p>
<p>import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;</p>
<p>public class ConcurrentDemo1 {</p>
<pre><code>private static final ConcurrentMap&lt;String, ConcurrentDemo1&gt; map = new ConcurrentHashMap&lt;String, ConcurrentDemo1&gt;();
private static ConcurrentDemo1 instance;
public static ConcurrentDemo1 getInstance() {
    if (instance == null) {

        map.putIfAbsent(&quot;INSTANCE&quot;, new ConcurrentDemo1());

        instance = map.get(&quot;INSTANCE&quot;);
    }
    return instance;
}

private ConcurrentDemo1() {
}
</code></pre><p>}</p>
<p>当然这里只是一个操作的例子，实际上在<a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html" target="_blank"><strong>单例模式</strong></a>文章中有很多的实现和比较。清单2 在存在大量单例的情况下可能有用，实际情况下很少用于单例模式。但是这个方法避免了向Map中的同一个Key提交多个结果的可能，有时候在去掉重复记录上很有用（如果记录的格式比较固定的话）。</p>
<p><strong>boolean remove(Object key,Object value)</strong></p>
<p>只有目前将键的条目映射到给定值时，才移除该键的条目。这等价于清单3 的操作。</p>
<p><strong><em>清单3 remove(Object,Object)的等价操作</em></strong>
if (map.containsKey(key) &amp;&amp; map.get(key).equals(value)) {
   map.remove(key);
   return true;
}
return false;</p>
<p>由于集合类通常比较的hashCode和equals方法，而这两个方法是在Object对象里面，因此两个对象如果hashCode一致，并且覆盖了equals方法后也一致，那么这两个对象在集合类里面就是“相同”的，不管是否是同一个对象或者同一类型的对象。也就是说只要key1.hashCode()==key2.hashCode() &amp;&amp; key1.equals(key2)，那么key1和key2在集合类里面就认为是一致，哪怕他们的Class类型不一致也没关系，所以在很多集合类里面允许通过Object来类型来比较（或者定位）。比如说Map尽管添加的时候只能通过制定的类型<K,V>，但是删除的时候却允许通过一个Object来操作，而不必是K类型。</p>
<p>既然Map里面有一个remove(Object)方法，为什么ConcurrentMap还需要remove(Object,Object)方法呢？这是因为尽管Map里面的key没有变化，但是value可能已经被其他线程修改了，如果修改后的值是我们期望的，那么我们就不能拿一个key来删除此值，尽管我们的期望值是删除此key对于的旧值。</p>
<p>这种特性在原子操作章节的<a href="http://www.blogjava.net/xylz/archive/2010/07/02/325079.html" target="_blank">AtomicMarkableReference</a>和<a href="http://www.blogjava.net/xylz/archive/2010/07/02/325079.html" target="_blank">AtomicStampedReference</a>里面介绍过。</p>
<p><strong>boolean replace(K key,V oldValue,V newValue)</strong></p>
<p>只有目前将键的条目映射到给定值时，才替换该键的条目。这等价于清单4 的操作。</p>
<p><strong><em>清单4 replace(K,V,V)的等价操作</em></strong>
if (map.containsKey(key) &amp;&amp; map.get(key).equals(oldValue)) {
   map.put(key, newValue);
   return true;
}
return false;</p>
<p><strong>V replace(K key,V value)</strong></p>
<p>只有当前键存在的时候更新此键对于的值。这等价于清单5 的操作。</p>
<p><strong><em>清单5 replace(K,V)的等价操作</em></strong>
if (map.containsKey(key)) {
   return map.put(key, value);
}
return null;</p>
<p>replace(K,V,V)相比replace(K,V)而言，就是增加了匹配oldValue的操作。</p>
<p>其实这4个扩展方法，是ConcurrentMap附送的四个操作，其实我们更关心的是Map本身的操作。当然如果没有这4个方法，要完成类似的功能我们可能需要额外的锁，所以有总比没有要好。比如清单6，如果没有putIfAbsent内置的方法，我们如果要完成此操作就需要完全锁住整个Map，这样就大大降低了ConcurrentMap的并发性。这在下一节中有详细的分析和讨论。</p>
<p><strong><em>清单6 putIfAbsent的外部实现</em></strong>
public V putIfAbsent(K key, V value) {
    synchronized (map) {
        if (!map.containsKey(key)) return map.put(key, value);
        return map.get(key);
    }
}</p>
<p>参考资料：</p>
<ul>
<li><a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html" target="_blank">单例模式完全解析</a></li>
<li><a href="http://www.blogjava.net/xylz/archive/2010/07/02/325079.html" target="_blank">原子操作 part 2 数组、引用的原子操作</a></li>
</ul>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/19/326527.html](http://www.blogjava.net/xylz/archive/2010/07/19/326527.html)">[http://www.blogjava.net/xylz/archive/2010/07/19/326527.html](http://www.blogjava.net/xylz/archive/2010/07/19/326527.html)</a></p>
<p>本来想比较全面和深入的谈谈ConcurrentHashMap的，发现网上有很多对HashMap和ConcurrentHashMap分析的文章，因此本小节尽可能的分析其中的细节，少一点理论的东西，多谈谈内部设计的原理和思想。</p>
<p>要谈ConcurrentHashMap的构造，就不得不谈HashMap的构造，因此先从HashMap开始简单介绍。</p>
<hr>
<p><strong>HashMap原理</strong></p>
<p>我们从头开始设想。要将对象存放在一起，如何设计这个容器。目前只有两条路可以走，一种是采用分格技术，每一个对象存放于一个格子中，这样通过对格子的编号就能取到或者遍历对象；另一种技术就是采用串联的方式，将各个对象串联起来，这需要各个对象至少带有下一个对象的索引（或者指针）。显然第一种就是数组的概念，第二种就是链表的概念。所有的容器的实现其实都是基于这两种方式的，不管是数组还是链表，或者二者俱有。HashMap采用的就是数组的方式。</p>
<p>有了存取对象的容器后还需要以下两个条件才能完成Map所需要的条件。</p>
<ul>
<li>能够快速定位元素：Map的需求就是能够根据一个查询条件快速得到需要的结果，所以这个过程需要的就是尽可能的快。</li>
<li>能够自动扩充容量：显然对于容器而然，不需要人工的去控制容器的容量是最好的，这样对于外部使用者来说越少知道底部细节越好，不仅使用方便，也越安全。</li>
</ul>
<p>首先条件1，快速定位元素。快速定位元素属于算法和数据结构的范畴，通常情况下哈希（Hash）算法是一种简单可行的算法。所谓<strong>哈希算法</strong>，是将任意长度的二进制值映射为固定长度的较小二进制值。常见的MD2,MD4,MD5，SHA-1等都属于Hash算法的范畴。具体的算法原理和介绍可以参考相应的算法和数据结构的书籍，但是这里特别提醒一句，由于将一个较大的集合映射到一个较小的集合上，所以必然就存在多个元素映射到同一个元素上的结果，这个叫“碰撞”，后面会用到此知识，暂且不表。</p>
<p>条件2，如果满足了条件1，一个元素映射到了某个位置，现在一旦扩充了容量，也就意味着元素映射的位置需要变化。因为对于Hash算法来说，调整了映射的小集合，那么原来映射的路径肯定就不复存在，那么就需要对现有重新计算映射路径，也就是所谓的rehash过程。</p>
<p>好了有了上面的理论知识后来看HashMap是如何实现的。</p>
<p>在HashMap中首先由一个对象数组table是不可避免的，修饰符transient只是表示序列号的时候不被存储而已。size描述的是Map中元素的大小，threshold描述的是达到指定元素个数后需要扩容，loadFactor是扩容因子(loadFactor&gt;0)，也就是计算threshold的。那么元素的容量就是table.length，也就是数组的大小。换句话说，如果存取的元素大小达到了整个容量(table.length)的loadFactor倍（也就是table.length/*loadFactor个），那么就需要扩充容量了。在HashMap中每次扩容就是将扩大数组的一倍，使数组大小为原来的两倍。</p>
<p> <a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency17part2ConcurrentMap2_FF15/image_2.png" target="_blank"><img src="&quot;HashMap数据结构&quot;" alt="HashMap数据结构"></a></p>
<p>然后接下来看如何将一个元素映射到数组table中。显然要映射的key是一个无尽的超大集合，而table是一个较小的有限集合，那么一种方式就是将key编码后的hashCode值取模映射到table上，这样看起来不错。但是在Java中采用了一种更高效的办法。由于与(&amp;)是比取模(%)更高效的操作，因此Java中采用hash值与数组大小-1后取与来确定数组索引的。为什么这样做是更有效的？<a href="http://www.javaeye.com/topic/539465" target="_blank">参考资料7</a>对这一块进行非常详细的分析，这篇文章的作者非常认真，也非常仔细的分析了里面包含的思想。</p>
<p><strong><em>清单1 indexFor片段</em></strong>
static int indexFor(int h, int length) {
    return h &amp; (length-1);
}</p>
<p>前面说明，既然是大集合映射到小集合上，那么就必然存在“碰撞”，也就是不同的key映射到了相同的元素上。那么HashMap是怎么解决这个问题的？</p>
<p>在HashMap中采用了下面方式，解决了此问题。</p>
<ol>
<li>同一个索引的数组元素组成一个链表，查找允许时循环链表找到需要的元素。</li>
<li>尽可能的将元素均匀的分布在数组上。</li>
</ol>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency17part2ConcurrentMap2_FF15/image_4.png" target="_blank"><img src="&quot;Map.Entry结构&quot;" alt="Map.Entry结构"></a>对于问题1，HashMap采用了上图的一种数据结构。table中每一个元素是一个Map.Entry，其中Entry包含了四个数据，key,value,hash,next。key和value是存储的数据；hash是元素key的Hash后的表现形式（最终要映射到数组上），这里链表上所有元素的hash经过清单1 的indexFor后将得到相同的数组索引；next是指向下一个元素的索引，同一个链表上的元素就是通过next串联起来的。</p>
<p>再来看问题2 尽可能的将元素均匀的分布在数组上这个问题是怎么解决的。首先清单2 是将key的hashCode经过一系列的变换，使之更符合小数据集合的散列模型。</p>
<p><strong><em>清单2 hashCode的二次散列</em></strong>
static int hash(int h) {
    // This function ensures that hashCodes that differ only by
    // constant multiples at each bit position have a bounded
    // number of collisions (approximately 8 at default load factor).
    h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);
    return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);
}</p>
<p>至于清单2 为什么这样散列我没有找到依据，也没有什么好的参考资料。<a href="http://www.javaeye.com/topic/709945" target="_blank">参考资料1</a> 分析了此过程，认为是一种比较有效的方式，有兴趣的可以研究下。</p>
<p>第二点就是在清单1 的描述中，尽可能的与数组的长度减1的数与操作，使之分布均匀。这在<a href="http://www.javaeye.com/topic/539465" target="_blank">参考资料7</a> 中有介绍。</p>
<p>第三点就是构造数组时数组的长度是2的倍数。清单3 反映了这个过程。为什么要是2的倍数？在<a href="http://www.javaeye.com/topic/539465" target="_blank">参考资料7</a> 中分析说是使元素尽可能的分布均匀。</p>
<p><strong><em>清单3 HashMap 构造数组</em></strong>
// Find a power of 2 &gt;= initialCapacity
int capacity = 1;
while (capacity &lt; initialCapacity)
    capacity &lt;&lt;= 1;</p>
<p>this.loadFactor = loadFactor;
threshold = (int)(capacity /* loadFactor);
table = new Entry[capacity];</p>
<p>另外loadFactor的默认值0.75和capacity的默认值16是经过大量的统计分析得出的，很久以前我见过相关的数据分析，现在找不到了，有兴趣的可以查询相关资料。这里不再叙述了。</p>
<p>有了上述原理后再来分析HashMap的各种方法就不是什么问题的。</p>
<p><strong><em>清单4 HashMap的get操作</em></strong>
public V get(Object key) {
    if (key == null)
        return getForNullKey();
    int hash = hash(key.hashCode());
    for (Entry<K,V> e = table[indexFor(hash, table.length)];
         e != null;
         e = e.next) {
        Object k;
        if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k)))
            return e.value;
    }
    return null;
}</p>
<p>清单4 描述的是HashMap的get操作，在这个操作中首先判断key是否为空，因为为空的话总是映射到table的第0个元素上（可以看上面的清单2和清单1）。然后就需要查找table的索引。一旦找到对应的Map.Entry元素后就开始遍历此链表。由于不同的hash可能映射到同一个table[index]上，而相同的key却同时映射到相同的hash上，所以一个key和Entry对应的条件就是hash(key)==e.hash 并且key.equals(e.key)。从这里我们看到，Object.hashCode()只是为了将相同的元素映射到相同的链表上（Map.Entry)，而Object.equals()才是比较两个元素是否相同的关键！这就是为什么总是成对覆盖hashCode()和equals()的原因。</p>
<p><strong><em>清单5 HashMap的put操作</em></strong>
public V put(K key, V value) {
    if (key == null)
        return putForNullKey(value);
    int hash = hash(key.hashCode());
    int i = indexFor(hash, table.length);
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        Object k;
        if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }</p>
<pre><code>modCount++;
addEntry(hash, key, value, i);
return null;
</code></pre><p>}
void addEntry(int hash, K key, V value, int bucketIndex) {
    Entry<K,V> e = table[bucketIndex];
        table[bucketIndex] = new Entry<K,V>(hash, key, value, e);
        if (size++ &gt;= threshold)
            resize(2 /* table.length);
}</p>
<p>清单5 描述的是HashMap的put操作。对比get操作，可以发现，put实际上是先查找，一旦找到key对应的Entry就直接修改Entry的value值，否则就增加一个元素。增加的元素是在链表的头部，也就是占据table中的元素，如果table中对应索引原来有元素的话就将整个链表添加到新增加的元素的后面。也就是说新增加的元素再次查找的话是优于在它之前添加的同一个链表上的元素。这里涉及到就是扩容，也就是一旦元素的个数达到了扩容因子规定的数量(threhold=table.length/*loadFactor)，就将数组扩大一倍。</p>
<p><strong><em>清单6 HashMap扩容过程</em></strong>
void resize(int newCapacity) {
    Entry[] oldTable = table;
    int oldCapacity = oldTable.length;
    if (oldCapacity == MAXIMUM_CAPACITY) {
        threshold = Integer.MAX_VALUE;
        return;
    }</p>
<pre><code>Entry[] newTable = new Entry[newCapacity];
transfer(newTable);
table = newTable;
threshold = (int)(newCapacity /* loadFactor);
</code></pre><p>}</p>
<p>void transfer(Entry[] newTable) {
    Entry[] src = table;
    int newCapacity = newTable.length;
    for (int j = 0; j &lt; src.length; j++) {
        Entry<K,V> e = src[j];
        if (e != null) {
            src[j] = null;
            do {
                Entry<K,V> next = e.next;
                int i = indexFor(e.hash, newCapacity);
                e.next = newTable[i];
                newTable[i] = e;
                e = next;
            } while (e != null);
        }
    }
}</p>
<p>清单6 描述的是HashMap扩容的过程。可以看到扩充过程会导致元素数据的所有元素进行重新hash计算，这个过程也叫rehash。显然这是一个非常耗时的过程，否则扩容都会导致所有元素重新计算hash。因此尽可能的选择合适的初始化大小是有效提高HashMap效率的关键。太大了会导致过多的浪费空间，太小了就可能会导致繁重的rehash过程。在这个过程中loadFactor也可以考虑。</p>
<p>举个例子来说，如果要存储1000个元素，采用默认扩容因子0.75，那么1024显然是不够的，因为1000&gt;0.75/*1024了，所以选择2048是必须的，显然浪费了1048个空间。如果确定最多只有1000个元素，那么扩容因子为1，那么1024是不错的选择。另外需要强调的一点是扩容因此越大，从统计学角度讲意味着链表的长度就也大，也就是在查找元素的时候就需要更多次的循环。所以凡事必然是一个平衡的过程。</p>
<p>这里可能有人要问题，一旦我将Map的容量扩大后（也就是数组的大小），这个容量还能减小么？比如说刚开始Map中可能有10000个元素，运行一旦时间以后Map的大小永远不会超过10个，那么Map的容量能减小到10个或者16个么？答案就是不能，这个capacity一旦扩大后就不能减小了，只能通过构造一个新的Map来控制capacity了。</p>
<p>HashMap的几个内部迭代器也是非常重要的，这里限于篇幅就不再展开了，有兴趣的可以自己研究下。</p>
<p>Hashtable的原理和HashMap的原理几乎一样，所以就不讨论了。另外LinkedHashMap是在Map.Entry的基础上增加了before/after两个双向索引，用来将所有Map.Entry串联起来，这样就可以遍历或者做LRU Cache等。这里也不再展开讨论了。</p>
<p><a href="http://memcached.org/" target="_blank">memcached</a> 内部数据结构就是采用了HashMap类似的思想来实现的，有兴趣的可以参考资料8,9，10。</p>
<p>为了不使这篇文章过长，因此将ConcurrentHashMap的原理放到下篇讲。需要说明的是，尽管ConcurrentHashMap与HashMap的名称有些渊源，而且实现原理有些相似，但是为了更好的支持并发，ConcurrentHashMap在内部也有一些比较大的调整，这个在下篇会具体介绍。</p>
<p>参考资料：</p>
<ol>
<li><a href="http://www.javaeye.com/topic/709945" target="_blank">HashMap hash方法分析</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-lo-hash/" target="_blank">通过分析 JDK 源代码研究 Hash 存储机制</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-jtp05273/" target="_blank">Java 理论与实践: 哈希</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-jtp08223/" target="_blank">Java 理论与实践: 构建一个更好的 HashMap</a></li>
<li><a href="http://yk94wo.blog.sohu.com/155835132.html" target="_blank">jdk1.6 ConcurrentHashMap</a></li>
<li><a href="http://www.javaeye.com/topic/344876" target="_blank">ConcurrentHashMap之实现细节</a></li>
<li><a href="http://www.javaeye.com/topic/539465" target="_blank">深入理解HashMap</a></li>
<li><a href="http://www.lampchina.net/article/htmls/201005/Mjg1MTYy.html" target="_blank">memcached-数据结构</a></li>
<li><a href="http://www.cublog.cn/u/20146/showart_1820089.html" target="_blank">memcached存储管理 数据结构</a></li>
<li><a href="http://memcached.org/" target="_blank">memcached</a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/20/326584.html](http://www.blogjava.net/xylz/archive/2010/07/20/326584.html)">[http://www.blogjava.net/xylz/archive/2010/07/20/326584.html](http://www.blogjava.net/xylz/archive/2010/07/20/326584.html)</a> </li>
</ol>
<p>在上一篇中介绍了HashMap的原理，这一节是ConcurrentMap的最后一节，所以会完整的介绍ConcurrentHashMap的实现。</p>
<p><strong>ConcurrentHashMap原理</strong></p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2010/07/14/326080.html" target="_blank">读写锁章节部分</a>介绍过一种是用读写锁实现Map的方法。此种方法看起来可以实现Map响应的功能，而且吞吐量也应该不错。但是通过前面对<a href="http://www.blogjava.net/xylz/archive/2010/07/15/326152.html" target="_blank">读写锁原理</a>的分析后知道，读写锁的适合场景是读操作&gt;&gt;写操作，也就是读操作应该占据大部分操作，另外读写锁存在一个很严重的问题是读写操作不能同时发生。要想解决读写同时进行问题（至少不同元素的读写分离），那么就只能将锁拆分，不同的元素拥有不同的锁，这种技术就是“锁分离”技术。</p>
<p>默认情况下ConcurrentHashMap是用了16个类似HashMap 的结构，其中每一个HashMap拥有一个独占锁。也就是说最终的效果就是通过某种Hash算法，将任何一个元素均匀的映射到某个HashMap的Map.Entry上面，而对某个一个元素的操作就集中在其分布的HashMap上，与其它HashMap无关。这样就支持最多16个并发的写操作。</p>
<p> <a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency18part3ConcurrentMap3_693/image_8.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>上图就是ConcurrentHashMap的类图。参考上面的说明和HashMap的原理分析，可以看到ConcurrentHashMap将整个对象列表分为segmentMask+1个片段（Segment）。其中每一个片段是一个类似于HashMap的结构，它有一个HashEntry的数组，数组的每一项又是一个链表，通过HashEntry的next引用串联起来。</p>
<p>这个类图上面的数据结构的定义非常有学问，接下来会一个个有针对性的分析。</p>
<p>首先如何从ConcurrentHashMap定位到HashEntry。在HashMap的原理分析部分说过，对于一个Hash的数据结构来说，为了减少浪费的空间和快速定位数据，那么就需要数据在Hash上的分布比较均匀。对于一次Map的查找来说，首先就需要定位到Segment，然后从过Segment定位到HashEntry链表，最后才是通过遍历链表得到需要的元素。</p>
<p>在不讨论并发的前提下先来讨论如何定位到HashEntry的。在ConcurrentHashMap中是通过hash(key.hashCode())和segmentFor(hash)来得到Segment的。清单1 描述了如何定位Segment的过程。其中hash(int)是将key的hashCode进行二次编码，使之能够在segmentMask+1个Segment上均匀分布（默认是16个）。可以看到的是这里和HashMap还是有点不同的，这里采用的算法叫Wang/Jenkins hash，有兴趣的可以<a href="http://tech.puredanger.com/2007/07/25/hash/" target="_blank">参考资料1</a>和<a href="http://www.goworkday.com/2010/03/19/single-word-wangjenkins-hash-concurrenthashmap/" target="_blank">参考资料2</a>。总之它的目的就是使元素能够均匀的分布在不同的Segment上，这样才能够支持最多segmentMask+1个并发，这里segmentMask+1是segments的大小。</p>
<p><strong><em>清单1 定位Segment</em></strong>
private static int hash(int h) {
    // Spread bits to regularize both segment and index locations,
    // using variant of single-word Wang/Jenkins hash.
    h += (h &lt;&lt;  15) ^ 0xffffcd7d;
    h ^= (h &gt;&gt;&gt; 10);
    h += (h &lt;&lt;   3);
    h ^= (h &gt;&gt;&gt;  6);
    h += (h &lt;&lt;   2) + (h &lt;&lt; 14);
    return h ^ (h &gt;&gt;&gt; 16);
}
final Segment<K,V> segmentFor(int hash) {
    return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];
}</p>
<p>显然在不能够对Segment扩容的情况下，segments的大小就应该是固定的。所以在ConcurrentHashMap中segments/segmentMask/segmentShift都是常量，一旦初始化后就不能被再次修改，其中segmentShift是查找Segment的一个常量偏移量。</p>
<p>有了Segment以后再定位HashEntry就和HashMap中定位HashEntry一样了，先将hash值与Segment中HashEntry的大小减1进行与操作定位到HashEntry链表，然后遍历链表就可以完成相应的操作了。</p>
<p>能够定位元素以后ConcurrentHashMap就已经具有了HashMap的功能了，现在要解决的就是如何并发的问题。要解决并发问题，加锁是必不可免的。再回头看Segment的类图，可以看到Segment除了有一个volatile类型的元素大小count外，Segment还是集成自ReentrantLock的。另外在前面的原子操作和锁机制中介绍过，要想最大限度的支持并发，那么能够利用的思路就是尽量读操作不加锁，写操作不加锁。如果是读操作不加锁，写操作加锁，对于竞争资源来说就需要定义为<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">volatile</a>类型的。<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">volatile</a>类型能够保证<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">happens-before法则</a>，所以volatile能够近似保证正确性的情况下最大程度的降低加锁带来的影响，同时还与写操作的锁不产生冲突。</p>
<p>同时为了防止在遍历HashEntry的时候被破坏，那么对于HashEntry的数据结构来说，除了value之外其他属性就应该是常量，否则不可避免的会得到ConcurrentModificationException。这就是为什么HashEntry数据结构中key,hash,next是常量的原因(final类型）。</p>
<p>有了上面的分析和条件后再来看Segment的get/put/remove就容易多了。</p>
<p><strong>get操作</strong></p>
<hr>
<p><strong><em>清单2 Segment定位元素</em></strong>
V get(Object key, int hash) {
    if (count != 0) { // read-volatile
        HashEntry<K,V> e = getFirst(hash);
        while (e != null) {
            if (e.hash == hash &amp;&amp; key.equals(e.key)) {
                V v = e.value;
                if (v != null)
                    return v;
                return readValueUnderLock(e); // recheck
            }
            e = e.next;
        }
    }
    return null;
}
HashEntry<K,V> getFirst(int hash) {
    HashEntry<K,V>[] tab = table;
    return tab[hash &amp; (tab.length - 1)];
}</p>
<p>V readValueUnderLock(HashEntry<K,V> e) {
    lock();
    try {
        return e.value;
    } finally {
        unlock();
    }
}</p>
<p>清单2 描述的是Segment如何定位元素。首先判断Segment的大小count&gt;0，Segment的大小描述的是HashEntry不为空(key不为空)的个数。如果Segment中存在元素那么就通过getFirst定位到指定的HashEntry链表的头节点上，然后遍历此节点，一旦找到key对应的元素后就返回其对应的值。但是在清单2 中可以看到拿到HashEntry的value后还进行了一次判断操作，如果为空还需要加锁再读取一次（readValueUnderLock）。为什么会有这样的操作？尽管ConcurrentHashMap不允许将value为null的值加入，但现在仍然能够读到一个为空的value就意味着此值对当前线程还不可见（这是因为HashEntry还没有完全构造完成就赋值导致的，后面还会谈到此机制）。</p>
<p><strong>put操作</strong></p>
<hr>
<p>清单3 描述的是Segment的put操作。首先就需要加锁了，修改一个竞争资源肯定是要加锁的，这个毫无疑问。需要说明的是Segment集成的是ReentrantLock，所以这里加的锁也就是独占锁，也就是说同一个Segment在同一时刻只有能一个put操作。</p>
<p>接下来来就是检查是否需要扩容，这和HashMap一样，如果需要的话就扩大一倍，同时进行rehash操作。</p>
<p>查找元素就和get操作是一样的，得到元素就直接修改其值就好了。这里onlyIfAbsent只是为了实现ConcurrentMap的putIfAbsent操作而已。需要说明以下几点：</p>
<ul>
<li>如果找到key对于的HashEntry后直接修改就好了，如果找不到那么就需要构造一个新的HashEntry出来加到hash对于的HashEntry的头部，同时就的头部就加到新的头部后面。这是因为HashEntry的next是final类型的，所以只能修改头节点才能加元素加入链表中。</li>
<li>如果增加了新的操作后，就需要将count+1写回去。前面说过count是volatile类型，而读取操作没有加锁，所以只能把元素真正写回Segment中的时候才能修改count值，这个要放到整个操作的最后。</li>
<li>在将新的HashEntry写入table中时是通过构造函数来设置value值的，这意味对table的赋值可能在设置value之前，也就是说得到了一个半构造完的HashEntry。这就是重排序可能引起的问题。所以在读取操作中，一旦读到了一个value为空的value是就需要加锁重新读取一次。为什么要加锁？加锁意味着前一个写操作的锁释放，也就是前一个锁的数据已经完成写完了了，根据happens-before法则，前一个写操作的结果对当前读线程就可见了。当然在JDK 6.0以后不一定存在此问题。</li>
<li>在Segment中table变量是volatile类型，多次读取volatile类型的开销要不非volatile开销要大，而且编译器也无法优化，所以在put操作中首先建立一个临时变量tab指向table，多次读写tab的效率要比volatile类型的table要高，JVM也能够对此进行优化。</li>
</ul>
<p><strong><em>清单3 Segment的put操作</em></strong>
V put(K key, int hash, V value, boolean onlyIfAbsent) {
    lock();
    try {
        int c = count;
        if (c++ &gt; threshold) // ensure capacity
            rehash();
        HashEntry<K,V>[] tab = table;
        int index = hash &amp; (tab.length - 1);
        HashEntry<K,V> first = tab[index];
        HashEntry<K,V> e = first;
        while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key)))
            e = e.next;</p>
<pre><code>    V oldValue;
    if (e != null) {
        oldValue = e.value;
        if (!onlyIfAbsent)
            e.value = value;
    }
    else {
        oldValue = null;
        ++modCount;
        tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value);
        count = c; // write-volatile
    }
    return oldValue;
} finally {
    unlock();
}
</code></pre><p>}</p>
<p><strong>remove 操作</strong></p>
<p>清单4 描述了Segment删除一个元素的过程。同put一样，remove也需要加锁，这是因为对table可能会有变更。由于HashEntry的next节点是final类型的，所以一旦删除链表中间一个元素，就需要将删除之前或者之后的元素重新加入新的链表。而Segment采用的是将删除元素之前的元素一个个重新加入删除之后的元素之前（也就是链表头结点）来完成新链表的构造。</p>
<p><strong><em>清单4 Segment的remove操作</em></strong>
V remove(Object key, int hash, Object value) {
    lock();
    try {
        int c = count - 1;
        HashEntry<K,V>[] tab = table;
        int index = hash &amp; (tab.length - 1);
        HashEntry<K,V> first = tab[index];
        HashEntry<K,V> e = first;
        while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key)))
            e = e.next;</p>
<pre><code>    V oldValue = null;
    if (e != null) {
        V v = e.value;
        if (value == null || value.equals(v)) {
            oldValue = v;
            // All entries following removed node can stay
            // in list, but all preceding ones need to be
            // cloned.
            ++modCount;
            HashEntry&lt;K,V&gt; newFirst = e.next;
            for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next)
                newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash,
                                              newFirst, p.value);
            tab[index] = newFirst;
            count = c; // write-volatile
        }
    }
    return oldValue;
} finally {
    unlock();
}
</code></pre><p>}</p>
<p>下面的示意图描述了如何删除一个已经存在的元素的。假设我们要删除B3元素。首先定位到B3所在的Segment，然后再定位到Segment的table中的B1元素，也就是Bx所在的链表。然后遍历链表找到B3，找到之后就从头结点B1开始构建新的节点B1（蓝色）加到B4的前面，继续B1后面的节点B2构造B2（蓝色），加到由蓝色的B1和B4构成的新的链表。继续下去，直到遇到B3后终止，这样就构造出来一个新的链表B2（蓝色）-&gt;B1（蓝色）-&gt;B4-&gt;B5，然后将此链表的头结点B2（蓝色）设置到Segment的table中。这样就完成了元素B3的删除操作。需要说明的是，尽管就的链表仍然存在(B1-&gt;B2-&gt;B3-&gt;B4-&gt;B5)，但是由于没有引用指向此链表，所以此链表中无引用的（B1-&gt;B2-&gt;B3）最终会被GC回收掉。这样做的一个好处是，如果某个读操作在删除时已经定位到了旧的链表上，那么此操作仍然将能读到数据，只不过读取到的是旧数据而已，这在多线程里面是没有问题的。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency18part3ConcurrentMap3_693/image_10.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency18part3ConcurrentMap3_693/image_12.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>除了对单个元素操作外，还有对全部的Segment的操作，比如size()操作等。</p>
<p><strong>size操作</strong></p>
<p>size操作涉及到统计所有Segment的大小，这样就会遍历所有的Segment，如果每次加锁就会导致整个Map都被锁住了，任何需要锁的操作都将无法进行。这里用到了一个比较巧妙的方案解决此问题。</p>
<p>在Segment中有一个变量modCount，用来记录Segment结构变更的次数，结构变更包括增加元素和删除元素，每增加一个元素操作就+1，每进行一次删除操作+1，每进行一次清空操作(clear)就+1。也就是说每次涉及到元素个数变更的操作modCount都会+1，而且一直是增大的，不会减小。</p>
<p>遍历两次ConcurrentHashMap中的segments，每次遍历是记录每一个Segment的modCount，比较两次遍历的modCount值的和是否相同，如果相同就返回在遍历过程中获取的Segment的count的和，也就是所有元素的个数。如果不相同就重复再做一次。重复一次还不相同就将所有Segment锁住，一个一个的获取其大小(count)，最后将这些count加起来得到总的大小。当然了最后需要将锁一一释放。清单5 描述了这个过程。</p>
<p>这里有一个比较高级的话题是为什么在读取modCount的时候总是先要读取count一下。为什么不是先读取modCount然后再读取count的呢？也就是说下面的两条语句能否交换下顺序？
sum += segments[i].count;
mcsum += mc[i] = segments[i].modCount;</p>
<p>答案是不能！为什么？这是因为modCount总是在加锁的情况下才发生变化，所以不会发生多线程同时修改的情况，也就是没必要时volatile类型。另外总是在count修改的情况下修改modCount，而count是一个volatile变量。于是这里就充分利用了volatile的特性。</p>
<p>根据<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">happens-before法则</a>，第（3）条：对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。也就是说一个操作C在volatile字段的写操作之后，那么volatile写操作之前的所有操作都对此操作C可见。所以修改modCount总是在修改count之前，也就是说如果读取到了一个count的值，那么在count变化之前的modCount也就能够读取到，换句话说就是如果看到了count值的变化，那么就一定看到了modCount值的变化。而如果上面两条语句交换下顺序就无法保证这个结果一定存在了。</p>
<p>在ConcurrentHashMap.containsValue中，可以看到每次遍历segments时都会执行int c = segments[i].count;，但是接下来的语句中又不用此变量c，尽管如此JVM仍然不能将此语句优化掉，因为这是一个volatile字段的读取操作，它保证了一些列操作的happens-before顺序，所以是至关重要的。在这里可以看到：
ConcurrentHashMap将volatile发挥到了极致！</p>
<p>另外isEmpty操作于size操作类似，不再累述。</p>
<p><strong><em>清单5 ConcurrentHashMap的size操作</em></strong>
public int size() {
    final Segment<K,V>[] segments = this.segments;
    long sum = 0;
    long check = 0;
    int[] mc = new int[segments.length];
    // Try a few times to get accurate count. On failure due to
    // continuous async changes in table, resort to locking.
    for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) {
        check = 0;
        sum = 0;
        int mcsum = 0;
        for (int i = 0; i &lt; segments.length; ++i) {
            sum += segments[i].count;
            mcsum += mc[i] = segments[i].modCount;
        }
        if (mcsum != 0) {
            for (int i = 0; i &lt; segments.length; ++i) {
                check += segments[i].count;
                if (mc[i] != segments[i].modCount) {
                    check = -1; // force retry
                    break;
                }
            }
        }
        if (check == sum)
            break;
    }
    if (check != sum) { // Resort to locking all segments
        sum = 0;
        for (int i = 0; i &lt; segments.length; ++i)
            segments[i].lock();
        for (int i = 0; i &lt; segments.length; ++i)
            sum += segments[i].count;
        for (int i = 0; i &lt; segments.length; ++i)
            segments[i].unlock();
    }
    if (sum &gt; Integer.MAX_VALUE)
        return Integer.MAX_VALUE;
    else
        return (int)sum;
}</p>
<p><strong>ConcurrentSkipListMap/Set</strong></p>
<p>本来打算介绍下ConcurrentSkipListMap的，结果打开源码一看，彻底放弃了。那里面的数据结构和算法我估计研究一周也未必能够完全弄懂。很久以前我看TreeMap的时候就头大，想想那些复杂的“红黑二叉树”我头都大了。这些都归咎于从前没有好好学习《数据结构和算法》，现在再回头看这些复杂的算法感觉非常头疼，为了减少脑细胞的死亡，暂且还是不要惹这些“玩意儿”。有兴趣的可以看看<a href="http://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html?ca=drs-" target="_blank">参考资料4</a> 中对TreeMap的介绍。</p>
<p>参考资料：</p>
<ol>
<li><a href="http://tech.puredanger.com/2007/07/25/hash/" target="_blank">Hash this</a></li>
<li><a href="http://www.goworkday.com/2010/03/19/single-word-wangjenkins-hash-concurrenthashmap/" target="_blank">Single-word Wang/Jenkins Hash in ConcurrentHashMap</a></li>
<li><a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">指令重排序与happens-before法则</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html?ca=drs-" target="_blank">通过分析 JDK 源代码研究 TreeMap 红黑树算法实现</a></li>
</ol>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/20/326661.html](http://www.blogjava.net/xylz/archive/2010/07/20/326661.html)">[http://www.blogjava.net/xylz/archive/2010/07/20/326661.html](http://www.blogjava.net/xylz/archive/2010/07/20/326661.html)</a></p>
<p>Queue是JDK 5以后引入的新的集合类，它属于Java Collections Framework的成员，在Collection集合中和List/Set是同一级别的接口。通常来讲Queue描述的是一种FIFO的队列，当然不全都是，比如PriorityQueue是按照优先级的顺序（或者说是自然顺序，借助于Comparator接口）。</p>
<p>下图描述了Java Collections Framework中Queue的整个家族体系。</p>
<p>对于Queue而言是在Collection的基础上增加了offer/remove/poll/element/peek方法，另外重新定义了add方法。对于这六个方法，有不同的定义。</p>
<hr>
<p><strong>抛出异常</strong></p>
<p><strong>返回特殊值</strong></p>
<p><strong>操作描述</strong> 插入</p>
<p>add(e)</p>
<p>offer(e)</p>
<p>将元素加入到队列尾部 移除</p>
<p>remove()</p>
<p>poll()</p>
<p>移除队列头部的元素 检查</p>
<p>element()</p>
<p>peek()</p>
<p>返回队列头部的元素而不移除此元素</p>
<p>特别说明的是对于Queue而言，规范并没有规定是线程安全的，为了解决这个问题，引入了可阻塞的队列BlockingQueue。对于BlockingQueue而言所有操作的是线程安全的，并且队列的操作可以被阻塞，直到满足某种条件。Queue的另一个子接口Deque描述的是一个双向的队列。与Queue不同的是，Deque允许在队列的头部增加元素和在队列的尾部删除元素。也就是说Deque是一个双向队列。二者功能都有的队列就是BlockingDeque，这种阻塞队列允许在队列的头和尾部分别操作元素，应该说是Queue中功能最强大的实现。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/ead4e8800e0c_FD45/image_4.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>在JDK 5之前LinkedList就已经存在，而且本身实现都是一种双向队列。所以到了JDK 5以后就将LinkedList同时实现Deque接口，这样LinkedList就又属于Queue的一部分了。</p>
<p>通常情况下Queue都是靠链表结构实现的，但是链表意味着有一些而外的引用开销，如果是双向链表开销就更大了。所以为了节省内存，一种方式就是使用固定大小的数组来实现队列。在这种情况下队列的大小是固定，元素的遍历通过数组的索引进行，很显然这是一种双向链表的模型。ArrayDeque就是这样一种实现。</p>
<p>另外ArrayBlockingQueue也是一种数组实现的队列，但是却没有改造成双向，仅仅实现了BlockingQueue的模型。理论上和ArrayDeque一样也应该容易改造成双向的实现。</p>
<p>PriorityQueue和PriorityBlockingQueue实现了一种排序的队列模型。这很类似与SortedSet，通过队列的Comparator接口或者Comparable元素来排序元素。这种情况下元素在队列中的出入就不是按照FIFO的形式，而是根据比较后的自然顺序来进行。</p>
<p>CocurrentLinkedQueue是一种线程安全却非阻塞的FIFO队列，这种队列通常实现起来比较简单，但是却很有效。在接下来的章节会详细的描述它。</p>
<p>SynchronousQueue是一种特别的BlockingQueue，它只是把一个add/offer操作的元素直接移交给remove/take操作。也就是说它本身不会缓存任何元素，所以严格意义上说来讲并不是一种真正的队列。此队列维护一个线程列表，这些线程等待从队列中加入元素或者移除元素。简单的说，至少有一个remove/take操作时add/offer操作才能成功，同样至少有一个add/offer操作时remove/take操作才能成功。这是一种双向等待的队列模型，出队列等待加入等列，而入队列又等待出队列。这种队列的好处在于能够最大线程的保持吞吐量却又是线程安全的。所以对于一个需要快速处理的任务队列，SynchronousQueue是一个不错的选择。</p>
<p>BlockingQueue还有一种实现DelayQueue，这种实现允许每一个元素(Delayed)带有一个延时时间，当调用take/poll的时候会检测队列头元素这个时间是否&lt;=0，如果满足就是说已经超时了，那么此元素就可以被移除了，否则就会等待。特别说明的是这个头元素应该是最先被超时的元素（这个时间是绝对时间）。这个类设计很巧妙，被用于ScheduledFutureTask来进行定时操作。希望后面会开辟一个章节讲讲这里面的想法。实在不行在讲线程池部分肯定会提到这个。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/21/326723.html](http://www.blogjava.net/xylz/archive/2010/07/21/326723.html)">[http://www.blogjava.net/xylz/archive/2010/07/21/326723.html](http://www.blogjava.net/xylz/archive/2010/07/21/326723.html)</a> </p>
<p>ConcurrentLinkedQueue是Queue的一个线程安全实现。先来看一段文档说明。</p>
<p>一个基于链接节点的无界线程安全队列。此队列按照 FIFO（先进先出）原则对元素进行排序。队列的头部 是队列中时间最长的元素。队列的尾部 是队列中时间最短的元素。新的元素插入到队列的尾部，队列获取操作从队列头部获得元素。当多个线程共享访问一个公共 collection 时，ConcurrentLinkedQueue 是一个恰当的选择。此队列不允许使用 null 元素。</p>
<p>由于ConcurrentLinkedQueue只是简单的实现了一个队列Queue，因此从API的角度讲，没有多少值的介绍，使用起来也很简单，和前面遇到的所有FIFO队列都类似。出队列只能操作头节点，入队列只能操作尾节点，任意节点操作就需要遍历完整的队列。</p>
<p>重点放在解释ConcurrentLinkedQueue的原理和实现上。</p>
<p>在继续探讨之前，结合前面线程安全的相关知识，我来分析设计一个线程安全的队列哪几种方法。</p>
<p>第一种：使用synchronized同步队列，就像Vector或者Collections.synchronizedList/Collection那样。显然这不是一个好的并发队列，这会导致吞吐量急剧下降。</p>
<p>第二种：使用Lock。一种好的实现方式是使用ReentrantReadWriteLock来代替ReentrantLock提高读取的吞吐量。但是显然ReentrantReadWriteLock的实现更为复杂，而且更容易导致出现问题，另外也不是一种通用的实现方式，因为ReentrantReadWriteLock适合哪种读取量远远大于写入量的场合。当然了ReentrantLock是一种很好的实现，结合Condition能够很方便的实现阻塞功能，这在后面介绍BlockingQueue的时候会具体分析。</p>
<p>第三种：使用CAS操作。尽管Lock的实现也用到了CAS操作，但是毕竟是间接操作，而且会导致线程挂起。一个好的并发队列就是采用某种非阻塞算法来取得最大的吞吐量。</p>
<p>ConcurrentLinkedQueue采用的就是第三种策略。它采用了<a href="http://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf" target="_blank">参考资料1</a> 中的算法。</p>
<p>在锁机制中谈到过，要使用非阻塞算法来完成队列操作，那么就需要一种“循环尝试”的动作，就是循环操作队列，直到成功为止，失败就会再次尝试。这在前面的章节中多次介绍过。</p>
<p>针对各种功能深入分析。</p>
<p>在开始之前先介绍下ConcurrentLinkedQueue的数据结构。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency20part5ConcurrentLinkedQu_C9AC/image_2.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>在上面的数据结构中，ConcurrentLinkedQueue只有头结点、尾节点两个元素，而对于一个节点Node而言除了保存队列元素item外，还有一个指向下一个节点的引用next。 看起来整个数据结构还是比较简单的。但是也有几点是需要说明：</p>
<ol>
<li>所有结构（head/tail/item/next）都是volatile类型。 这是因为ConcurrentLinkedQueue是非阻塞的，所以只有volatile才能使变量的写操作对后续读操作是可见的（这个是有happens-before法则保证的）。同样也不会导致指令的重排序。</li>
<li>所有结构的操作都带有原子操作，这是由AtomicReferenceFieldUpdater保证的，这在原子操作中介绍过。它能保证需要的时候对变量的修改操作是原子的。</li>
<li>由于队列中任何一个节点（Node）只有下一个节点的引用，所以这个队列是单向的，根据FIFO特性，也就是说出队列在头部(head)，入队列在尾部(tail)。头部保存有进入队列最长时间的元素，尾部是最近进入的元素。</li>
<li>没有对队列长度进行计数，所以队列的长度是无限的，同时获取队列的长度的时间不是固定的，这需要遍历整个队列，并且这个计数也可能是不精确的。</li>
<li>初始情况下队列头和队列尾都指向一个空节点，但是非null，这是为了方便操作，不需要每次去判断head/tail是否为空。但是head却不作为存取元素的节点，tail在不等于head情况下保存一个节点元素。也就是说head.item这个应该一直是空，但是tail.item却不一定是空（如果head!=tail，那么tail.item!=null）。</li>
</ol>
<p>对于第5点，可以从ConcurrentLinkedQueue的初始化中看到。这种头结点也叫“伪节点”，也就是说它不是真正的节点，只是一标识，就像c中的字符数组后面的\0以后，只是用来标识结束，并不是真正字符数组的一部分。
private transient volatile Node<E> head = new Node<E>(null, null);
private transient volatile Node<E> tail = head;</p>
<p>有了上述5点再来解释相关API操作就容易多了。</p>
<p>在上一节中列出了add/offer/remove/poll/element/peek等价方法的区别，所以这里就不再重复了。</p>
<p><strong><em>清单1 入队列操作</em></strong>
public boolean offer(E e) {
    if (e == null) throw new NullPointerException();
    Node<E> n = new Node<E>(e, null);
    for (;;) {
        Node<E> t = tail;
        Node<E> s = t.getNext();
        if (t == tail) {
            if (s == null) {
                if (t.casNext(s, n)) {
                    casTail(t, n);
                    return true;
                }
            } else {
                casTail(t, s);
            }
        }
    }
}</p>
<p>清单1 描述的是入队列的过程。整个过程是这样的。</p>
<ol>
<li>获取尾节点t，以及尾节点的下一个节点s。如果尾节点没有被别人修改，也就是t==tail，进行2，否则进行1。</li>
<li>如果s不为空，也就是说此时尾节点后面还有元素，那么就需要把尾节点往后移，进行1。否则进行3。</li>
<li>修改尾节点的下一个节点为新节点，如果成功就修改尾节点，返回true。否则进行1。</li>
</ol>
<p>从操作3中可以看到是先修改尾节点的下一个节点，然后才修改尾节点位置的，所以这才有操作2中为什么获取到的尾节点的下一个节点不为空的原因。</p>
<p>特别需要说明的是，对尾节点的tail的操作需要换成临时变量t和s，一方面是为了去掉volatile变量的可变性，另一方面是为了减少volatile的性能影响。</p>
<p>清单2 描述的出队列的过程，这个过程和入队列相似，有点意思。</p>
<p>头结点是为了标识队列起始，也为了减少空指针的比较，所以头结点总是一个item为null的非null节点。也就是说head!=null并且head.item==null总是成立。所以实际上获取的是head.next，一旦将头结点head设置为head.next成功就将新head的item设置为null。至于以前就的头结点h，h.item=null并且h.next为新的head，但是由于没有对h的引用，所以最终会被GC回收。这就是整个出队列的过程。</p>
<p><strong><em>清单2 出队列操作</em></strong>
public E poll() {
    for (;;) {
        Node<E> h = head;
        Node<E> t = tail;
        Node<E> first = h.getNext();
        if (h == head) {
            if (h == t) {
                if (first == null)
                    return null;
                else
                    casTail(t, first);
            } else if (casHead(h, first)) {
                E item = first.getItem();
                if (item != null) {
                    first.setItem(null);
                    return item;
                }
                // else skip over deleted item, continue loop,
            }
        }
    }
}</p>
<p>另外对于清单3 描述的获取队列大小的过程，由于没有一个计数器来对队列大小计数，所以获取队列的大小只能通过从头到尾完整的遍历队列，显然这个代价是很大的。所以通常情况下ConcurrentLinkedQueue需要和一个AtomicInteger搭配才能获取队列大小。后面介绍的BlockingQueue正是使用了这种思想。</p>
<p><strong>清单3 遍历队列大小</strong>
public int size() {
    int count = 0;
    for (Node<E> p = first(); p != null; p = p.getNext()) {
        if (p.getItem() != null) {
            // Collections.size() spec says to max out
            if (++count == Integer.MAX_VALUE)
                break;
        }
    }
    return count;
}</p>
<p>参考资料：</p>
<ol>
<li><a href="http://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf" target="_blank">Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms</a></li>
<li><a href="http://yanxuxin.javaeye.com/blog/586943" target="_blank">多线程基础总结十一—ConcurrentLinkedQueue</a></li>
<li><a href="http://www.javaeye.com/topic/68279" target="_blank">对ConcurrentLinkedQueue进行的并发测试</a> </li>
</ol>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/23/326934.html](http://www.blogjava.net/xylz/archive/2010/07/23/326934.html)">[http://www.blogjava.net/xylz/archive/2010/07/23/326934.html](http://www.blogjava.net/xylz/archive/2010/07/23/326934.html)</a></p>
<p>在《<a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">并发容器 part 4 并发队列与Queue简介</a>》节中的类图中可以看到，对于Queue来说，BlockingQueue是主要的线程安全版本。这是一个可阻塞的版本，也就是允许添加/删除元素被阻塞，直到成功为止。</p>
<p>BlockingQueue相对于Queue而言增加了两个操作：put/take。下面是一张整理的表格。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency21part5ConcurrentLinkedQu_E370/image_4.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>看似简单的API，非常有用。这在控制队列的并发上非常有好处。既然加入队列和移除队列能够被阻塞，这在实现生产者-消费者模型上就简单多了。</p>
<p>清单1 是生产者-消费者模型的一个例子。这个例子是一个真实的场景。服务端（ICE服务）接受客户端的请求(accept)，请求计算此人的好友生日，然后将计算的结果存取缓存中（Memcache）中。在这个例子中采用了ExecutorService实现多线程的功能，尽可能的提高吞吐量，这个在后面线程池的部分会详细说明。目前就可以理解为new Thread(r).start()就可以了。另外这里阻塞队列使用的是LinkedBlockingQueue。</p>
<p><strong><em>清单1 一个生产者-消费者例子</em></strong>
package xylz.study.concurrency;</p>
<p>import java.util.concurrent.BlockingQueue;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.LinkedBlockingDeque;</p>
<p>public class BirthdayService {</p>
<pre><code>final int workerNumber;

final Worker[] workers;

final ExecutorService threadPool;

static volatile boolean running = true;

public BirthdayService(int workerNumber, int capacity) {
    if (workerNumber &lt;= 0) throw new IllegalArgumentException();
    this.workerNumber = workerNumber;
    workers = new Worker[workerNumber];
    for (int i = 0; i &lt; workerNumber; i++) {
        workers[i] = new Worker(capacity);
    }
    //
    boolean b = running;// kill the resorting
    threadPool = Executors.newFixedThreadPool(workerNumber);
    for (Worker w : workers) {
        threadPool.submit(w);
    }
}

Worker getWorker(int id) {
    return workers[id % workerNumber];

}

class Worker implements Runnable {

    final BlockingQueue&lt;Integer&gt; queue;

    public Worker(int capacity) {
        queue = new LinkedBlockingQueue&lt;Integer&gt;(capacity);
    }

    public void run() {
        while (true) {
            try {
                consume(queue.take());
            } catch (InterruptedException e) {
                return;
            }
        }
    }

    void put(int id) {
        try {
            queue.put(id);
        } catch (InterruptedException e) {
            return;
        }
    }
}

public void accept(int id) {
    //accept client request
    getWorker(id).put(id);
}

protected void consume(int id) {
    //do the work
    //get the list of friends and save the birthday to cache
}
</code></pre><p>}</p>
<p>在清单1 中可以看到不管是put()还是get()，都抛出了一个InterruptedException。我们就从这里开始，为什么会抛出这个异常。</p>
<p><a href="http://www.blogjava.net/xylz/archive/2010/07/23/326934.html" target="_blank">上一节</a>中提到实现一个并发队列有三种方式。显然只有第二种 Lock 才能实现阻塞队列。在锁机制中提到过，Lock结合Condition就可以实现线程的阻塞，这在锁机制部分的很多工具中都详细介绍过，而接下来要介绍的LinkedBlockingQueue就是采用这种方式。</p>
<p><strong>LinkedBlockingQueue 原理</strong></p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency21part5ConcurrentLinkedQu_E370/image8_1.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>对比<a href="http://www.blogjava.net/xylz/archive/2010/07/23/326934.html" target="_blank">ConcurrentLinkedQueue的结构图</a>，LinkedBlockingQueue多了两个ReentrantLock和两个Condition以及用于计数的AtomicInteger，显然这会导致LinkedBlockingQueue的实现有点复杂。对照此结构，有以下几点说明：</p>
<ol>
<li>但是整体上讲，LinkedBlockingQueue和ConcurrentLinkedQueue的结构类似，都是采用头尾节点，每个节点指向下一个节点的结构，这表示它们在操作上应该类似。</li>
<li>LinkedBlockingQueue引入了原子计数器count，这意味着获取队列大小size()已经是常量时间了，不再需要遍历队列。每次队列长度有变更时只需要修改count即可。</li>
<li>有了修改Node指向有了锁，所以不需要volatile特性了。既然有了锁Node的item为什么需要volatile在后面会详细分析，暂且不表。</li>
<li>引入了两个锁，一个入队列锁，一个出队列锁。当然同时有一个队列不满的Condition和一个队列不空的Condition。其实参照锁机制前面介绍过的生产者-消费者模型就知道，入队列就代表生产者，出队列就代表消费者。为什么需要两个锁？一个锁行不行？其实一个锁完全可以，但是一个锁意味着入队列和出队列同时只能有一个在进行，另一个必须等待其释放锁。而从ConcurrentLinkedQueue的实现原理来看，事实上head和last (ConcurrentLinkedQueue中是tail)是分离的，互相独立的，这意味着入队列实际上是不会修改出队列的数据的，同时出队列也不会修改入队列，也就是说这两个操作是互不干扰的。更通俗的将，这个锁相当于两个写入锁，入队列是一种写操作，操作head，出队列是一种写操作，操作tail。可见它们是无关的。但是并非完全无关，后面详细分析。</li>
</ol>
<p>在没有揭示入队列和出队列过程前，暂且猜测下实现原理。</p>
<p>根据前面学到的锁机制原理结合ConcurrentLinkedQueue的原理，入队列的阻塞过程大概是这样的：</p>
<ol>
<li>获取入队列的锁putLock，检测队列大小，如果队列已满，那么就挂起线程，等待队列不满信号notFull的唤醒。</li>
<li>将元素加入到队列尾部，同时修改队列尾部引用last。</li>
<li>队列大小加1。</li>
<li>释放锁putLock。</li>
<li>唤醒notEmpty线程（如果有挂起的出队列线程），告诉消费者，已经有了新的产品。</li>
</ol>
<p>对比入队列，出队列的阻塞过程大概是这样的：</p>
<ol>
<li>获取出队列的锁takeLock，检测队列大小，如果队列为空，那么就挂起线程，等待队列不为空notEmpty的唤醒。</li>
<li>将元素从头部移除，同时修改队列头部引用head。</li>
<li>队列大小减1。</li>
<li>释放锁takeLock。</li>
<li>唤醒notFull线程（如果有挂起的入队列线程），告诉生产者，现在还有空闲的空间。</li>
</ol>
<p>下面来验证上面的过程。</p>
<p><strong>入队列过程（put/offer）</strong></p>
<p><strong><em>清单2 阻塞的入队列过程</em></strong>
public void put(E e) throws InterruptedException {
    if (e == null) throw new NullPointerException();
    int c = -1;
    final ReentrantLock putLock = this.putLock;
    final AtomicInteger count = this.count;
    putLock.lockInterruptibly();
    try {
        try {
            while (count.get() == capacity)
                notFull.await();
        } catch (InterruptedException ie) {
            notFull.signal(); // propagate to a non-interrupted thread
            throw ie;
        }
        insert(e);
        c = count.getAndIncrement();
        if (c + 1 &lt; capacity)
            notFull.signal();
    } finally {
        putLock.unlock();
    }
    if (c == 0)
        signalNotEmpty();
}</p>
<p>清单2 描述的是入队列的阻塞过程。可以看到和上面描述的入队列的过程基本相同。但是也有以下几个问题：</p>
<ol>
<li>如果在入队列的时候线程被中断，那么就需要发出一个notFull的信号，表示下一个入队列的线程能够被唤醒（如果阻塞的话）。</li>
<li>入队列成功后如果队列不满需要补一个notFull的信号。为什么？队列不满的时候其它入队列的阻塞线程难道不知道么？有可能。这是因为为了减少上下文切换的次数，每次唤醒一个线程（不管是入队列还是出队列）都是只随机唤醒一个(notify)，而不是唤醒所有的（notifyall()）。这会导致其它阻塞的入队列线程不能够即使处理队列不满的情况。</li>
<li>如果队列不为空并且可能有一个元素的话就唤醒一个出队列线程。这么做说明之前队列一定为空，因为在加入队列之后队列最多只能为1，那么说明未加入之前是0，那么就可能有被阻塞的出队列线程，所以就唤醒一个出队列线程。特别说明的是为什么使用一个临时变量c，而不用count。这是因为读取一个count的开销比读取一个临时一个变量大，而此处c又能够完成确认队列最多只有一个元素的判断。首先c默认为-1，如果加入队列后获取原子计数器的结果为0，说明之前队列为空，不可能消费（出队列），也不可能入队列，因为此时锁还在当前线程上，那么加入一个后队列就不为空了，所以就可以安全的唤醒一个消费（出对立）线程。</li>
<li>入队列的过程允许被中断，所以总是抛出InterruptedException 异常。</li>
</ol>
<p>针对第2点，特别补充说明下。本来这属于锁机制中条件队列的范围，由于没有应用场景，所以当时没有提。</p>
<p>前面提高notifyall总是比notify更可靠，因为notify可能丢失通知，为什么不适用notifyall呢？</p>
<p>先解释下notify丢失通知的问题。</p>
<p><strong>notify丢失通知问题</strong></p>
<p>假设线程A因为某种条件在条件队列中等待，同时线程B因为另外一种条件在同一个条件队列中等待，也就是说线程A/B都被同一个Conditon.await()挂起，但是等待的条件不同。现在假设线程B的线程被满足，线程C执行一个notify操作，此时JVM从Conditon.await()的多个线程（A/B）中随机挑选一个唤醒，不幸的是唤醒了A。此时A的条件不满足，于是A继续挂起。而此时B仍然在傻傻的等待被唤醒的信号。也就是说本来给B的通知却被一个无关的线程持有了，真正需要通知的线程B却没有得到通知，而B仍然在等待一个已经发生过的通知。</p>
<p>如果使用notifyall，则能够避免此问题。notifyall会唤醒所有正在等待的线程，线程C发出的通知线程A同样能够收到，但是由于对于A没用，所以A继续挂起，而线程B也收到了此通知，于是线程B正常被唤醒。</p>
<p>既然notifyall能够解决单一notify丢失通知的问题，那么为什么不总是使用notifyall替换notify呢？</p>
<p>假设有N个线程在条件队列中等待，调用notifyall会唤醒所有线程，然后这N个线程竞争同一个锁，最多只有一个线程能够得到锁，于是其它线程又回到挂起状态。这意味每一次唤醒操作可能带来大量的上下文切换（如果N比较大的话），同时有大量的竞争锁的请求。这对于频繁的唤醒操作而言性能上可能是一种灾难。</p>
<p>如果说总是只有一个线程被唤醒后能够拿到锁，那么为什么不使用notify呢？所以某些情况下使用notify的性能是要高于notifyall的。</p>
<p>如果满足下面的条件，可以使用单一的notify取代notifyall操作：
相同的等待者，也就是说等待条件变量的线程操作相同，每一个从wait放回后执行相同的逻辑，同时一个条件变量的通知至多只能唤醒一个线程。</p>
<p>也就是说理论上讲在put/take中如果使用sinallAll唤醒的话，那么在清单2 中的notFull.singal就是多余的。</p>
<p><strong>出队列过程（poll/take）</strong></p>
<p>再来看出队列过程。清单3 描述了出队列的过程。可以看到这和入队列是对称的。从这里可以看到，出队列使用的是和入队列不同的锁，所以入队列、出队列这两个操作才能并行进行。</p>
<p><strong><em>清单3 阻塞的出队列过程</em></strong>
public E take() throws InterruptedException {
    E x;
    int c = -1;
    final AtomicInteger count = this.count;
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lockInterruptibly();
    try {
        try {
            while (count.get() == 0)
                notEmpty.await();
        } catch (InterruptedException ie) {
            notEmpty.signal(); // propagate to a non-interrupted thread
            throw ie;
        }</p>
<pre><code>    x = extract();
    c = count.getAndDecrement();
    if (c &gt; 1)
        notEmpty.signal();
} finally {
    takeLock.unlock();
}
if (c == capacity)
    signalNotFull();
return x;
</code></pre><p>}</p>
<p><strong>为什么有异常？</strong></p>
<p>有了入队列、出队列的过程后再来回答前面的几个问题。</p>
<p>为什么总是抛出InterruptedException 异常？ 这是很大一块内容，其实是Java对线程中断的处理问题，希望能够在系列文章的最后能够对此开辟单独的篇章来谈谈。</p>
<p>在锁机制里面也是总遇到，这是因为，Java里面没有一种直接的方法中断一个挂起的线程，所以通常情况下等于一个处于WAITING状态的线程，允许设置一个中断位，一旦线程检测到这个中断位就会从WAITING状态退出，以一个InterruptedException 的异常返回。所以只要是对一个线程挂起操作都会导致InterruptedException 的可能，比如Thread.sleep()、Thread.join()、Object.wait()。尽管LockSupport.park()不会抛出一个InterruptedException 异常，但是它会将当前线程的的interrupted状态位置上，而对于Lock/Condition而言，当捕捉到interrupted状态后就认为线程应该终止任务，所以就抛出了一个InterruptedException 异常。</p>
<p><strong>又见volatile</strong></p>
<p>还有一个不容易理解的问题。<strong>为什么Node.item是volatile类型的？</strong></p>
<p>起初我不大明白，因为对于一个进入队列的Node，它的item是不变，当且仅当出队列的时候会将头结点元素的item 设置为null。尽管在remove(o)的时候也是设置为null,但是那时候是加了putLock/takeLock两个锁的，所以肯定是没有问题的。那么问题出在哪？</p>
<p>我们知道，item的值是在put/offer的时候加入的。这时候都是有putLock锁保证的，也就是说它保证使用putLock锁的读取肯定是没有问题的。那么问题就只可能出在一个不适用putLock却需要读取Node.item的地方。</p>
<p>peek操作时获取头结点的元素而不移除它。显然他不会操作尾节点，所以它不需要putLock锁，也就是说它只有takeLock锁。清单4 描述了这个过程。</p>
<p><strong><em>清单4 查询队列头元素过程</em></strong>
public E peek() {
    if (count.get() == 0)
        return null;
    final ReentrantLock takeLock = this.takeLock;
    takeLock.lock();
    try {
        Node<E> first = head.next;
        if (first == null)
            return null;
        else
            return first.item;
    } finally {
        takeLock.unlock();
    }
}</p>
<p>清单4 描述了peek的过程，最后返回一个非null节点的结果是Node.item。这里读取了Node的item值，但是整个过程却是使用了takeLock而非putLock。换句话说putLock对Node.item的操作，peek()线程可能不可见！</p>
<p><strong><em>清单5 队列尾部加入元素</em></strong>
private void insert(E x) {
    last = last.next = new Node<E>(x);
}</p>
<p>清单5 是入队列offer/put的一部分，这里关键在于last=new Node<E>(x)可能发生重排序。Node构造函数是这样的：Node(E x) { item = x; }。在这一步里面我们可能得到以下一种情况：</p>
<ol>
<li>构建一个Node对象n；</li>
<li>将Node的n赋给last</li>
<li>初始化n，设置item=x</li>
</ol>
<p>在执行步骤2 的时候一个peek线程可能拿到了新的Node n，这时候它读取item，得到了一个null。显然这是不可靠的。</p>
<p>对item采用volatile之后，JMM保证对item=x的赋值一定在last=n之前，也就是说last得到的一个是一个已经赋值了的新节点n。这就不会导致读取空元素的问题的。</p>
<p>出对了poll/take和peek都是使用的takeLock锁，所以不会导致此问题。</p>
<p>删除操作和遍历操作由于同时获取了takeLock和putLock，所以也不会导致此问题。</p>
<p>总结：当前仅当元素加入队列时读取此元素才可能导致不一致的问题。采用volatile正式避免此问题。</p>
<p><strong>附加功能</strong></p>
<p>BlockingQueue有一个额外的功能，允许批量从队列中异常元素。这个API是：
<strong><em>int drainTo(Collection&lt;? super E&gt; c, int maxElements);</em></strong> 最多从此队列中移除给定数量的可用元素，并将这些元素添加到给定 collection 中。</p>
<p><strong><em>int drainTo(Collection&lt;? super E&gt; c);</em></strong> 移除此队列中所有可用的元素，并将它们添加到给定 collection 中。</p>
<p>清单6 描述的是最多移除指定数量元素的过程。由于批量操作只需要一次获取锁，所以效率会比每次获取锁要高。但是需要说明的，需要同时获取takeLock/putLock两把锁，因为当移除完所有元素后这会涉及到尾节点的修改（last节点仍然指向一个已经移走的节点）。</p>
<p>由于迭代操作<strong>contains()/remove()/iterator()</strong>也是获取了两个锁，所以迭代操作也是线程安全的。</p>
<p><strong><em>清单6 批量移除操作</em></strong>
public int drainTo(Collection&lt;? super E&gt; c, int maxElements) {
    if (c == null)
        throw new NullPointerException();
    if (c == this)
        throw new IllegalArgumentException();
    fullyLock();
    try {
        int n = 0;
        Node<E> p = head.next;
        while (p != null &amp;&amp; n &lt; maxElements) {
            c.add(p.item);
            p.item = null;
            p = p.next;
            ++n;
        }
        if (n != 0) {
            head.next = p;
            assert head.item == null;
            if (p == null)
                last = head;
            if (count.getAndAdd(-n) == capacity)
                notFull.signalAll();
        }
        return n;
    } finally {
        fullyUnlock();
    }
}</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/24/326988.html](http://www.blogjava.net/xylz/archive/2010/07/24/326988.html)">[http://www.blogjava.net/xylz/archive/2010/07/24/326988.html](http://www.blogjava.net/xylz/archive/2010/07/24/326988.html)</a></p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2010/07/24/326988.html" target="_blank">上一节</a>中详细分析了<strong>LinkedBlockingQueue </strong>的实现原理。实现一个可扩展的队列通常有两种方式：一种方式就像LinkedBlockingQueue一样使用链表，也就是每一个元素带有下一个元素的引用，这样的队列原生就是可扩展的；另外一种就是通过数组实现，一旦队列的大小达到数组的容量的时候就将数组扩充一倍（或者一定的系数倍），从而达到扩容的目的。常见的ArrayList就属于第二种。前面章节介绍过的HashMap确是综合使用了这两种方式。</p>
<p>对于一个Queue而言，同样可以使用数组实现。使用数组的好处在于各个元素之间原生就是通过数组的索引关联起来的，一次元素之间就是有序的，在通过索引操作数组就方便多了。当然也有它不利的一面，扩容起来比较麻烦，同时删除一个元素也比较低效。</p>
<p>ArrayBlockingQueue 就是Queue的一种数组实现。</p>
<p><strong>ArrayBlockingQueue 原理</strong></p>
<p>在没有介绍ArrayBlockingQueue原理之前可以想象下，一个数组如何实现Queue的FIFO特性。首先，数组是固定大小的，这个是毫无疑问的，那么初始化就是所有元素都为null。假设数组一段为头，另一端为尾。那么头和尾之间的元素就是FIFO队列。</p>
<ol>
<li>入队列就将尾索引往右移动一个，新元素加入尾索引的位置；</li>
<li>出队列就将头索引往尾索引方向移动一个，同时将旧头索引元素设为null，返回旧头索引的元素。</li>
<li>一旦数组已满，那么就不允许添加新元素（除非扩充容量）</li>
<li>如果尾索引移到了数组的最后（最大索引处），那么就从索引0开始，形成一个“闭合”的数组。</li>
<li>由于头索引和尾索引之间的元素都不能为空（因为为空不知道take出来的元素为空还是队列为空），所以删除一个头索引和尾索引之间的元素的话，需要移动删除索引前面或者后面的所有元素，以便填充删除索引的位置。</li>
<li>由于是阻塞队列，那么显然需要一个锁，另外由于只是一份数据（一个数组），所以只能有一个锁，也就是同时只能有一个线程操作队列。</li>
</ol>
<p>有了上述几点分析，设计一个可阻塞的数组队列就比较容易了。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency22part7BlockingQueue2_1216F/image_4.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>上图描述的ArrayBlockingQueue的数据结构。首先有一个数组E[]，用来存储所有的元素。由于ArrayBlockingQueue最终设置为一个不可扩展大小的Queue，所以这里items就是初始化就固定大小的数组（final类型）；另外有两个索引，头索引takeIndex，尾索引putIndex；一个队列的大小count；要支持阻塞就必须需要一个锁lock和两个条件（非空、非满），这三个元素都是不可变更类型的（final）。</p>
<p>由于只有一把锁，所以任何时刻对队列的操作都只有一个线程，这意味着对索引和大小的操作都是线程安全的，所以可以看到这个takeIndex/putIndex/count就不需要原子操作和volatile语义了。</p>
<p>清单1 描述的是一个可阻塞的添加元素过程。这与前面介绍的消费者、生产者模型相同。如果队列已经满了就挂起等待，否则就插入元素，同时唤醒一个队列已空的线程。对比清单2 可以看到是完全相反的两个过程。这在前面几种实现生产者-消费者模型的时候都介绍过了。</p>
<p><strong><em>清单1 可阻塞的添加元素</em></strong>
public void put(E e) throws InterruptedException {
    if (e == null) throw new NullPointerException();
    final E[] items = this.items;
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        try {
            while (count == items.length)
                notFull.await();
        } catch (InterruptedException ie) {
            notFull.signal(); // propagate to non-interrupted thread
            throw ie;
        }
        insert(e);
    } finally {
        lock.unlock();
    }
}</p>
<p> <strong><em>清单2 可阻塞的移除元素</em></strong>
public E take() throws InterruptedException {
    final ReentrantLock lock = this.lock;
    lock.lockInterruptibly();
    try {
        try {
            while (count == 0)
                notEmpty.await();
        } catch (InterruptedException ie) {
            notEmpty.signal(); // propagate to non-interrupted thread
            throw ie;
        }
        E x = extract();
        return x;
    } finally {
        lock.unlock();
    }
}</p>
<p>需要注意到的是，尽管每次加入、移除一个元素使用的都是signal()通知，而不是signalAll()通知。我们参考上一节中notify替换notifyAll的原则：每一个await醒来的动作相同，每次最多唤醒一个线程来操作。显然这里符合这两种条件，因此使用signal要比使用signalAll要高效，并且是可靠的。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency22part7BlockingQueue2_1216F/image_10.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>上图描述了take()/put()的索引位置示意图。</p>
<p>一开始takeIndex/putIndex都在E/0位置，然后每加入一个元素offer/put，putIndex都增加1，也就是往后边移动一位；每移除一个元素poll/take，takeIndex都增加1，也是往后边移动一位，显然takeIndex总是在putIndex的“后边”，因为当队列中没有元素的时候takeIndex和putIndex相等，同时当前位置也没有元素，takeIndex也就是无法再往右边移动了；一旦putIndex/takeIndex移动到了最后面，也就是size-1的位置（这里size是指数组的长度），那么就移动到0，继续循环。循环的前提是数组中元素的个数小于数组的长度。整个过程就是这样的。可见putIndex同时指向头元素的下一个位置（如果队列已经满了，那么就是尾元素位置，否则就是一个元素为null的位置）。</p>
<p>比较复杂的操作时删除任意一个元素。清单3 描述的是删除任意一个元素的过程。显然删除任何一个元素需要遍历整个数组，也就是它的复杂度是O(n)，这与根据索引从ArrayList中查找一个元素的复杂度O(1)相比开销要大得多。参考声明的结构图，一旦删除的是takeIndex位置的元素，那么只需要将takeIndex往“右边”移动一位即可；如果删除的是takeIndex和putIndex之间的元素怎么办？这时候就从删除的位置i开始，将i后面的所有元素位置都往“左”移动一位，直到putIndex为止。最终的结果是删除位置的所有元素都“后退”了一个位置，同时putIndex也后退了一个位置。</p>
<p><strong><em>清单3 删除任意一个元素</em></strong>
public boolean remove(Object o) {
    if (o == null) return false;
    final E[] items = this.items;
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        int i = takeIndex;
        int k = 0;
        for (;;) {
            if (k++ &gt;= count)
                return false;
            if (o.equals(items[i])) {
                removeAt(i);
                return true;
            }
            i = inc(i);
        }</p>
<pre><code>} finally {
    lock.unlock();
}
</code></pre><p>}
void removeAt(int i) {
    final E[] items = this.items;
    // if removing front item, just advance
    if (i == takeIndex) {
        items[takeIndex] = null;
        takeIndex = inc(takeIndex);
    } else {
        // slide over all others up through putIndex.
        for (;;) {
            int nexti = inc(i);
            if (nexti != putIndex) {
                items[i] = items[nexti];
                i = nexti;
            } else {
                items[i] = null;
                putIndex = i;
                break;
            }
        }
    }
    --count;
    notFull.signal();
}</p>
<p>对于其他的操作，由于都是带着Lock的操作，所以都比较简单就不再展开了。</p>
<p>下一篇中将介绍另外两个BlockingQueue， PriorityBlockingQueue和SynchronousQueue 然后对这些常见的Queue进行一个小范围的对比。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/27/327265.html](http://www.blogjava.net/xylz/archive/2010/07/27/327265.html)">[http://www.blogjava.net/xylz/archive/2010/07/27/327265.html](http://www.blogjava.net/xylz/archive/2010/07/27/327265.html)</a> </p>
<p>在Set中有一个排序的集合SortedSet，用来保存按照自然顺序排列的对象。Queue中同样引入了一个支持排序的FIFO模型。</p>
<h3 id="-queue-http-www-blogjava-net-xylz-archive-2010-07-21-326723-html-priorityqueue-priorityblockingqueue-queue-queue-queue-priorityblockingqueue-priorityqueue-blocking-"><a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">并发队列与Queue简介</a> 中介绍了，PriorityQueue和PriorityBlockingQueue就是支持排序的Queue。显然一个支持阻塞的排序Queue要比一个非线程安全的Queue实现起来要复杂的多，因此下面只介绍PriorityBlockingQueue，至于PriorityQueue只需要去掉Blocking功能就基本相同了。</h3>
<p><strong>排序的BlockingQueue — PriorityBlockingQueue</strong></p>
<p>先简单介绍下PriorityQueue，因为PriorityBlockingQueue内部就是通过PriorityQueue适配实现的，只不过通过锁进行同步和阻塞而已。</p>
<p>PriorityQueue是一个数组实现的，是一个二叉树的实现，这个二叉树的任意一个节点都比其子节点要小，这样顶点就是最小的节点。每一个元素或者节点要么本身是可比较的（Comparable），或者队列本身带有一个比较器（Comparator&lt;? super E&gt;），所有元素就是靠比较自身的大小来确定顺序的。而数组中顶点就是数组的第0个元素，因此出队列的话总是取第0个元素。对于第0个元素，其子节点是第1个元素和第2个元素，对于第1个元素，其子元素又是第3/4个元素，以此类推，第i个元素的父节点就是(i-1)/2。这样任意一个元素加入队列就从其父节点(i-1)/2开始比较，一旦新节点比父节点小就交换两个节点，然后继续比较新节点与其新的父节点。知道所有节点都是按照父节点一定比子节点小的顺序排列。这是一个有点复杂的算法，此处不再讨论更多的细节。不管是删除还是查找，我们只需要了解的顶点（索引为0的元素）总是最小的。</p>
<p>特别需要说明的是PriorityQueue是一个无界的队列，也就是说一旦元素的个数达到了数组的大小，那么就将数组扩大50%，这样这个数组就是无穷大的。当然了如果达到了整数的最大值就会得到一个OutOfMemoryError，这个是由逻辑保证的。</p>
<p>对于PriorityBlockingQueue而言，由于是无界的，因此就只有非空的信号，也就是说只有take()才能阻塞，put是永远不会阻塞（除非达到Integer.MAX_VALUE直到抛出一个OutOfMemoryError异常）。</p>
<p>只有take()操作的时候才可能因为队列为空而挂起。同时其它需要操作队列变化和大小的只需要使用独占锁ReentrantLock就可以了，非常方便。需要说明的是PriorityBlockingQueue采用了一个公平的锁。</p>
<p>总的来说PriorityBlockingQueue 不是一个FIFO的队列，而是一个有序的队列，这个队列总是取“自然顺序”最小的对象，同时又是一个只能出队列阻塞的BlockingQueue，对于入队列却不是阻塞的。所有操作都是线程安全的。</p>
<p><strong>直接交换的BlockingQueue — SynchronousQueue</strong></p>
<p>这是一个很有意思的阻塞队列，其中每个插入操作必须等待另一个线程的移除操作，同样任何一个移除操作都等待另一个线程的插入操作。因此此队列内部其实没有任何一个元素，或者说容量是0，严格说并不是一种容器。由于队列没有容量，因此不能调用peek操作，因为只有移除元素时才有元素。</p>
<p>一个没有容量的并发队列有什么用了？或者说存在的意义是什么？</p>
<p>SynchronousQueue 的实现非常复杂，当然了如果真要去分析还是能够得到一些经验的，但是前面分析了过多的结构后，发现越来越陷于数据结构与算法里面了。我的初衷是通过研究并发实现的原理来更好的利用并发来最大限度的利用可用资源。所以在后面的章节中尽可能的少研究数据结构和算法，但是为了弄清楚里面的原理，必不可免的会涉及到一些这方面的知识，希望后面能够适可而止。</p>
<p>再回到话题。SynchronousQueue 内部没有容量，但是由于一个插入操作总是对应一个移除操作，反过来同样需要满足。那么一个元素就不会再SynchronousQueue 里面长时间停留，一旦有了插入线程和移除线程，元素很快就从插入线程移交给移除线程。也就是说这更像是一种信道（管道），资源从一个方向快速传递到另一方向。</p>
<p>需要特别说明的是，尽管元素在SynchronousQueue 内部不会“停留”，但是并不意味之SynchronousQueue 内部没有队列。实际上SynchronousQueue 维护者线程队列，也就是插入线程或者移除线程在不同时存在的时候就会有线程队列。既然有队列，同样就有公平性和非公平性特性，公平性保证正在等待的插入线程或者移除线程以FIFO的顺序传递资源。</p>
<p>显然这是一种快速传递元素的方式，也就是说在这种情况下元素总是以最快的方式从插入着（生产者）传递给移除着（消费者），这在多任务队列中是最快处理任务的方式。在线程池的相关章节中还会更多的提到此特性。</p>
<p>事实上在《<a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">并发队列与Queue简介</a>》中介绍了还有一种BlockingQueue的实现DelayQueue，它描述的是一种延时队列。这个队列的特性是，队列中的元素都要延迟时间（超时时间），只有一个元素达到了延时时间才能出队列，也就是说每次从队列中获取的元素总是最先到达延时的元素。这种队列的场景就是计划任务。比如以前要完成计划任务，很有可能是使用Timer/TimerTask，这是一种循环检测的方式，也就是在循环里面遍历所有元素总是检测元素是否满足条件，一旦满足条件就执行相关任务。显然这中方式浪费了很多的检测工作，因为大多数时间总是在进行无谓的检测。而DelayQueue 却能避免这种无谓的检测。在线程池的计划任务部分还有更加详细的讨论此队列实现。</p>
<p>下面就对常见的BlockingQueue进行小节下，这里不包括双向的队列，尽管ConcurrentLinkedQueue不是可阻塞的Queue，但是这里还是将其放在一起进行对比。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency23part8BlockingQueue3_1086D/image_2.png" target="_blank"><img src="&quot;并发队列比较&quot;" alt="并发队列比较"></a></p>
<p>如果不需要阻塞队列，优先选择ConcurrentLinkedQueue；如果需要阻塞队列，队列大小固定优先选择ArrayBlockingQueue，队列大小不固定优先选择LinkedBlockingQueue；如果需要对队列进行排序，选择PriorityBlockingQueue；如果需要一个快速交换的队列，选择SynchronousQueue；如果需要对队列中的元素进行延时操作，则选择DelayQueue。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/30/327582.html](http://www.blogjava.net/xylz/archive/2010/07/30/327582.html)">[http://www.blogjava.net/xylz/archive/2010/07/30/327582.html](http://www.blogjava.net/xylz/archive/2010/07/30/327582.html)</a> </p>
<p>有一段时间没有更新了。接着上节继续吧。</p>
<p>Queue除了前面介绍的实现外，还有一种双向的Queue实现Deque。这种队列允许在队列头和尾部进行入队出队操作，因此在功能上比Queue显然要更复杂。下图描述的是Deque的完整体系图。需要说明的是LinkedList也已经加入了Deque的一部分（LinkedList是从jdk1.2 开始就存在数据结构）。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency24part9Deque_1425C/image_2.png" target="_blank"><img src="&quot;Deque体系结构&quot;" alt="Deque体系结构"></a></p>
<p>Deque在Queue的基础上增加了更多的操作方法。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency24part9Deque_1425C/image_4.png" target="_blank"><img src="&quot;Deque操作方法&quot;" alt="Deque操作方法"></a></p>
<p>从上图可以看到，Deque不仅具有FIFO的Queue实现，也有FILO的实现，也就是不仅可以实现队列，也可以实现一个堆栈。</p>
<p>同时在Deque的体系结构图中可以看到，实现一个Deque可以使用数组（ArrayDeque），同时也可以使用链表（LinkedList），还可以同实现一个支持阻塞的线程安全版本队列LinkedBlockingDeque。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency24part9Deque_1425C/image_6.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>对于数组实现的Deque来说，数据结构上比较简单，只需要一个存储数据的数组以及头尾两个索引即可。由于数组是固定长度的，所以很容易就得到数组的头和尾，那么对于数组的操作只需要移动头和尾的索引即可。</p>
<p>特别说明的是ArrayDeque并不是一个固定大小的队列，每次队列满了以后就将队列容量扩大一倍（doubleCapacity()），因此加入一个元素总是能成功，而且也不会抛出一个异常。也就是说ArrayDeque是一个没有容量限制的队列。</p>
<p>同样继续性能的考虑，使用System.arraycopy复制一个数组比循环设置要高效得多。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency24part9Deque_1425C/image_8.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>对于LinkedList本身而言，数据结构就更简单了，除了一个size用来记录大小外，只有head一个元素Entry。对比Map和Queue的其它数据结构可以看到这里的Entry有两个引用，是双向的队列。</p>
<p>在示意图中，LinkedList总是有一个“傀儡”节点，用来描述队列“头部”，但是并不表示头部元素，它是一个执行null的空节点。</p>
<p>队列一开始只有head一个空元素，然后从尾部加入E1(add/addLast)，head和E1之间建立双向链接。然后继续从尾部加入E2，E2就在head和E1之间建立双向链接。最后从队列的头部加入E3(push/addFirst)，于是E3就在E1和head之间链接双向链接。</p>
<p>双向链表的数据结构比较简单，操作起来也比较容易，从事从“傀儡”节点开始，“傀儡”节点的下一个元素就是队列的头部，前一个元素是队列的尾部，换句话说，“傀儡”节点在头部和尾部之间建立了一个通道，是整个队列形成一个循环，这样就可以从任意一个节点的任意一个方向能遍历完整的队列。</p>
<p>同样LinkedList也是一个没有容量限制的队列，因此入队列（不管是从头部还是尾部）总能成功。</p>
<p>上面描述的ArrayDeque和LinkedList是两种不同方式的实现，通常在遍历和节省内存上ArrayDeque更高效（索引更快，另外不需要Entry对象），但是在队列扩容下LinkedList更灵活，因为不需要复制原始的队列，某些情况下可能更高效。</p>
<p>同样需要注意的上述两个实现都不是线程安全的，因此只适合在单线程环境下使用，下面章节要介绍的LinkedBlockingDeque就是线程安全的可阻塞的Deque。事实上也应该是功能最强大的Queue实现，当然了实现起来也许会复杂一点。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/08/12/328587.html](http://www.blogjava.net/xylz/archive/2010/08/12/328587.html)">[http://www.blogjava.net/xylz/archive/2010/08/12/328587.html](http://www.blogjava.net/xylz/archive/2010/08/12/328587.html)</a> </p>
<p>这个小节介绍Queue的最后一个工具，也是最强大的一个工具。从名称上就可以看到此工具的特点：双向并发阻塞队列。所谓双向是指可以从队列的头和尾同时操作，并发只是线程安全的实现，阻塞允许在入队出队不满足条件时挂起线程，这里说的队列是指支持FIFO/FILO实现的链表。</p>
<p>首先看下LinkedBlockingDeque的数据结构。通常情况下从数据结构上就能看出这种实现的优缺点，这样就知道如何更好的使用工具了。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency25part10BlockingDeque_CB65/image_2.png" target="_blank"><img src="&quot;LinkedBlockingDeque类图&quot;" alt="LinkedBlockingDeque类图"></a></p>
<p>从数据结构和功能需求上可以得到以下结论：</p>
<ol>
<li>要想支持阻塞功能，队列的容量一定是固定的，否则无法在入队的时候挂起线程。也就是capacity是final类型的。</li>
<li>既然是双向链表，每一个结点就需要前后两个引用，这样才能将所有元素串联起来，支持双向遍历。也即需要prev/next两个引用。</li>
<li>双向链表需要头尾同时操作，所以需要first/last两个节点，当然可以参考LinkedList那样采用一个节点的双向来完成，那样实现起来就稍微麻烦点。</li>
<li>既然要支持阻塞功能，就需要锁和条件变量来挂起线程。这里使用一个锁两个条件变量来完成此功能。</li>
</ol>
<p>有了上面的结论再来研究LinkedBlockingDeque的优缺点。</p>
<p>优点当然是功能足够强大，同时由于采用一个独占锁，因此实现起来也比较简单。所有对队列的操作都加锁就可以完成。同时独占锁也能够很好的支持双向阻塞的特性。</p>
<p>凡事有利必有弊。缺点就是由于独占锁，所以不能同时进行两个操作，这样性能上就大打折扣。从性能的角度讲LinkedBlockingDeque要比LinkedBlockingQueue要低很多，比CocurrentLinkedQueue就低更多了，这在高并发情况下就比较明显了。</p>
<p>前面分析足够多的Queue实现后，LinkedBlockingDeque的原理和实现就不值得一提了，无非是在独占锁下对一个链表的普通操作。</p>
<p>有趣的是此类支持序列化，但是Node并不支持序列化，因此fist/last就不能序列化，那么如何完成序列化/反序列化过程呢？</p>
<p><strong><em>清单1 LinkedBlockingDeque的序列化、反序列化</em></strong>
private void writeObject(java.io.ObjectOutputStream s)
    throws java.io.IOException {
    lock.lock();
    try {
        // Write out capacity and any hidden stuff
        s.defaultWriteObject();
        // Write out all elements in the proper order.
        for (Node<E> p = first; p != null; p = p.next)
            s.writeObject(p.item);
        // Use trailing null as sentinel
        s.writeObject(null);
    } finally {
        lock.unlock();
    }
}</p>
<p>private void readObject(java.io.ObjectInputStream s)
    throws java.io.IOException, ClassNotFoundException {
    s.defaultReadObject();
    count = 0;
    first = null;
    last = null;
    // Read in all elements and place in queue
    for (;;) {
        E item = (E)s.readObject();
        if (item == null)
            break;
        add(item);
    }
}</p>
<p>清单1 描述的是LinkedBlockingDeque序列化/反序列化的过程。序列化时将真正的元素写入输出流，最后还写入了一个null。读取的时候将所有对象列表读出来，如果读取到一个null就表示结束。这就是为什么写入的时候写入一个null的原因，因为没有将count写入流，所以就靠null来表示结束，省一个整数空间。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/08/18/329227.html](http://www.blogjava.net/xylz/archive/2010/08/18/329227.html)">[http://www.blogjava.net/xylz/archive/2010/08/18/329227.html](http://www.blogjava.net/xylz/archive/2010/08/18/329227.html)</a> </p>
<p>可以在对中对元素进行配对和交换的线程的同步点。每个线程将条目上的某个方法呈现给 </p>
<p>exchange
 方法，与伙伴线程进行匹配，并且在返回时接收其伙伴的对象。Exchanger 可能被视为 </p>
<p>SynchronousQueue
 的双向形式。</p>
<p>换句话说Exchanger提供的是一个交换服务，允许原子性的交换两个（多个）对象，但同时只有一对才会成功。先看一个简单的实例模型。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-26--part-11--BlockingD_12273/Exchanger_2.png" target="_blank"><img src="&quot;Exchanger&quot;" alt="Exchanger"></a></p>
<p>在上面的模型中，我们假定一个空的栈（Stack），栈顶（Top）当然是没有元素的。同时我们假定一个数据结构Node，包含一个要交换的元素E和一个要填充的“洞”Node。这时线程T1携带节点node1进入栈（cas_push)，当然这是CAS操作，这样栈顶就不为空了。线程T2携带节点node2进入栈，发现栈里面已经有元素了node1，同时发现node1的hold（Node）为空，于是将自己（node2）填充到node1的hold中（cas_fill）。然后将元素node1从栈中弹出（cas_take）。这样线程T1就得到了node1.hold.item也就是node2的元素e2，线程T2就得到了node1.item也就是e1，从而达到了交换的目的。</p>
<p>算法描述就是下图展示的内容。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-26--part-11--BlockingD_12273/image_4.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>JDK 5就是采用类似的思想实现的Exchanger。JDK 6以后为了支持多线程多对象同时Exchanger了就进行了改造（为了支持更好的并发），采用ConcurrentHashMap的思想，将Stack分割成很多的片段（或者说插槽Slot），线程Id（Thread.getId()）hash相同的落在同一个Slot上，这样在默认32个Slot上就有很好的吞吐量。当然会根据机器CPU内核的数量有一定的优化，有兴趣的可以去了解下Exchanger的源码。</p>
<p>至于Exchanger的使用，在JDK文档上有个例子，讲述的是两个线程交换数据缓冲区的例子（实际上仍然可以认为是生产者/消费者模型）。
class FillAndEmpty {
   Exchanger<DataBuffer> exchanger = new Exchanger<DataBuffer>();
   DataBuffer initialEmptyBuffer = <img src="" alt=""> a made-up type
   DataBuffer initialFullBuffer = <img src="" alt="">
   class FillingLoop implements Runnable {
     public void run() {
       DataBuffer currentBuffer = initialEmptyBuffer;
       try {
         while (currentBuffer != null) {
           addToBuffer(currentBuffer);
           if (currentBuffer.isFull())
             currentBuffer = exchanger.exchange(currentBuffer);
         }
       } catch (InterruptedException ex) { <img src="" alt=""> handle <img src="" alt=""> }
     }
   }
   class EmptyingLoop implements Runnable {
     public void run() {
       DataBuffer currentBuffer = initialFullBuffer;
       try {
         while (currentBuffer != null) {
           takeFromBuffer(currentBuffer);
           if (currentBuffer.isEmpty())
             currentBuffer = exchanger.exchange(currentBuffer);
         }
       } catch (InterruptedException ex) { <img src="" alt=""> handle <img src="" alt="">}
     }
   }
   void start() {
     new Thread(new FillingLoop()).start();
     new Thread(new EmptyingLoop()).start();
   }
  }</p>
<p>Exchanger实现的是一种数据分片的思想，这在大数据情况下将数据分成一定的片段并且多线程执行的情况下有一定的使用价值。</p>
<p>最近一直推托工作忙，更新频度越来越低了，好在现在的工作还有点个人时间，以后争取多更新下吧，至少也要把这个专辑写完。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/11/22/338733.html](http://www.blogjava.net/xylz/archive/2010/11/22/338733.html)">[http://www.blogjava.net/xylz/archive/2010/11/22/338733.html](http://www.blogjava.net/xylz/archive/2010/11/22/338733.html)</a> </p>
<p>本小节是《并发容器》的最后一部分，这一个小节描述的是针对List/Set接口的一个线程版本。</p>
<p>在《<a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">并发队列与Queue简介</a>》中介绍了并发容器的一个概括，主要描述的是Queue的实现。其中特别提到一点LinkedList是List/Queue的实现，但是LinkedList确实非线程安全的。不管BlockingQueue还是ConcurrentMap的实现，我们发现都是针对链表的实现，当然尽可能的使用CAS或者Lock的特性，同时都有通过锁部分容器来提供并发的特性。而对于List或者Set而言，增、删操作其实都是针对整个容器，因此每次操作都不可避免的需要锁定整个容器空间，性能肯定会大打折扣。要实现一个线程安全的List/Set，只需要在修改操作的时候进行同步即可，比如使用java.util.Collections.synchronizedList(List<T>)或者java.util.Collections.synchronizedSet(Set<T>)。当然也可以使用Lock来实现线程安全的List/Set。</p>
<p>通常情况下我们的高并发都发生在“多读少写”的情况，因此如果能够实现一种更优秀的算法这对生产环境还是很有好处的。ReadWriteLock当然是一种实现。CopyOnWriteArrayList/CopyOnWriteArraySet确实另外一种思路。</p>
<p>CopyOnWriteArrayList/CopyOnWriteArraySet的基本思想是一旦对容器有修改，那么就“复制”一份新的集合，在新的集合上修改，然后将新集合复制给旧的引用。当然了这部分少不了要加锁。显然对于CopyOnWriteArrayList/CopyOnWriteArraySet来说最大的好处就是“读”操作不需要锁了。</p>
<p>我们来看看源码。
//<em>/</em> The array, accessed only via getArray/setArray. /*/
private volatile transient Object[] array;
public E get(int index) {
    return (E)(getArray()[index]);
}
private static int indexOf(Object o, Object[] elements,
                           int index, int fence) {
    if (o == null) {
        for (int i = index; i &lt; fence; i++)
            if (elements[i] == null)
                return i;
    } else {
        for (int i = index; i &lt; fence; i++)
            if (o.equals(elements[i]))
                return i;
    }
    return -1;
}
public Iterator<E> iterator() {
    return new COWIterator<E>(getArray(), 0);
}
    public void clear() {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        setArray(new Object[0]);
    } finally {
        lock.unlock();
    }
    }</p>
<p>对于上述代码，有几点说明：</p>
<ol>
<li>List仍然是基于数组的实现，因为只有数组是最快的。</li>
<li>为了保证无锁的读操作能够看到写操作的变化，因此数组array是volatile类型的。</li>
<li>get/indexOf/iterator等操作都是无锁的，同时也可以看到所操作的都是某一时刻array的镜像（这得益于数组是不可变化的）</li>
<li>add/set/remove/clear等元素变化的都是需要加锁的，这里使用的是ReentrantLock。</li>
</ol>
<p>这里有一段有意思的代码片段。
    public E set(int index, E element) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        Object[] elements = getArray();
        Object oldValue = elements[index];
        if (oldValue != element) {
        int len = elements.length;
        Object[] newElements = Arrays.copyOf(elements, len);
        newElements[index] = element;
        setArray(newElements);
        } else {
        // Not quite a no-op; ensures volatile write semantics
        setArray(elements);
        }
        return (E)oldValue;
    } finally {
        lock.unlock();
    }
    }
final void setArray(Object[] a) {
    array = a;
}</p>
<p>对于set操作，如果元素有变化，修改后setArray(newElements);将新数组赋值还好理解。那么如果一个元素没有变化，也就是上述代码的else部分，为什么还需要进行一个无谓的setArray操作？毕竟setArray操作没有改变任何数据。</p>
<p>对于这个问题也是很有意思，有一封邮件讨论了此问题（<a href="http://cs.oswego.edu/pipermail/concurrency-interest/2010-February/006886.html" target="_blank">1</a>、<a href="http://cs.oswego.edu/pipermail/concurrency-interest/2010-February/006887.html" target="_blank">2</a>、<a href="http://cs.oswego.edu/pipermail/concurrency-interest/2010-February/006888.html" target="_blank">3</a>）。
大致的意思是，尽管没有改变任何数据，但是为了保持“volatile”的语义，任何一个读操作都应该是一个写操作的结果，也就是读操作看到的数据一定是某个写操作的结果（尽管写操作没有改变数据本身）。所以这里即使不设置也没有问题，仅仅是为了一个语义上的补充（个人理解）。</p>
<p>这里还有一个有意思的讨论，说什么addIfAbsent在元素没有变化的时候为什么没有setArray操作？这个要看怎么理解addIfAbsent的语义了。如果说addIfAbsent语义是”写“或者”不写“操作，而把”不写“操作当作一次”读“操作的话，那么”读“操作就不需要保持volatile语义了。</p>
<p>对于CopyOnWriteArraySet而言就简单多了，只是持有一个CopyOnWriteArrayList，仅仅在add/addAll的时候检测元素是否存在，如果存在就不加入集合中。
private final CopyOnWriteArrayList<E> al;
//<em>/</em>
/<em> Creates an empty set.
/</em>/
public CopyOnWriteArraySet() {
    al = new CopyOnWriteArrayList<E>();
}
public boolean add(E e) {
    return al.addIfAbsent(e);
}</p>
<p>在使用上CopyOnWriteArrayList/CopyOnWriteArraySet就简单多了，和List/Set基本相同，这里就不再介绍了。</p>
<p>整个并发容器结束了，接下来好好规划下线程池部分，然后进入最后一部分的梳理。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/11/23/338853.html](http://www.blogjava.net/xylz/archive/2010/11/23/338853.html)">[http://www.blogjava.net/xylz/archive/2010/11/23/338853.html](http://www.blogjava.net/xylz/archive/2010/11/23/338853.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency4-并发容器/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency4-并发容器" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency37-并发总结/">深入浅出 Java Concurrency (37)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency37-并发总结/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-37-">深入浅出 Java Concurrency (37): 并发总结</h1>
<p><a href="http://www.blogjava.net/xylz/archive/2011/12/29/365149.html" target="_blank">深入浅出 Java Concurrency (37): 并发总结 part 1 死锁与活跃度</a></p>
<h1 id="-">死锁与活跃度</h1>
<p>前面谈了很多并发的特性和工具，但是大部分都是和锁有关的。我们使用锁来保证线程安全，但是这也会引起一些问题。</p>
<ul>
<li>锁顺序死锁(lock-ordering deadlock)：多个线程试图通过不同的顺序获得多个相同的资源，则发生的循环锁依赖现象。</li>
<li>动态的锁顺序死锁（Dynamic Lock Order Deadlocks）：多个线程通过传递不同的锁造成的锁顺序死锁问题。</li>
<li>资源死锁（Resource Deadlocks）：线程间相互等待对方持有的锁，并且谁都不会释放自己持有的锁发生的死锁。也就是说当现场持有和等待的目标成为资源，就有可能发生此死锁。这和锁顺序死锁不一样的地方是，竞争的资源之间并没有严格先后顺序，仅仅是相互依赖而已。</li>
</ul>
<h2 id="-">锁顺序死锁</h2>
<p>最经典的锁顺序死锁就是LeftRightDeadLock.
<img src="" alt=""></p>
<p>public class LeftRightDeadLock {
    final Object left = new Object();
    final Object right = new Object();
    public void doLeftRight() {
        synchronized (left) {
            synchronized (right) {
                execute1();
            }
        }
    }
    public void doRightLeft() {
        synchronized (right) {
            synchronized (left) {
                execute2();
            }
        }
    }
    private void execute2() {
    }
    private void execute1() {
    }
}</p>
<p>这个例子很简单，当两个线程分别获取到left和right锁时，互相等待对方释放其对应的锁，很显然双方都陷入了绝境。</p>
<h2 id="-">动态的锁顺序死锁</h2>
<p>与锁顺序死锁不同的是动态的锁顺序死锁只是将静态的锁变成了动态锁。 一个比较生动的例子是这样的。</p>
<p>public void transferMoney(Account fromAccount,//
        Account toAccount,//
        int amount
        ) {
    synchronized (fromAccount) {
        synchronized (toAccount) {
            fromAccount.decr(amount);
            toAccount.add(amount);
        }
    }
}
当我们银行转账的时候，我们期望锁住双方的账户，这样保证是原子操作。 看起来很合理，可是如果双方同时在进行转账操作，那么就有可能发生死锁的可能性。</p>
<p>很显然，动态的锁顺序死锁的解决方案应该看起来和锁顺序死锁解决方案差不多。 但是一个比较特殊的解决方式是纠正这种顺序。 例如可以调整成这样：
Object lock = new Object();
public void transferMoney(Account fromAccount,//
        Account toAccount,//
        int amount
        ) {
    int order = fromAccount.name().compareTo(toAccount.name());
    Object lockFirst = order&gt;0?toAccount:fromAccount;
    Object lockSecond = order&gt;0?fromAccount:toAccount;
    if(order==0){
        synchronized(lock){
            synchronized(lockFirst){
                synchronized(lockSecond){
                    //do work
                }
            }
        }
    }else{
        synchronized(lockFirst){
            synchronized(lockSecond){
                //do work
            }
        }
    }
}</p>
<p>这个挺有意思的。比较两个账户的顺序，保证此两个账户之间的传递顺序总是按照某一种锁的顺序进行的， 即使多个线程同时发生，也会遵循一次操作完释放完锁才进行下一次操作的顺序，从而可以避免死锁的发生。</p>
<h2 id="-">资源死锁</h2>
<p>资源死锁比较容易理解，就是需要的资源远远大于已有的资源，这样就有可能线程间的资源竞争从而发生死锁。 一个简单的场景是，应用同时从两个连接池中获取资源，两个线程都在等待对方释放连接池的资源以便能够同时获取 到所需要的资源，从而发生死锁。</p>
<p>资源死锁除了这种资源之间的直接依赖死锁外，还有一种叫线程饥饿死锁（thread-starvation deadlock）。 严格意义上讲，这种死锁更像是活跃度问题。例如提交到线程池中的任务由于总是不能够抢到线程从而一直不被执行， 造成任务的“假死”状况。</p>
<p>除了上述几种问题外，还有协作对象间的死锁以及开发调用的问题。这个描述起来会比较困难，也不容易看出死锁来。</p>
<h1 id="-">避免和解决死锁</h1>
<p>通常发生死锁后程序难以自恢复。但也不是不能避免的。 有一些技巧和原则是可以降低死锁可能性的。</p>
<p>最简单的原则是尽可能的减少锁的范围。锁的范围越小，那么竞争的可能性也越小。 尽快释放锁也有助于避开锁顺序。如果一个线程每次最多只能够获取一个锁，那么就不会产生锁顺序死锁。尽管应用中比较困难，但是减少锁的边界有助于分析程序的设计和简化流程。 减少锁之间的依赖以及遵守获取锁的顺序是避免锁顺序死锁的有效途径。</p>
<p>另外尽可能的使用定时的锁有助于程序从死锁中自恢复。 例如对于上述顺序锁死锁中，使用定时锁很容易解决此问题。</p>
<p>public void doLeftRight() throws Exception {
    boolean over = false;
    while (!over) {
        if (left.tryLock(1, TimeUnit.SECONDS)) {
            try {
                if (right.tryLock(1, TimeUnit.SECONDS)) {
                    try {
                        execute1();
                    } finally {
                        right.unlock();
                        over = true;
                    }
                }
            } finally {
                left.unlock();
            }
        }
    }
}
public void doRightLeft() throws Exception {
    boolean over = false;
    while (!over) {
        if (right.tryLock(1, TimeUnit.SECONDS)) {
            try {
                if (left.tryLock(1, TimeUnit.SECONDS)) {
                    try {
                        execute2();
                    } finally {
                        left.unlock();
                        over = true;
                    }
                }
            } finally {
                right.unlock();
            }
        }
    }
}
看起来代码会比较复杂，但是这是避免死锁的有效方式。</p>
<h1 id="-">活跃度</h1>
<p>对于多线程来说，死锁是非常严重的系统问题，必须修正。除了死锁，遇到很多的就是活跃度问题了。 活跃度问题主要包括：饥饿，丢失信号，和活锁等。</p>
<h2 id="-">饥饿</h2>
<p>饥饿是指线程需要访问的资源被永久拒绝，以至于不能在继续进行。 比如说：某个权重比较低的线程可能一直不能够抢到CPU周期，从而一直不能够被执行。</p>
<p>也有一些场景是比较容易理解的。对于一个固定大小的连接池中，如果连接一直被用完，那么过多的任务可能由于一直无法抢占到连接从而不能够被执行。这也是饥饿的一种表现。</p>
<p>对于饥饿而言，就需要平衡资源的竞争，例如线程的优先级，任务的权重，执行的周期等等。总之，当空闲的资源较多的情况下，发生饥饿的可能性就越小。</p>
<h2 id="-">弱响应性</h2>
<p>弱响应是指，线程最终能够得到有效的执行，只是等待的响应时间较长。 最常见的莫过于GUI的“假死”了。很多时候GUI的响应只是为了等待后台数据的处理，如果线程协调不好，很有可能就会发生“失去响应”的现象。</p>
<p>另外，和饥饿很类似的情况。如果一个线程长时间独占一个锁，那么其它需要此锁的线程很有可能就会被迫等待。</p>
<h2 id="-">活锁</h2>
<p>活锁（Livelock）是指线程虽然没有被阻塞，但是由于某种条件不满足，一直尝试重试，却终是失败。</p>
<p>考虑一个场景，我们从队列中拿出一个任务来执行，如果任务执行失败，那么将任务重新加入队列，继续执行。假如任务总是执行失败，或者某种依赖的条件总是不满足，那么线程一直在繁忙却没有任何结果。</p>
<p>错误的循环引用和判断也有可能导致活锁。当某些条件总是不能满足的时候，可能陷入死循环的境地。</p>
<p>线程间的协同也有可能导致活锁。例如如果两个线程发生了某些条件的碰撞后重新执行，那么如果再次尝试后依然发生了碰撞，长此下去就有可能发生活锁。</p>
<p>解决活锁的一种方案是对重试机制引入一些随机性。例如如果检测到冲突，那么就暂停随机的一定时间进行重试。这回大大减少碰撞的可能性。</p>
<p>另外为了避免可能的死锁，适当加入一定的重试次数也是有效的解决办法。尽管这在业务上会引起一些复杂的逻辑处理。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/12/29/365149.html](http://www.blogjava.net/xylz/archive/2011/12/29/365149.html)">[http://www.blogjava.net/xylz/archive/2011/12/29/365149.html](http://www.blogjava.net/xylz/archive/2011/12/29/365149.html)</a> </p>
<h1 id="-">常见的并发场景</h1>
<h2 id="-">线程池</h2>
<p>并发最常见用于线程池，显然使用线程池可以有效的提高吞吐量。</p>
<p>最常见、比较复杂一个场景是Web容器的线程池。Web容器使用线程池同步或者异步处理HTTP请求，同时这也可以有效的复用HTTP连接，降低资源申请的开销。通常我们认为HTTP请求时非常昂贵的，并且也是比较耗费资源和性能的，所以线程池在这里就扮演了非常重要的角色。</p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2010/12/19/341098.html" target="_blank">线程池</a>的章节中非常详细的讨论了线程池的原理和使用，同时也提到了，线程池的配置和参数对性能的影响是巨大的。不尽如此，受限于资源（机器的性能、网络的带宽等等）、依赖的服务，客户端的响应速度等，线程池的威力也不会一直增长。达到了线程池的瓶颈后，性能和吞吐量都会大幅度降低。</p>
<p>一直增加机器的性能或者增大线程的个数，并不一定能有效的提高吞吐量。高并发的情况下，机器的负载会大幅提升，这时候机器的稳定性、服务的可靠性都会下降。</p>
<p>尽管如此，线程池依然是提高吞吐量的一个有效措施，配合合适的参数能够有效的充分利用资源，提高资源的利用率。</p>
<h2 id="-">任务队列</h2>
<p>除了线程池是比较发杂的并发场景外，<a href="http://www.blogjava.net/xylz/archive/2010/07/21/326723.html" target="_blank">任务队列</a>也是一个不错的并发工具。JDK内部有大量的队列（Queue),这些工具不仅能够方便使用，提高生产力，也能够进行组合适应于不同的场景。即使线程池内部，也是用了任务队列来处理任务的积压，平衡资源的消耗。</p>
<p>安全的任务队列能够有效的平衡机器的复杂，抵消由于峰值和波动带来的不稳定，有效提高服务的可靠性。同时任务队列的处理也有助于统计和分析服务的状况。</p>
<p>任务队列也可以在多个线程之间传递数据，有助于并行处理任务。例如经典的“生产者-消费者”模型就可以有效的提高多个线程的并行处理能力。在IO延时比较大的服务中尤其有效。 我最喜欢的一个案例是导数据是，一个线程负责往固定大小的任务队列中压入大量的数据，队列满了以后就暂停，另外几个线程负责从任务队列中获取数据并消费。这将串行的“生产-消费”，变成了并行的“生产-消费”。实践证明极大的节省任务处理时间。</p>
<h2 id="-">异步处理</h2>
<p>线程池也是异步处理的一种表现形式，除此之外，使用异步处理的目的也是为了提高服务的处理速度。 例如AOP的一个例子就是使用切面来记录日志，如果说我们要远程收集日志，显然不希望由于收集日志而影响服务本身。这时候就将日志收集的过程进行异步处理。</p>
<p>如今大量的开源组件都喜欢使用异步处理来提高IO的效率，某些不需要同步返回的操作使用异步处理后能够有效的提高吞吐量。</p>
<p>当然，异步也不总是令人满意的，也会有相应的问题。例如引入异步设计后的复杂性，线程中断后的处理机制，失败后的处理策略，产生的消息比消费的还快时怎么办，关闭程序时如何关闭异步处理逻辑等等。这都会增加系统的复杂性。</p>
<p>尽管大量的服务、业务使用异步来处理，但是很显然需要有保障机制能够保证异步处理的逻辑正确性。如果认为异步处理的任务不是特别重要，或者说主业务不能因为附属业务的逻辑出错而崩溃，那么使用异步处理是正确的选择。</p>
<h2 id="-">同步操作</h2>
<p>并发操作的同时还需要维护数据的一致性，或多或少的会涉及到同步操作。正确的使用原子操作，合理的使用独占锁和读写锁也是一个很大的挑战。</p>
<p>线程间的协调与通信，尤其是状态的同步都是比较困难的。我们看到线程池<a href="http://www.blogjava.net/xylz/archive/2011/01/18/343183.html" target="_blank">ThreadPoolExecutor</a>的实现为了解决各个线程的执行状态，引入的很多的同步操作。线程越来越多的情况下，同步的成本会越来越高，同时也有可能引入死锁的情况。</p>
<p>尽管如此，单个JVM内部的多线程同步还是比较容易控制的。JDK内部也提供了大量的工具来方便完成数据的同步。例如<a href="http://www.blogjava.net/xylz/archive/2010/07/05/325274.html" target="_blank">Lock</a>/<a href="http://www.blogjava.net/xylz/archive/2010/07/08/325540.html" target="_blank">Condition</a>/<a href="http://www.blogjava.net/xylz/archive/2010/07/09/325612.html" target="_blank">CountDownLatch</a>/<a href="http://www.blogjava.net/xylz/archive/2010/07/12/325913.html" target="_blank">CyclicBarrier</a>/<a href="http://www.blogjava.net/xylz/archive/2010/07/13/326021.html" target="_blank">Semaphore</a>/<a href="http://www.blogjava.net/xylz/archive/2010/11/22/338733.html" target="_blank">Exchanger</a>等等。</p>
<h2 id="-">分布式锁</h2>
<p>分布式的并发问题更难以处理，根据<a href="http://en.wikipedia.org/wiki/CAP_theorem" target="_blank">CAP</a>的原理，基本上没有一个至善至美的方案。 分布式资源协调使用分布式锁是一个不错的选择。<a href="http://blog.nosqlfan.com/html/1038.html" target="_blank">Google的分布式锁</a>（建立在BigTable之上），<a href="http://zookeeper.apache.org/doc/r3.3.2/zookeeperOver.html" target="_blank">Zookeeper的分布式锁</a>，甚至简单的利用<a href="http://memcached.org/" target="_blank">memcache</a>的add操作或者<a href="http://redis.io/" target="_blank">redis</a>的setnx操作建立伪分布式锁也可以解决类似的问题。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/12/29/367480.html](http://www.blogjava.net/xylz/archive/2011/12/29/367480.html)">[http://www.blogjava.net/xylz/archive/2011/12/29/367480.html](http://www.blogjava.net/xylz/archive/2011/12/29/367480.html)</a> </p>
<h1 id="-">常见的并发陷阱</h1>
<h2 id="volatile">volatile</h2>
<p>volatile只能强调数据的可见性，并不能保证原子操作和线程安全，因此volatile不是万能的。参考<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">指令重排序</a></p>
<p>volatile最常见于下面两种场景。</p>
<p>a. 循环检测机制
volatile boolean done = false;
<img src="" alt="">
    while( ! done ){
        dosomething();
    }</p>
<p>b. 单例模型 （<a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html%ef%bc%89" target="_blank"><a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html）">http://www.blogjava.net/xylz/archive/2009/12/18/306622.html）</a>
</a></p>
<p><a href="http://www.blogjava.net/xylz/archive/2009/12/18/306622.html%ef%bc%89">public class DoubleLockSingleton {
    private static volatile DoubleLockSingleton instance = null;
    private DoubleLockSingleton() {
    }
    public static DoubleLockSingleton getInstance() {
        if (instance == null) {
            synchronized (DoubleLockSingleton.class) {
                if (instance == null) {
                    instance = new DoubleLockSingleton();
                }
            }
        }
        return instance;
    }
}</a></p>
<h2 id="synchronized-lock">synchronized/Lock</h2>
<p>看起来Lock有更好的性能以及更灵活的控制，是否完全可以替换synchronized？</p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2010/07/16/326246.html" target="_blank">锁的一些其它问题</a>中说过，synchronized的性能随着JDK版本的升级会越来越高，而Lock优化的空间受限于CPU的性能，很有限。另外JDK内部的工具（线程转储）对synchronized是有一些支持的（方便发现死锁等），而对Lock是没有任何支持的。</p>
<p>也就说简单的逻辑使用synchronized完全没有问题，随着机器的性能的提高，这点开销是可以忽略的。而且从代码结构上讲是更简单的。简单就是美。</p>
<p>对于复杂的逻辑，如果涉及到读写锁、条件变量、更高的吞吐量以及更灵活、动态的用法，那么就可以考虑使用Lock。当然这里尤其需要注意Lock的正确用法。
Lock lock = <img src="" alt="">
lock.lock();
try{
    //do something
}finally{
    lock.unlock();
}</p>
<p>一定要将Lock的释放放入finally块中，否则一旦发生异常或者逻辑跳转，很有可能会导致锁没有释放，从而发生死锁。而且这种死锁是难以排查的。</p>
<p>如果需要synchronized无法做到的尝试锁机制，或者说担心发生死锁无法自恢复，那么使用tryLock()是一个比较明智的选择的。
Lock lock = <img src="" alt="">
if(lock.tryLock()){
    try{
        //do something
    }finally{
        lock.unlock();
    }
}</p>
<p>甚至可以使用获取锁一段时间内超时的机制Lock.tryLock(long,TimeUnit)。 锁的使用可以参考前面文章的描述和建议。</p>
<h2 id="-">锁的边界</h2>
<p>一个流行的错误是这样的。
ConcurrentMap<String,String> map = new ConcurrentHashMap<String,String>();
if(!map.containsKey(key)){
    map.put(key,value);
}</p>
<p>看起来很合理的，对于一个线程安全的Map实现，要存取一个不重复的结果，先检测是否存在然后加入。 其实我们知道两个原子操作和在一起的指令序列不代表就是线程安全的。 割裂的多个原子操作放在一起在多线程的情况下就有可能发生错误。</p>
<p>实际上ConcurrentMap提供了putIfAbsent(K, V)的“原子操作”机制，这等价于下面的逻辑：
if(map.containsKey(key)){
    return map.get(key);
}else{
    return map.put(k,v);
}</p>
<p>除了putIfAbsent还有replace(K, V)以及replace(K, V, V)两种机制来完成组合的操作。</p>
<p>提到Map，这里有一篇谈<a href="http://www.blogjava.net/xylz/archive/2009/12/18/306602.html" target="_blank">HashMap读写并发</a>的问题。</p>
<h2 id="-">构造函数启动线程</h2>
<p>下面的实例是在构造函数中启动一个线程。
public class Runner{
   int x,y;
   Thread thread;
   public Runner(){
      this.x=1;
      this.y=2;
      this.thread=new MyThread();
      this.thread.start();
   }
}</p>
<p>这里可能存在的陷阱是如果此类被继承，那么启动的线程可能无法正确读取子类的初始化操作。</p>
<p>因此一个简单的原则是，禁止在构造函数中启动线程，可以考虑但是提供一个方法来启动线程。如果非要这么做，最好将类设置为final，禁止继承。</p>
<h2 id="-">丢失通知的问题</h2>
<p><a href="http://www.blogjava.net/xylz/archive/2011/09/05/326988.html" target="_blank">这篇文章</a>里面提到过notify丢失通知的问题。</p>
<p>对于wait/notify/notifyAll以及await/singal/singalAll，如果不确定到底是否能够正确的收到消息，担心丢失通知，简单一点就是总是通知所有。</p>
<p>如果担心只收到一次消息，使用循环一直监听是不错的选择。</p>
<p>非常主用性能的系统，可能就需要区分到底是通知单个还是通知所有的挂起者。</p>
<h2 id="-">线程数</h2>
<p>并不是线程数越多越好，在下一篇文章里面会具体了解下性能和可伸缩性。 简单的说，线程数多少没有一个固定的结论，受限于CPU的内核数，IO的性能以及依赖的服务等等。因此选择一个合适的线程数有助于提高吞吐量。</p>
<p>对于CPU密集型应用，线程数和CPU的内核数一致有助于提高吞吐量，所有CPU都很繁忙，效率就很高。 对于IO密集型应用，线程数受限于IO的性能，某些时候单线程可能比多线程效率更高。但通常情况下适当提高线程数，有利于提高网络IO的效率，因为我们总是认为网络IO的效率比较低。</p>
<p>对于线程池而言，选择合适的线程数以及任务队列是提高线程池效率的手段。
public ThreadPoolExecutor(
    int corePoolSize,
    int maximumPoolSize,
    long keepAliveTime,
    TimeUnit unit,
    BlockingQueue<Runnable> workQueue,
    ThreadFactory threadFactory,
    RejectedExecutionHandler handler)</p>
<p>对于线程池来说，如果任务总是有积压，那么可以适当提高corePoolSize大小；如果机器负载较低，那么可以适当提高maximumPoolSize的大小；任务队列不长的情况下减小keepAliveTime的时间有助于降低负载；另外任务队列的长度以及任务队列的<a href="http://www.blogjava.net/xylz/archive/2011/01/18/343183.html" target="_blank">拒绝策略</a>也会对任务的处理有一些影响。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/12/30/367592.html](http://www.blogjava.net/xylz/archive/2011/12/30/367592.html)">[http://www.blogjava.net/xylz/archive/2011/12/30/367592.html](http://www.blogjava.net/xylz/archive/2011/12/30/367592.html)</a> </p>
<h1 id="-">性能与伸缩性</h1>
<p>使用线程的一种说法是为了提高性能。多线程可以使程序充分利用闲置的资源，提高资源的利用率，同时能够并行处理任务，提高系统的响应性。 但是很显然，引入线程的同时也引入了系统的复杂性。另外系统的性能并不是总是随着线程数的增加而总是提高。</p>
<h2 id="-">性能与伸缩性</h2>
<p>性能的提升通常意味着可以用更少的资源做更多的事情。这里资源是包括我们常说的CPU周期、内存、网络带宽、磁盘IO、数据库、WEB服务等等。 引入多线程可以充分利用多核的优势，充分利用IO阻塞带来的延迟，也可以降低网络开销带来的影响，从而提高单位时间内的响应效率。</p>
<p>为了提高性能，需要有效的利用我们现有的处理资源，同时也要开拓新的可用资源。例如，对于CPU而言，理想状况下希望CPU能够满负荷工作。当然这里满负荷工作是指做有用的事情，而不是无谓的死循环或者等待。受限于CPU的计算能力，如果CPU达到了极限，那么很显然我们充分利用了计算能力。对于IO而言（内存、磁盘、网络等），如果达到了其对于的带宽，这些资源的利用率也就上去了。理想状况下所有资源的能力都被用完了，那么这个系统的性能达到了最大值。</p>
<p>为了衡量系统的性能，有一些指标用于定性、定量的分析。例如服务时间、等待时间、吞吐量、效率、可伸缩性、生成量等等。服务时间、等待时间等用于衡量系统的效率，即到底有多快。吞吐量、生成量等用于衡量系统的容量，即能够处理多少数据。除此之外，有效服务时间、中断时间等用于能力系统的可靠性和稳定性等。</p>
<p>可伸缩性的意思是指增加计算资源，吞吐量和生产量相应得到的改进。 从算法的角度讲，通常用复杂度来衡量其对应的性能。例如时间复杂度、空间复杂度等。</p>
<h2 id="amdahl-">Amdahl定律</h2>
<p>并行的任务增加资源显然能够提高性能，但是如果是串行的任务，增加资源并不一定能够得到合理的性能提升。 <a href="http://en.wikipedia.org/wiki/Amdahl%27s_law" target="_blank">Amdahl定律</a>描述的在一个系统中，增加处理器资源对系统行的提升比率。 假定在一个系统中，F是必须串行化执行的比重，N是处理器资源，那么随着N的增加最多增加的加速比：
<img src="" alt=""></p>
<p>理论上，当N趋近于无穷大时，加速比最大值无限趋近于1/F。 这意味着如果一个程序的串行化比重为50%，那么并行化后最大加速比为2倍。</p>
<p>加速比除了可以用于加速的比率外，也可以用于衡量CPU资源的利用率。如果每一个CPU的资源利用率为100%，那么CPU的资源每次翻倍时，加速比也应该翻倍。 事实上，在拥有10个处理器的系统中，程序如果有10%是串行化的，那么最多可以加速1/(0.1+(1-0.1)/10)=5.3倍，换句话说CPU的利用率只用5.3/10=53%。而如果处理器增加到100倍，那么加速比为9.2倍，也就是说CPU的利用率只有个9.3%。</p>
<p>显然增加CPU的数量并不能提高CPU的利用率。下图描述的是随着CPU的数量增加，不同串行化比重的系统的加速比。
<img src="" alt=""></p>
<p>很显然，串行比重越大，增加CPU资源的效果越不明显。</p>
<h2 id="-">性能提升</h2>
<p>性能的提升可以从以下几个方面入手。</p>
<h3 id="-">系统平台的资源利用率</h3>
<p>一个程序对系统平台的资源利用率是指某一个设备繁忙且服务于此程序的时间占所有时间的比率。从物理学的角度讲类似于有用功的比率。简单的说就是：资源利用率=有效繁忙时间/总耗费时间。</p>
<p>也就说尽可能的让设备做有用的功，同时榨取其最大值。无用的循环可能会导致CPU 100%的使用率，但不一定是有效的工作。有效性通常难以衡量，通常只能以主观来评估，或者通过被优化的程序的行为来判断是否提高了有效性。</p>
<h3 id="-">延迟</h3>
<p>延迟描述的是完成任务所耗费的时间。延迟有时候也成为响应时间。如果有多个并行的操作，那么延迟取决于耗费时间最大的任务。</p>
<h3 id="-">多处理</h3>
<p>多处理是指在单一系统上同时执行多个进程或者多个程序的能力。多处理能力的好处是可以提高吞吐量。多处理可以有效利用多核CPU的资源。</p>
<h3 id="-">多线程</h3>
<p>多线程描述的是同一个地址空间内同时执行多个线程的过程。这些线程都有不同的执行路径和不同的栈结构。我们说的并发性更多的是指针对线程。</p>
<h3 id="-">并发性</h3>
<p>同时执行多个程序或者任务称之为并发。单程序内的多任务处理或者多程序间的多任务处理都认为是并发。</p>
<h3 id="-">吞吐量</h3>
<p>吞吐量衡量系统在单位之间内可以完成的工作总量。对于硬件系统而言，吞吐量是物理介质的上限。在没有达到物理介质之前，提高系统的吞吐量也可以大幅度改进性能。同时吞吐量也是衡量性能的一个指标。</p>
<h3 id="-">瓶颈</h3>
<p>程序运行过程中性能最差的地方。通常而言，串行的IO、磁盘IO、内存单元分配、网络IO等都可能造成瓶颈。某些使用太频繁的算法也有可能成为瓶颈。</p>
<h3 id="-">可扩展性</h3>
<p>这里的可扩展性主要是指程序或系统通过增加可使用的资源而增加性能的能力。</p>
<h2 id="-">线程开销</h2>
<p>假设引入的多线程都用于计算，那么性能一定会有很大的提升么？ 其实引入多线程以后也会引入更多的开销。</p>
<h3 id="-">切换上下文</h3>
<p>如果可运行的线程数大于CPU的内核数，那么OS会根据一定的调度算法，强行切换正在运行的线程，从而使其它线程能够使用CPU周期。</p>
<p>切换线程会导致上下文切换。线程的调度会导致CPU需要在操作系统和进程间花费更多的时间片段，这样真正执行应用程序的时间就减少了。另外上下文切换也会导致缓存的频繁进出，对于一个刚被切换的线程来说，可能由于高速缓冲中没有数据而变得更慢，从而导致更多的IO开销。</p>
<h3 id="-">内存同步</h3>
<p>不同线程间要进行数据同步，synchronized以及volatile提供的可见性都会导致缓存失效。线程栈之间的数据要和主存进行同步，这些同步有一些小小的开销。如果线程间同时要进行数据同步，那么这些同步的线程可能都会受阻。</p>
<h3 id="-">阻塞</h3>
<p>当发生锁竞争时，失败的线程会导致阻塞。通常阻塞的线程可能在JVM内部进行自旋等待，或者被操作系统挂起。自旋等待可能会导致更多的CPU切片浪费，而操作系统挂起则会导致更多的上下文切换。</p>
<p>了解了性能的提升的几个方面，也了解性能的开销后，应用程序就要根据实际的场景进行取舍和评估。没有一劳永逸的优化方案，不断的进行小范围改进和调整是提高性能的有效手段。当前一些大的架构调整也会导致较大的性能的提升。</p>
<p>简单的原则是在保证逻辑正确的情况小，找到性能瓶颈，小步改进和优化。</p>
<h2 id="-">参考资料</h2>
<ul>
<li>Amdahl&#39;s law: <a href="http://en.wikipedia.org/wiki/Amdahl%27s_law" target="_blank"><a href="http://en.wikipedia.org/wiki/Amdahl%27s_law">http://en.wikipedia.org/wiki/Amdahl%27s_law</a></a></li>
<li>Gustafson&#39;s law: <a href="http://en.wikipedia.org/wiki/Gustafson%27s_law" target="_blank"><a href="http://en.wikipedia.org/wiki/Gustafson%27s_law">http://en.wikipedia.org/wiki/Gustafson%27s_law</a></a></li>
<li>Sun-Ni law: <a href="http://en.wikipedia.org/wiki/Sun-Ni_law" target="_blank"><a href="http://en.wikipedia.org/wiki/Sun-Ni_law">http://en.wikipedia.org/wiki/Sun-Ni_law</a></a></li>
<li>多核系统中三种典型锁竞争的加速比分析 <a href="http://blog.csdn.net/drzhouweiming/article/details/1800319" target="_blank"><a href="http://blog.csdn.net/drzhouweiming/article/details/1800319">http://blog.csdn.net/drzhouweiming/article/details/1800319</a></a></li>
<li>阿姆达尔定律和Gustafson定律的等价性 <a href="http://book.51cto.com/art/201004/197506.htm" target="_blank"><a href="http://book.51cto.com/art/201004/197506.htm">http://book.51cto.com/art/201004/197506.htm</a></a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/12/31/367641.html](http://www.blogjava.net/xylz/archive/2011/12/31/367641.html)">[http://www.blogjava.net/xylz/archive/2011/12/31/367641.html](http://www.blogjava.net/xylz/archive/2011/12/31/367641.html)</a> </li>
</ul>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency37-并发总结/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency37-并发总结" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency3-锁机制/">深入浅出 Java Concurrency (3)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency3-锁机制/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-3-">深入浅出 Java Concurrency (3): 锁机制</h1>
<p>前面的章节主要谈谈原子操作，至于与原子操作一些相关的问题或者说陷阱就放到最后的总结篇来整体说明。从这一章开始花少量的篇幅谈谈锁机制。</p>
<p><a href="http://www.blogjava.net/xylz/archive/2010/07/04/325206.html" target="_blank">上一个章节</a>中谈到了锁机制，并且针对于原子操作谈了一些相关的概念和设计思想。接下来的文章中，尽可能的深入研究锁机制，并且理解里面的原理和实际应用场合。</p>
<p>尽管synchronized在语法上已经足够简单了，在JDK 5之前只能借助此实现，但是由于是独占锁，性能却不高，因此JDK 5以后就开始借助于JNI来完成更高级的锁实现。</p>
<p>JDK 5中的锁是接口<strong>java.util.concurrent.locks.Lock</strong>。另外<strong>java.util.concurrent.locks.ReadWriteLock</strong>提供了一对可供读写并发的锁。根据前面的规则，我们从<strong>java.util.concurrent.locks.Lock</strong>的API开始。</p>
<p><strong>void lock();</strong></p>
<p>获取锁。</p>
<p>如果锁不可用，出于线程调度目的，将禁用当前线程，并且在获得锁之前，该线程将一直处于休眠状态。</p>
<p><strong>void lockInterruptibly() throws InterruptedException;</strong></p>
<p>如果当前线程未被中断，则获取锁。</p>
<p>如果锁可用，则获取锁，并立即返回。</p>
<p>如果锁不可用，出于线程调度目的，将禁用当前线程，并且在发生以下两种情况之一以前，该线程将一直处于休眠状态：</p>
<ul>
<li>锁由当前线程获得；或者</li>
<li>其他某个线程<a href="http://www.blogjava.net/xylz/java/lang/Thread.html#interrupt(" target="_blank">中断</a>)当前线程，并且支持对锁获取的中断。</li>
</ul>
<p>如果当前线程：</p>
<ul>
<li>在进入此方法时已经设置了该线程的中断状态；或者</li>
<li>在获取锁时被<a href="http://www.blogjava.net/xylz/java/lang/Thread.html#interrupt(" target="_blank">中断</a>)，并且支持对锁获取的中断，
则将抛出 </li>
</ul>
<p>InterruptedException
，并清除当前线程的已中断状态。</p>
<p><strong>Condition newCondition();</strong></p>
<p>返回绑定到此 </p>
<p>Lock
 实例的新 </p>
<p>Condition
 实例。下一小节中会重点谈Condition，此处不做过多的介绍。</p>
<p><strong>boolean tryLock();</strong></p>
<p>仅在调用时锁为空闲状态才获取该锁。</p>
<p>如果锁可用，则获取锁，并立即返回值 </p>
<p>true
。如果锁不可用，则此方法将立即返回值 </p>
<p>false
。</p>
<p>通常对于那些不是必须获取锁的操作可能有用。</p>
<p><strong>boolean tryLock(long time, TimeUnit unit) throws InterruptedException;</strong></p>
<p>如果锁在给定的等待时间内空闲，并且当前线程未被中断，则获取锁。</p>
<p>如果锁可用，则此方法将立即返回值 </p>
<p>true
。如果锁不可用，出于线程调度目的，将禁用当前线程，并且在发生以下三种情况之一前，该线程将一直处于休眠状态：</p>
<ul>
<li>锁由当前线程获得；或者</li>
<li>其他某个线程中断当前线程，并且支持对锁获取的中断；或者</li>
<li>已超过指定的等待时间</li>
</ul>
<p>如果获得了锁，则返回值 </p>
<p>true
。</p>
<p>如果当前线程：</p>
<ul>
<li>在进入此方法时已经设置了该线程的中断状态；或者</li>
<li>在获取锁时被中断，并且支持对锁获取的中断，
则将抛出 </li>
</ul>
<p>InterruptedException
，并会清除当前线程的已中断状态。</p>
<p>如果超过了指定的等待时间，则将返回值 </p>
<p>false
。如果 time 小于等于 0，该方法将完全不等待。</p>
<p><strong>void unlock();</strong></p>
<p>释放锁。对应于lock()、tryLock()、tryLock(xx)、lockInterruptibly()等操作，如果成功的话应该对应着一个unlock()，这样可以避免死锁或者资源浪费。</p>
<p>相对于比较空洞的API，来看一个实际的例子。下面的代码实现了一个类似于AtomicInteger的操作。
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;</p>
<p>public class AtomicIntegerWithLock {</p>
<pre><code>private int value;

private Lock lock = new ReentrantLock();

public AtomicIntegerWithLock() {
    super();
}

public AtomicIntegerWithLock(int value) {
    this.value = value;
}

public final int get() {
    lock.lock();
    try {
        return value;
    } finally {
        lock.unlock();
    }
}

public final void set(int newValue) {
    lock.lock();
    try {
        value = newValue;
    } finally {
        lock.unlock();
    }

}

public final int getAndSet(int newValue) {
    lock.lock();
    try {
        int ret = value;
        value = newValue;
        return ret;
    } finally {
        lock.unlock();
    }
}

public final boolean compareAndSet(int expect, int update) {
    lock.lock();
    try {
        if (value == expect) {
            value = update;
            return true;
        }
        return false;
    } finally {
        lock.unlock();
    }
}

public final int getAndIncrement() {
    lock.lock();
    try {
        return value++;
    } finally {
        lock.unlock();
    }
}

public final int getAndDecrement() {
    lock.lock();
    try {
        return value--;
    } finally {
        lock.unlock();
    }
}

public final int incrementAndGet() {
    lock.lock();
    try {
        return ++value;
    } finally {
        lock.unlock();
    }
}

public final int decrementAndGet() {
    lock.lock();
    try {
        return --value;
    } finally {
        lock.unlock();
    }
}

public String toString() {
    return Integer.toString(get());
}
</code></pre><p>}</p>
<p>类<strong>AtomicIntegerWithLock</strong>是线程安全的，此结构中大量使用了Lock对象的lock/unlock方法对。同样可以看到的是对于自增和自减操作使用了++/--。之所以能够保证线程安全，是因为Lock对象的lock()方法保证了只有一个线程能够只有此锁。需要说明的是对于任何一个lock()方法，都需要一个unlock()方法与之对于，通常情况下为了保证unlock方法总是能够得到执行，unlock方法被置于finally块中。另外这里使用了<strong>java.util.concurrent.locks.ReentrantLock.ReentrantLock</strong>对象，下一个小节中会具体描述此类作为Lock的唯一实现是如何设计和实现的。</p>
<p>尽管synchronized实现Lock的相同语义，并且在语法上比Lock要简单多，但是前者却比后者的开销要大得多。做一个简单的测试。
public static void main(String[] args) throws Exception{
     final int max = 10;
     final int loopCount = 100000;
     long costTime = 0;
     for (int m = 0; m &lt; max; m++) {
         long start1 = System.nanoTime();
         final AtomicIntegerWithLock value1 = new AtomicIntegerWithLock(0);
         Thread[] ts = new Thread[max];
         for(int i=0;i&lt;max;i++) {
             ts[i] = new Thread() {
                 public void run() {
                     for (int i = 0; i &lt; loopCount; i++) {
                         value1.incrementAndGet();
                     }
                 }
             };
         }
         for(Thread t:ts) {
             t.start();
         }
         for(Thread t:ts) {
             t.join();
         }
         long end1 = System.nanoTime();
         costTime += (end1-start1);
     }
     System.out.println(&quot;cost1: &quot; + (costTime));
     //
     System.out.println();
     costTime = 0;
     //
     final Object lock = new Object();
     for (int m = 0; m &lt; max; m++) {
         staticValue=0;
         long start1 = System.nanoTime();
         Thread[] ts = new Thread[max];
         for(int i=0;i&lt;max;i++) {
             ts[i] = new Thread() {
                 public void run() {
                     for (int i = 0; i &lt; loopCount; i++) {
                         synchronized(lock) {
                             ++staticValue;
                         }
                     }
                 }
             };
         }
         for(Thread t:ts) {
             t.start();
         }
         for(Thread t:ts) {
             t.join();
         }
         long end1 = System.nanoTime();
         costTime += (end1-start1);
     }
     //
     System.out.println(&quot;cost2: &quot; + (costTime));
}</p>
<p>static int staticValue = 0;</p>
<p>在这个例子中每次启动10个线程，每个线程计算100000次自增操作，重复测试10次，下面是某此测试的结果：</p>
<p>cost1: 624071136</p>
<p>cost2: 2057847833</p>
<p>尽管上面的例子不是非常正式的测试案例，但上面的例子在于说明，Lock的性能比synchronized的要好得多。如果可以的话总是使用Lock替代synchronized是一个明智的选择。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/05/325274.html](http://www.blogjava.net/xylz/archive/2010/07/05/325274.html)">[http://www.blogjava.net/xylz/archive/2010/07/05/325274.html](http://www.blogjava.net/xylz/archive/2010/07/05/325274.html)</a> </p>
<p>在理解J.U.C原理以及锁机制之前，我们来介绍J.U.C框架最核心也是最复杂的一个基础类：<strong>java.util.concurrent.locks.AbstractQueuedSynchronizer</strong>。</p>
<p><strong>AQS</strong></p>
<p>AbstractQueuedSynchronizer，简称AQS，是J.U.C最复杂的一个类，导致绝大多数讲解并发原理或者实战的时候都不会提到此类。但是虚心的作者愿意借助自己有限的能力和精力来探讨一二（参考资源中也有一些作者做了部分的分析。）。</p>
<p>首先从理论知识开始，在了解了相关原理后会针对源码进行一些分析，最后加上一些实战来描述。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency72_93BD/image_2.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a></p>
<p>上面的继承体系中，AbstractQueuedSynchronizer是CountDownLatch/FutureTask/ReentrantLock/RenntrantReadWriteLock/Semaphore的基础，因此AbstractQueuedSynchronizer是Lock/Executor实现的前提。公平锁、不公平锁、Condition、CountDownLatch、Semaphore等放到后面的篇幅中说明。</p>
<p>完整的设计原理可以参考Doug Lea的论文 <a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf" target="_blank"><em>The java</em>.<em>util</em>.<em>concurrent Synchronizer Framework</em></a> ，这里做一些简要的分析。</p>
<p>基本的思想是表现为一个同步器，支持下面两个操作：</p>
<p>获取锁：首先判断当前状态是否允许获取锁，如果是就获取锁，否则就阻塞操作或者获取失败，也就是说如果是独占锁就可能阻塞，如果是共享锁就可能失败。另外如果是阻塞线程，那么线程就需要进入阻塞队列。当状态位允许获取锁时就修改状态，并且如果进了队列就从队列中移除。
while(synchronization state does not allow acquire){</p>
<pre><code>enqueue current thread if not already queued;

possibly block current thread;
</code></pre><p>}</p>
<p>dequeue current thread if it was queued;</p>
<p>释放锁:这个过程就是修改状态位，如果有线程因为状态位阻塞的话就唤醒队列中的一个或者更多线程。</p>
<p>update synchronization state;</p>
<p>if(state may permit a blocked thread to acquire)</p>
<pre><code>unlock one or more queued threads;
</code></pre><p>要支持上面两个操作就必须有下面的条件：</p>
<ul>
<li>原子性操作同步器的状态位</li>
<li>阻塞和唤醒线程</li>
<li>一个有序的队列</li>
</ul>
<p>目标明确，要解决的问题也清晰了，那么剩下的就是解决上面三个问题。</p>
<p><strong>状态位的原子操作</strong></p>
<p>这里使用一个32位的整数来描述状态位，前面章节的原子操作的理论知识整好派上用场，在这里依然使用CAS操作来解决这个问题。事实上这里还有一个64位版本的同步器（AbstractQueuedLongSynchronizer），这里暂且不谈。</p>
<p><strong>阻塞和唤醒线程</strong></p>
<p>标准的JAVA API里面是无法挂起（阻塞）一个线程，然后在将来某个时刻再唤醒它的。JDK 1.0的API里面有Thread.suspend和Thread.resume，并且一直延续了下来。但是这些都是过时的API，而且也是不推荐的做法。</p>
<p>在JDK 5.0以后利用JNI在LockSupport类中实现了此特性。
LockSupport.park()
LockSupport.park(Object)
LockSupport.parkNanos(Object, long)
LockSupport.parkNanos(long)
LockSupport.parkUntil(Object, long)
LockSupport.parkUntil(long)
LockSupport.unpark(Thread)</p>
<p>上面的API中park()是在当前线程中调用，导致线程阻塞，带参数的Object是挂起的对象，这样监视的时候就能够知道此线程是因为什么资源而阻塞的。由于park()立即返回，所以通常情况下需要在循环中去检测竞争资源来决定是否进行下一次阻塞。park()返回的原因有三：</p>
<ul>
<li>其他某个线程调用将当前线程作为目标调用 <a href="http://www.blogjava.net/xylz/java/util/concurrent/locks/LockSupport.html#unpark(java.lang.Thread">
unpark
</a>)；</li>
<li>其他某个线程<a href="http://www.blogjava.net/xylz/java/lang/Thread.html#interrupt(" target="_blank">中断</a>)当前线程；</li>
<li>该调用不合逻辑地（即毫无理由地）返回。</li>
</ul>
<p>其实第三条就决定了需要循环检测了，类似于通常写的while(checkCondition()){Thread.sleep(time);}类似的功能。</p>
<p><strong>有序队列</strong></p>
<p>在AQS中采用CHL列表来解决有序的队列的问题。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/WindowsLiveWriter/JavaConcurrency72_93BD/image_6.png" target="_blank"><img src="&quot;image&quot;" alt="image"></a>AQS采用的CHL模型采用下面的算法完成FIFO的入队列和出队列过程。</p>
<p>对于入队列(<em>enqueue)：</em>采用CAS操作，每次比较尾结点是否一致，然后插入的到尾结点中。
do {</p>
<pre><code>    pred = tail;
</code></pre><p>}while ( !compareAndSet(pred,tail,node) );</p>
<p>对于出队列(<em>dequeue</em>):由于每一个节点也缓存了一个状态，决定是否出队列，因此当不满足条件时就需要自旋等待，一旦满足条件就将头结点设置为下一个节点。</p>
<p>while (pred.status != RELEASED) ;</p>
<p>head  = node;</p>
<p>实际上这里自旋等待也是使用LockSupport.park()来实现的。</p>
<p>AQS里面有三个核心字段：
private volatile int state;</p>
<p>private transient volatile Node head;</p>
<p>private transient volatile Node tail;</p>
<p>其中state描述的有多少个线程取得了锁，对于互斥锁来说state&lt;=1。head/tail加上CAS操作就构成了一个CHL的FIFO队列。下面是Node节点的属性。</p>
<p><strong><em>volatile int waitStatus;</em></strong> 节点的等待状态，一个节点可能位于以下几种状态：</p>
<ul>
<li>CANCELLED = 1： 节点操作因为超时或者对应的线程被interrupt。节点不应该留在此状态，一旦达到此状态将从CHL队列中踢出。</li>
<li>SIGNAL = -1： 节点的继任节点是（或者将要成为）BLOCKED状态（例如通过LockSupport.park()操作），因此一个节点一旦被释放（解锁）或者取消就需要唤醒（LockSupport.unpack()）它的继任节点。</li>
<li>CONDITION = -2：表明节点对应的线程因为不满足一个条件（Condition）而被阻塞。</li>
<li>0： 正常状态，新生的非CONDITION节点都是此状态。</li>
<li>非负值标识节点不需要被通知（唤醒）。</li>
</ul>
<p><strong><em>volatile Node prev;</em></strong>此节点的前一个节点。节点的waitStatus依赖于前一个节点的状态。</p>
<p><strong><em>volatile Node next;</em></strong>此节点的后一个节点。后一个节点是否被唤醒（uppark()）依赖于当前节点是否被释放。</p>
<p><strong><em>volatile Thread thread;</em></strong>节点绑定的线程。</p>
<p><strong><em>Node nextWaiter;</em></strong>下一个等待条件（Condition）的节点，由于Condition是独占模式，因此这里有一个简单的队列来描述Condition上的线程节点。</p>
<p><strong>AQS 在J.U.C里面是一个非常核心的工具，而且也非常复杂，里面考虑到了非常多的逻辑实现，所以在后面的章节中总是不断的尝试介绍AQS的特性和实现。</strong></p>
<p>这一个小节主要介绍了一些理论背景和相关的数据结构，在下一个小节中将根据以上知识来了解Lock.lock/unlock是如何实现的。</p>
<p>参考资料：</p>
<p>（1）<a href="http://www.cnblogs.com/MichaelPeng/archive/2010/02/12/1667947.html" target="_blank">ReentrantLock代码剖析之ReentrantLock.lock</a> <a href="http://www.cnblogs.com/MichaelPeng/archive/2010/02/17/1668986.html" target="_blank">ReentrantLock代码剖析之ReentrantLock.unlock</a> <a href="http://www.cnblogs.com/MichaelPeng/archive/2010/02/18/1669150.html" target="_blank">ReentrantLock代码剖析之ReentrantLock.lockInterruptibly</a></p>
<p>（2）<a href="http://wagtto.javaeye.com/blog/607848" target="_blank">java多线程--java.util.concurrent.locks.AbstractQueuedSynchronizer解析(只包含多线程同步示例)</a></p>
<p>（3）<a href="http://www.ibm.com/developerworks/cn/java/j-jtp05236.html" target="_blank">处理 InterruptedException</a></p>
<p>（4）<a href="http://hi.baidu.com/gefforey520/blog/item/6f64eb442300a446500ffe3f.html" target="_blank">AbstractQueuedSynchronizer源码解析之ReentrantLock(一)</a>  <a href="http://hi.baidu.com/gefforey520/blog/item/ce633582511217a80df4d26c.html" target="_blank">AbstractQueuedSynchronizer源码解析之ReentrantLock(二)</a></p>
<p>（5）<a href="http://gee.cs.oswego.edu/dl/papers/aqs.pdf" target="_blank"><em>The java</em>.<em>util</em>.<em>concurrent Synchronizer Framework</em></a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/06/325390.html](http://www.blogjava.net/xylz/archive/2010/07/06/325390.html)">[http://www.blogjava.net/xylz/archive/2010/07/06/325390.html](http://www.blogjava.net/xylz/archive/2010/07/06/325390.html)</a> </p>
<p>接上篇，这篇从Lock.lock/unlock开始。特别说明在没有特殊情况下所有程序、API、文档都是基于JDK 6.0的。</p>
<p><strong>public void java.util.concurrent.locks.ReentrantLock.lock()</strong>
<em>获取锁。</em></p>
<p><em>如果该锁没有被另一个线程保持，则获取该锁并立即返回，将锁的保持计数设置为 1。</em></p>
<p><em>如果当前线程已经保持该锁，则将保持计数加 1，并且该方法立即返回。</em></p>
<p><em>如果该锁被另一个线程保持，则出于线程调度的目的，禁用当前线程，并且在获得锁之前，该线程将一直处于休眠状态，此时锁保持计数被设置为 1。</em></p>
<p>从上面的文档可以看出ReentrantLock是可重入锁的实现。而内部是委托java.util.concurrent.locks.ReentrantLock.Sync.lock()实现的。java.util.concurrent.locks.ReentrantLock.Sync是抽象类，有java.util.concurrent.locks.ReentrantLock.FairSync和java.util.concurrent.locks.ReentrantLock.NonfairSync两个实现，也就是常说的公平锁和不公平锁。</p>
<p><strong>公平锁和非公平锁</strong>
如果获取一个锁是按照请求的顺序得到的，那么就是公平锁，否则就是非公平锁。</p>
<p>在没有深入了解内部机制及实现之前，先了解下为什么会存在公平锁和非公平锁。公平锁保证一个阻塞的线程最终能够获得锁，因为是有序的，所以总是可以按照请求的顺序获得锁。不公平锁意味着后请求锁的线程可能在其前面排列的休眠线程恢复前拿到锁，这样就有可能提高并发的性能。这是因为通常情况下挂起的线程重新开始与它真正开始运行，二者之间会产生严重的延时。因此非公平锁就可以利用这段时间完成操作。这是非公平锁在某些时候比公平锁性能要好的原因之一。</p>
<p>二者在实现上的区别会在后面介绍，我们先从公平锁（FairSync）开始。</p>
<p>前面说过<strong>java.util.concurrent.locks.AbstractQueuedSynchronizer （AQS)</strong>是Lock的基础，对于一个FairSync而言，lock()就直接调用AQS的acquire(int arg);
<strong>public final void acquire(int arg)</strong> <em>以独占模式获取对象，忽略中断。通过至少调用一次 </em><a href="http://www.blogjava.net/xylz/java/util/concurrent/locks/AbstractQueuedSynchronizer.html#tryAcquire(int">
<em>tryAcquire(int)</em>
</a>)<em> 来实现此方法，并在成功时返回。否则在成功之前，一直调用 </em><a href="http://www.blogjava.net/xylz/java/util/concurrent/locks/AbstractQueuedSynchronizer.html#tryAcquire(int">
<em>tryAcquire(int)</em>
</a>)<em> 将线程加入队列，线程可能重复被阻塞或不被阻塞。</em></p>
<p>在介绍实现之前先要补充上一节的知识，对于一个AQS的实现而言，通常情况下需要实现以下方法来描述如何锁定线程。</p>
<ul>
<li><strong>tryAcquire(int)</strong> 
试图在独占模式下获取对象状态。此方法应该查询是否允许它在独占模式下获取对象状态，如果允许，则获取它。</li>
</ul>
<p>此方法总是由执行 acquire 的线程来调用。如果此方法报告失败，则 acquire 方法可以将线程加入队列（如果还没有将它加入队列），直到获得其他某个线程释放了该线程的信号。也就是说此方法是一种尝试性方法，如果成功获取锁那最好，如果没有成功也没有关系，直接返回false。</p>
<ul>
<li><strong>tryRelease(int)</strong> 
试图设置状态来反映独占模式下的一个释放。 此方法总是由正在执行释放的线程调用。释放锁可能失败或者抛出异常，这个在后面会具体分析。</li>
<li><strong>tryAcquireShared(int)</strong> 试图在共享模式下获取对象状态。</li>
<li><strong>tryReleaseShared(int)</strong> 试图设置状态来反映共享模式下的一个释放。</li>
<li><strong>isHeldExclusively()</strong> 如果对于当前（正调用的）线程，同步是以独占方式进行的，则返回         true    。</li>
</ul>
<p>除了tryAcquire(int)外，其它方法会在后面具体介绍。首先对于ReentrantLock而言，不管是公平锁还是非公平锁，都是独占锁，也就是说同时能够有一个线程持有锁。因此对于acquire(int arg)而言，arg==1。在AQS中acquire的实现如下：</p>
<p>public final void acquire(int arg) {
    if (!tryAcquire(arg) &amp;&amp;
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}</p>
<p>这个看起来比较复杂，我们分解以下4个步骤。</p>
<ol>
<li>如果tryAcquire(arg)成功，那就没有问题，已经拿到锁，整个lock()过程就结束了。如果失败进行操作2。</li>
<li>创建一个独占节点（Node）并且此节点加入CHL队列末尾。进行操作3。</li>
<li>自旋尝试获取锁，失败根据前一个节点来决定是否挂起（park()），直到成功获取到锁。进行操作4。</li>
<li>如果当前线程已经中断过，那么就中断当前线程（清除中断位）。</li>
</ol>
<p>这是一个比较复杂的过程，我们按部就班一个一个分析。</p>
<p><strong>tryAcquire(acquires)</strong></p>
<p>对于公平锁而言，它的实现方式如下：
    protected final boolean tryAcquire(int acquires) {
        final Thread current = Thread.currentThread();
        int c = getState();
        if (c == 0) {
            if (isFirst(current) &amp;&amp;
                compareAndSetState(0, acquires)) {
                setExclusiveOwnerThread(current);
                return true;
            }
        }
        else if (current == getExclusiveOwnerThread()) {
            int nextc = c + acquires;
            if (nextc &lt; 0)
                throw new Error(&quot;Maximum lock count exceeded&quot;);
            setState(nextc);
            return true;
        }
        return false;
    }
}</p>
<p>在这段代码中，前面说明对于AQS存在一个state来描述当前有多少线程持有锁。由于AQS支持共享锁（例如读写锁，后面会继续讲），所以这里state&gt;=0，但是由于ReentrantLock是独占锁，所以这里不妨理解为0&lt;=state，acquires=1。isFirst(current)是一个很复杂的逻辑，包括踢出无用的节点等复杂过程，这里暂且不提，大体上的意思是说判断AQS是否为空或者当前线程是否在队列头（为了区分公平与非公平锁）。</p>
<ol>
<li>如果当前锁有其它线程持有，c!=0，进行操作2。否则，如果当前线程在AQS队列头部，则尝试将AQS状态state设为acquires（等于1），成功后将AQS独占线程设为当前线程返回true，否则进行2。这里可以看到compareAndSetState就是使用了CAS操作。</li>
<li>判断当前线程与AQS的独占线程是否相同，如果相同，那么就将当前状态位加1（这里+1后结果为负数后面会讲，这里暂且不理它），修改状态位，返回true，否则进行3。这里之所以不是将当前状态位设置为1，而是修改为旧值+1呢？这是因为ReentrantLock是可重入锁，同一个线程每持有一次就+1。</li>
<li>返回false。</li>
</ol>
<p>比较非公平锁的tryAcquire实现java.util.concurrent.locks.ReentrantLock.Sync.nonfairTryAcquire(int)，公平锁多了一个判断当前节点是否在队列头，这个就保证了是否按照请求锁的顺序来决定获取锁的顺序（同一个线程的多次获取锁除外）。</p>
<p>现在再回头看公平锁和非公平锁的lock()方法。公平锁只有一句acquire(1)；而非公平锁的调用如下：
final void lock() {
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
}</p>
<p>很显然，非公平锁在第一次获取锁，或者其它线程释放锁后（可能等待），优先采用compareAndSetState(0,1)然后设置AQS独占线程而持有锁，这样有时候比acquire(1)顺序检查锁持有而要高效。即使在重入锁上，也就是compareAndSetState(0,1)失败，但是是当前线程持有锁上，非公平锁也没有问题。</p>
<p><strong>addWaiter(mode)</strong></p>
<p>tryAcquire失败就意味着入队列了。此时AQS的队列中节点Node就开始发挥作用了。一般情况下AQS支持独占锁和共享锁，而独占锁在Node中就意味着条件（Condition）队列为空（上一篇中介绍过相关概念）。在java.util.concurrent.locks.AbstractQueuedSynchronizer.Node中有两个常量，
static final Node EXCLUSIVE = null; //独占节点模式</p>
<p>static final Node SHARED = new Node(); //共享节点模式</p>
<p>addWaiter(mode)中的mode就是节点模式，也就是共享锁还是独占锁模式。</p>
<p>前面一再强调ReentrantLock是独占锁模式。
private Node addWaiter(Node mode) {
     Node node = new Node(Thread.currentThread(), mode);
     // Try the fast path of enq; backup to full enq on failure
     Node pred = tail;
     if (pred != null) {
         node.prev = pred;
         if (compareAndSetTail(pred, node)) {
             pred.next = node;
             return node;
         }
     }
     enq(node);
     return node;
}</p>
<p>上面是节点如队列的一部分。当前仅当队列不为空并且将新节点插入尾部成功后直接返回新节点。否则进入enq(Node)进行操作。</p>
<p>private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        if (t == null) { // Must initialize
            Node h = new Node(); // Dummy header
            h.next = node;
            node.prev = h;
            if (compareAndSetHead(h)) {
                tail = node;
                return h;
            }
        }
        else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}</p>
<p>enq(Node)去队列操作实现了CHL队列的算法，如果为空就创建头结点，然后同时比较节点尾部是否是改变来决定CAS操作是否成功，当且仅当成功后才将为不节点的下一个节点指向为新节点。可以看到这里仍然是CAS操作。</p>
<p><strong>acquireQueued(node,arg)</strong></p>
<p>自旋请求锁，如果可能的话挂起线程，直到得到锁，返回当前线程是否中断过（如果park()过并且中断过的话有一个interrupted中断位）。
final boolean acquireQueued(final Node node, int arg) {
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } catch (RuntimeException ex) {
        cancelAcquire(node);
        throw ex;
    }
}</p>
<p>下面的分析就需要用到上节节点的状态描述了。acquireQueued过程是这样的：</p>
<ol>
<li>如果当前节点是AQS队列的头结点（如果第一个节点是DUMP节点也就是傀儡节点，那么第二个节点实际上就是头结点了），就尝试在此获取锁tryAcquire(arg)。如果成功就将头结点设置为当前节点（不管第一个结点是否是DUMP节点），返回中断位。否则进行2。</li>
<li>检测当前节点是否应该park()，如果应该park()就挂起当前线程并且返回当前线程中断位。进行操作1。</li>
</ol>
<p>一个节点是否该park()是关键，这是由方法java.util.concurrent.locks.AbstractQueuedSynchronizer.shouldParkAfterFailedAcquire(Node, Node)实现的。
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int s = pred.waitStatus;
    if (s &lt; 0) return true;
    if (s &gt; 0) {
        do {
            node.prev = pred = pred.prev;
        } while (pred.waitStatus &gt; 0);
        pred.next = node;
    } else compareAndSetWaitStatus(pred, 0, Node.SIGNAL);
    return false;
}</p>
<ol>
<li>如果前一个节点的等待状态waitStatus&lt;0，也就是前面的节点还没有获得到锁，那么返回true，表示当前节点（线程）就应该park()了。否则进行2。</li>
<li>如果前一个节点的等待状态waitStatus&gt;0，也就是前一个节点被CANCELLED了，那么就将前一个节点去掉，递归此操作直到所有前一个节点的waitStatus&lt;=0，进行4。否则进行3。</li>
<li>前一个节点等待状态waitStatus=0，修改前一个节点状态位为SINGAL，表示后面有节点等待你处理，需要根据它的等待状态来决定是否该park()。进行4。</li>
<li>返回false，表示线程不应该park()。</li>
</ol>
<p><strong>selfInterrupt()</strong>
private static void selfInterrupt() {
    Thread.currentThread().interrupt();
}</p>
<p>如果线程曾经中断过（或者阻塞过）（比如手动interrupt()或者超时等等，那么就再中断一次，中断两次的意思就是清除中断位）。</p>
<p>大体上整个Lock.lock()就这样一个流程。除了lock()方法外，还有lockInterruptibly()/tryLock()/unlock()/newCondition()等，在接下来的章节中会一一介绍。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/07/325410.html](http://www.blogjava.net/xylz/archive/2010/07/07/325410.html)">[http://www.blogjava.net/xylz/archive/2010/07/07/325410.html](http://www.blogjava.net/xylz/archive/2010/07/07/325410.html)</a> </p>
<p>本小节介绍锁释放Lock.unlock()。</p>
<p><strong>Release/TryRelease</strong></p>
<p>unlock操作实际上就调用了<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>的release操作，释放持有的锁。
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null &amp;&amp; h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}</p>
<p>前面提到过<strong><em>tryRelease(arg)</em></strong>操作，此操作里面总是尝试去释放锁，如果成功，说明锁确实被当前线程持有，那么就看<strong>AQS</strong>队列中的头结点是否为空并且能否被唤醒，如果可以的话就唤醒继任节点（下一个非CANCELLED节点，下面会具体分析）。</p>
<p>对于独占锁而言，java.util.concurrent.locks.ReentrantLock.Sync.tryRelease(int)展示了如何尝试释放锁(<strong><em>tryRelease</em></strong>)操作。
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}</p>
<p>整个<strong><em>tryRelease</em></strong>操作是这样的：</p>
<ol>
<li>判断持有锁的线程是否是当前线程，如果不是就抛出IllegalMonitorStateExeception()，因为一个线程是不能释放另一个线程持有的锁（否则锁就失去了意义）。否则进行2。</li>
<li>将AQS状态位减少要释放的次数（对于独占锁而言总是1），如果剩余的状态位0（也就是没有线程持有锁），那么当前线程就是最后一个持有锁的线程，清空AQS持有锁的独占线程。进行3。</li>
<li>将剩余的状态位写回AQS，如果没有线程持有锁就返回true，否则就是false。</li>
</ol>
<p>参考上一节的分析就可以知道，这里c==0决定了是否完全释放了锁。由于<strong><em>ReentrantLock</em></strong>是可重入锁，因此同一个线程可能多重持有锁，那么当且仅当最后一个持有锁的线程释放锁是才能将AQS中持有锁的独占线程清空，这样接下来的操作才需要唤醒下一个需要锁的<strong>AQS</strong>节点（Node），否则就只是减少锁持有的计数器，并不能改变其他操作。</p>
<p>当<strong><em>tryRelease</em></strong>操作成功后（也就是完全释放了锁），release操作才能检查是否需要唤醒下一个继任节点。这里的前提是<strong>AQS</strong>队列的头结点需要锁(<em>waitStatus!=0</em>)，如果头结点需要锁，就开始检测下一个继任节点是否需要锁操作。</p>
<p>在上一节中说道<strong><em>acquireQueued</em></strong>操作完成后（拿到了锁），会将当前持有锁的节点设为头结点，所以一旦头结点释放锁，那么就需要寻找头结点的下一个需要锁的继任节点，并唤醒它。
private void unparkSuccessor(Node node) {
        //此时node是需要是需要释放锁的头结点</p>
<pre><code>    //清空头结点的waitStatus，也就是不再需要锁了
    compareAndSetWaitStatus(node, Node.SIGNAL, 0);

    //从头结点的下一个节点开始寻找继任节点，当且仅当继任节点的waitStatus&lt;=0才是有效继任节点，否则将这些waitStatus&gt;0（也就是CANCELLED的节点）从AQS队列中剔除  
   //这里并没有从head-&gt;tail开始寻找，而是从tail-&gt;head寻找最后一个有效节点。
   //解释在这里 http://www.blogjava.net/xylz/archive/2010/07/08/325540.html/#377512

    Node s = node.next;
    if (s == null || s.waitStatus &gt; 0) {
        s = null;
        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)
            if (t.waitStatus &lt;= 0)
                s = t;
    }

    //如果找到一个有效的继任节点，就唤醒此节点线程
    if (s != null)
        LockSupport.unpark(s.thread);
}
</code></pre><p>这里再一次把<strong><em>acquireQueued</em></strong>的过程找出来。对比<strong><em>unparkSuccessor</em></strong>，一旦头节点的继任节点被唤醒，那么继任节点就会尝试去获取锁（在<strong><em>acquireQueued</em></strong>中node就是有效的继任节点，p就是唤醒它的头结点），如果成功就会将头结点设置为自身，并且将头结点的前任节点清空，这样前任节点（已经过时了）就可以被GC释放了。</p>
<p>final boolean acquireQueued(final Node node, int arg) {
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head &amp;&amp; tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } catch (RuntimeException ex) {
        cancelAcquire(node);
        throw ex;
    }
}</p>
<p>在<strong><em>setHead</em></strong>中，将头结点的前任节点清空并且将头结点的线程清空就是为了更好的GC，防止内存泄露。</p>
<p>private void setHead(Node node) {
    head = node;
    node.thread = null;
    node.prev = null;
}</p>
<p>对比lock()操作，unlock()操作还是比较简单的，主要就是释放响应的资源，并且唤醒<strong>AQS</strong>队列中有效的继任节点。这样所就按照请求的顺序去尝试获取锁了。</p>
<p>整个lock()/unlock()过程完成了，我们再回头看公平锁(FairSync)和非公平锁(NonfairSync)。</p>
<p>公平锁和非公平锁只是在获取锁的时候有差别，其它都是一样的。
final void lock() {
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
}</p>
<p>在上面非公平锁的代码中总是优先尝试当前是否有线程持有锁，一旦没有任何线程持有锁，那么非公平锁就霸道的尝试将锁“占为己有”。如果在抢占锁的时候失败就和公平锁一样老老实实的去排队。</p>
<p>也即是说公平锁和非公平锁只是在入<strong>AQS</strong>的<strong>CLH</strong>队列之前有所差别，一旦进入了队列，所有线程都是按照队列中先来后到的顺序请求锁。</p>
<p><strong>Condition</strong></p>
<p>条件变量很大一个程度上是为了解决Object.wait/notify/notifyAll难以使用的问题。</p>
<p>条件（也称为<em>条件队列</em> 或<em>条件变量</em>）为线程提供了一个含义，以便在某个状态条件现在可能为 true 的另一个线程通知它之前，一直挂起该线程（即让其“等待”）。因为访问此共享状态信息发生在不同的线程中，所以它必须受保护，因此要将某种形式的锁与该条件相关联。等待提供一个条件的主要属性是：<em>以原子方式</em> 释放相关的锁，并挂起当前线程，就像 </p>
<p>Object.wait
 做的那样。</p>
<p>上述API说明表明条件变量需要与锁绑定，而且多个Condition需要绑定到同一锁上。前面的<strong>Lock</strong>中提到，获取一个条件变量的方法是<strong>Lock.newCondition()</strong>。
void await() throws InterruptedException;
void awaitUninterruptibly();
long awaitNanos(long nanosTimeout) throws InterruptedException;
boolean await(long time, TimeUnit unit) throws InterruptedException;
boolean awaitUntil(Date deadline) throws InterruptedException;
void signal();
void signalAll();</p>
<p>以上是<strong>Condition</strong>接口定义的方法，<em>await/**对应于</em>Object.wait<em>，</em>signal<em>对应于</em>Object.notify<em>，</em>signalAll<em>对应于</em>Object.notifyAll<em>。特别说明的是<strong>Condition</strong>的接口改变名称就是为了避免与Object中的</em>wait/notify/notifyAll<em>的语义和使用上混淆，因为Condition同样有</em>wait/notify/notifyAll*方法。</p>
<p>每一个<strong>Lock</strong>可以有任意数据的<strong>Condition</strong>对象，<strong>Condition</strong>是与<strong>Lock</strong>绑定的，所以就有<strong>Lock</strong>的公平性特性：如果是公平锁，线程为按照FIFO的顺序从<em>Condition.await</em>中释放，如果是非公平锁，那么后续的锁竞争就不保证FIFO顺序了。</p>
<p>一个使用Condition实现生产者消费者的模型例子如下。
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;</p>
<p>public class ProductQueue<T> {</p>
<pre><code>private final T[] items;

private final Lock lock = new ReentrantLock();

private Condition notFull = lock.newCondition();

private Condition notEmpty = lock.newCondition();

//
private int head, tail, count;

public ProductQueue(int maxSize) {
    items = (T[]) new Object[maxSize];
}

public ProductQueue() {
    this(10);
}

public void put(T t) throws InterruptedException {
    lock.lock();
    try {
        while (count == getCapacity()) {
            notFull.await();
        }
        items[tail] = t;
        if (++tail == getCapacity()) {
            tail = 0;
        }
        ++count;
        notEmpty.signalAll();
    } finally {
        lock.unlock();
    }
}

public T take() throws InterruptedException {
    lock.lock();
    try {
        while (count == 0) {
            notEmpty.await();
        }
        T ret = items[head];
        items[head] = null;//GC
        //
        if (++head == getCapacity()) {
            head = 0;
        }
        --count;
        notFull.signalAll();
        return ret;
    } finally {
        lock.unlock();
    }
}

public int getCapacity() {
    return items.length;
}

public int size() {
    lock.lock();
    try {
        return count;
    } finally {
        lock.unlock();
    }
}
</code></pre><p>}</p>
<p>在这个例子中消费<em>take()</em>需要 队列不为空，如果为空就挂起（<em>await()</em>），直到收到<em>notEmpty</em>的信号；生产<em>put()</em>需要队列不满，如果满了就挂起（<em>await()</em>），直到收到<em>notFull</em>的信号。</p>
<p>可能有人会问题，如果一个线程<em>lock()</em>对象后被挂起还没有<em>unlock</em>，那么另外一个线程就拿不到锁了（<em>lock()</em>操作会挂起），那么就无法通知(<em>notify</em>)前一个线程，这样岂不是“死锁”了？</p>
<p><strong>await/* 操作</strong></p>
<p>上一节中说过多次<em>ReentrantLock</em>是独占锁，一个线程拿到锁后如果不释放，那么另外一个线程肯定是拿不到锁，所以在<em>lock.lock()</em>和<em>lock.unlock()</em>之间可能有一次释放锁的操作（同样也必然还有一次获取锁的操作）。我们再回头看代码，不管<em>take()</em>还是<em>put()</em>，在进入<em>lock.lock()</em>后唯一可能释放锁的操作就是<em>await()</em>了。也就是说<em>await()</em>操作实际上就是释放锁，然后挂起线程，一旦条件满足就被唤醒，再次获取锁！
public final void await() throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    Node node = addConditionWaiter();
    int savedState = fullyRelease(node);
    int interruptMode = 0;
    while (!isOnSyncQueue(node)) {
        LockSupport.park(this);
        if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
            break;
    }
    if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)
        interruptMode = REINTERRUPT;
    if (node.nextWaiter != null)
        unlinkCancelledWaiters();
    if (interruptMode != 0)
        reportInterruptAfterWait(interruptMode);
}</p>
<p>上面是<em>await()</em>的代码片段。上一节中说过，<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>在获取锁的时候需要有一个<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>CHL</strong></a>的FIFO队列，所以对于一个<em>Condition.await()</em>而言，如果释放了锁，要想再一次获取锁那么就需要进入队列，等待被通知获取锁。完整的await()操作是安装如下步骤进行的：</p>
<ol>
<li>将当前线程加入<em>Condition</em>锁队列。特别说明的是，这里不同于<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>的队列，这里进入的是<em>Condition</em>的FIFO队列。后面会具体谈到此结构。进行2。</li>
<li>释放锁。这里可以看到将锁释放了，否则别的线程就无法拿到锁而发生死锁。进行3。</li>
<li>自旋(while)挂起，直到被唤醒或者超时或者CACELLED等。进行4。</li>
<li>获取锁(<em>acquireQueued</em>)。并将自己从<em>Condition</em>的FIFO队列中释放，表明自己不再需要锁（我已经拿到锁了）。</li>
</ol>
<p>这里再回头介绍<em>Condition</em>的数据结构。我们知道一个<em>Condition</em>可以在多个地方被<em>await/</em>()<em>，那么就需要一个FIFO的结构将这些</em>Condition<em>串联起来，然后根据需要唤醒一个或者多个（通常是所有）。所以在</em>Condition*内部就需要一个FIFO的队列。
private transient Node firstWaiter;
private transient Node lastWaiter;</p>
<p>上面的两个节点就是描述一个FIFO的队列。我们再结合<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">前面</a>提到的<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">节点（Node）数据结构</a>。我们就发现<em>Node.nextWaiter</em>就派上用场了！<em>nextWaiter</em>就是将一系列的<em>Condition.await/*</em>串联起来组成一个FIFO的队列。</p>
<p><strong>signal/signalAll 操作</strong></p>
<p><em>await/</em>()<em>清楚了，现在再来看</em>signal/signalAll<em>就容易多了。按照</em>signal/signalAll<em>的需求，就是要将</em>Condition.await/<em>()</em>中FIFO队列中第一个<strong>Node</strong>唤醒（或者全部<strong>Node</strong>）唤醒。尽管所有<strong>Node</strong>可能都被唤醒，但是要知道的是仍然只有一个线程能够拿到锁，其它没有拿到锁的线程仍然需要自旋等待，就上上面提到的第4步(acquireQueued)。
private void doSignal(Node first) {
    do {
        if ( (firstWaiter = first.nextWaiter) == null)
            lastWaiter = null;
        first.nextWaiter = null;
    } while (!transferForSignal(first) &amp;&amp;
             (first = firstWaiter) != null);
}</p>
<p>private void doSignalAll(Node first) {
    lastWaiter = firstWaiter  = null;
    do {
        Node next = first.nextWaiter;
        first.nextWaiter = null;
        transferForSignal(first);
        first = next;
    } while (first != null);
}</p>
<p>上面的代码很容易看出来，<em>signal</em>就是唤醒<strong>Condition</strong>队列中的第一个非CANCELLED节点线程，而signalAll就是唤醒所有非CANCELLED节点线程。当然了遇到CANCELLED线程就需要将其从FIFO队列中剔除。</p>
<p>final boolean transferForSignal(Node node) {
    if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
        return false;</p>
<pre><code>Node p = enq(node);
int c = p.waitStatus;
if (c &gt; 0 || !compareAndSetWaitStatus(p, c, Node.SIGNAL))
    LockSupport.unpark(node.thread);
return true;
</code></pre><p>}</p>
<p>上面就是唤醒一个<em>await/</em>()<em>线程的过程，根据前面的小节介绍的，如果要</em>unpark<em>线程，并使线程拿到锁，那么就需要线程节点进入<strong>AQS</strong>的队列。所以可以看到在</em>LockSupport.unpark<em>之前调用了</em>enq(node)<em>操作，将当前节点加入到<em>*AQS</em></em>队列。</p>
<p>整个锁机制的原理就介绍完了，从下一节开始就进入了锁机制的应用了。</p>
<p>此小节介绍几个与锁有关的有用工具。</p>
<p><strong>闭锁（Latch）</strong></p>
<p>闭锁（Latch）：一种同步方法，可以延迟线程的进度直到线程到达某个终点状态。通俗的讲就是，一个闭锁相当于一扇大门，在大门打开之前所有线程都被阻断，一旦大门打开所有线程都将通过，但是一旦大门打开，所有线程都通过了，那么这个闭锁的状态就失效了，门的状态也就不能变了，只能是打开状态。也就是说闭锁的状态是一次性的，它确保在闭锁打开之前所有特定的活动都需要在闭锁打开之后才能完成。</p>
<p><strong>CountDownLatch</strong>是JDK 5+里面闭锁的一个实现，允许一个或者多个线程等待某个事件的发生。<strong>CountDownLatch</strong>有一个正数计数器，<em>countDown</em>方法对计数器做减操作，<em>await</em>方法等待计数器达到0。所有<em>await</em>的线程都会阻塞直到计数器为0或者等待线程中断或者超时。</p>
<p><strong>CountDownLatch</strong>的API如下。</p>
<ul>
<li>public void await() throws InterruptedException</li>
<li>public boolean await(long timeout, TimeUnit unit) throws InterruptedException</li>
<li>public void countDown()</li>
<li>public long getCount()</li>
</ul>
<p>其中<em>getCount()</em>描述的是当前计数，通常用于调试目的。</p>
<p>下面的例子中描述了闭锁的两种常见的用法。
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.CountDownLatch;</p>
<p>public class PerformanceTestTool {</p>
<pre><code>public long timecost(final int times, final Runnable task) throws InterruptedException {
    if (times &lt;= 0) throw new IllegalArgumentException();
    final CountDownLatch startLatch = new CountDownLatch(1);
    final CountDownLatch overLatch = new CountDownLatch(times);
    for (int i = 0; i &lt; times; i++) {
        new Thread(new Runnable() {
            public void run() {
                try {
                    startLatch.await();
                    //
                    task.run();
                } catch (InterruptedException ex) {
                    Thread.currentThread().interrupt();
                } finally {
                    overLatch.countDown();
                }
            }
        }).start();
    }
    //
    long start = System.nanoTime();
    startLatch.countDown();
    overLatch.await();
    return System.nanoTime() - start;
}
</code></pre><p>}</p>
<p>在上面的例子中使用了两个闭锁，第一个闭锁确保在所有线程开始执行任务前，所有准备工作都已经完成，一旦准备工作完成了就调用<em>startLatch.countDown()</em>打开闭锁，所有线程开始执行。第二个闭锁在于确保所有任务执行完成后主线程才能继续进行，这样保证了主线程等待所有任务线程执行完成后才能得到需要的结果。在第二个闭锁当中，初始化了一个N次的计数器，每个任务执行完成后都会将计数器减一，所有任务完成后计数器就变为了0，这样主线程闭锁overLatch拿到此信号后就可以继续往下执行了。</p>
<p>根据前面的<a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">happend-before法则</a>可以知道闭锁有以下特性：
**内存一致性效果：线程中调用 </p>
<p>countDown()
 之前的操作 <strong><a href="http://www.blogjava.net/xylz/archive/2010/07/03/325168.html" target="_blank">happen-before</a><strong>**</strong></strong> 紧跟在从另一个线程中对应 </p>
<p>await()
 成功返回的操作。**</p>
<p>在上面的例子中第二个闭锁相当于把一个任务拆分成N份，每一份独立完成任务，主线程等待所有任务完成后才能继续执行。这个特性在后面的线程池框架中会用到，其实<strong>FutureTask</strong>就可以看成一个闭锁。后面的章节还会具体分析<strong>FutureTask</strong>的。</p>
<p>同样基于探索精神，仍然需要“窥探”下<strong>CountDownLatch</strong>里面到底是如何实现<em>await/**和</em>countDown*的。</p>
<p>首先，研究下<em>await()</em>方法。内部直接调用了<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>的<em>acquireSharedInterruptibly(1)</em>。
public final void acquireSharedInterruptibly(int arg) throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    if (tryAcquireShared(arg) &lt; 0)
        doAcquireSharedInterruptibly(arg);
}</p>
<p>前面一直提到的都是独占锁（排它锁、互斥锁），现在就用到了另外一种锁，共享锁。</p>
<p>所谓共享锁是说所有共享锁的线程共享同一个资源，一旦任意一个线程拿到共享资源，那么所有线程就都拥有的同一份资源。也就是通常情况下共享锁只是一个标志，所有线程都等待这个标识是否满足，一旦满足所有线程都被激活（相当于所有线程都拿到锁一样）。这里的闭锁<strong>CountDownLatch</strong>就是基于共享锁的实现。</p>
<p>闭锁中关于<strong>AQS</strong>的<em>tryAcquireShared</em>的实现是如下代码（<strong>java.util.concurrent.CountDownLatch.Sync.tryAcquireShared</strong>）：
public int tryAcquireShared(int acquires) {
    return getState() == 0? 1 : -1;
}</p>
<p>在这份逻辑中，对于闭锁而言第一次await时tryAcquireShared应该总是-1，因为对于闭锁<strong>CountDownLatch</strong>而言<em>state</em>的值就是初始化的<em>count</em>值。这也就解释了为什么在<em>countDown</em>调用之前闭锁的<em>count</em>总是&gt;0。</p>
<p>private void doAcquireSharedInterruptibly(int arg)
    throws InterruptedException {
    final Node node = addWaiter(Node.SHARED);
    try {
        for (;;) {
            final Node p = node.predecessor();
            if (p == head) {
                int r = tryAcquireShared(arg);
                if (r &gt;= 0) {
                    setHeadAndPropagate(node, r);
                    p.next = null; // help GC
                    return;
                }
            }
            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;
                parkAndCheckInterrupt())
                break;
        }
    } catch (RuntimeException ex) {
        cancelAcquire(node);
        throw ex;
    }
    // Arrive here only if interrupted
    cancelAcquire(node);
    throw new InterruptedException();
}</p>
<p>上面的逻辑展示了如何通过<em>await</em>将所有线程串联并挂起，直到被唤醒或者条件满足或者被中断。整个过程是这样的：</p>
<ol>
<li>将当前线程节点以共享模式加入<strong>AQS</strong>的<strong>CLH</strong>队列中（相关概念参考<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">这里</a>和<a href="http://www.blogjava.net/xylz/archive/2010/07/07/325410.html" target="_blank">这里</a>）。进行2。</li>
<li>检查当前节点的前任节点，如果是头结点并且当前闭锁计数为0就将当前节点设置为头结点，唤醒继任节点，返回（结束线程阻塞）。否则进行3。</li>
<li>检查线程是否该阻塞，如果应该就阻塞(park)，直到被唤醒（unpark）。重复2。</li>
<li>如果2、3有异常就抛出异常（结束线程阻塞）。</li>
</ol>
<p>这里有一点值得说明下，设置头结点并唤醒继任节点<em>setHeadAndPropagate</em>。由于前面<em>tryAcquireShared</em>总是返回1或者-1，而进入<em>setHeadAndPropagate</em>时总是<em>propagate&gt;=0</em>，所以这里<em>propagate==1</em>。后面唤醒继任节点操作就非常熟悉了。
private void setHeadAndPropagate(Node node, int propagate) {
    setHead(node);
    if (propagate &gt; 0 &amp;&amp; node.waitStatus != 0) {
        Node s = node.next;
        if (s == null || s.isShared())
            unparkSuccessor(node);
    }
}</p>
<p>从上面的所有逻辑可以看出<em>countDown</em>应该就是在条件满足（计数为0）时唤醒头结点（时间最长的一个节点），然后头结点就会根据FIFO队列唤醒整个节点列表（如果有的话）。</p>
<p>从<strong>CountDownLatch</strong>的<em>countDown</em>代码中看到，直接调用的是<strong>AQS</strong>的<em>releaseShared(1)</em>，参考前面的知识，这就印证了上面的说法。</p>
<p><strong><em>tryReleaseShared</em></strong>中正是采用CAS操作减少计数（每次减-1）。
public boolean tryReleaseShared(int releases) {
    for (;;) {
        int c = getState();
        if (c == 0)
            return false;
        int nextc = c-1;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}</p>
<p>整个<strong>CountDownLatch</strong>就是这个样子的。其实有了前面原子操作和<strong>AQS</strong>的原理及实现，分析<strong>CountDownLatch</strong>还是比较容易的。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/09/325612.html](http://www.blogjava.net/xylz/archive/2010/07/09/325612.html)">[http://www.blogjava.net/xylz/archive/2010/07/09/325612.html](http://www.blogjava.net/xylz/archive/2010/07/09/325612.html)</a> </p>
<p>如果说<a href="http://www.blogjava.net/xylz/archive/2010/07/09/325612.html" target="_blank">CountDownLatch</a>是一次性的，那么<strong>CyclicBarrier</strong>正好可以循环使用。它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。所谓屏障点就是一组任务执行完毕的时刻。</p>
<p><strong><em>清单1 一个使用CyclicBarrier的例子</em></strong>
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.BrokenBarrierException;
import java.util.concurrent.CyclicBarrier;</p>
<p>public class CyclicBarrierDemo {</p>
<pre><code>final CyclicBarrier barrier;

final int MAX_TASK;

public CyclicBarrierDemo(int cnt) {
    barrier = new CyclicBarrier(cnt + 1);
    MAX_TASK = cnt;
}

public void doWork(final Runnable work) {
    new Thread() {

        public void run() {
            work.run();
            try {
                int index = barrier.await();
                doWithIndex(index);
            } catch (InterruptedException e) {
                return;
            } catch (BrokenBarrierException e) {
                return;
            }
        }
    }.start();
}

private void doWithIndex(int index) {
    if (index == MAX_TASK / 3) {
        System.out.println(&quot;Left 30%.&quot;);
    } else if (index == MAX_TASK / 2) {
        System.out.println(&quot;Left 50%&quot;);
    } else if (index == 0) {
        System.out.println(&quot;run over&quot;);
    }
}

public void waitForNext() {
    try {
        doWithIndex(barrier.await());
    } catch (InterruptedException e) {
        return;
    } catch (BrokenBarrierException e) {
        return;
    }
}

public static void main(String[] args) {
    final int count = 10;
    CyclicBarrierDemo demo = new CyclicBarrierDemo(count);
    for (int i = 0; i &lt; 100; i++) {
        demo.doWork(new Runnable() {

            public void run() {
                //do something
                try {
                    Thread.sleep(1000L);
                } catch (Exception e) {
                    return;
                }
            }
        });
        if ((i + 1) % count == 0) {
            demo.waitForNext();
        }
    }
}
</code></pre><p>}</p>
<p>清单1描述的是一个周期性处理任务的例子，在这个例子中有一对的任务（100个），希望每10个为一组进行处理，当前仅当上一组任务处理完成后才能进行下一组，另外在每一组任务中，当任务剩下50%，30%以及所有任务执行完成时向观察者发出通知。</p>
<p>在这个例子中，CyclicBarrierDemo 构建了一个count+1的任务组（其中一个任务时为了外界方便挂起主线程）。每一个子任务里，人物本身执行完毕后都需要等待同组内其它任务执行完成后才能继续。同时在剩下任务50%、30%已经0时执行特殊的其他任务（发通知）。</p>
<p>很显然CyclicBarrier有以下几个特点：</p>
<ul>
<li>await()方法将挂起线程，直到同组的其它线程执行完毕才能继续</li>
<li>await()方法返回线程执行完毕的索引，注意，索引时从任务数-1开始的，也就是第一个执行完成的任务索引为parties-1,最后一个为0，这个parties为总任务数，清单中是cnt+1</li>
<li>CyclicBarrier 是可循环的，显然名称说明了这点。在清单1中，每一组任务执行完毕就能够执行下一组任务。</li>
</ul>
<p>另外除了CyclicBarrier除了以上特点外，还有以下几个特点：</p>
<ul>
<li>如果屏障操作不依赖于挂起的线程，那么任何线程都可以执行屏障操作。在清单1中可以看到并没有指定那个线程执行50%、30%、0%的操作，而是一组线程（cnt+1）个中任何一个线程只要到达了屏障点都可以执行相应的操作</li>
<li>CyclicBarrier 的构造函数允许携带一个任务，这个任务将在0%屏障点执行，它将在await()==0后执行。</li>
<li>CyclicBarrier 如果在await时因为中断、失败、超时等原因提前离开了屏障点，那么任务组中的其他任务将立即被中断，以InterruptedException异常离开线程。</li>
<li>所有await()之前的操作都将在屏障点之前运行，也就是CyclicBarrier 的内存一致性效果</li>
</ul>
<p>CyclicBarrier 的所有API如下：</p>
<ul>
<li><em>public CyclicBarrier(int parties)</em> 创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，但它不会在启动 barrier 时执行预定义的操作。</li>
<li><em>public CyclicBarrier(int parties, Runnable barrierAction)</em> 创建一个新的 CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，并在启动 barrier 时执行给定的屏障操作，该操作由最后一个进入 barrier 的线程执行。</li>
<li><em>public int await() throws InterruptedException, BrokenBarrierException</em> 在所有参与者都已经在此 barrier 上调用 await 方法之前，将一直等待。</li>
<li><em>public int await(long timeout,TimeUnit unit) throws InterruptedException, BrokenBarrierException,TimeoutException</em> 在所有参与者都已经在此屏障上调用 await 方法之前将一直等待,或者超出了指定的等待时间。</li>
<li><em>public int getNumberWaiting() </em>返回当前在屏障处等待的参与者数目。此方法主要用于调试和断言。</li>
<li><em>public int getParties()</em> 返回要求启动此 barrier 的参与者数目。</li>
<li><em>public boolean isBroken()</em> 查询此屏障是否处于损坏状态。</li>
<li><em>public void reset()</em> 将屏障重置为其初始状态。</li>
</ul>
<p>针对以上API，下面来探讨下CyclicBarrier 的实现原理，以及为什么有这样的API。</p>
<p><strong><em>清单2 CyclicBarrier.await/</em>()的实现片段*</strong>
    private int dowait(boolean timed, long nanos)
    throws InterruptedException, BrokenBarrierException,
           TimeoutException {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        final Generation g = generation;
        if (g.broken)
            throw new BrokenBarrierException();</p>
<pre><code>    if (Thread.interrupted()) {
        breakBarrier();
        throw new InterruptedException();
    }

   int index = --count;
   if (index == 0) {  // tripped
       boolean ranAction = false;
       try {
           final Runnable command = barrierCommand;
           if (command != null)
               command.run();
           ranAction = true;
           nextGeneration();
           return 0;
       } finally {
           if (!ranAction)
               breakBarrier();
       }
   }

    // loop until tripped, broken, interrupted, or timed out
    for (;;) {
        try {
            if (!timed)
                trip.await();
            else if (nanos &gt; 0L)
                nanos = trip.awaitNanos(nanos);
        } catch (InterruptedException ie) {
            if (g == generation &amp;&amp; ! g.broken) {
                breakBarrier();
                throw ie;
            } else {
                Thread.currentThread().interrupt();
            }
        }

        if (g.broken)
            throw new BrokenBarrierException();

        if (g != generation)
            return index;

        if (timed &amp;&amp; nanos &lt;= 0L) {
            breakBarrier();
            throw new TimeoutException();
        }
    }
} finally {
    lock.unlock();
}
</code></pre><p>}</p>
<p>清单2有点复杂，这里一点一点的剖析，并且还原到最原始的状态。</p>
<p>利用前面学到的知识，我们知道要想让线程等待其他线程执行完毕，那么已经执行完毕的线程（进入await/*()方法）就需要park()，直到超时或者被中断，或者被其它线程唤醒。</p>
<p>前面说过CyclicBarrier 的特点是要么大家都正常执行完毕，要么大家都异常被中断，不会其中有一个被中断而其它正常执行完毕的现象存在。这种特点叫all-or-none。类似的概念是原子操作中的要么大家都执行完，要么一个操作都不执行完。当前这其实是两个概念了。要完成这样的特点就必须有一个状态来描述曾经是否有过线程被中断（broken)了，这样后面执行完的线程就该知道是否需要继续等待了。而在CyclicBarrier 中Generation 就是为了完成这件事情的。Generation的定义非常简单，整个结构就只有一个变量<em>boolean broken = false;，</em>定义是否发生了broken操作。</p>
<p>由于有竞争资源的存在（broken/index），所以毫无疑问需要一把锁lock。拿到锁后整个过程是这样的：</p>
<ol>
<li>检查是否存在中断位(broken)，如果存在就立即以BrokenBarrierException异常返回。此异常描述的是线程进入屏障被破坏的等待状态。否则进行2。</li>
<li>检查当前线程是否被中断，如果是那么就设置中断位（使其它将要进入等待的线程知道），另外唤醒已经等待的线程，同时以InterruptedException异常返回，表示线程要处理中断。否则进行3。</li>
<li>将剩余任务数减1，如果此时剩下的任务数为0，也就是达到了公共屏障点，那么就执行屏障点任务（如果有的话），同时创建新的Generation（在这个过程中会唤醒其它所有线程，因此当前线程是屏障点线程，那么其它线程就都应该在等待状态）。否则进行4。</li>
<li>到这里说明还没有到达屏障点，那么此时线程就应该park()。很显然在下面的for循环中就是要park线程。这里park线程采用的是Condition.await()方法。也就是trip.await/<em>()。为什么需要Condition？因为所有的await/</em>()其实等待的都是一个条件，一旦条件满足就应该都被唤醒，所以Condition整好满足这个特点。所以到这里就会明白为什么在步骤3中到达屏障点时创建新的Generation的时候是一定要唤醒其它线程的原因了。</li>
</ol>
<p>上面4个步骤其实只是描述主体结构，事实上整个过程中有非常多的逻辑来处理异常引发的问题，比如执行屏障点任务引发的异常，park线程超时引发的中断异常和超时异常等等。所以对于await()而言，异常的处理比业务逻辑的处理更复杂，这就解释了为什么await()的时候可能引发<em>InterruptedException,BrokenBarrierException,TimeoutException</em> 三种异常。</p>
<p><strong><em>清单3 生成下一个循环周期并唤醒其它线程</em></strong>
private void nextGeneration() {
     trip.signalAll();
     count = parties;
     generation = new Generation();
}</p>
<p>清单3 描述了如何生成下一个循环周期的过程，在这个过程中当然需要使用Condition.signalAll()唤醒所有已经执行完成并且正在等待的线程。另外这里count描述的是还有多少线程需要执行，是为了线程执行完毕索引计数。</p>
<p>isBroken() 方法描述的就是generation.broken，也即线程组是否发生了异常。这里再一次解释下为什么要有这个状态的存在。</p>
<p>如果一个将要位于屏障点或者已经位于屏障点的而执行屏障点任务的线程发生了异常，那么即使唤醒了其它等待的线程，其它等待的线程也会因为循环等待而“死去”，因为再也没有一个线程来唤醒这些第二次进行park的线程了。还有一个意图是，如果屏障点都已经损坏了，那么其它将要等待屏障点的再线程挂起就没有意义了。
<em><a href="http://www.imxylz.info/p/336.html" target="_blank">写到这里的时候非常不幸，用了4年多了台灯终于“寿终正寝了”。</a></em></p>
<p>其实CyclicBarrier 还有一个reset方法，描述的是手动立即将所有线程中断，恢复屏障点，进行下一组任务的执行。也就是与重新创建一个新的屏障点相比，可能维护的代价要小一些（减少同步，减少上一个CyclicBarrier 的管理等等）。</p>
<p>本来是想和Semaphore 一起将的，最后发现铺开后就有点长了，而且也不利于理解和吸收，所以放到下一篇吧。</p>
<p><strong>参考资料：</strong></p>
<ol>
<li><a href="http://blog.sina.com.cn/s/blog_5ce5700e0100e44l.html" target="_blank">使用 CyclicBarrier 做线程间同步</a></li>
<li><a href="http://spring21.javaeye.com/blog/363149" target="_blank">CyclicBarrier And CountDownLatch Tutorial</a></li>
<li><a href="http://www.blogjava.net/kissyan4916/articles/307091.html" target="_blank">线程—CyclicBarrier</a></li>
<li><a href="http://www.javaeye.com/topic/657295" target="_blank">Java线程学习笔记（十）CountDownLatch 和CyclicBarrier</a></li>
<li><a href="http://www.jspcn.net/htmlnews/11500653090781610.html" target="_blank">关于多线程同步的初步教程－－Barrier的设计及使用</a></li>
<li><a href="http://tech.puredanger.com/2007/11/11/thread-coord/" target="_blank">Thread coordination with CountDownLatch and CyclicBarrier</a></li>
<li><a href="http://flysnow.javaeye.com/blog/711162" target="_blank">如何充分利用多核CPU，计算很大的List中所有整数的和</a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/12/325913.html](http://www.blogjava.net/xylz/archive/2010/07/12/325913.html)">[http://www.blogjava.net/xylz/archive/2010/07/12/325913.html](http://www.blogjava.net/xylz/archive/2010/07/12/325913.html)</a> </li>
</ol>
<p>Semaphore 是一个计数信号量。从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 </p>
<p>acquire()
，然后再获取该许可。每个 </p>
<p>release()
 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，</p>
<p>Semaphore
 只对可用许可的号码进行计数，并采取相应的行动。</p>
<p>说白了，Semaphore是一个计数器，在计数器不为0的时候对线程就放行，一旦达到0，那么所有请求资源的新线程都会被阻塞，包括增加请求到许可的线程，也就是说Semaphore不是可重入的。每一次请求一个许可都会导致计数器减少1，同样每次释放一个许可都会导致计数器增加1，一旦达到了0，新的许可请求线程将被挂起。</p>
<p>缓存池整好使用此思想来实现的，比如链接池、对象池等。</p>
<p><strong><em>清单1 对象池</em></strong>
package xylz.study.concurrency.lock;</p>
<p>import java.util.concurrent.Semaphore;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;</p>
<p>public class ObjectCache<T> {</p>
<pre><code>public interface ObjectFactory&lt;T&gt; {

    T makeObject();
}

class Node {

    T obj;

    Node next;
}

final int capacity;

final ObjectFactory&lt;T&gt; factory;

final Lock lock = new ReentrantLock();

final Semaphore semaphore;

private Node head;

private Node tail;

public ObjectCache(int capacity, ObjectFactory&lt;T&gt; factory) {
    this.capacity = capacity;
    this.factory = factory;
    this.semaphore = new Semaphore(this.capacity);
    this.head = null;
    this.tail = null;
}

public T getObject() throws InterruptedException {
    semaphore.acquire();
    return getNextObject();
}

private T getNextObject() {
    lock.lock();
    try {
        if (head == null) {
            return factory.makeObject();
        } else {
            Node ret = head;
            head = head.next;
            if (head == null) tail = null;
            ret.next = null;//help GC
            return ret.obj;
        }
    } finally {
        lock.unlock();
    }
}

private void returnObjectToPool(T t) {
    lock.lock();
    try {
        Node node = new Node();
        node.obj = t;
        if (tail == null) {
            head = tail = node;
        } else {
            tail.next = node;
            tail = node;
        }

    } finally {
        lock.unlock();
    }
}

public void returnObject(T t) {
    returnObjectToPool(t);
    semaphore.release();
}
</code></pre><p>}</p>
<p>清单1描述了一个基于信号量Semaphore的对象池实现。此对象池最多支持capacity个对象，这在构造函数中传入。对象池有一个基于FIFO的队列，每次从对象池的头结点开始取对象，如果头结点为空就直接构造一个新的对象返回。否则将头结点对象取出，并且头结点往后移动。特别要说明的如果对象的个数用完了，那么新的线程将被阻塞，直到有对象被返回回来。返还对象时将对象加入FIFO的尾节点并且释放一个空闲的信号量，表示对象池中增加一个可用对象。</p>
<p>实际上对象池、线程池的原理大致上就是这样的，只不过真正的对象池、线程池要处理比较复杂的逻辑，所以实现起来还需要做很多的工作，例如超时机制，自动回收机制，对象的有效期等等问题。</p>
<p>这里特别说明的是信号量只是在信号不够的时候挂起线程，但是并不能保证信号量足够的时候获取对象和返还对象是线程安全的，所以在清单1中仍然需要锁Lock来保证并发的正确性。</p>
<p>将信号量初始化为 1，使得它在使用时最多只有一个可用的许可，从而可用作一个相互排斥的锁。这通常也称为<em>二进制信号量</em>，因为它只能有两种状态：一个可用的许可，或零个可用的许可。按此方式使用时，二进制信号量具有某种属性（与很多 </p>
<p>Lock
 实现不同），即可以由线程释放“锁”，而不是由所有者（因为信号量没有所有权的概念）。在某些专门的上下文（如死锁恢复）中这会很有用。</p>
<p>上面这段话的意思是说当某个线程A持有信号量数为1的信号量时，其它线程只能等待此线程释放资源才能继续，这时候持有信号量的线程A就相当于持有了“锁”，其它线程的继续就需要这把锁，于是线程A的释放才能决定其它线程的运行，相当于扮演了“锁”的角色。</p>
<p>另外同公平锁非公平锁一样，信号量也有公平性。如果一个信号量是公平的表示线程在获取信号量时按FIFO的顺序得到许可，也就是按照请求的顺序得到释放。这里特别说明的是：所谓请求的顺序是指在请求信号量而进入FIFO队列的顺序，有可能某个线程先请求信号而后进去请求队列，那么次线程获取信号量的顺序就会晚于其后请求但是先进入请求队列的线程。这个在公平锁和非公平锁中谈过很多。</p>
<p>除了acquire以外，Semaphore还有几种类似的acquire方法，这些方法可以更好的处理中断和超时或者异步等特性，可以参考JDK API。</p>
<p>按照同样的学习原则，下面对主要的实现进行分析。Semaphore的acquire方法实际上访问的是<strong>AQS</strong>的<em>acquireSharedInterruptibly(arg)</em>方法。这个可以参考<a href="http://www.blogjava.net/xylz/archive/2010/07/09/325612.html" target="_blank"><strong>CountDownLatch</strong></a>一节或者<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank"><strong>AQS</strong></a>一节。</p>
<p>所以Semaphore的await实现也是比较简单的。与CountDownLatch不同的是，Semaphore区分公平信号和非公平信号。</p>
<p><strong><em>清单2 公平信号获取方法</em></strong>
protected int tryAcquireShared(int acquires) {
    Thread current = Thread.currentThread();
    for (;;) {
        Thread first = getFirstQueuedThread();
        if (first != null &amp;&amp; first != current)
            return -1;
        int available = getState();
        int remaining = available - acquires;
        if (remaining &lt; 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}</p>
<p><strong><em>清单3 非公平信号获取方法</em></strong></p>
<p>protected int tryAcquireShared(int acquires) {
    return nonfairTryAcquireShared(acquires);
}</p>
<p>final int nonfairTryAcquireShared(int acquires) {
    for (;;) {
        int available = getState();
        int remaining = available - acquires;
        if (remaining &lt; 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}</p>
<p>对比清单2和清单3可以看到，公平信号和非公平信号在于第一次尝试能否获取信号时，公平信号量总是将当前线程进入AQS的CLH队列进行排队（因为第一次尝试时队列的头结点线程很有可能不是当前线程，当然不排除同一个线程第二次进入信号量），从而根据AQS的CLH队列的顺序FIFO依次获取信号量；而对于非公平信号量，第一次立即尝试能否拿到信号量，一旦信号量的剩余数available大于请求数（acquires通常为1），那么线程就立即得到了释放，而不需要进行AQS队列进行排队。只有remaining&lt;0的时候（也就是信号量不够的时候）才会进入AQS队列。</p>
<p>所以非公平信号量的吞吐量总是要比公平信号量的吞吐量要大，但是需要强调的是非公平信号量和非公平锁一样存在“饥渴死”的现象，也就是说活跃线程可能总是拿到信号量，而非活跃线程可能难以拿到信号量。而对于公平信号量由于总是靠请求的线程的顺序来获取信号量，所以不存在此问题。</p>
<p> <strong>参考资料：</strong></p>
<ol>
<li><a href="http://blog.csdn.net/java2000_net/archive/2009/03/17/3997449.aspx" target="_blank">信号量(Semaphore)在生产者和消费者模式的使用</a></li>
<li><a href="http://stackoverflow.com/questions/771347/what-is-mutex-and-semaphore-in-java-what-is-the-main-difference" target="_blank">What is mutex and semaphore in Java ? What is the main difference ?</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/java/j-5things5.html" target="_blank">关于 java.util.concurrent 您不知道的 5 件事，第 2 部分</a></li>
<li><a href="http://tutorials.jenkov.com/java-concurrency/semaphores.html" target="_blank">Semahores</a></li>
</ol>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/13/326021.html](http://www.blogjava.net/xylz/archive/2010/07/13/326021.html)">[http://www.blogjava.net/xylz/archive/2010/07/13/326021.html](http://www.blogjava.net/xylz/archive/2010/07/13/326021.html)</a></p>
<p>从这一节开始介绍锁里面的最后一个工具：读写锁(ReadWriteLock)。</p>
<p>ReentrantLock 实现了标准的互斥操作，也就是一次只能有一个线程持有锁，也即所谓独占锁的概念。前面的章节中一直在强调这个特点。显然这个特点在一定程度上面减低了吞吐量，实际上独占锁是一种保守的锁策略，在这种情况下任何“读/读”，“写/读”，“写/写”操作都不能同时发生。但是同样需要强调的一个概念是，锁是有一定的开销的，当并发比较大的时候，锁的开销就比较客观了。所以如果可能的话就尽量少用锁，非要用锁的话就尝试看能否改造为读写锁。</p>
<p>ReadWriteLock描述的是：一个资源能够被多个读线程访问，或者被一个写线程访问，但是不能同时存在读写线程。也就是说读写锁使用的场合是一个共享资源被大量读取操作，而只有少量的写操作（修改数据）。清单1描述了ReadWriteLock的API。</p>
<p> <strong><em>清单1 ReadWriteLock 接口</em></strong>
public interface ReadWriteLock {
    Lock readLock();
    Lock writeLock();
}</p>
<p>清单1描述的ReadWriteLock结构，这里需要说明的是ReadWriteLock并不是Lock的子接口，只不过ReadWriteLock借助Lock来实现读写两个视角。在ReadWriteLock中每次读取共享数据就需要读取锁，当需要修改共享数据时就需要写入锁。看起来好像是两个锁，但其实不尽然，在下一节中的分析中会解释这点奥秘。</p>
<p>在JDK 6里面ReadWriteLock的实现是ReentrantReadWriteLock。</p>
<p><strong><em>清单2 SimpleConcurrentMap</em></strong>
package xylz.study.concurrency.lock;</p>
<p>import java.util.ArrayList;
import java.util.Collection;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReadWriteLock;
import java.util.concurrent.locks.ReentrantReadWriteLock;</p>
<p>public class SimpleConcurrentMap<K, V> implements Map<K, V> {</p>
<pre><code>final ReadWriteLock lock = new ReentrantReadWriteLock();

final Lock r = lock.readLock();

final Lock w = lock.writeLock();

final Map&lt;K, V&gt; map;

public SimpleConcurrentMap(Map&lt;K, V&gt; map) {
    this.map = map;
    if (map == null) throw new NullPointerException();
}

public void clear() {
    w.lock();
    try {
        map.clear();
    } finally {
        w.unlock();
    }
}

public boolean containsKey(Object key) {
    r.lock();
    try {
        return map.containsKey(key);
    } finally {
        r.unlock();
    }
}

public boolean containsValue(Object value) {
    r.lock();
    try {
        return map.containsValue(value);
    } finally {
        r.unlock();
    }
}

public Set&lt;java.util.Map.Entry&lt;K, V&gt;&gt; entrySet() {
    throw new UnsupportedOperationException();
}

public V get(Object key) {
    r.lock();
    try {
        return map.get(key);
    } finally {
        r.unlock();
    }
}

public boolean isEmpty() {
    r.lock();
    try {
        return map.isEmpty();
    } finally {
        r.unlock();
    }
}

public Set&lt;K&gt; keySet() {
    r.lock();
    try {
        return new HashSet&lt;K&gt;(map.keySet());
    } finally {
        r.unlock();
    }
}

public V put(K key, V value) {
    w.lock();
    try {
        return map.put(key, value);
    } finally {
        w.unlock();
    }
}

public void putAll(Map&lt;? extends K, ? extends V&gt; m) {
    w.lock();
    try {
        map.putAll(m);
    } finally {
        w.unlock();
    }
}

public V remove(Object key) {
    w.lock();
    try {
        return map.remove(key);
    } finally {
        w.unlock();
    }
}

public int size() {
    r.lock();
    try {
        return map.size();
    } finally {
        r.unlock();
    }
}

public Collection&lt;V&gt; values() {
    r.lock();
    try {
        return new ArrayList&lt;V&gt;(map.values());
    } finally {
        r.unlock();
    }
}
</code></pre><p>}</p>
<p>清单2描述的是用读写锁实现的一个线程安全的Map。其中需要特别说明的是并没有实现entrySet()方法，这是因为实现这个方法比较复杂，在后面章节中讲到ConcurrentHashMap的时候会具体谈这些细节。另外这里keySet()和values()也没有直接返回Map的视图，而是一个映射原有元素的新视图，其实这个entrySet()一样，是为了保护原始Map的数据逻辑，防止不正确的修改导致原始Map发生数据错误。特别说明的是在没有特别需求的情况下没有必要按照清单2写一个线程安全的Map实现，因为ConcurrentHashMap已经完成了此操作。</p>
<p>ReadWriteLock需要严格区分读写操作，如果读操作使用了写入锁，那么降低读操作的吞吐量，如果写操作使用了读取锁，那么就可能发生数据错误。</p>
<p>另外ReentrantReadWriteLock还有以下几个特性：</p>
<ul>
<li><p><strong>公平性</strong></p>
</li>
<li><p>非公平锁（默认） 这个和独占锁的非公平性一样，由于读线程之间没有锁竞争，所以读操作没有公平性和非公平性，写操作时，由于写操作可能立即获取到锁，所以会推迟一个或多个读操作或者写操作。因此非公平锁的吞吐量要高于公平锁。</p>
</li>
<li>公平锁 利用AQS的CLH队列，释放当前保持的锁（读锁或者写锁）时，优先为等待时间最长的那个写线程分配写入锁，当前前提是写线程的等待时间要比所有读线程的等待时间要长。同样一个线程持有写入锁或者有一个写线程已经在等待了，那么试图获取公平锁的（非重入）所有线程（包括读写线程）都将被阻塞，直到最先的写线程释放锁。如果读线程的等待时间比写线程的等待时间还有长，那么一旦上一个写线程释放锁，这一组读线程将获取锁。</li>
<li><p><strong>重入性</strong></p>
</li>
<li><p>读写锁允许读线程和写线程按照请求锁的顺序重新获取读取锁或者写入锁。当然了只有写线程释放了锁，读线程才能获取重入锁。</p>
</li>
<li>写线程获取写入锁后可以再次获取读取锁，但是读线程获取读取锁后却不能获取写入锁。</li>
<li>另外读写锁最多支持65535个递归写入锁和65535个递归读取锁。</li>
<li><p><strong>锁降级</strong></p>
</li>
<li><p>写线程获取写入锁后可以获取读取锁，然后释放写入锁，这样就从写入锁变成了读取锁，从而实现锁降级的特性。</p>
</li>
<li><p>锁升级</p>
</li>
<li><p>读取锁是不能直接升级为写入锁的。因为获取一个写入锁需要释放所有读取锁，所以如果有两个读取锁视图获取写入锁而都不释放读取锁时就会发生死锁。</p>
</li>
<li><p><strong>锁获取中断</strong></p>
</li>
<li><p>读取锁和写入锁都支持获取锁期间被中断。这个和独占锁一致。</p>
</li>
<li><p><strong>条件变量</strong></p>
</li>
<li><p>写入锁提供了条件变量(Condition)的支持，这个和独占锁一致，但是读取锁却不允许获取条件变量，将得到一个</p>
</li>
</ul>
<p>UnsupportedOperationException
异常。</p>
<ul>
<li><p><strong>重入数</strong></p>
</li>
<li><p>读取锁和写入锁的数量最大分别只能是65535（包括重入数）。这在下节中有介绍。</p>
</li>
</ul>
<p>上面几个特性对读写锁的理解很有帮助，而且也是必要的，另外在下一节中讲ReadWriteLock的实现会用到这些知识的。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/14/326080.html](http://www.blogjava.net/xylz/archive/2010/07/14/326080.html)">[http://www.blogjava.net/xylz/archive/2010/07/14/326080.html](http://www.blogjava.net/xylz/archive/2010/07/14/326080.html)</a> </p>
<p>这一节主要是谈谈读写锁的实现。</p>
<p>上一节中提到，ReadWriteLock看起来有两个锁：readLock/writeLock。如果真的是两个锁的话，它们之间又是如何相互影响的呢？</p>
<p>事实上在ReentrantReadWriteLock里锁的实现是靠java.util.concurrent.locks.ReentrantReadWriteLock.Sync完成的。这个类看起来比较眼熟，实际上它是AQS的一个子类，这中类似的结构在CountDownLatch、ReentrantLock、Semaphore里面都存在。同样它也有两种实现：公平锁和非公平锁，也就是java.util.concurrent.locks.ReentrantReadWriteLock.FairSync和java.util.concurrent.locks.ReentrantReadWriteLock.NonfairSync。这里暂且不提。</p>
<p>在ReentrantReadWriteLock里面的锁主体就是一个Sync，也就是上面提到的FairSync或者NonfairSync，所以说实际上只有一个锁，只是在获取读取锁和写入锁的方式上不一样，所以前面才有读写锁是独占锁的两个不同视图一说。</p>
<p>ReentrantReadWriteLock里面有两个类：ReadLock/WriteLock，这两个类都是Lock的实现。</p>
<p><strong><em>清单1 ReadLock 片段</em></strong>
public static class ReadLock implements Lock, java.io.Serializable  {
    private final Sync sync;</p>
<pre><code>protected ReadLock(ReentrantReadWriteLock lock) {
    sync = lock.sync;
}

public void lock() {
    sync.acquireShared(1);
}

public void lockInterruptibly() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

public  boolean tryLock() {
    return sync.tryReadLock();
}

public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireSharedNanos(1, unit.toNanos(timeout));
}

public  void unlock() {
    sync.releaseShared(1);
}

public Condition newCondition() {
    throw new UnsupportedOperationException();
}
</code></pre><p>}</p>
<p><strong><em>清单2 WriteLock 片段</em></strong></p>
<p>public static class WriteLock implements Lock, java.io.Serializable  {
    private final Sync sync;
    protected WriteLock(ReentrantReadWriteLock lock) {
        sync = lock.sync;
    }
    public void lock() {
        sync.acquire(1);
    }</p>
<pre><code>public void lockInterruptibly() throws InterruptedException {
    sync.acquireInterruptibly(1);
}

public boolean tryLock( ) {
    return sync.tryWriteLock();
}

public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
    return sync.tryAcquireNanos(1, unit.toNanos(timeout));
}

public void unlock() {
    sync.release(1);
}

public Condition newCondition() {
    return sync.newCondition();
}

public boolean isHeldByCurrentThread() {
    return sync.isHeldExclusively();
}

public int getHoldCount() {
    return sync.getWriteHoldCount();
}
</code></pre><p>}</p>
<p>清单1描述的是读锁的实现，清单2描述的是写锁的实现。显然WriteLock就是一个独占锁，这和ReentrantLock里面的实现几乎相同，都是使用了AQS的acquire/release操作。当然了在内部处理方式上与ReentrantLock还是有一点不同的。对比清单1和清单2可以看到，ReadLock获取的是共享锁，WriteLock获取的是独占锁。</p>
<p>在AQS章节中介绍到AQS中有一个state字段（int类型，32位）用来描述有多少线程获持有锁。在独占锁的时代这个值通常是0或者1（如果是重入的就是重入的次数），在共享锁的时代就是持有锁的数量。在上一节中谈到，ReadWriteLock的读、写锁是相关但是又不一致的，所以需要两个数来描述读锁（共享锁）和写锁（独占锁）的数量。显然现在一个state就不够用了。于是在ReentrantReadWrilteLock里面将这个字段一分为二，高位16位表示共享锁的数量，低位16位表示独占锁的数量（或者重入数量）。2^16-1=65536，这就是上节中提到的为什么共享锁和独占锁的数量最大只能是65535的原因了。</p>
<p>有了上面的知识后再来分析读写锁的获取和释放就容易多了。</p>
<p><strong><em>清单3 写入锁获取片段</em></strong>
protected final boolean tryAcquire(int acquires) {
    Thread current = Thread.currentThread();
    int c = getState();
    int w = exclusiveCount(c);
    if (c != 0) {
        if (w == 0 || current != getExclusiveOwnerThread())
            return false;
        if (w + exclusiveCount(acquires) &gt; MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
    }
    if ((w == 0 &amp;&amp; writerShouldBlock(current)) ||
        !compareAndSetState(c, c + acquires))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}</p>
<p>清单3 是写入锁获取的逻辑片段，整个工作流程是这样的：</p>
<ol>
<li>持有锁线程数非0（c=getState()不为0），如果写线程数（w）为0（那么读线程数就不为0）或者独占锁线程（持有锁的线程）不是当前线程就返回失败，或者写入锁的数量（其实是重入数）大于65535就抛出一个Error异常。否则进行2。</li>
<li>如果当且写线程数位0（那么读线程也应该为0，因为步骤1已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果增加写线程数失败也返回失败。否则进行3。</li>
<li>设置独占线程（写线程）为当前线程，返回true。</li>
</ol>
<p>清单3 中 exclusiveCount(c)就是获取写线程数（包括重入数），也就是state的低16位值。另外这里有一段逻辑是当前写线程是否需要阻塞writerShouldBlock(current)。清单4 和清单5 就是公平锁和非公平锁中是否需要阻塞的片段。很显然对于非公平锁而言总是不阻塞当前线程，而对于公平锁而言如果AQS队列不为空或者当前线程不是在AQS的队列头那么就阻塞线程，直到队列前面的线程处理完锁逻辑。</p>
<p><strong><em>清单4 公平读写锁写线程是否阻塞</em></strong>
final boolean writerShouldBlock(Thread current) {
    return !isFirst(current);
}</p>
<p><strong><em>清单5 非公平读写锁写线程是否阻塞</em></strong></p>
<p>final boolean writerShouldBlock(Thread current) {
    return false;
}</p>
<p>写入锁的获取逻辑清楚后，释放锁就比较简单了。清单6 描述的写入锁释放逻辑片段，其实就是检测下剩下的写入锁数量，如果是0就将独占锁线程清空（意味着没有线程获取锁），否则就是说当前是重入锁的一次释放，所以不能将独占锁线程清空。然后将剩余线程状态数写回AQS。</p>
<p><strong><em>清单6 写入锁释放逻辑片段</em></strong>
protected final boolean tryRelease(int releases) {
    int nextc = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    if (exclusiveCount(nextc) == 0) {
        setExclusiveOwnerThread(null);
        setState(nextc);
        return true;
    } else {
        setState(nextc);
        return false;
    }
}</p>
<p>清单3~6 描述的写入锁的获取释放过程。读取锁的获取和释放过程要稍微复杂些。 清单7描述的是读取锁的获取过程。</p>
<p><strong><em>清单7 读取锁获取过程片段</em></strong>
protected final int tryAcquireShared(int unused) {
    Thread current = Thread.currentThread();
    int c = getState();
    if (exclusiveCount(c) != 0 &amp;&amp;
        getExclusiveOwnerThread() != current)
        return -1;
    if (sharedCount(c) == MAX_COUNT)
        throw new Error(&quot;Maximum lock count exceeded&quot;);
    if (!readerShouldBlock(current) &amp;&amp;
        compareAndSetState(c, c + SHARED_UNIT)) {
        HoldCounter rh = cachedHoldCounter;
        if (rh == null || rh.tid != current.getId())
            cachedHoldCounter = rh = readHolds.get();
        rh.count++;
        return 1;
    }
    return fullTryAcquireShared(current);
}</p>
<p>final int fullTryAcquireShared(Thread current) {
    HoldCounter rh = cachedHoldCounter;
    if (rh == null || rh.tid != current.getId())
        rh = readHolds.get();
    for (;;) {
        int c = getState();
        int w = exclusiveCount(c);
        if ((w != 0 &amp;&amp; getExclusiveOwnerThread() != current) ||
            ((rh.count | w) == 0 &amp;&amp; readerShouldBlock(current)))
            return -1;
        if (sharedCount(c) == MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        if (compareAndSetState(c, c + SHARED_UNIT)) {
            cachedHoldCounter = rh; // cache for release
            rh.count++;
            return 1;
        }
    }
}</p>
<p>读取锁获取的过程是这样的：</p>
<ol>
<li>如果写线程持有锁（也就是独占锁数量不为0），并且独占线程不是当前线程，那么就返回失败。因为允许写入线程获取锁的同时获取读取锁。否则进行2。</li>
<li>如果读线程请求锁数量达到了65535（包括重入锁），那么就跑出一个错误Error，否则进行3。</li>
<li>如果读线程不用等待（实际上是是否需要公平锁），并且增加读取锁状态数成功，那么就返回成功，否则进行4。</li>
<li>步骤3失败的原因是CAS操作修改状态数失败，那么就需要循环不断尝试去修改状态直到成功或者锁被写入线程占有。实际上是过程3的不断尝试直到CAS计数成功或者被写入线程占有锁。</li>
</ol>
<p>在清单7 中有一个对象HoldCounter，这里暂且不提这是什么结构和为什么存在这样一个结构。</p>
<p>接下来根据清单8 我们来看如何释放一个读取锁。同样先不理HoldCounter，关键的在于for循环里面，其实就是一个不断尝试的CAS操作，直到修改状态成功。前面说过state的高16位描述的共享锁（读取锁）的数量，所以每次都需要减去2^16，这样就相当于读取锁数量减1。实际上SHARED_UNIT=1&lt;&lt;16。</p>
<p><strong><em>清单8 读取锁释放过程</em></strong>
protected final boolean tryReleaseShared(int unused) {
    HoldCounter rh = cachedHoldCounter;
    Thread current = Thread.currentThread();
    if (rh == null || rh.tid != current.getId())
        rh = readHolds.get();
    if (rh.tryDecrement() &lt;= 0)
        throw new IllegalMonitorStateException();
    for (;;) {
        int c = getState();
        int nextc = c - SHARED_UNIT;
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}</p>
<p>好了，现在回头看HoldCounter到底是一个什么东西。首先我们可以看到只有在获取共享锁（读取锁）的时候加1，也只有在释放共享锁的时候减1有作用，并且在释放锁的时候抛出了一个IllegalMonitorStateException异常。而我们知道IllegalMonitorStateException通常描述的是一个线程操作一个不属于自己的监视器对象的引发的异常。也就是说这里的意思是一个线程释放了一个不属于自己或者不存在的共享锁。</p>
<p>前面的章节中一再强调，对于共享锁，其实并不是锁的概念，更像是计数器的概念。一个共享锁就相对于一次计数器操作，一次获取共享锁相当于计数器加1，释放一个共享锁就相当于计数器减1。显然只有线程持有了共享锁（也就是当前线程携带一个计数器，描述自己持有多少个共享锁或者多重共享锁），才能释放一个共享锁。否则一个没有获取共享锁的线程调用一次释放操作就会导致读写锁的state（持有锁的线程数，包括重入数）错误。</p>
<p>明白了HoldCounter的作用后我们就可以猜到它的作用其实就是当前线程持有共享锁（读取锁）的数量，包括重入的数量。那么这个数量就必须和线程绑定在一起。</p>
<p>在Java里面将一个对象和线程绑定在一起，就只有ThreadLocal才能实现了。所以毫无疑问HoldCounter就应该是绑定到线程上的一个计数器。</p>
<p><strong><em>清单9 线程持有读取锁数量的计数器</em></strong>
static final class HoldCounter {
    int count;
    final long tid = Thread.currentThread().getId();
    int tryDecrement() {
        int c = count;
        if (c &gt; 0)
            count = c - 1;
        return c;
    }
}</p>
<p>static final class ThreadLocalHoldCounter
    extends ThreadLocal<HoldCounter> {
    public HoldCounter initialValue() {
        return new HoldCounter();
    }
}</p>
<p>清单9 描述的是线程持有读取锁数量的计数器。可以看到这里使用ThreadLocal将HoldCounter绑定到当前线程上，同时HoldCounter也持有线程Id，这样在释放锁的时候才能知道ReadWriteLock里面缓存的上一个读取线程（cachedHoldCounter）是否是当前线程。这样做的好处是可以减少ThreadLocal.get()的次数，因为这也是一个耗时操作。需要说明的是这样HoldCounter绑定线程id而不绑定线程对象的原因是避免HoldCounter和ThreadLocal互相绑定而GC难以释放它们（尽管GC能够智能的发现这种引用而回收它们，但是这需要一定的代价），所以其实这样做只是为了帮助GC快速回收对象而已。</p>
<p>除了readLock()和writeLock()外，Lock对象还允许tryLock()，那么ReadLock和WriteLock的tryLock()不一样。清单10 和清单11 分别描述了读取锁的tryLock()和写入锁的tryLock()。</p>
<p>读取锁tryLock()也就是tryReadLock()成功的条件是：没有写入锁或者写入锁是当前线程，并且读线程共享锁数量没有超过65535个。</p>
<p>写入锁tryLock()也就是tryWriteLock()成功的条件是: 没有写入锁或者写入锁是当前线程，并且尝试一次修改state成功。</p>
<p><strong><em>清单10 读取锁的tryLock()</em></strong>
final boolean tryReadLock() {
    Thread current = Thread.currentThread();
    for (;;) {
        int c = getState();
        if (exclusiveCount(c) != 0 &amp;&amp;
            getExclusiveOwnerThread() != current)
            return false;
        if (sharedCount(c) == MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
        if (compareAndSetState(c, c + SHARED_UNIT)) {
            HoldCounter rh = cachedHoldCounter;
            if (rh == null || rh.tid != current.getId())
                cachedHoldCounter = rh = readHolds.get();
            rh.count++;
            return true;
        }
    }
}</p>
<p><strong><em>清单11 写入锁的tryLock()</em></strong></p>
<p>final boolean tryWriteLock() {
    Thread current = Thread.currentThread();
    int c = getState();
    if (c != 0) {
        int w = exclusiveCount(c);
        if (w == 0 ||current != getExclusiveOwnerThread())
            return false;
        if (w == MAX_COUNT)
            throw new Error(&quot;Maximum lock count exceeded&quot;);
    }
    if (!compareAndSetState(c, c + 1))
        return false;
    setExclusiveOwnerThread(current);
    return true;
}</p>
<p>整个读写锁的逻辑大概就这么多，其实真正研究起来也不是很复杂，真正复杂的东西都在AQS里面。</p>
<p>锁部分的原理和思想都介绍完了，下一节里面会对锁机进行小节，并对线程并发也会有一些简单的小节。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/15/326152.html](http://www.blogjava.net/xylz/archive/2010/07/15/326152.html)">[http://www.blogjava.net/xylz/archive/2010/07/15/326152.html](http://www.blogjava.net/xylz/archive/2010/07/15/326152.html)</a> </p>
<p>主要谈谈锁的性能以及其它一些理论知识，内容主要的出处是《<a href="http://www.amazon.com/exec/obidos/ASIN/0321349601/ref=nosim/none0b69" target="_blank">Java Concurrency in Practice</a>》，结合自己的理解和实际应用对锁机制进行一个小小的总结。</p>
<p>首先需要强调的一点是：所有锁（包括内置锁和高级锁）都是有性能消耗的，也就是说在高并发的情况下，由于锁机制带来的上下文切换、资源同步等消耗是非常可观的。在某些极端情况下，线程在锁上的消耗可能比线程本身的消耗还要多。所以如果可能的话，在任何情况下都尽量少用锁，如果不可避免那么采用非阻塞算法是一个不错的解决方案，但是却也不是绝对的。</p>
<p><strong>内部锁</strong></p>
<p>Java语言通过synchronized关键字来保证原子性。这是因为每一个Object都有一个隐含的锁，这个也称作监视器对象。在进入synchronized之前自动获取此内部锁，而一旦离开此方式（不管通过和中方式离开此方法）都会自动释放锁。显然这是一个独占锁，每个锁请求之间是互斥的。相对于前面介绍的众多高级锁（Lock/ReadWriteLock等），synchronized的代价都比后者要高。但是synchronized的语法比较简单，而且也比较容易使用和理解，不容易写法上的错误。而我们知道Lock一旦调用了lock()方法获取到锁而未正确释放的话很有可能就死锁了。所以Lock的释放操作总是跟在finally代码块里面，这在代码结构上也是一次调整和冗余。另外前面介绍中说过Lock的实现已经将硬件资源用到了极致，所以未来可优化的空间不大，除非硬件有了更高的性能。但是synchronized只是规范的一种实现，这在不同的平台不同的硬件还有很高的提升空间，未来Java在锁上的优化也会主要在这上面。</p>
<p><strong>性能</strong></p>
<p>由于锁总是带了性能影响，所以是否使用锁和使用锁的场合就变得尤为重要。如果在一个高并发的Web请求中使用了强制的独占锁，那么就可以发现Web的吞吐量将急剧下降。</p>
<p>为了利用并发来提高性能，出发点就是：更有效的利用现有的资源，同时让程序尽可能的开拓更多可用的资源。这意味着机器尽可能的处于忙碌的状态，通常意义是说CPU忙于计算，而不是等待。当然CPU要做有用的事情，而不是进行无谓的循环。当然在实践中通常会预留一些资源出来以便应急特殊情况，这在以后的线程池并发中可以看到很多例子。</p>
<p><strong>线程阻塞</strong></p>
<p>锁机制的实现通常需要操作系统提供支持，显然这会增加开销。当锁竞争的时候，失败的线程必然会发生阻塞。JVM既能自旋等待（不断尝试，知道成功，很多CAS就是这样实现的），也能够在操作系统中挂起阻塞的线程，直到超时或者被唤醒。通常情况下这取决于上下文切换的开销以及与获取锁需要等待的时间二者之间的关系。自旋等待适合于比较短的等待，而挂起线程比较适合那些比较耗时的等待。</p>
<p>挂起一个线程可能是因为无法获取到锁，或者需要某个特定的条件，或者耗时的I/O操作。挂起一个线程需要两次额外的上下文切换以及操作系统、缓存等多资源的配合：如果线程被提前换出，那么一旦拿到锁或者条件满足，那么又需要将线程换回执行队列，这对线程而言，两次上下文切换可能比较耗时。</p>
<hr>
<p><strong>锁竞争</strong></p>
<p>影响锁竞争性的条件有两个：锁被请求的频率和每次持有锁的时间。显然当而这二者都很小的时候，锁竞争不会成为主要的瓶颈。但是如果锁使用不当，导致二者都比较大，那么很有可能CPU不能有效的处理任务，任务被大量堆积。</p>
<p>所以减少锁竞争的方式有下面三种：</p>
<ol>
<li>减少锁持有的时间</li>
<li>减少锁请求的频率</li>
<li>采用共享锁取代独占锁</li>
</ol>
<p><strong>死锁</strong></p>
<p>如果一个线程永远不释放另外一个线程需要的资源那么就会导致死锁。这有两种情况：一种情况是线程A永远不释放锁，结果B一直拿不到锁，所以线程B就“死掉”了；第二种情况下，线程A拥有线程B需要的锁Y，同时线程B拥有线程A需要的锁X，那么这时候线程A/B互相依赖对方释放锁，于是二者都“死掉”了。</p>
<p>还有一种情况为发生死锁，如果一个线程总是不能被调度，那么等待此线程结果的线程可能就死锁了。这种情况叫做线程饥饿死锁。比如说在前面介绍的非公平锁中，如果某些线程非常活跃，在高并发情况下这类线程可能总是拿到锁，那么那些活跃度低的线程可能就一直拿不到锁，这样就发生了“饥饿死”。</p>
<p>避免死锁的解决方案是：尽可能的按照锁的使用规范请求锁，另外锁的请求粒度要小（不要在不需要锁的地方占用锁，锁不用了尽快释放）；在高级锁里面总是使用tryLock或者定时机制（这个以后会讲，就是指定获取锁超时的时间，如果时间到了还没有获取到锁那么就放弃）。高级锁（Lock）里面的这两种方式可以有效的避免死锁。</p>
<p><strong>活锁</strong></p>
<p>活锁描述的是线程总是尝试某项操作却总是失败的情况。这种情况下尽管线程没有被阻塞，但是人物却总是不能被执行。比如在一个死循环里面总是尝试做某件事，结果却总是失败，现在线程将永远不能跳出这个循环。另外一种情况是在一个队列中每次从队列头取出一个任务来执行，每次都失败，然后将任务放入队列头，接下来再一次从队列头取出任务执行，仍然失败。</p>
<p>还有一种活锁方式发生在“碰撞协让”情况下：两个人过独木桥，如果在半路相撞，双方礼貌退出去然后再试一次。如果总是失败，那么这两个任务将一直无法得到执行。</p>
<p><strong>总之解决锁问题的关键就是：从简单的开始，先保证正确，然后再开始优化。</strong>
<strong>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/16/326246.html](http://www.blogjava.net/xylz/archive/2010/07/16/326246.html)">[http://www.blogjava.net/xylz/archive/2010/07/16/326246.html](http://www.blogjava.net/xylz/archive/2010/07/16/326246.html)</a> </strong></p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency3-锁机制/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency3-锁机制" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency28-线程池/">深入浅出 Java Concurrency (28)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency28-线程池/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-28-">深入浅出 Java Concurrency (28): 线程池</h1>
<p><a href="http://www.blogjava.net/xylz/archive/2010/12/19/341098.html" target="_blank"> 简介</a></p>
<p>从这一节开始正式进入线程池的部分。其实整个体系已经拖了很长的时间，因此后面的章节会加快速度，甚至只是一个半成品或者简单化，以后有时间的慢慢补充、完善。</p>
<p>其实线程池是并发包里面很重要的一部分，在实际情况中也是使用很多的一个重要组件。</p>
<p>下图描述的是线程池API的一部分。广义上的完整线程池可能还包括Thread/Runnable、Timer/TimerTask等部分。这里只介绍主要的和高级的API以及架构和原理。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-part-1-_8E6F/ThreadPool2_2.png" target="_blank"><img src="&quot;ThreadPool2&quot;" alt="ThreadPool2"></a></p>
<p>大多数并发应用程序是围绕执行任务（Task）进行管理的。所谓任务就是抽象、离散的工作单元（unit of work）。把一个应用程序的工作（work）分离到任务中，可以简化程序的管理；这种分离还在不同事物间划分了自然的分界线，可以方便程序在出现错误时进行恢复；同时这种分离还可以为并行工作提供一个自然的结构，有利于提高程序的并发性。<a href="http://www.blogjava.net/xylz/archive/2010/12/19/341098.html#jcp" target="_blank">[1]</a></p>
<p>并发执行任务的一个很重要前提是拆分任务。把一个大的过程或者任务拆分成很多小的工作单元，每一个工作单元可能相关、也可能无关，这些单元在一定程度上可以充分利用CPU的特性并发的执行，从而提高并发性（性能、响应时间、吞吐量等）。</p>
<p>所谓的任务拆分就是确定每一个执行任务（工作单元）的边界。理想情况下独立的工作单元有最大的吞吐量，这些工作单元不依赖于其它工作单元的状态、结果或者其他资源等。因此将任务尽可能的拆分成一个个独立的工作单元有利于提高程序的并发性。</p>
<p>对于有依赖关系以及资源竞争的工作单元就涉及到任务的调度和负载均衡。工作单元的状态、结果或者其他资源等有关联的工作单元就需要有一个总体的调度者来协调资源和执行顺序。同样在有限的资源情况下，大量的任务也需要一个协调各个工作单元的调度者。这就涉及到任务执行的策略问题。</p>
<p>任务的执行策略包括4W3H部分：</p>
<ul>
<li>任务在什么（What）线程中执行</li>
<li>任务以什么（What）顺序执行（FIFO/LIFO/优先级等）</li>
<li>同时有多少个（How Many）任务并发执行</li>
<li>允许有多少个（How Many）个任务进入执行队列</li>
<li>系统过载时选择放弃哪一个（Which）任务，如何（How）通知应用程序这个动作</li>
<li>任务执行的开始、结束应该做什么（What）处理</li>
</ul>
<p>在后面的章节中会详细分写这些策略是如何实现的。我们先来简单回答些如何满足上面的条件。</p>
<ol>
<li>首先明确一定是在Java里面可以供使用者调用的启动线程类是Thread。因此Runnable或者Timer/TimerTask等都是要依赖Thread来启动的，因此在ThreadPool里面同样也是靠Thread来启动多线程的。</li>
<li>默认情况下Runnable接口执行完毕后是不能拿到执行结果的，因此在ThreadPool里就定义了一个Callable接口来处理执行结果。</li>
<li>为了异步阻塞的获取结果，Future可以帮助调用线程获取执行结果。</li>
<li>Executor解决了向线程池提交任务的入口问题，同时ScheduledExecutorService解决了如何进行重复调用任务的问题。</li>
<li>CompletionService解决了如何按照执行完毕的顺序获取结果的问题，这在某些情况下可以提高任务执行的并发，调用线程不必在长时间任务上等待过多时间。</li>
<li>显然线程的数量是有限的，而且也不宜过多，因此合适的任务队列是必不可少的，BlockingQueue的容量正好可以解决此问题。</li>
<li>固定任务容量就意味着在容量满了以后需要一定的策略来处理过多的任务（新任务），RejectedExecutionHandler正好解决此问题。</li>
<li>一定时间内阻塞就意味着有超时，因此TimeoutException就是为了描述这种现象。TimeUnit是为了描述超时时间方便的一个时间单元枚举类。</li>
<li>有上述问题就意味了配置一个合适的线程池是很复杂的，因此Executors默认的一些线程池配置可以减少这个操作。</li>
</ol>
<p>线程池的基本策略大致就这些，从下一节开始就从线程池的基本原理和执行方法开始描述。</p>
<p><a href="">[1] Java Concurrency in Practice</a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/12/19/341098.html](http://www.blogjava.net/xylz/archive/2010/12/19/341098.html)">[http://www.blogjava.net/xylz/archive/2010/12/19/341098.html](http://www.blogjava.net/xylz/archive/2010/12/19/341098.html)</a> <a href="http://www.blogjava.net/xylz/archive/2010/12/21/341281.html" target="_blank">Executor 以及Executors</a>
Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。</p>
<p>下面这张图完整描述了线程池的类体系结构。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-28--part-1-_1302E/Executor-class_2.png" target="_blank"><img src="&quot;Executor-class&quot;" alt="Executor-class"></a></p>
<p>首先Executor的execute方法只是执行一个Runnable的任务，当然了从某种角度上将最后的实现类也是在线程中启动此任务的。根据线程池的执行策略最后这个任务可能在新的线程中执行，或者线程池中的某个线程，甚至是调用者线程中执行（相当于直接运行Runnable的run方法）。这点在后面会详细说明。</p>
<p>ExecutorService在Executor的基础上增加了一些方法，其中有两个核心的方法：</p>
<ul>
<li>Future&lt;?&gt; submit(Runnable task)</li>
<li><T> Future<T> submit(Callable<T> task)</li>
</ul>
<p>这两个方法都是向线程池中提交任务，它们的区别在于Runnable在执行完毕后没有结果，Callable执行完毕后有一个结果。这在多个线程中传递状态和结果是非常有用的。另外他们的相同点在于都返回一个Future对象。Future对象可以阻塞线程直到运行完毕（获取结果，如果有的话），也可以取消任务执行，当然也能够检测任务是否被取消或者是否执行完毕。</p>
<p>在没有Future之前我们检测一个线程是否执行完毕通常使用Thread.join()或者用一个死循环加状态位来描述线程执行完毕。现在有了更好的方法能够阻塞线程，检测任务执行完毕甚至取消执行中或者未开始执行的任务。</p>
<p>ScheduledExecutorService描述的功能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。这包括延迟时间一次性执行、延迟时间周期性执行以及固定延迟时间周期性执行等。当然了继承ExecutorService的ScheduledExecutorService拥有ExecutorService的全部特性。</p>
<p>ThreadPoolExecutor是ExecutorService的默认实现，其中的配置、策略也是比较复杂的，在后面的章节中会有详细的分析。</p>
<p>ScheduledThreadPoolExecutor是继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现，在后面的章节中会有详细的分析。</p>
<p>这里需要稍微提一下的是CompletionService接口，它是用于描述顺序获取执行结果的一个线程池包装器。它依赖一个具体的线程池调度，但是能够根据任务的执行先后顺序得到执行结果，这在某些情况下可能提高并发效率。</p>
<p>要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。</p>
<ul>
<li><strong>newSingleThreadExecutor</strong>：创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。</li>
<li><strong>newFixedThreadPool</strong>：创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。</li>
<li><strong>newCachedThreadPool</strong>：创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。</li>
<li><strong>newScheduledThreadPool</strong>：创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。</li>
<li><strong>newSingleThreadScheduledExecutor</strong>：创建一个单线程的线程池。此线程池支持定时以及周期性执行任务的需求。</li>
</ul>
<p>在详细讲解ThreadPoolExecutor的时候会具体讨论上述参数配置后的意义和原理。</p>
<p>线程池是一个复杂的任务调度工具，因此它涉及到任务、线程池等的生命周期问题，在下一节中来探讨下这个问题。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/12/21/341281.html](http://www.blogjava.net/xylz/archive/2010/12/21/341281.html)">[http://www.blogjava.net/xylz/archive/2010/12/21/341281.html](http://www.blogjava.net/xylz/archive/2010/12/21/341281.html)</a> <a href="http://www.blogjava.net/xylz/archive/2011/01/04/342316.html" target="_blank">Executor 生命周期</a></p>
<p>我们知道线程是有多种执行状态的，同样管理线程的线程池也有多种状态。JVM会在所有线程（非后台daemon线程）全部终止后才退出，为了节省资源和有效释放资源关闭一个线程池就显得很重要。有时候无法正确的关闭线程池，将会阻止JVM的结束。</p>
<p>线程池Executor是异步的执行任务，因此任何时刻不能够直接获取提交的任务的状态。这些任务有可能已经完成，也有可能正在执行或者还在排队等待执行。因此关闭线程池可能出现一下几种情况：</p>
<ul>
<li>平缓关闭：已经启动的任务全部执行完毕，同时不再接受新的任务</li>
<li>立即关闭：取消所有正在执行和未执行的任务</li>
</ul>
<p>另外关闭线程池后对于任务的状态应该有相应的反馈信息。</p>
<p>图1 描述了线程池的4种状态。</p>
<ul>
<li>线程池在构造前（new操作）是初始状态，一旦构造完成线程池就进入了执行状态RUNNING。严格意义上讲线程池构造完成后并没有线程被立即启动，只有进行“预启动”或者接收到任务的时候才会启动线程。这个会后面线程池的原理会详细分析。但是线程池是出于运行状态，随时准备接受任务来执行。</li>
<li>线程池运行中可以通过shutdown()和shutdownNow()来改变运行状态。shutdown()是一个平缓的关闭过程，线程池停止接受新的任务，同时等待已经提交的任务执行完毕，包括那些进入队列还没有开始的任务，这时候线程池处于SHUTDOWN状态；shutdownNow()是一个立即关闭过程，线程池停止接受新的任务，同时线程池取消所有执行的任务和已经进入队列但是还没有执行的任务，这时候线程池处于STOP状态。</li>
<li>一旦shutdown()或者shutdownNow()执行完毕，线程池就进入TERMINATED状态，此时线程池就结束了。</li>
<li>isTerminating()描述的是SHUTDOWN和STOP两种状态。</li>
<li>isShutdown()描述的是非RUNNING状态，也就是SHUTDOWN/STOP/TERMINATED三种状态。</li>
</ul>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-part-3-Executor-_12486/Executor-Lifecycle_4.png" target="_blank"><img src="&quot;Executor-Lifecycle&quot;" alt="Executor-Lifecycle"></a></p>
<p>图1</p>
<p>线程池的API如下：</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-part-3-Executor-_12486/ExecutorService-LifeCycle_2.png" target="_blank"><img src="&quot;ExecutorService-LifeCycle&quot;" alt="ExecutorService-LifeCycle"></a></p>
<p>图2</p>
<p>其中shutdownNow()会返回那些已经进入了队列但是还没有执行的任务列表。awaitTermination描述的是等待线程池关闭的时间，如果等待时间线程池还没有关闭将会抛出一个超时异常。</p>
<p>对于关闭线程池期间发生的任务提交情况就会触发一个拒绝执行的操作。这是java.util.concurrent.RejectedExecutionHandler描述的任务操作。下一个小结中将描述这些任务被拒绝后的操作。</p>
<p>总结下这个小节：</p>
<ol>
<li>线程池有运行、关闭、停止、结束四种状态，结束后就会释放所有资源</li>
<li>平缓关闭线程池使用shutdown()</li>
<li>立即关闭线程池使用shutdownNow()，同时得到未执行的任务列表</li>
<li>检测线程池是否正处于关闭中，使用isShutdown()</li>
<li>检测线程池是否已经关闭使用isTerminated()</li>
<li>定时或者永久等待线程池关闭结束使用awaitTermination()操作</li>
</ol>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2011/01/04/342316.html](http://www.blogjava.net/xylz/archive/2011/01/04/342316.html)">[http://www.blogjava.net/xylz/archive/2011/01/04/342316.html](http://www.blogjava.net/xylz/archive/2011/01/04/342316.html)</a></p>
<p><strong>线程池数据结构与线程构造方法</strong></p>
<p>由于已经看到了ThreadPoolExecutor的源码，因此很容易就看到了ThreadPoolExecutor线程池的数据结构。图1描述了这种数据结构。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-32--part-5-_72AF/ThreadPoolExecutor_2.png" target="_blank"><img src="&quot;ThreadPoolExecutor&quot;" alt="ThreadPoolExecutor"></a></p>
<p>图1 ThreadPoolExecutor 数据结构</p>
<p>其实，即使没有上述图形描述ThreadPoolExecutor的数据结构，我们根据线程池的要求也很能够猜测出其数据结构出来。</p>
<ul>
<li>线程池需要支持多个线程并发执行，因此有一个线程集合Collection<Thread>来执行线程任务；</li>
<li>涉及任务的异步执行，因此需要有一个集合来缓存任务队列Collection<Runnable>；</li>
<li>很显然在多个线程之间协调多个任务，那么就需要一个线程安全的任务集合，同时还需要支持阻塞、超时操作，那么BlockingQueue是必不可少的；</li>
<li>既然是线程池，出发点就是提高系统性能同时降低资源消耗，那么线程池的大小就有限制，因此需要有一个核心线程池大小（线程个数）和一个最大线程池大小（线程个数），有一个计数用来描述当前线程池大小；</li>
<li>如果是有限的线程池大小，那么长时间不使用的线程资源就应该销毁掉，这样就需要一个线程空闲时间的计数来描述线程何时被销毁；</li>
<li>前面描述过线程池也是有生命周期的，因此需要有一个状态来描述线程池当前的运行状态；</li>
<li>线程池的任务队列如果有边界，那么就需要有一个任务拒绝策略来处理过多的任务，同时在线程池的销毁阶段也需要有一个任务拒绝策略来处理新加入的任务；</li>
<li>上面种的线程池大小、线程空闲实际那、线程池运行状态等等状态改变都不是线程安全的，因此需要有一个全局的锁（mainLock）来协调这些竞争资源；</li>
<li>除了以上数据结构以外，ThreadPoolExecutor还有一些状态用来描述线程池的运行计数，例如线程池运行的任务数、曾经达到的最大线程数，主要用于调试和性能分析。</li>
</ul>
<p>对于ThreadPoolExecutor而言，一个线程就是一个Worker对象，它与一个线程绑定，当Worker执行完毕就是线程执行完毕，这个在后面详细讨论线程池中线程的运行方式。</p>
<p>既然是线程池，那么就首先研究下线程的构造方法。
public interface ThreadFactory {
    Thread newThread(Runnable r);
}</p>
<p>ThreadPoolExecutor使用一个线程工厂来构造线程。线程池都是提交一个任务Runnable，然后在某一个线程Thread中执行，ThreadFactory 负责如何创建一个新线程。</p>
<p>在J.U.C中有一个通用的线程工厂java.util.concurrent.Executors.DefaultThreadFactory，它的构造方式如下：
static class DefaultThreadFactory implements ThreadFactory {
    static final AtomicInteger poolNumber = new AtomicInteger(1);
    final ThreadGroup group;
    final AtomicInteger threadNumber = new AtomicInteger(1);
    final String namePrefix;
    DefaultThreadFactory() {
        SecurityManager s = System.getSecurityManager();
        group = (s != null)? s.getThreadGroup() :
                             Thread.currentThread().getThreadGroup();
        namePrefix = &quot;pool-&quot; +
                      poolNumber.getAndIncrement() +
                     &quot;-thread-&quot;;
    }
    public Thread newThread(Runnable r) {
        Thread t = new Thread(group, r,
                              namePrefix + threadNumber.getAndIncrement(),
                              0);
        if (t.isDaemon())
            t.setDaemon(false);
        if (t.getPriority() != Thread.NORM_PRIORITY)
            t.setPriority(Thread.NORM_PRIORITY);
        return t;
    }
}</p>
<p>在这个线程工厂中，同一个线程池的所有线程属于同一个线程组，也就是创建线程池的那个线程组，同时线程池的名称都是“pool-<poolNum>-thread-<threadNum>”，其中poolNum是线程池的数量序号，threadNum是此线程池中的线程数量序号。这样如果使用jstack的话很容易就看到了系统中线程池的数量和线程池中线程的数量。另外对于线程池中的所有线程默认都转换为非后台线程，这样主线程退出时不会直接退出JVM，而是等待线程池结束。还有一点就是默认将线程池中的所有线程都调为同一个级别，这样在操作系统角度来看所有系统都是公平的，不会导致竞争堆积。</p>
<p><strong>线程池中线程生命周期</strong></p>
<p>一个线程Worker被构造出来以后就开始处于运行状态。以下是一个线程执行的简版逻辑。
private final class Worker implements Runnable {
    private final ReentrantLock runLock = new ReentrantLock();
    private Runnable firstTask;
    Thread thread;
    Worker(Runnable firstTask) {
        this.firstTask = firstTask;
    }
    private void runTask(Runnable task) {
        final ReentrantLock runLock = this.runLock;
        runLock.lock();
        try {
           task.run();
        } finally {
            runLock.unlock();
        }
    }
    public void run() {
        try {
            Runnable task = firstTask;
            firstTask = null;
            while (task != null || (task = getTask()) != null) {
                runTask(task);
                task = null;
            }
        } finally {
            workerDone(this);
        }
    }
}</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-32--part-5-_72AF/ThreadPoolExecutor-Worker_2.png" target="_blank"><img src="&quot;ThreadPoolExecutor-Worker&quot;" alt="ThreadPoolExecutor-Worker"></a></p>
<p>当提交一个任务时，如果需要创建一个线程（何时需要在下一节中探讨）时，就调用线程工厂创建一个线程，同时将线程绑定到Worker工作队列中。需要说明的是，Worker队列构造的时候带着一个任务Runnable，因此Worker创建时总是绑定着一个待执行任务。换句话说，创建线程的前提是有必要创建线程（任务数已经超出了线程或者强制创建新的线程，至于为何强制创建新的线程后面章节会具体分析），不会无缘无故创建一堆空闲线程等着任务。这是节省资源的一种方式。</p>
<p>一旦线程池启动线程后（调用线程run()）方法，那么线程工作队列Worker就从第1个任务开始执行（这时候发现构造Worker时传递一个任务的好处了），一旦第1个任务执行完毕，就从线程池的任务队列中取出下一个任务进行执行。循环如此，直到线程池被关闭或者任务抛出了一个RuntimeException。</p>
<p>由此可见，线程池的基本原理其实也很简单，无非预先启动一些线程，线程进入死循环状态，每次从任务队列中获取一个任务进行执行，直到线程池被关闭。如果某个线程因为执行某个任务发生异常而终止，那么重新创建一个新的线程而已。如此反复。</p>
<p>其实，线程池原理看起来简单，但是复杂的是各种策略，例如何时该启动一个线程，何时该终止、挂起、唤醒一个线程，任务队列的阻塞与超时，线程池的生命周期以及任务拒绝策略等等。下一节将研究这些策略问题。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2011/01/18/343183.html](http://www.blogjava.net/xylz/archive/2011/01/18/343183.html)">[http://www.blogjava.net/xylz/archive/2011/01/18/343183.html](http://www.blogjava.net/xylz/archive/2011/01/18/343183.html)</a> </p>
<p><strong>线程池任务执行流程</strong></p>
<p>我们从一个API开始接触Executor是如何处理任务队列的。</p>
<p>java.util.concurrent.Executor.execute(Runnable)
Executes the given task sometime in the future. The task may execute in a new thread or in an existing pooled thread. If the task cannot be submitted for execution, either because this executor has been shutdown or because its capacity has been reached, the task is handled by the current RejectedExecutionHandler.</p>
<p>线程池中所有任务执行都依赖于此接口。这段话有以下几个意思：</p>
<ol>
<li>任务可能在将来某个时刻被执行，有可能不是立即执行。为什么这里有两个“可能”？继续往下面看。</li>
<li>任务可能在一个新的线程中执行或者线程池中存在的一个线程中执行。</li>
<li>任务无法被提交执行有以下两个原因：线程池已经关闭或者线程池已经达到了容量限制。</li>
<li>所有失败的任务都将被“当前”的任务拒绝策略RejectedExecutionHandler 处理。</li>
</ol>
<p>回答上面两个“可能“。任务可能被执行，那不可能的情况就是上面说的情况3；可能不是立即执行，是因为任务可能还在队列中排队，因此还在等待分配线程执行。了解完了字面上的问题，我们再来看具体的实现。
public void execute(Runnable command) {
    if (command == null)
        throw new NullPointerException();
    if (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) {
        if (runState == RUNNING &amp;&amp; workQueue.offer(command)) {
            if (runState != RUNNING || poolSize == 0)
                ensureQueuedTaskHandled(command);
        }
        else if (!addIfUnderMaximumPoolSize(command))
            reject(command); // is shutdown or saturated
    }
}</p>
<p>这一段代码看起来挺简单的，其实这就是线程池最重要的一部分，如果能够完全理解这一块，线程池还是挺容易的。整个执行流程是这样的：</p>
<ol>
<li>如果任务command为空，则抛出空指针异常，返回。否则进行2。</li>
<li>如果当前线程池大小 大于或等于 核心线程池大小，进行4。否则进行3。</li>
<li>创建一个新工作队列（线程，参考上一节），成功直接返回，失败进行4。</li>
<li>如果线程池正在运行并且任务加入线程池队列成功，进行5，否则进行7。</li>
<li>如果线程池已经关闭或者线程池大小为0，进行6，否则直接返回。</li>
<li>如果线程池已经关闭则执行拒绝策略返回，否则启动一个新线程来进行执行任务，返回。</li>
<li>如果线程池大小 不大于 最大线程池数量，则启动新线程来进行执行，否则进行拒绝策略，结束。</li>
</ol>
<p>文字描述步骤不够简单？下面图形详细表述了此过程。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-34--part-7--2_BFAE/Executor.execute_8.png" target="_blank"><img src="&quot;Executor.execute&quot;" alt="Executor.execute"></a></p>
<p>老实说这个图比上面步骤更难以理解，那么从何入手呢。</p>
<p>流程的入口很简单，我们就是要执行一个任务（Runnable command)，那么它的结束点在哪或者有哪几个？</p>
<p>根据左边这个图我们知道可能有以下几种出口：</p>
<p>（1）图中的P1、P7，我们根据这条路径可以看到，仅仅是将任务加入任务队列（offer(command)）了；</p>
<p>（2）图中的P3，这条路径不将任务加入任务队列，但是启动了一个新工作线程（Worker）进行扫尾操作，用户处理为空的任务队列；</p>
<p>（3）图中的P4，这条路径没有将任务加入任务队列，但是启动了一个新工作线程（Worker），并且工作现场的第一个任务就是当前任务；</p>
<p>（4）图中的P5、P6，这条路径没有将任务加入任务队列，也没有启动工作线程，仅仅是抛给了任务拒绝策略。P2是任务加入了任务队列却因为线程池已经关闭于是又从任务队列中删除，并且抛给了拒绝策略。</p>
<p>如果上面的解释还不清楚，可以去研究下面两段代码：
java.util.concurrent.ThreadPoolExecutor.addIfUnderCorePoolSize(Runnable)
java.util.concurrent.ThreadPoolExecutor.addIfUnderMaximumPoolSize(Runnable)
java.util.concurrent.ThreadPoolExecutor.ensureQueuedTaskHandled(Runnable)</p>
<p>那么什么时候一个任务被立即执行呢？</p>
<p>在线程池运行状态下，如果线程池大小 小于 核心线程池大小或者线程池已满（任务队列已满）并且线程池大小 小于 最大线程池大小（此时线程池大小 大于 核心线程池大小的），用程序描述为：
runState == RUNNING &amp;&amp; ( poolSize &lt; corePoolSize || poolSize &lt; maxnumPoolSize &amp;&amp; workQueue.isFull())</p>
<p>上面的条件就是一个任务能够被立即执行的条件。</p>
<p>有了execute的基础，我们看看ExecutorService中的几个submit方法的实现。
    public Future&lt;?&gt; submit(Runnable task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<Object> ftask = newTaskFor(task, null);
        execute(ftask);
        return ftask;
    }
    public <T> Future<T> submit(Runnable task, T result) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<T> ftask = newTaskFor(task, result);
        execute(ftask);
        return ftask;
    }
    public <T> Future<T> submit(Callable<T> task) {
        if (task == null) throw new NullPointerException();
        RunnableFuture<T> ftask = newTaskFor(task);
        execute(ftask);
        return ftask;
    }</p>
<p>很简单，不是么？对于一个线程池来说复杂的地方也就在execute方法的执行流程。在下一节中我们来讨论下如何获取任务的执行结果，也就是Future类的使用和原理。</p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2011/02/11/344091.html](http://www.blogjava.net/xylz/archive/2011/02/11/344091.html)">[http://www.blogjava.net/xylz/archive/2011/02/11/344091.html](http://www.blogjava.net/xylz/archive/2011/02/11/344091.html)</a> </p>
<p><strong>线程池任务执行结果</strong></p>
<p>这一节来探讨下线程池中任务执行的结果以及如何阻塞线程、取消任务等等。
1 package info.imxylz.study.concurrency.future;
2 
3 public class SleepForResultDemo implements Runnable {
4 
5     static boolean result = false;
6 
7     static void sleepWhile(long ms) {
8         try {
9             Thread.sleep(ms);
10         } catch (Exception e) {}
11     }
12 
13     @Override
14     public void run() {
15         //do work
16         System.out.println(&quot;Hello, sleep a while.&quot;);
17         sleepWhile(2000L);
18         result = true;
19     }
20 
21     public static void main(String[] args) {
22         SleepForResultDemo demo = new SleepForResultDemo();
23         Thread t = new Thread(demo);
24         t.start();
25         sleepWhile(3000L);
26         System.out.println(result);
27     }
28 
29 }
30 </p>
<p>在没有线程池的时代里面，使用Thread.sleep(long)去获取线程执行完毕的场景很多。显然这种方式很笨拙，他需要你事先知道任务可能的执行时间，并且还会阻塞主线程，不管任务有没有执行完毕。</p>
<p>1 package info.imxylz.study.concurrency.future;
2 
3 public class SleepLoopForResultDemo implements Runnable {
4 
5     boolean result = false;
6 
7     volatile boolean finished = false;
8 
9     static void sleepWhile(long ms) {
10         try {
11             Thread.sleep(ms);
12         } catch (Exception e) {}
13     }
14 
15     @Override
16     public void run() {
17         //do work
18         try {
19             System.out.println(&quot;Hello, sleep a while.&quot;);
20             sleepWhile(2000L);
21             result = true;
22         } finally {
23             finished = true;
24         }
25     }
26 
27     public static void main(String[] args) {
28         SleepLoopForResultDemo demo = new SleepLoopForResultDemo();
29         Thread t = new Thread(demo);
30         t.start();
31         while (!demo.finished) {
32             sleepWhile(10L);
33         }
34         System.out.println(demo.result);
35     }
36 
37 }
38 </p>
<p>使用volatile与while死循环的好处就是等待的时间可以稍微小一点，但是依然有CPU负载高并且阻塞主线程的问题。最简单的降低CPU负载的方式就是使用Thread.join().</p>
<pre><code>    SleepLoopForResultDemo demo = new SleepLoopForResultDemo();
    Thread t = new Thread(demo);
    t.start();
    t.join();
    System.out.println(demo.result);
</code></pre><p>显然这也是一种不错的方式，另外还有自己写锁使用wait/notify的方式。其实join()从本质上讲就是利用while和wait来实现的。</p>
<p>上面的方式中都存在一个问题，那就是会阻塞主线程并且任务不能被取消。为了解决这个问题，线程池中提供了一个Future接口。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-35--part-8--2_BFEA/ThreadPoolExecutor-Future_2.png" target="_blank"><img src="&quot;ThreadPoolExecutor-Future&quot;" alt="ThreadPoolExecutor-Future"></a></p>
<p>在Future接口中提供了5个方法。</p>
<ul>
<li>V get() throws InterruptedException, ExecutionException： 等待计算完成，然后获取其结果。</li>
<li>V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException。最多等待为使计算完成所给定的时间之后，获取其结果（如果结果可用）。</li>
<li>boolean cancel(boolean mayInterruptIfRunning)：试图取消对此任务的执行。</li>
<li>boolean isCancelled()：如果在任务正常完成前将其取消，则返回 true。</li>
<li>boolean isDone()：如果任务已完成，则返回 true。 可能由于正常终止、异常或取消而完成，在所有这些情况中，此方法都将返回 true。</li>
</ul>
<p>API看起来容易，来研究下异常吧。get()请求获取一个结果会阻塞当前进程，并且可能抛出以下三种异常：</p>
<ul>
<li>InterruptedException：执行任务的线程被中断则会抛出此异常，此时不能知道任务是否执行完毕，因此其结果是无用的，必须处理此异常。</li>
<li>ExecutionException：任务执行过程中(Runnable/#run()）方法可能抛出RuntimeException，如果提交的是一个java.util.concurrent.Callable<V>接口任务，那么java.util.concurrent.Callable.call()方法有可能抛出任意异常。</li>
<li>CancellationException：实际上get()方法还可能抛出一个CancellationException的RuntimeException，也就是任务被取消了但是依然去获取结果。</li>
</ul>
<p>对于get(long timeout, TimeUnit unit)而言，除了get()方法的异常外，由于有超时机制，因此还可能得到一个TimeoutException。</p>
<p>boolean cancel(boolean mayInterruptIfRunning)方法比较复杂，各种情况比较多：</p>
<ol>
<li>如果任务已经执行完毕，那么返回false。</li>
<li>如果任务已经取消，那么返回false。</li>
<li>循环直到设置任务为取消状态，对于未启动的任务将永远不再执行，对于正在运行的任务，将根据mayInterruptIfRunning是否中断其运行，如果不中断那么任务将继续运行直到结束。</li>
<li>此方法返回后任务要么处于运行结束状态，要么处于取消状态。isDone()将永远返回true，如果cancel()方法返回true，isCancelled()始终返回true。</li>
</ol>
<p>来看看Future接口的实现类java.util.concurrent.FutureTask<V>具体是如何操作的。</p>
<p>在FutureTask中使用了一个<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">AQS</a>数据结构来完成各种状态以及加锁、阻塞的实现。</p>
<p>在此AQS类java.util.concurrent.FutureTask.Sync中一个任务用4中状态：</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-35--part-8--2_BFEA/ThreadPoolExecutor-FutureTask-state_2.png" target="_blank"><img src="&quot;ThreadPoolExecutor-FutureTask-state&quot;" alt="ThreadPoolExecutor-FutureTask-state"></a></p>
<p>初始情况下任务状态state=0，任务执行(innerRun)后状态变为运行状态RUNNING(state=1)，执行完毕后变成运行结束状态RAN(state=2)。任务在初始状态或者执行状态被取消后就变为状态CANCELLED(state=4)。<a href="http://www.blogjava.net/xylz/archive/2010/07/06/325390.html" target="_blank">AQS</a>最擅长无锁情况下处理几种简单的状态变更的。
        void innerRun() {
            if (!compareAndSetState(0, RUNNING))
                return;
            try {
                runner = Thread.currentThread();
                if (getState() == RUNNING) // recheck after setting thread
                    innerSet(callable.call());
                else
                    releaseShared(0); // cancel
            } catch (Throwable ex) {
                innerSetException(ex);
            }
        }</p>
<p>执行一个任务有四步：设置运行状态、设置当前线程（AQS需要）、执行任务(Runnable/#run或者Callable/#call）、设置执行结果。这里也可以看到，一个任务只能执行一次，因为执行完毕后它的状态不在为初始值0，要么为CANCELLED，要么为RAN。</p>
<p>取消一个任务(cancel)又是怎样进行的呢？对比下前面取消任务的描述是不是很简单，这里无非利用AQS的状态来改变任务的执行状态，最终达到放弃未启动或者正在执行的任务的目的。
boolean innerCancel(boolean mayInterruptIfRunning) {
    for (;;) {
        int s = getState();
        if (ranOrCancelled(s))
            return false;
        if (compareAndSetState(s, CANCELLED))
            break;
    }
    if (mayInterruptIfRunning) {
        Thread r = runner;
        if (r != null)
            r.interrupt();
    }
    releaseShared(0);
    done();
    return true;
}</p>
<p>到目前为止我们依然没有说明到底是如何阻塞获取一个结果的。下面四段代码描述了这个过程。</p>
<p>1     V innerGet() throws InterruptedException, ExecutionException {
2         acquireSharedInterruptibly(0);
3         if (getState() == CANCELLED)
4             throw new CancellationException();
5         if (exception != null)
6             throw new ExecutionException(exception);
7         return result;
8     }
9     //AQS/#acquireSharedInterruptibly
10     public final void acquireSharedInterruptibly(int arg) throws InterruptedException {
11         if (Thread.interrupted())
12             throw new InterruptedException();
13         if (tryAcquireShared(arg) &lt; 0)
14             doAcquireSharedInterruptibly(arg); //park current Thread for result
15     }
16     protected int tryAcquireShared(int ignore) {
17         return innerIsDone()? 1 : -1;
18     }
19 
20     boolean innerIsDone() {
21         return ranOrCancelled(getState()) &amp;&amp; runner == null;
22     }</p>
<p>当调用Future/#get()的时候尝试去获取一个共享变量。这就涉及到AQS的使用方式了。这里获取一个共享变量的状态是任务是否结束(innerIsDone())，也就是任务是否执行完毕或者被取消。如果不满足条件，那么在AQS中就会doAcquireSharedInterruptibly(arg)挂起当前线程，直到满足条件。AQS前面讲过，挂起线程使用的是LockSupport的park方式，因此性能消耗是很低的。</p>
<p>至于将Runnable接口转换成Callable接口，java.util.concurrent.Executors.callable(Runnable, T)也提供了一个简单实现。
    static final class RunnableAdapter<T> implements Callable<T> {
        final Runnable task;
        final T result;
        RunnableAdapter(Runnable  task, T result) {
            this.task = task;
            this.result = result;
        }
        public T call() {
            task.run();
            return result;
        }
    }</p>
<p><strong>延迟、周期性任务调度的实现</strong></p>
<p>java.util.concurrent.ScheduledThreadPoolExecutor是默认的延迟、周期性任务调度的实现。</p>
<p>有了整个线程池的实现，再回头来看延迟、周期性任务调度的实现应该就很简单了，因为所谓的延迟、周期性任务调度，无非添加一系列有序的任务队列，然后按照执行顺序的先后来处理整个任务队列。如果是周期性任务，那么在执行完毕的时候加入下一个时间点的任务即可。</p>
<p>由此可见，ScheduledThreadPoolExecutor和ThreadPoolExecutor的唯一区别在于任务是有序（按照执行时间顺序）的，并且需要到达时间点（临界点）才能执行，并不是任务队列中有任务就需要执行的。也就是说唯一不同的就是任务队列BlockingQueue<Runnable> workQueue不一样。ScheduledThreadPoolExecutor的任务队列是java.util.concurrent.ScheduledThreadPoolExecutor.DelayedWorkQueue，它是基于java.util.concurrent.DelayQueue<RunnableScheduledFuture>队列的实现。</p>
<p>DelayQueue是基于有序队列<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>实现的。<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a> 也叫优先级队列，按照自然顺序对元素进行排序，类似于TreeMap/Collections.sort一样。</p>
<p>同样是有序队列，DelayQueue和<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>区别在什么地方？</p>
<p>由于DelayQueue在获取元素时需要检测元素是否“可用”，也就是任务是否达到“临界点”（指定时间点），因此加入元素和移除元素会有一些额外的操作。</p>
<p>典型的，移除元素需要检测元素是否达到“临界点”，增加元素的时候如果有一个元素比“头元素”更早达到临界点，那么就需要通知任务队列。因此这需要一个条件变量final Condition available 。</p>
<p>移除元素（出队列）的过程是这样的：</p>
<ul>
<li>总是检测队列的头元素（顺序最小元素，也是最先达到临界点的元素）</li>
<li>检测头元素与当前时间的差，如果大于0，表示还未到底临界点，因此等待响应时间（使用条件变量available)</li>
<li>如果小于或者等于0，说明已经到底临界点或者已经过了临界点，那么就移除头元素，并且唤醒其它等待任务队列的线程。
  public E take() throws InterruptedException {<pre><code>  final ReentrantLock lock = this.lock;
  lock.lockInterruptibly();
  try {
      for (;;) {
          E first = q.peek();
          if (first == null) {
              available.await();
          } else {
              long delay =  first.getDelay(TimeUnit.NANOSECONDS);
              if (delay &gt; 0) {
                  long tl = available.awaitNanos(delay);
              } else {
                  E x = q.poll();
                  assert x != null;
                  if (q.size() != 0)
                      available.signalAll(); // wake up other takers
                  return x;
              }
          }
      }
  } finally {
      lock.unlock();
  }
</code></pre>  }</li>
</ul>
<p>同样加入元素也会有相应的条件变量操作。当前仅当队列为空或者要加入的元素比队列中的头元素还小的时候才需要唤醒“等待线程”去检测元素。因为头元素都没有唤醒那么比头元素更延迟的元素就更加不会唤醒。</p>
<pre><code>public boolean offer(E e) {
    final ReentrantLock lock = this.lock;
    lock.lock();
    try {
        E first = q.peek();
        q.offer(e);
        if (first == null || e.compareTo(first) &lt; 0)
            available.signalAll();
        return true;
    } finally {
        lock.unlock();
    }
}
</code></pre><p>有了任务队列后再来看Future在ScheduledThreadPoolExecutor中是如何操作的。</p>
<p>java.util.concurrent.ScheduledThreadPoolExecutor.ScheduledFutureTask<V>是继承java.util.concurrent.FutureTask<V>的，区别在于执行任务是否是周期性的。
        private void runPeriodic() {
            boolean ok = ScheduledFutureTask.super.runAndReset();
            boolean down = isShutdown();
            // Reschedule if not cancelled and not shutdown or policy allows
            if (ok &amp;&amp; (!down ||
                       (getContinueExistingPeriodicTasksAfterShutdownPolicy() &amp;&amp;
                        !isStopped()))) {
                long p = period;
                if (p &gt; 0)
                    time += p;
                else
                    time = now() - p;
                ScheduledThreadPoolExecutor.super.getQueue().add(this);
            }
            // This might have been the final executed delayed
            // task.  Wake up threads to check.
            else if (down)
                interruptIdleWorkers();
        }
        //<em>/</em>
         /<em> Overrides FutureTask version so as to reset/requeue if periodic.
         /</em>/
        public void run() {
            if (isPeriodic())
                runPeriodic();
            else
                ScheduledFutureTask.super.run();
        }
    }</p>
<p>如果不是周期性任务调度，那么就和java.util.concurrent.FutureTask.Sync的调度方式是一样的。如果是周期性任务（isPeriodic()）那么就稍微有所不同的。</p>
<p><a href="http://www.blogjava.net/images/blogjava_net/xylz/Windows-Live-Writer/-Java-Concurrency-35--part-8--2_BFEA/ScheduledThreadPoolExecutor-ScheduledFutureTask_4.png" target="_blank"><img src="&quot;ScheduledThreadPoolExecutor-ScheduledFutureTask&quot;" alt="ScheduledThreadPoolExecutor-ScheduledFutureTask"></a></p>
<p>先从功能/结构上分析下。第一种情况假设提交的任务每次执行花费10s，间隔（delay/period)为20s，对于scheduleAtFixedRate而言，每次执行开始时间20s，对于scheduleWithFixedDelay来说每次执行开始时间30s。第二种情况假设提交的任务每次执行时间花费20s，间隔（delay/period)为10s，对于scheduleAtFixedRate而言，每次执行开始时间10s，对于scheduleWithFixedDelay来说每次执行开始时间30s。（具体分析可以参考<a href="http://www.blogjava.net/xylz/archive/2011/01/10/342738.html" target="_blank">这里</a>）</p>
<p>也就是说scheduleWithFixedDelay的执行开始时间为(delay+cost)，而对于scheduleAtFixedRate来说执行开始时间为max(period,cost)。</p>
<p>回头再来看上面源码runPeriodic()就很容易了。但特别要提醒的，如果任务的任何一个执行遇到异常，则后续执行都会被取消，这从runPeriodic()就能看出。要强调的第二点就是<strong>同一个周期性任务不会被同时执行</strong>。就比如说尽管上面第二种情况的scheduleAtFixedRate任务每隔10s执行到达一个时间点，但是由于每次执行时间花费为20s，因此每次执行间隔为20s，只不过执行的任务次数会多一点。但从本质上讲就是每隔20s执行一次，如果任务队列不取消的话。</p>
<p>为什么不会同时执行？</p>
<p>这是因为ScheduledFutureTask执行的时候会将任务从队列中移除来，执行完毕以后才会添加下一个同序列的任务，因此任务队列中其实最多只有同序列的任务的一份副本，所以永远不会同时执行（尽管要执行的时间在过去）。</p>
<p>ScheduledThreadPoolExecutor使用一个无界（容量无限，整数的最大值）的容器（DelayedWorkQueue队列），根据<a href="http://www.blogjava.net/xylz/archive/2011/02/11/344091.html" target="_blank">ThreadPoolExecutor</a>的原理，只要当容器满的时候才会启动一个大于corePoolSize的线程数。因此实际上ScheduledThreadPoolExecutor是一个固定线程大小的线程池，固定大小为corePoolSize，构造函数里面的Integer.MAX_VALUE其实是不生效的（尽管<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>使用数组实现有<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>大小限制，如果你的任务数超过了2147483647就会导致OutOfMemoryError，这个参考<a href="http://www.blogjava.net/xylz/archive/2010/07/30/327582.html" target="_blank">PriorityQueue</a>的grow方法）。</p>
<p>再回头看scheduleAtFixedRate等方法就容易多了。无非就是往任务队列中添加一个未来某一时刻的ScheduledFutureTask任务，如果是scheduleAtFixedRate那么period/delay就是正数，如果是scheduleWithFixedDelay那么period/delay就是一个负数，如果是0那么就是一次性任务。直接调用父类<a href="http://www.blogjava.net/xylz/archive/2011/02/11/344091.html" target="_blank">ThreadPoolExecutor</a>的execute/submit等方法就相当于period/delay是0，并且initialDelay也是0。
    public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command,
                                                  long initialDelay,
                                                  long period,
                                                  TimeUnit unit) {
        if (command == null || unit == null)
            throw new NullPointerException();
        if (period &lt;= 0)
            throw new IllegalArgumentException();
        if (initialDelay &lt; 0) initialDelay = 0;
        long triggerTime = now() + unit.toNanos(initialDelay);
        RunnableScheduledFuture&lt;?&gt; t = decorateTask(command,
            new ScheduledFutureTask<Object>(command,
                                            null,
                                            triggerTime,
                                            unit.toNanos(period)));
        delayedExecute(t);
        return t;
    }</p>
<p>另外需要补充说明的一点，前面说过java.util.concurrent.FutureTask.Sync任务只能执行一次，那么在runPeriodic()里面怎么又将执行过的任务加入队列中呢？这是因为java.util.concurrent.FutureTask.Sync提供了一个innerRunAndReset()方法，此方法不仅执行任务还将任务的状态还原成0（初始状态）了，所以此任务就可以重复执行。这就是为什么runPeriodic()里面调用runAndRest()的缘故。</p>
<pre><code>    boolean innerRunAndReset() {
        if (!compareAndSetState(0, RUNNING))
            return false;
        try {
            runner = Thread.currentThread();
            if (getState() == RUNNING)
                callable.call(); // don&#39;t set result
            runner = null;
            return compareAndSetState(RUNNING, 0);
        } catch (Throwable ex) {
            innerSetException(ex);
            return false;
        }
    }
</code></pre><p><strong>后话</strong></p>
<p>整个并发实践原理和实现（源码）上的东西都讲完了，后面几个小节是一些总结和扫尾的工作，包括超时机制、异常处理等一些细节问题。也就是说大部分只需要搬出一些理论和最佳实践知识出来就好了，不会有大量费脑筋的算法分析和原理、思想探讨之类的。后面的章节也会加快一些进度。</p>
<p>老实说从刚开始的好奇到中间的兴奋，再到现在的彻悟，收获还是很多，个人觉得这是最认真、最努力也是自我最满意的一次技术研究和探讨，同时在这个过程中将很多技术细节都串联起来了，慢慢就有了那种技术相通的感觉。原来有了理论以后再去实践、再去分析问题、解决问题和那种纯解决问题得到的经验完全不一样。整个专辑下来不仅仅是并发包这一点点知识，设计到硬件、软件、操作系统、网络、安全、性能、算法、理论等等，总的来说这也算是一次比较成功的研究切入点，这比<a href="http://www.blogjava.net/xylz/archive/2009/12/22/306955.html" target="_blank">Guice</a>那次探讨要深入和持久的多。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/02/13/344207.html](http://www.blogjava.net/xylz/archive/2011/02/13/344207.html)">[http://www.blogjava.net/xylz/archive/2011/02/13/344207.html](http://www.blogjava.net/xylz/archive/2011/02/13/344207.html)</a> </p>
<p><a href="http://www.blogjava.net/xylz/archive/2011/07/12/354206.html" target="_blank">并发操作异常体系</a> </p>
<p>并发包引入的工具类很多方法都会抛出一定的异常，这些异常描述了任务在线程池中执行时发生的例外情况，而通常这些例外需要应用程序进行捕捉和处理。</p>
<p>例如在Future接口中有如下一个API：</p>
<p>java.util.concurrent.Future.get(long, TimeUnit) throws InterruptedException, ExecutionException, TimeoutException;</p>
<p>在<a href="http://www.blogjava.net/xylz/archive/2011/02/13/344207.html" target="_blank">前面的章节</a>中描述了Future类的具体实现原理。这里不再讨论，但是比较好奇的抛出的三个异常。</p>
<p>这里有一篇文章（<a href="http://www.ibm.com/developerworks/cn/java/j-jtp05236.html" target="_blank">Java 理论与实践: 处理 InterruptedException</a>）描述了InterruptedException的来源和处理方式。简单的说就是线程在执行的过程中被自己或者别人中断了。这时候为了响应中断就需要处理当前的异常。</p>
<p>对于java.lang.Thread而言，InterruptedException也是一个很诡异的问题。</p>
<p>中断一个线程Thread.<strong>interrupt()</strong>时会触发下面一种情况：
如果线程在调用 Object 类的 wait()、wait(long) 或 wait(long, int) 方法，或者该类的 join()、join(long)、join(long, int)、sleep(long) 或 sleep(long, int) 方法过程中受阻，则其中断状态将被清除，它还将收到一个 InterruptedException。</p>
<p>检测一个线程的中断状态描述是这样的Thread.<strong>interrupted()：</strong></p>
<p>测试当前线程是否已经中断。线程的<em>中断状态</em> 由该方法清除。换句话说，如果连续两次调用该方法，则第二次调用将返回 false（在第一次调用已清除了其中断状态之后，且第二次调用检验完中断状态前，当前线程再次中断的情况除外）。 </p>
<p>也就是说如果检测到一个线程已经被中断了，那么线程的使用方（挂起、等待或者正在执行）都将应该得到一个中断异常，同时将会清除异常中断状态。</p>
<p>V innerGet(long nanosTimeout) throws InterruptedException, ExecutionException, TimeoutException {
    if (!tryAcquireSharedNanos(0, nanosTimeout))
        throw new TimeoutException();
    if (getState() == CANCELLED)
        throw new CancellationException();
    if (exception != null)
        throw new ExecutionException(exception);
    return result;
}</p>
<p>上面获取任务结果的方法实现中，将在获取锁的过程中得到一个中断异常。代码java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(int, long)描述了这种情况：
    public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) throws InterruptedException {
    if (Thread.interrupted())
        throw new InterruptedException();
    return tryAcquireShared(arg) &gt;= 0 ||
        doAcquireSharedNanos(arg, nanosTimeout);
    }</p>
<p>这里在获取锁的时候检测线程中断情况，如果被中断则清除中断位，同时抛出一个中断异常。为什么如此做？因为我们的线程在线程池中是被重复执行的，所以一旦线程被中断后并不会退出线程，而是设置中断位，等候任务队列自己处理线程，从而达到线程被重复利用的目的。有兴趣的可以参考代码java.util.concurrent.ThreadPoolExecutor.Worker.runTask(Runnable)。这里在关闭线程池时就会导致中断所有线程。</p>
<p>除了InterruptedException 异常我们还发现了一个全新的异常java.util.concurrent.TimeoutException，此异常是用来描述任务执行时间超过了期望等待时间，也许是一直没有获取到锁，也许是还没有执行完成。</p>
<p>在innerGet代码片段中我们看到，如果线程在指定的时间无法获取到锁，那么就会得到一个超时异常。这个很好理解，比如如果执行一个非常耗时的网络任务，我们不希望任务一直等待从而占用大量的资源，可能在一定时间后就会希望取消此操作。此时超时异常很好的描述了这种需求。</p>
<p>与此同时，如果取消了一个任务，那么再次从任务中获取执行结果，那么将会得到一个任务被取消的异常java.util.concurrent.CancellationException。</p>
<p>除了上述异常外，还将得到一个java.util.concurrent.ExecutionException异常，</p>
<p>这是因为我们的提交的任务java.util.concurrent.Callable在call()方法中允许抛出任何异常，另外常规的线程执行也可能抛出一个RuntimeException，所以这里简单包装了下所有异常，当作执行过程中发生的异常ExecutionException抛出。</p>
<p>以上就是整个异常体系，所有并发操作的异常都可以归结于上述几类。</p>
<p>很多情况下处理时间长度都是用<strong>java.util.concurrent.TimeUnit</strong>，这是一个枚举类型，用来描述时间长度。其中内置了一些长度的单位。其中包括纳秒、微秒、毫秒、秒、分、时、天。例如超时操作5秒，可以使用</p>
<p>Future.get(5,TimeUnit.SECONDS) 或者 Future.get(5000L,TimeUnit.MILLISECONDS)</p>
<p>当然一种单位的时间转换成另一种单位的时间也是非常方便的。另外还有线程的sleep/join以及对象的wait操作的便捷操作。
来源： <a href="[http://www.blogjava.net/xylz/archive/2011/07/12/354206.html](http://www.blogjava.net/xylz/archive/2011/07/12/354206.html)">[http://www.blogjava.net/xylz/archive/2011/07/12/354206.html](http://www.blogjava.net/xylz/archive/2011/07/12/354206.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency28-线程池/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency28-线程池" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>



  <article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title"><a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency2-原子操作/">深入浅出 Java Concurrency (2)</a></h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:41.000Z"> <a href="/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency2-原子操作/">feb. 2 2014</a></time></span>      
    </header>
    
    
    <div class="entry">
      
        <h1 id="-java-concurrency-2-">深入浅出 Java Concurrency (2): 原子操作</h1>
<p>从相对简单的Atomic入手（java.util.concurrent是基于Queue的并发包，而Queue，很多情况下使用到了Atomic操作，因此首先从这里开始）。很多情况下我们只是需要一个简单的、高效的、线程安全的递增递减方案。注意，这里有三个条件：简单，意味着程序员尽可能少的操作底层或者实现起来要比较容易；高效意味着耗用资源要少，程序处理速度要快；线程安全也非常重要，这个在多线程下能保证数据的正确性。这三个条件看起来比较简单，但是实现起来却难以令人满意。</p>
<p>通常情况下，在Java里面，++i或者--i不是线程安全的，这里面有三个独立的操作：或者变量当前值，为该值+1/-1，然后写回新的值。在没有额外资源可以利用的情况下，只能使用加锁才能保证读-改-写这三个操作时“原子性”的。</p>
<p>Doug Lea在未将<a href="http://backport-jsr166.sourceforge.net/" target="_blank">backport-util-concurrent</a>合并到<a href="http://jcp.org/en/jsr/detail?id=166" target="_blank">JSR 166</a>里面来之前，是采用纯Java实现的，于是不可避免的采用了synchronized关键字。</p>
<p>public final synchronized void set(int newValue);</p>
<p>public final synchronized int getAndSet(int newValue);</p>
<p>public final synchronized int incrementAndGet();</p>
<p>同时在变量上使用了volatile （后面会具体来讲volatile到底是个什么东东）来保证get()的时候不用加锁。尽管synchronized的代价还是很高的，但是在没有JNI的手段下纯Java语言还是不能实现此操作的。</p>
<p>JSR 166提上日程后，backport-util-concurrent就合并到JDK 5.0里面了，在这里面重复使用了现代CPU的特性来降低锁的消耗。后本章的最后小结中会谈到这些原理和特性。在此之前先看看API的使用。</p>
<p>一切从java.util.concurrent.atomic.AtomicInteger开始。</p>
<p>int addAndGet(int delta)
          以原子方式将给定值与当前值相加。 实际上就是等于线程安全版本的i =i+delta操作。</p>
<p>boolean compareAndSet(int expect, int update)
          如果当前值 == 预期值，则以原子方式将该值设置为给定的更新值。 如果成功就返回true，否则返回false，并且不修改原值。</p>
<p>int decrementAndGet()
          以原子方式将当前值减 1。 相当于线程安全版本的--i操作。</p>
<p>int get()
          获取当前值。</p>
<p>int getAndAdd(int delta)
          以原子方式将给定值与当前值相加。 相当于线程安全版本的t=i;i+=delta;return t;操作。</p>
<p>int getAndDecrement()
          以原子方式将当前值减 1。 相当于线程安全版本的i--操作。</p>
<p>int getAndIncrement()
          以原子方式将当前值加 1。 相当于线程安全版本的i++操作。</p>
<p>int getAndSet(int newValue)
          以原子方式设置为给定值，并返回旧值。 相当于线程安全版本的t=i;i=newValue;return t;操作。</p>
<p>int incrementAndGet()
          以原子方式将当前值加 1。 相当于线程安全版本的++i操作。 </p>
<p>void lazySet(int newValue)
          最后设置为给定值。 延时设置变量值，这个等价于set()方法，但是由于字段是volatile类型的，因此次字段的修改会比普通字段（非volatile字段）有稍微的性能延时（尽管可以忽略），所以如果不是想立即读取设置的新值，允许在“后台”修改值，那么此方法就很有用。如果还是难以理解，这里就类似于启动一个后台线程如执行修改新值的任务，原线程就不等待修改结果立即返回（这种解释其实是不正确的，但是可以这么理解）。</p>
<p>void set(int newValue)
          设置为给定值。 直接修改原始值，也就是i=newValue操作。</p>
<p>boolean weakCompareAndSet(int expect, int update)
          如果当前值 == 预期值，则以原子方式将该设置为给定的更新值。JSR规范中说：以原子方式读取和有条件地写入变量但<em>不</em> 创建任何 happen-before 排序，因此不提供与除 weakCompareAndSet 目标外任何变量以前或后续读取或写入操作有关的任何保证。大意就是说调用weakCompareAndSet时并不能保证不存在happen-before的发生（也就是可能存在指令重排序导致此操作失败）。但是从Java源码来看，其实此方法并没有实现JSR规范的要求，最后效果和compareAndSet是等效的，都调用了unsafe.compareAndSwapInt()完成操作。
下面的代码是一个测试样例，为了省事就写在一个方法里面来了。
<img src="" alt="">package xylz.study.concurrency.atomic;
<img src="" alt="">
<img src="" alt="">import java.util.concurrent.atomic.AtomicInteger;
<img src="" alt="">
<img src="" alt="">import org.junit.Test;
<img src="" alt="">
<img src="" alt="">import static org.junit.Assert./*;
<img src="" alt="">
<img src="" alt="">public class AtomicIntegerTest {
<img src="" alt="">
<img src="" alt="">    @Test
<img src="" alt="">    public void testAll() throws InterruptedException{
<img src="" alt="">        final AtomicInteger value = new AtomicInteger(10);
<img src="" alt="">        assertEquals(value.compareAndSet(1, 2), false);
<img src="" alt="">        assertEquals(value.get(), 10);
<img src="" alt="">        assertTrue(value.compareAndSet(10, 3));
<img src="" alt="">        assertEquals(value.get(), 3);
<img src="" alt="">        value.set(0);
<img src="" alt="">        //
<img src="" alt="">        assertEquals(value.incrementAndGet(), 1);
<img src="" alt="">        assertEquals(value.getAndAdd(2),1);
<img src="" alt="">        assertEquals(value.getAndSet(5),3);
<img src="" alt="">        assertEquals(value.get(),5);
<img src="" alt="">        //
<img src="" alt="">        final int threadSize = 10;
<img src="" alt="">        Thread[] ts = new Thread[threadSize];
<img src="" alt="">        for (int i = 0; i &lt; threadSize; i++) {
<img src="" alt="">            ts[i] = new Thread() {
<img src="" alt="">                public void run() {
<img src="" alt="">                    value.incrementAndGet();
<img src="" alt="">                }
<img src="" alt="">            };
<img src="" alt="">        }
<img src="" alt="">        //
<img src="" alt="">        for(Thread t:ts) {
<img src="" alt="">            t.start();
<img src="" alt="">        }
<img src="" alt="">        for(Thread t:ts) {
<img src="" alt="">            t.join();
<img src="" alt="">        }
<img src="" alt="">        //
<img src="" alt="">        assertEquals(value.get(), 5+threadSize);
<img src="" alt="">    }
<img src="" alt="">
<img src="" alt="">}
<img src="" alt="">
 由于这里例子比较简单，这里就不做过多介绍了。
AtomicInteger和AtomicLong、AtomicBoolean、AtomicReference差不多，这里就不介绍了。在下一篇中就介绍下数组、字段等其他方面的原子操作。
 参考资料：
(1)<a href="http://stackoverflow.com/questions/2443239/java-atomicinteger-what-are-the-differences-between-compareandset-and-weakcompar" target="_blank"><a href="http://stackoverflow.com/questions/2443239/java-atomicinteger-what-are-the-differences-between-compareandset-and-weakcompar">http://stackoverflow.com/questions/2443239/java-atomicinteger-what-are-the-differences-between-compareandset-and-weakcompar</a></a>
(2)<a href="http://stackoverflow.com/questions/1468007/atomicinteger-lazyset-and-set" target="_blank"><a href="http://stackoverflow.com/questions/1468007/atomicinteger-lazyset-and-set">http://stackoverflow.com/questions/1468007/atomicinteger-lazyset-and-set</a></a></p>
<p>来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/01/324988.html](http://www.blogjava.net/xylz/archive/2010/07/01/324988.html)">[http://www.blogjava.net/xylz/archive/2010/07/01/324988.html](http://www.blogjava.net/xylz/archive/2010/07/01/324988.html)</a></p>
<p>在这一部分开始讨论数组原子操作和一些其他的原子操作。</p>
<p><strong>AtomicIntegerArray/AtomicLongArray/AtomicReferenceArray</strong>的API类似，选择有代表性的AtomicIntegerArray来描述这些问题。</p>
<p><strong>int get(int i)</strong></p>
<p>获取位置 </p>
<p>i
 的当前值。很显然，由于这个是数组操作，就有索引越界的问题（IndexOutOfBoundsException异常）。</p>
<p>对于下面的API起始和AtomicInteger是类似的，这种通过方法、参数的名称就能够得到函数意义的写法是非常值得称赞的。在<a href="http://www.china-pub.com/12901" target="_blank">《重构：改善既有代码的设计》</a>和<a href="http://www.china-pub.com/196266" target="_blank">《代码整洁之道》</a>中都非常推崇这种做法。</p>
<p><strong>void set(int i, int newValue)</strong>
<strong>void lazySet(int i, int newValue)
int getAndSet(int i, int newValue)
boolean compareAndSet(int i, int expect, int update)
boolean weakCompareAndSet(int i, int expect, int update)
int getAndIncrement(int i)
int getAndDecrement(int i)
int getAndAdd(int i, int delta)
int incrementAndGet(int i)
int decrementAndGet(int i)
int addAndGet(int i, int delta)</strong></p>
<p>整体来说，数组的原子操作在理解上还是相对比较容易的，这些API就是有多使用才能体会到它们的好处，而不仅仅是停留在理论阶段。</p>
<p>现在关注字段的原子更新。</p>
<p><strong>AtomicIntegerFieldUpdater<T>/AtomicLongFieldUpdater<T>/AtomicReferenceFieldUpdater<T,V></strong>是基于反射的原子更新字段的值。</p>
<p>相应的API也是非常简单的，但是也是有一些约束的。</p>
<p>（1）字段必须是volatile类型的！在后面的章节中会详细说明为什么必须是volatile，volatile到底是个什么东西。</p>
<p>（2）字段的描述类型（修饰符public/protected/default/private）是与调用者与操作对象字段的关系一致。也就是说调用者能够直接操作对象字段，那么就可以反射进行原子操作。但是对于父类的字段，子类是不能直接操作的，尽管子类可以访问父类的字段。</p>
<p>（3）只能是实例变量，不能是类变量，也就是说不能加static关键字。</p>
<p>（4）只能是可修改变量，不能使final变量，因为final的语义就是不可修改。实际上final的语义和volatile是有冲突的，这两个关键字不能同时存在。</p>
<p>（5）对于<strong>AtomicIntegerFieldUpdater</strong>和<strong>AtomicLongFieldUpdater</strong>只能修改int/long类型的字段，不能修改其包装类型（Integer/Long）。如果要修改包装类型就需要使用<strong>AtomicReferenceFieldUpdater</strong>。</p>
<p>在下面的例子中描述了操作的方法。</p>
<p><img src="" alt="">package xylz.study.concurrency.atomic; 
<img src="" alt="">
<img src="" alt="">import java.util.concurrent.atomic.AtomicIntegerFieldUpdater; 
<img src="" alt="">
<img src="" alt="">public class AtomicIntegerFieldUpdaterDemo { 
<img src="" alt="">
<img src="" alt="">   class DemoData{
<img src="" alt="">       public volatile int value1 = 1;
<img src="" alt="">       volatile int value2 = 2;
<img src="" alt="">       protected volatile int value3 = 3;
<img src="" alt="">       private volatile int value4 = 4;
<img src="" alt="">   }
<img src="" alt="">    AtomicIntegerFieldUpdater<DemoData> getUpdater(String fieldName) {
<img src="" alt="">        return AtomicIntegerFieldUpdater.newUpdater(DemoData.class, fieldName);
<img src="" alt="">    }
<img src="" alt="">    void doit() {
<img src="" alt="">        DemoData data = new DemoData();
<img src="" alt="">        System.out.println(&quot;1 ==&gt; &quot;+getUpdater(&quot;value1&quot;).getAndSet(data, 10));
<img src="" alt="">        System.out.println(&quot;3 ==&gt; &quot;+getUpdater(&quot;value2&quot;).incrementAndGet(data));
<img src="" alt="">        System.out.println(&quot;2 ==&gt; &quot;+getUpdater(&quot;value3&quot;).decrementAndGet(data));
<img src="" alt="">        System.out.println(&quot;true ==&gt; &quot;+getUpdater(&quot;value4&quot;).compareAndSet(data, 4, 5));
<img src="" alt="">    }
<img src="" alt="">    public static void main(String[] args) {
<img src="" alt="">        AtomicIntegerFieldUpdaterDemo demo = new AtomicIntegerFieldUpdaterDemo();
<img src="" alt="">        demo.doit();
<img src="" alt="">    }
<img src="" alt="">} 
<img src="" alt="">
<img src="" alt=""></p>
<p>在上面的例子中DemoData的字段value3/value4对于AtomicIntegerFieldUpdaterDemo类是不可见的，因此通过反射是不能直接修改其值的。</p>
<p><strong>AtomicMarkableReference</strong>类描述的一个<Object,Boolean>的对，可以原子的修改Object或者Boolean的值，这种数据结构在一些缓存或者状态描述中比较有用。这种结构在单个或者同时修改Object/Boolean的时候能够有效的提高吞吐量。</p>
<p><strong>AtomicStampedReference</strong>类维护带有整数“标志”的对象引用，可以用原子方式对其进行更新。对比<strong>AtomicMarkableReference</strong>类的<Object,Boolean>，<strong>AtomicStampedReference</strong>维护的是一种类似<Object,int>的数据结构，其实就是对对象（引用）的一个并发计数。但是与<strong>AtomicInteger</strong>不同的是，此数据结构可以携带一个对象引用（Object），并且能够对此对象和计数同时进行原子操作。</p>
<p>在后面的章节中会提到“ABA问题”，而<strong>AtomicMarkableReference/**</strong>AtomicStampedReference<strong>在解决“ABA问题”上很有用</strong>。**</p>
<hr>
<p>原子操作的使用大概就是这么多，大体来说还算是比较清晰的，在下一个章节中，将对象原子操作进行总结，重点介绍下原子操作的原理和设计思想。
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/02/325079.html](http://www.blogjava.net/xylz/archive/2010/07/02/325079.html)">[http://www.blogjava.net/xylz/archive/2010/07/02/325079.html](http://www.blogjava.net/xylz/archive/2010/07/02/325079.html)</a> </p>
<p>在这个小结里面重点讨论原子操作的原理和设计思想。</p>
<p>由于在下一个章节中会谈到锁机制，因此此小节中会适当引入锁的概念。</p>
<p>在<a href="http://www.amazon.com/exec/obidos/ASIN/0321349601/ref=nosim/none0b69" title="http://www.amazon.com/exec/obidos/ASIN/0321349601/ref=nosim/none0b69" target="_blank">Java Concurrency in Practice</a>中是这样定义线程安全的：
<strong>当多个线程访问一个类时，如果不用考虑这些线程在运行时环境下的调度和交替运行，并且不需要额外的同步及在调用方代码不必做其他的协调，这个类的行为仍然是正确的，那么这个类就是线程安全的。</strong></p>
<p>显然只有资源竞争时才会导致线程不安全，因此<strong><em>无状态对象永远是线程安全的</em></strong>。</p>
<p>原子操作的描述是： 多个线程执行一个操作时，其中<strong><em>任何一个线程要么完全执行完此操作，要么没有执行此操作的任何步骤</em></strong>，那么这个操作就是原子的。</p>
<p>枯燥的定义介绍完了，下面说更枯燥的理论知识。</p>
<p><strong>指令重排序</strong></p>
<p>Java语言规范规定了JVM线程内部维持顺序化语义，也就是说只要程序的最终结果等同于它在严格的顺序化环境下的结果，那么指令的执行顺序就可能与代码的顺序不一致。这个过程通过叫做指令的重排序。指令重排序存在的意义在于：JVM能够根据处理器的特性（CPU的多级缓存系统、多核处理器等）适当的重新排序机器指令，使机器指令更符合CPU的执行特点，最大限度的发挥机器的性能。</p>
<p>程序执行最简单的模型是按照指令出现的顺序执行，这样就与执行指令的CPU无关，最大限度的保证了指令的可移植性。这个模型的专业术语叫做顺序化一致性模型。但是现代计算机体系和处理器架构都不保证这一点（因为人为的指定并不能总是保证符合CPU处理的特性）。</p>
<p>我们来看最经典的一个案例。
<img src="" alt="">package xylz.study.concurrency.atomic; 
<img src="" alt="">
<img src="" alt="">public class ReorderingDemo { 
<img src="" alt="">
<img src="" alt="">    static int x = 0, y = 0, a = 0, b = 0; 
<img src="" alt="">
<img src="" alt="">    public static void main(String[] args) throws Exception { 
<img src="" alt="">
<img src="" alt="">        for (int i = 0; i &lt; 100; i++) {
<img src="" alt="">            x=y=a=b=0;
<img src="" alt="">            Thread one = new Thread() {
<img src="" alt="">                public void run() {
<img src="" alt="">                    a = 1;
<img src="" alt="">                    x = b;
<img src="" alt="">                }
<img src="" alt="">            };
<img src="" alt="">            Thread two = new Thread() {
<img src="" alt="">                public void run() {
<img src="" alt="">                    b = 1;
<img src="" alt="">                    y = a;
<img src="" alt="">                }
<img src="" alt="">            };
<img src="" alt="">            one.start();
<img src="" alt="">            two.start();
<img src="" alt="">            one.join();
<img src="" alt="">            two.join();
<img src="" alt="">            System.out.println(x + &quot; &quot; + y);
<img src="" alt="">        }
<img src="" alt="">    } 
<img src="" alt="">
<img src="" alt="">}
<img src="" alt="">
<img src="" alt="">
在这个例子中one/two两个线程修改区x,y,a,b四个变量，在执行100次的情况下，可能得到(0 1)或者（1 0）或者（1 1）。事实上按照JVM的规范以及CPU的特性有很可能得到（0 0）。当然上面的代码大家不一定能得到（0 0），因为run()里面的操作过于简单，可能比启动一个线程花费的时间还少，因此上面的例子难以出现（0,0）。但是在现代CPU和JVM上确实是存在的。由于run()里面的动作对于结果是无关的，因此里面的指令可能发生指令重排序，即使是按照程序的顺序执行，数据变化刷新到主存也是需要时间的。假定是按照a=1;x=b;b=1;y=a;执行的，x=0是比较正常的，虽然a=1在y=a之前执行的，但是由于线程one执行a=1完成后还没有来得及将数据1写回主存（这时候数据是在线程one的堆栈里面的），线程two从主存中拿到的数据a可能仍然是0（显然是一个过期数据，但是是有可能的），这样就发生了数据错误。</p>
<p>在两个线程交替执行的情况下数据的结果就不确定了，在机器压力大，多核CPU并发执行的情况下，数据的结果就更加不确定了。</p>
<p><strong>Happens-before法则</strong></p>
<p>Java存储模型有一个happens-before原则，就是如果动作B要看到动作A的执行结果（无论A/B是否在同一个线程里面执行），那么A/B就需要满足happens-before关系。</p>
<p>在介绍happens-before法则之前介绍一个概念：JMM动作（Java Memeory Model Action），Java存储模型动作。一个动作（Action）包括：变量的读写、监视器加锁和释放锁、线程的start()和join()。后面还会提到锁的的。</p>
<p>happens-before完整规则：
（1）同一个线程中的每个Action都happens-before于出现在其后的任何一个Action。</p>
<p>（2）对一个监视器的解锁happens-before于每一个后续对同一个监视器的加锁。</p>
<p>（3）对volatile字段的写入操作happens-before于每一个后续的同一个字段的读操作。</p>
<p>（4）Thread.start()的调用会happens-before于启动线程里面的动作。</p>
<p>（5）Thread中的所有动作都happens-before于其他线程检查到此线程结束或者Thread.join（）中返回或者Thread.isAlive()==false。</p>
<p>（6）一个线程A调用另一个另一个线程B的interrupt（）都happens-before于线程A发现B被A中断（B抛出异常或者A检测到B的isInterrupted（）或者interrupted()）。</p>
<p>（7）一个对象构造函数的结束happens-before与该对象的finalizer的开始</p>
<p>（8）如果A动作happens-before于B动作，而B动作happens-before与C动作，那么A动作happens-before于C动作。</p>
<p><strong>volatile语义</strong></p>
<p>到目前为止，我们多次提到volatile，但是却仍然没有理解volatile的语义。</p>
<p>volatile相当于synchronized的弱实现，也就是说volatile实现了类似synchronized的语义，却又没有锁机制。它确保对volatile字段的更新以可预见的方式告知其他的线程。</p>
<p>volatile包含以下语义：</p>
<p>（1）Java 存储模型不会对valatile指令的操作进行重排序：这个保证对volatile变量的操作时按照指令的出现顺序执行的。</p>
<p>（2）volatile变量不会被缓存在寄存器中（只有拥有线程可见）或者其他对CPU不可见的地方，每次总是从主存中读取volatile变量的结果。也就是说对于volatile变量的修改，其它线程总是可见的，并且不是使用自己线程栈内部的变量。也就是在happens-before法则中，对一个valatile变量的写操作后，其后的任何读操作理解可见此写操作的结果。</p>
<p>尽管volatile变量的特性不错，但是volatile并不能保证线程安全的，也就是说volatile字段的操作不是原子性的，volatile变量只能保证可见性（一个线程修改后其它线程能够理解看到此变化后的结果），要想保证原子性，目前为止只能加锁！</p>
<p>volatile通常在下面的场景：</p>
<p><img src="" alt="">volatile boolean done = false;
<img src="" alt="">
<img src="" alt="">…
<img src="" alt="">
<img src="" alt="">    while( ! done ){
<img src="" alt="">        dosomething();
<img src="" alt="">    }</p>
<p>应用volatile变量的三个原则：
（1）写入变量不依赖此变量的值，或者只有一个线程修改此变量</p>
<p>（2）变量的状态不需要与其它变量共同参与不变约束</p>
<p>（3）访问变量不需要加锁</p>
<p><strong>这一节理论知识比较多，但是这是很面很多章节的基础，在后面的章节中会多次提到这些特性。</strong></p>
<p>本小节中还是没有谈到原子操作的原理和思想，在下一节中将根据上面的一些知识来介绍原子操作。</p>
<p>参考资料：</p>
<p>（1）<a href="http://www.amazon.com/exec/obidos/ASIN/0321349601/ref=nosim/none0b69" title="http://www.amazon.com/exec/obidos/ASIN/0321349601/ref=nosim/none0b69" target="_blank">Java Concurrency in Practice</a></p>
<p>（2）<a href="http://www.ibm.com/developerworks/cn/java/j-jtp06197.html" target="_blank">正确使用 Volatile 变量</a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/03/325168.html](http://www.blogjava.net/xylz/archive/2010/07/03/325168.html)">[http://www.blogjava.net/xylz/archive/2010/07/03/325168.html](http://www.blogjava.net/xylz/archive/2010/07/03/325168.html)</a> </p>
<p>在JDK 5之前Java语言是靠synchronized关键字保证同步的，这会导致有锁（后面的章节还会谈到锁）。</p>
<p>锁机制存在以下问题：</p>
<p>（1）在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。</p>
<p>（2）一个线程持有锁会导致其它所有需要此锁的线程挂起。</p>
<p>（3）如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。</p>
<p>volatile是不错的机制，但是volatile不能保证原子性。因此对于同步最终还是要回到锁机制上来。</p>
<p>独占锁是一种悲观锁，synchronized就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。</p>
<p><strong>CAS 操作</strong></p>
<p>上面的乐观锁用到的机制就是CAS，Compare and Swap。</p>
<p>CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。</p>
<p><strong>非阻塞算法 （nonblocking algorithms）</strong>
一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。</p>
<p>现代的CPU提供了特殊的指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。</p>
<p>拿出AtomicInteger来研究在没有锁的情况下是如何做到数据正确性的。
private volatile int value;</p>
<p>首先毫无以为，在没有锁的机制下可能需要借助volatile原语，保证线程间的数据是可见的（共享的）。</p>
<p>这样才获取变量的值的时候才能直接读取。
public final int get() {
        return value;
    }</p>
<p>然后来看看++i是怎么做到的。</p>
<p>public final int incrementAndGet() {
    for (;;) {
        int current = get();
        int next = current + 1;
        if (compareAndSet(current, next))
            return next;
    }
}</p>
<p>在这里采用了CAS操作，每次从内存中读取数据然后将此数据和+1后的结果进行CAS操作，如果成功就返回结果，否则重试直到成功为止。</p>
<p>而compareAndSet利用JNI来完成CPU指令的操作。
public final boolean compareAndSet(int expect, int update) {<br>    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
    }</p>
<p>整体的过程就是这样子的，利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法。其它原子操作都是利用类似的特性完成的。</p>
<p>而整个J.U.C都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。参考资料的文章中介绍了如果利用CAS构建非阻塞计数器、队列等数据结构。</p>
<p>CAS看起来很爽，但是会导致“ABA问题”。</p>
<p>CAS算法实现一个重要前提需要取出内存中某时刻的数据，而在下时刻比较并替换，那么在这个时间差类会导致数据的变化。</p>
<p>比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。如果链表的头在变化了两次后恢复了原值，但是不代表链表就没有变化。因此前面提到的原子操作AtomicStampedReference/AtomicMarkableReference就很有用了。这允许一对变化的元素进行原子操作。</p>
<p>参考资料：</p>
<p>（1）<a href="http://www.ibm.com/developerworks/cn/java/j-jtp04186/" target="_blank">非阻塞算法简介</a></p>
<p>（2）<a href="https://www.ibm.com/developerworks/cn/java/j-jtp11234/" target="_blank">流行的原子</a>
来源： <a href="[http://www.blogjava.net/xylz/archive/2010/07/04/325206.html](http://www.blogjava.net/xylz/archive/2010/07/04/325206.html)">[http://www.blogjava.net/xylz/archive/2010/07/04/325206.html](http://www.blogjava.net/xylz/archive/2010/07/04/325206.html)</a> </p>

      
    </div>
    
    
      
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li></span><span class="breadcrumb"><li><a href="/categories/Java&J2EE/">Java&J2EE</a></li><li><a href="/categories/Java&J2EE/Java_多线程/">Java_多线程</a></li><li><a href="/categories/Java&J2EE/Java_多线程/并发/">并发</a></li></span></span> | <span class="tags">Tagged <a href="/tags/Java&J2EE/" class="label label-primary">Java&J2EE</a><a href="/tags/Java_多线程/" class="label label-success">Java_多线程</a><a href="/tags/并发/" class="label label-info">并发</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:41"datetime="2014-03-07 09:54:41"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency2-原子操作/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-JavaJ2EE-Java_多线程-并发--深入浅出JavaConcurrency2-原子操作" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>





<ul id="pagination" class="pagination pagination-lg">
  <li><a class="extend prev" href="/page/53/">&laquo;</a></li><li><a class="page-number" href="/">1</a></li><li><a class="page-number" href="/page/2/">2</a></li><li><span class="space">&hellip;</span></li><li><a class="page-number" href="/page/51/">51</a></li><li><a class="page-number" href="/page/52/">52</a></li><li><a class="page-number" href="/page/53/">53</a></li><li class="active"><li><span class="page-number current">54</span></li><li><a class="page-number" href="/page/55/">55</a></li><li><a class="page-number" href="/page/56/">56</a></li><li><a class="page-number" href="/page/57/">57</a></li><li><span class="space">&hellip;</span></li></li><li><a class="page-number" href="/page/164/">164</a></li><li><a class="page-number" href="/page/165/">165</a></li><li><a class="extend next" href="/page/55/">&raquo;</a></li>
  <div class="clearfix"></div>
</ul></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Blog powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a> Theme <strong><a href='https://github.com/chenall/hexo-theme-chenall'>chenall</a></strong>(Some change in it)<span class="pull-right"> 更新时间: <em>2014-03-15 16:47:45</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
