
<!DOCTYPE HTML>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>CentOS的Hadoop集群配置 | It so life</title>
<meta name="author" content="RobinChia">

<meta name="description" content="CentOS的Hadoop集群配置CentOS的Hadoop集群配置（一）
 
参考资料：

http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/">


<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<meta property="og:title" content="CentOS的Hadoop集群配置"/>
<meta property="og:site_name" content="It so life"/>

<!--[if IE]><style>.testIE.IE{display:inline;}</style><![endif]-->
<!--[if lte IE 7]><link rel="stylesheet" href="/css/ie7.css" type="text/css"><![endif]-->
<!--[if (lt IE 9)&(gt IE 7)]><style>.testIE.IE8{display:inline;}</style><![endif]-->
<!--[if gt IE 8]><style>.testIE.IE9{display:inline;}</style><![endif]-->

<link href="/favicon.png" rel="icon">
<link rel="alternate" href="/atom.xml" title="It so life Feed" type="application/atom+xml">

<link rel="stylesheet" href="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/css/bootstrap.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/font-awesome/4.0.3/css/font-awesome.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/prettify/r298/prettify.min.css" type="text/css">
<link rel="stylesheet" href="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" type="text/css">
<link rel="stylesheet" href="/css/style.css" type="text/css">
<!--[if lt IE 9]>
   <style>article,aside,dialog,footer,header,section,footer,nav,figure,menu{display:block}</style>
   <script src="http://cdn.staticfile.org/html5shiv/r29/html5.min.js"></script>
   <script src="http://cdn.staticfile.org/respond.js/1.4.2/respond.min.js"></script>
<link href="http://cdn.staticfile.org/respond.js/1.4.2/respond-proxy.html" id="respond-proxy" rel="respond-proxy" />
<link href="/js/respond.proxy.gif" id="respond-redirect" rel="respond-redirect" />
<script src="/js/respond.proxy.js"></script>
   <script src="http://cdn.bootcss.com/selectivizr/1.0.2/selectivizr-min.js"></script>
<![endif]-->
<script type="text/javascript">
function loadjs(c,d){var a=document.createElement("script");a.async=!0;a.type="text/javascript";a.src=c;a.charset=d||"gbk";(document.getElementsByTagName("HEAD")[0]||document.getElementsByTagName("BODY")[0]).appendChild(a)};
var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
var _js2load = [];
</script>

</head>
<body>
      <header id="header" class="container"><nav id="main-nav" class="navbar navbar-default navbar-fixed-top " role="navigation">
  <div class="container">
    <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
      <span class="sr-only">Toggle navigation</span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="/">It so life</a>
    </div>
    <div  class="collapse navbar-collapse">
      <ul  class="nav navbar-nav">
  
        <li><a href="/" title="Home">Home</a></li>      
        <li><a href="/about/" title="About">About</a></li>      
        <li><a href="/archives/" title="Archives">Archives</a></li>      
      <li class='dropdown'>
        <a class='dropdown-toggle' data-toggle='dropdown' href='#'>website<b class='caret'></b></a>
        <ul class='dropdown-menu pure-menu-selected'>
    
          <li><a href="//groups.google.com/forum/#!forum/pongba" title="TopLanguage">TopLanguage</a></li>    
          <li><a href="//itpub.net/" title="ITPub">ITPub</a></li>    
          <li><a href="//blog.jobbole.com/" title="Bole">Bole</a></li>    
          <li><a href="//nosql-database.org/" title="nosql">nosql</a></li>    
          <li><a href="//gitimmersion.googol.im/" title="Git">Git</a></li>    
        </ul>
      </li>
    
      </ul>
      <ul class="nav navbar-nav navbar-right">
      
        <li><a href="/atom.xml">RSS</a></li>
      
      
        <li><a href="https://twitter.com/robinchia">twitter</a></li>
      
      
      
      
        <li><a href="https://github.com/robinchia">github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
<div class="clearfix"></div>
</header>
  <div id='content' class="container">
     <div class="page-header-wrapper">
      <!--[if lt IE 9]><div class="alert alert-warning alert-dismissable"><button type="button" class="close" data-dismiss="alert" aria-hidden="true">&times;</button><strong>提示:</strong>您的浏览器版本太低了,建议升级到 <strong><a href="http://windows.microsoft.com/zh-cn/internet-explorer/download-ie" title="IE9">IE9</a></strong> 以上,本站使用<a href="https://www.google.com/intl/zh-CN/chrome/">Chrome浏览器</a>可以获得最好的显示效果.</div><![endif]-->
      <div class="page-header"><h1 align="center"><big>It so life</big> </h1>
        <h5 align="center"><big>love as life</big></h5>
      </div>
     </div>
     <div class="row">
       <div id="main-col" class="alignleft col-sx-12 col-sm-8 col-md-9 col-lg-9">
      <section id='header_widget'></section>
          <div id="wrapper"><article>
<div id="post" class="post well">
  <div class="post-content">
    <header class="well-sm">
      <i class="fa icon fa-5x pull-left"></i>
      <h1 class="title">CentOS的Hadoop集群配置</h1>
      
        <span>Posted on<time datetime="2014-02-02T01:54:36.000Z"> <a href="/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/">feb. 2 2014</a></time></span>      
    </header>
    
    <section id='before_content_widget'></section>
    <div class="entry">
      
        <h1 id="centos-hadoop-">CentOS的Hadoop集群配置</h1>
<h3 id="-centos-hadoop-http-blog-csdn-net-inte_sleeper-article-details-6569985-"><a href="http://blog.csdn.net/inte_sleeper/article/details/6569985" target="_blank">CentOS的Hadoop集群配置（一）</a></h3>
<h3 id="-"> </h3>
<p>参考资料：</p>
<p><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/" target="_blank"><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/">http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/</a></a></p>
<p><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/" target="_blank"><a href="http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/">http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-multi-node-cluster/</a></a></p>
<p><a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/" target="_blank"><a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/">http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/</a></a></p>
<p><a href="http://hadoop.apache.org/common/docs/current/cluster_setup.html" target="_blank"><a href="http://hadoop.apache.org/common/docs/current/cluster_setup.html">http://hadoop.apache.org/common/docs/current/cluster_setup.html</a></a></p>
<p>以下集群配置内容，以两台机器为例。其中一台是 master ，另一台是 slave1 。</p>
<p>master 上运行 name node, data node, task tracker, job tracker ， secondary name node ；</p>
<p>slave1 上运行 data node, task tracker 。</p>
<p>前面加 /* 表示对两台机器采取相同的操作</p>
<ol>
<li>安装 JDK /*</li>
</ol>
<p>yum install java-1.6.0-openjdk-devel</p>
<ol>
<li>设置环境变量 /*</li>
</ol>
<p>编辑 /etc/profile 文件，设置 JAVA_HOME 环境变量以及类路径：</p>
<p>export JAVA_HOME=&quot;/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0.x86_64&quot;</p>
<p>export PATH=$PATH:$JAVA_HOME/bin</p>
<p>export CLASSPATH=.:$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar</p>
<ol>
<li>添加 hosts 的映射 /*</li>
</ol>
<p>编辑 /etc/hosts 文件，<strong>注意</strong> <strong>host name **</strong>不要有下划线，见下步骤 9**</p>
<p>192.168.225.16 master</p>
<p>192.168.225.66 slave1</p>
<ol>
<li>配置 SSH /*</li>
</ol>
<p>cd /root &amp; mkdir .ssh</p>
<p>chmod 700 .ssh &amp; cd .ssh</p>
<p>创建密码为空的 RSA 密钥对：</p>
<p>ssh-keygen -t rsa -P &quot;&quot;</p>
<p>在提示的对称密钥名称中输入 id_rsa</p>
<p>将公钥添加至 authorized_keys 中：</p>
<p>cat id_rsa.pub &gt;&gt; authorized_keys</p>
<p>chmod 644 authorized_keys <strong>/#</strong> <strong>重要</strong></p>
<p>编辑 sshd 配置文件 /etc/ssh/sshd_config ，把 /#AuthorizedKeysFile  .ssh/authorized_keys 前面的注释取消掉。</p>
<p>重启 sshd 服务：</p>
<p>service sshd restart</p>
<p>测试 SSH 连接。连接时会提示是否连接，按回车后会将此公钥加入至 knows_hosts 中：</p>
<p>ssh localhost</p>
<ol>
<li>配置 master 和 slave1 的 ssh 互通</li>
</ol>
<p>在 slave1 中重复步骤 4 ，然后把 slave1 中的 .ssh/authorized_keys 复制至 master 的 .ssh/authorized_keys中。注意复制过去之后，要看最后的类似 root@localhost 的字符串，修改成 root@slave1 。同样将 master的 key 也复制至 slave1 ，并将最后的串修改成 root@master 。</p>
<p>或者使用如下命令：</p>
<p>ssh-copy-id -i ~/.ssh/id_rsa.pub root@slave1</p>
<p>测试 SSH 连接：</p>
<p>在 master 上运行：</p>
<p>ssh slave1</p>
<p>在 slave1 上运行：</p>
<p>ssh master</p>
<ol>
<li>安装 Hadoop</li>
</ol>
<p>下载 hadoop 安装包：</p>
<p>wget <a href="http://mirror.bjtu.edu.cn/apache/hadoop/common/hadoop-0.20.203.0/hadoop-0.20.203.0rc1.tar.gz" target="_blank"><a href="http://mirror.bjtu.edu.cn/apache/hadoop/common/hadoop-0.20.203.0/hadoop-0.20.203.0rc1.tar.gz">http://mirror.bjtu.edu.cn/apache/hadoop/common/hadoop-0.20.203.0/hadoop-0.20.203.0rc1.tar.gz</a></a></p>
<p>复制安装包至 slave1 ：</p>
<p>scp hadoop-0.20.203.0rc1.tar.gz root@slave1:/root/</p>
<p>解压：</p>
<p>tar xzvf hadoop-0.20.203.0rc1.tar.gz</p>
<p>mkdir /usr/local/hadoop</p>
<p>mv hadoop-0.20.203.0//* /usr/local/hadoop</p>
<pre><code>     修改 .bashrc 文件（位于用户目录下，即 ~/.bashrc ，对于 root ，即为 /root/.bashrc ）

     添加环境变量：

     export HADOOP_HOME=/usr/local/hadoop

export PATH=$PATH:$HADOOP_HOME/bin
</code></pre><ol>
<li>配置 Hadoop 环境变量 /*</li>
</ol>
<p><strong>以下所有 hadoop **</strong>目录下的文件，均以相对路径 hadoop <strong>**开始</strong></p>
<p>修改 hadoop/conf/hadoop-env.sh 文件，将里面的 JAVA_HOME 改成步骤 2 中设置的值。</p>
<ol>
<li>创建 Hadoop 本地临时文件夹 /*</li>
</ol>
<p>mkdir /root/hadoop_tmp （<strong>注意这一步，千万不要放在</strong> <strong>/tmp **</strong>目录下面！！因为 <strong><strong>/tmp </strong></strong>默认分配的空间是很小的，往 <strong><strong>hdfs </strong></strong>里放几个大文件就会导致空间满了，就会报错）**</p>
<p>修改权限：</p>
<p>chown -R hadoop:hadoop /root/hadoop_tmp</p>
<p>更松地，也可以这样：</p>
<p>chmod –R 777 /root/hadoop_tmp</p>
<ol>
<li>配置 Hadoop</li>
</ol>
<p>修改 master 的 hadoop/conf/core-site.xml ，在 <configuration> 节中添加如下内容：</p>
<p>注意： <strong>fs.default.name **</strong>的值不能带下划线**</p>
<property>

    <name>hadoop.tmp.dir</name>

    <value>/root/hadoop<em>tmp/hadoop</em>${user.name}</value>

</property>

<property>

    <name>fs.default.name</name>

    <value>hdfs://localhost:54310</value> 

</property>

<property>

    <name>io.sort.mb</name>

    <value>1024</value> 

</property>

<pre><code>     其中 io.sort.mb 值，指定了排序使用的内存，大的内存可以加快 job 的处理速度。



     修改 hadoop/conf/mapred-site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>mapred.job.tracker</name>

    <value>localhost:54311</value>

</property>

<property>

    <name>mapred.map.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<property>

    <name>mapred.reduce.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<pre><code>     其中 mapred.map.child.java.opts, mapred.reduce.child.java.opts 分别指定 map/reduce 任务使用的最大堆内存。较小的内存可能导致程序抛出 OutOfMemoryException 。
</code></pre><p>修改 conf/hdfs -site.xml ，在 <configuration> 节中添加如下内容：</p>
<property>

    <name>dfs.replication</name>

    <value>2</value>

</property>



<p>同样，修改 slave1 的 /usr/local/hadoop/conf/core-site.xml ，在 <configuration> 节中添加如下内容：</p>
<property>

    <name>hadoop.tmp.dir</name>

    <value>/root/hadoop<em>tmp/hadoop</em>${user.name}</value>

</property>

<property>

    <name>fs.default.name</name>

    <value>hdfs://localhost:54310</value> 

</property>

<property>

    <name>io.sort.mb</name>

    <value>1024</value> 

</property>



<pre><code>     修改 conf/mapred-site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>mapred.job.tracker</name>

    <value>localhost:54311</value>

</property>

<property>

    <name>mapred.map.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<property>

    <name>mapred.reduce.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>



<pre><code>     修改 conf/hdfs -site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>dfs.replication</name>

    <value>2</value>

    </property>



<ol>
<li>修改 hadoop/bin/hadoop 文件</li>
</ol>
<p>把 221 行修改成如下。因为对于 root 用户， -jvm 参数是有问题的，所以需要加一个判断 ( 或者以非 root 用户运行这个脚本也没问题 )</p>
<p>HADOOP_OPTS=&quot;$HADOOP_OPTS -jvm server $HADOOP_DATANODE_OPTS&quot;  à</p>
<pre><code>/#for root, -jvm option is invalid.

CUR_USER=`whoami`

if [ &quot;$CUR_USER&quot; = &quot;root&quot; ]; then

    HADOOP_OPTS=&quot;$HADOOP_OPTS -server $HADOOP_DATANODE_OPTS&quot;

else

    HADOOP_OPTS=&quot;$HADOOP_OPTS -jvm server $HADOOP_DATANODE_OPTS&quot;

fi 
</code></pre><p>unset $CUR_USER</p>
<p>至此， master 和 slave1 都已经完成了 single_node 的搭建，可以分别在两台机器上测试单节点。</p>
<p>启动节点：</p>
<p>hadoop/bin/start-all.sh</p>
<p>运行 jps 命令，应能看到类似如下的输出：</p>
<p>937 DataNode</p>
<p>9232 Jps</p>
<p>8811 NameNode</p>
<p>12033 JobTracker</p>
<p>12041 TaskTracker
来源： <a href="[http://blog.csdn.net/inte_sleeper/article/details/6569985](http://blog.csdn.net/inte_sleeper/article/details/6569985)">[http://blog.csdn.net/inte_sleeper/article/details/6569985](http://blog.csdn.net/inte_sleeper/article/details/6569985)</a> </p>
<p><a href="http://blog.csdn.net/inte_sleeper/article/details/6569990" target="_blank">CentOS的Hadoop集群配置（二）</a>
下面的教程把它们合并至 multi-node cluster 。</p>
<ol>
<li>合并 single-node 至 multi-node cluster</li>
</ol>
<p>修改 master 的 hadoop/conf/core-site.xml ：</p>
<property>

    <name>hadoop.tmp.dir</name>

    <value>/root/hadoop<em>tmp/hadoop</em>${user.name}</value>

</property>

<property>

    <name>fs.default.name</name>

    <value>hdfs://<strong>master</strong> :54310</value>

</property>

<property>

    <name>io.sort.mb</name>

    <value>1024</value> 

</property>



<pre><code>     修改 conf/mapred-site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>mapred.job.tracker</name>

    <value><strong>master</strong> :54311</value>

</property>

<property>

    <name>mapred.map.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<property>

    <name>mapred.reduce.child.java.opts</name>

    <value>-Xmx4096m</value>

</property>

<pre><code>     修改 conf/hdfs -site.xml ，在 &lt;configuration&gt; 节中添加如下内容：
</code></pre><property>

    <name>dfs.replication</name>

    <value>2</value>

</property>

<p>把这三个文件复制至 slave1 相应的目录 hadoop/conf 中 <strong>( **</strong>即 master <strong><strong>和 slave1 </strong></strong>的内容完全一致 )**</p>
<pre><code>     修改所有节点的 hadoop/conf/masters ，把文件内容改成： master

     修改所有节点的 hadoop/conf/slaves ，把文件内容改成：
</code></pre><p>master</p>
<pre><code>slave1



     分别删除 master 和 slave1 的 dfs/data 文件：

     rm –rf /root/hadoop_tmp/hadoop_root/dfs/data
</code></pre><p>重新格式化 namenode ：</p>
<pre><code>     hadoop/bin/hadoop namenode -format



     测试，在 master 上运行：

     hadoop/bin/start-all.sh

     在 master 上运行 jps 命令
</code></pre><p>此时输出应类似于：</p>
<pre><code>     11648 TaskTracker
</code></pre><p>11166 NameNode</p>
<p>11433 SecondaryNameNode</p>
<p>12552 Jps</p>
<p>11282 DataNode</p>
<p>11525 JobTracker</p>
<p>在 slave1 上运行 jps</p>
<p>此时输出应包含 ( 即至少有 DataNode, 否则即为出错 ) ：</p>
<p>3950 Jps</p>
<p>3121 TaskTracker</p>
<p>3044 DataNode</p>
<ol>
<li>测试一个 JOB</li>
</ol>
<p>首先升级 python( 可选，如果 JOB 是 python 写的 ) ：</p>
<p>cd /etc/yum.repos.d/</p>
<p>wget <a href="http://mirrors.geekymedia.com/centos/geekymedia.repo" target="_blank">http://mirrors.geekymedia.com/centos/geekymedia.repo</a></p>
<p>yum makecache</p>
<p>yum -y install python26</p>
<p><strong>升级 python **</strong>的教程，见另外一篇文档。如果已经通过以上方法安装了 python2.6 <strong>**，那需要先卸载：</strong></p>
<p>yum remove python26 python26-devel</p>
<pre><code>     CentOS 的 yum 依赖于 python2.4 ，而 /usr/bin 中 python 程序即为 python2.4 。我们需要把它修改成python2.6 。



     cd /usr/bin/

     编辑 yum 文件，把第一行的
</code></pre><p>/#!/usr/bin/python   à   /#!/usr/bin/python2.4  </p>
<p>保存文件。</p>
<pre><code>     删除旧版本的 python 可执行文件（这个文件跟该目录下 python2.4 其实是一样的，所以可以直接删除）

     rm -f python

     让 python 指向 python2.6 的可执行程序。

     ln -s python26 python  
</code></pre><ol>
<li>Word count python 版本</li>
</ol>
<p><strong>Map.py</strong></p>
<p>/#! /usr/bin/python</p>
<p>import sys;</p>
<p>for line in sys.stdin:</p>
<p>  line =  line.strip();</p>
<p>  words = line.split();</p>
<p>  for word in words:</p>
<pre><code>  print &#39;%s/t%s&#39; % (word,1);
</code></pre><p><strong>Reduce.py</strong></p>
<p>/#!/usr/bin/python</p>
<p>import sys;</p>
<p>wc = {};</p>
<p>for line in sys.stdin:</p>
<p>  line = line.strip();</p>
<p>  word,count = line.split(&#39;/t&#39;,1);</p>
<p>  try:</p>
<pre><code>  count = int(count);
</code></pre><p>  except Error:</p>
<pre><code>  pass;
</code></pre><p>  if wc.has_key(word):</p>
<pre><code>  wc[word] += count;
</code></pre><p>  else: wc[word] = count;</p>
<p>for key in wc.keys():</p>
<p>  print &#39;%s/t%s&#39; % (key, wc[key]);</p>
<p>本机测试：</p>
<p>echo &quot;foo foo bar bar foo abc&quot; | map.py</p>
<p>echo &quot;foo foo bar bar foo abc&quot; | map.py | sort | reduce.py</p>
<p>在 hadoop 中测试：</p>
<p>hadoop jar /usr/local/hadoop/contrib/streaming/hadoop-streaming-0.20.203.0.jar -file mapper.py -mapper mapper.py -file reducer.py -reducer reducer.py -input wc//* -output wc-out</p>
<p>Job 成功后，会在 HDFS 中生成 wc-out 目录。</p>
<p>查看结果：</p>
<p>hadoop fs –ls wc-out</p>
<p>hadoop fs –cat wc-out/part-00000</p>
<ol>
<li>集群增加新节点</li>
</ol>
<p>a.       执行步骤 1 ， 2.</p>
<p>b.       修改 hosts 文件，将集群中的 hosts 加入本身 /etc/hosts 中。并修改集群中其他节点的 hosts ，将新节点加入。</p>
<p>c.       master 的 conf/slaves 文件中，添加新节点。</p>
<p>d.       启动 datanode 和 task tracker 。</p>
<p>hadoop-daemon.sh start datanode</p>
<p>hadoop-daemon.sh start tasktracker</p>
<ol>
<li>Trouble-shooting</li>
</ol>
<p>hadoop 的日志在 hadoop/logs 中。</p>
<p>其中， logs 根目录包含的是 namenode, datanode, jobtracker, tasktracker 等的日志。分别以 hadoop-{username}-namenode/datanode/jobtracker/tasktracker-hostname.log 命名。</p>
<p>userlogs 目录里包含了具体的 job 日志，每个 job 有一个单独的目录，以 job<em>YYYYmmddHHmm_xxxx 命名。里面包含数个 attempt</em>{jobname}<em>m_xxxxx 或 attempt</em>{jobname}_r_xxxx 等数个目录。其中目录名中的m 表示 map 任务的日志， r 表示 reduce 任务的日志。因此，出错时，可以有针对性地查看特定的日志。</p>
<p>常见错误：</p>
<ol>
<li>出现类似：</li>
</ol>
<p><em>ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: java.io.IOException: Incompatible namespaceIDs …</em></p>
<p>的异常，是因为先格式化了 namenode ，后来又修改了配置导致。将 dfs/data 文件夹内容删除，再重新格式化 namenode 即可。</p>
<ol>
<li>出现类似：</li>
</ol>
<p><em>INFO org.apache.hadoop.ipc.Client: Retrying connect to server:…</em></p>
<p>的异常，首先确认 name node 是否启动。如果已经启动，有可能是 master 或 slave1 中的配置出错，集群配置参考步骤 11 。也有可能是防火墙问题，需添加以下例外：</p>
<p>50010 端口用于数据传输， 50020 用于 RPC 调用， 50030 是 WEB 版的 JOB 状态监控， 54311 是job tracker ， 54310 是与 master 通信的端口。</p>
<p>完整的端口列表见：</p>
<p><a href="http://www.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/" target="_blank"><a href="http://www.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/">http://www.cloudera.com/blog/2009/08/hadoop-default-ports-quick-reference/</a></a></p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 50010 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 50020 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 50030 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 50060 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 54310 -j ACCEPT</p>
<p>iptables -A RH-Firewall-1-INPUT -p tcp -m tcp --dport 54311 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 50010 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 50020 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 50010 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 50020 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 50030 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 50030 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 50060 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 50060 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 54310 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 54310 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --dport 54311 -j ACCEPT</p>
<p>iptables -A OUTPUT -p tcp -m tcp --sport 54311 -j ACCEPT</p>
<p>保存规则：</p>
<p>/etc/init.d/iptables save</p>
<p>重启 iptables 服务：</p>
<p>service iptables restart</p>
<p>如果还是出现问题 2 的错误，那可能需要手工修改 /etc/sysconfig/iptables 的规则。手动添加这些规则。若有 ”reject-with icmp-host-prohibited” 的规则，需将规则加到它的前面。注意修改配置文件的时候，不需要带 iptables 命令。直接为类似于：</p>
<p>-A OUTPUT -p tcp -m tcp --sport 54311 -j ACCEPT</p>
<p>或关闭防火墙 <strong>( **</strong>建议，因为端口太多，要加的例外很多 )**</p>
<p>service iptables stop</p>
<ol>
<li><p>在 /etc/hosts 文件中，确保一个 host 只对应一个 IP ，否则会出错（如同时将 slave1 指向 127.0.0.1 和192.168.225.66 ），<strong>可能导致数据无法从一个节点复制至另一节点。</strong></p>
</li>
<li><p>出现类似：</p>
</li>
</ol>
<p><em>FATAL org.apache.hadoop.mapred.TaskTracker: Error running child : java.lang.OutOfMemoryError: Java heap space…</em></p>
<p>的异常，是因为堆内存不够。有以下几个地方可以考虑配置：</p>
<p>a.       conf/hadoop-env.sh 中， export HADOOP_HEAPSIZE=1000 这一行，默认为注释掉，堆大小为1000M ，可以取消注释，将这个值调大一些（对于 16G 的内存，可以调至 8G ）。</p>
<p>b.       conf/mapred-site.xml 中，添加 mapred.map.child.java.opts 属性，手动指定 JAVA 堆的参数值为 -Xmx2048m 或更大。这个值调整 map 任务的堆大小。即：</p>
<property>

    <name>mapred.map.child.java.opts </name>

    <value>-Xmx2048m</value>

</property>

<p>c.       conf/mapred-site.xml 中，添加 mapred.reduce.child.java.opts 属性，手动指定 JAVA 堆的参数值为 -Xmx2048m 或更大。这个值调整 reduce 任务的堆大小。即：</p>
<property>

    <name>mapred.reduce.child.java.opts </name>

    <value>-Xmx2048m</value>

</property>

<pre><code>               注意调整这些值之后，要重启 name node 。
</code></pre><p><em>5.       </em>出现类似： <em>java.io.IOException: File /user/root/pv_product_110124 could only be replicated to 0 nodes, instead of 1…</em></p>
<p>的异常，首先确保 hadoop 临时文件夹中有足够的空间，空间不够会导致这个错误。</p>
<p>如果空间没问题，那就尝试把临时文件夹中 dfs/data 目录删除，然后重新格式化 name node ：</p>
<p>hadoop namenode -format</p>
<p>注意：此命令会删除 hdfs 上的文件</p>
<p><em>6.       </em>出现类似： <em>java.io.IOException: Broken pipe…</em></p>
<p>的异常，检查你的程序吧，没准输出了不该输出的信息，如调试信息等。
来源： <a href="[http://blog.csdn.net/inte_sleeper/article/details/6569990](http://blog.csdn.net/inte_sleeper/article/details/6569990)">[http://blog.csdn.net/inte_sleeper/article/details/6569990](http://blog.csdn.net/inte_sleeper/article/details/6569990)</a> </p>

      
    </div>
    <section id='after_content_widget'><div class="widget" id="widget_after_content_wumiiRelatedItems>">
<script type="text/javascript" id="wumiiRelatedItems"></script>
</div><div class="widget" id="widget_after_content_post_footer_info>">
<div class="panel panel-success">
    <div class="panel-heading" align="center">希望本站内容对您有点用处,有什么疑问或建议请在后面留言评论</div>
    <div align="center" class="panel-body">转载请注明作者(<a href="http://itsolife.com/about/">RobinChia</a>)和出处 <a href="http://itsolife.com">It so life</a> ，请勿用于任何商业用途</div>
    <div class="panel-body">本文链接: <a href="/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/">CentOS的Hadoop集群配置</a></div>
</div>
</div></section>
    
    
        <footer id="post-meta">
        <span class="categories">Posted in<span class="breadcrumb fa fa-folder"><li><a href="/categories/hadoop/">hadoop</a></li></span></span> | <span class="tags">Tagged <a href="/tags/hadoop/" class="label label-primary">hadoop</a></span> | <span class="time">recent updated:<time title="2014-03-07 09:54:36"datetime="2014-03-07 09:54:36"> mar. 7 2014</time></span> | <span class="comment-link">
<a href="http://itsolife.com/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/#comments" class="ds-thread-count comment-link" data-thread-key="2014-02-02-hadoop--CentOS的Hadoop集群配置" data-count-type="comments">暂无评论</a></span>
        </footer>
    
    <div class="clearfix"></div>
  </div>
</div>
</article>


    <section id='after_post_widget'><div class="widget" id="widget_after_post_post_pageNav>">
<ul class="pager">
  
  <li class="previous"><a href="/2014/02/02/2014-02-02-linux--linux之cut用法/" title="linux之cut用法">&larr; linux之cut用法</a></li>
  
  
  <li class="next"><a href="/2014/02/02/2014-02-02-linux--linux之awk用法/" title="linux之awk用法">linux之awk用法 &rarr;</a></li>
  
</ul></div><div class="widget" id="widget_after_post_related_posts>">
<ul class="list-group"><li class="list-group-item"><a href="/2014/02/02/2014-02-02-hadoop--NotesforHadoopthedefinitiveguide/">Notes for Hadoop the definitive guide</a></li><li class="list-group-item"><a href="/2014/02/02/2014-02-02-hadoop--基于Hadoop220的高可用性集群搭建步骤（64位）/">基于Hadoop 2.2.0的高可用性集群搭建步骤（64位）</a></li><li class="list-group-item"><a href="/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/">CentOS的Hadoop集群配置</a></li><li class="list-group-item"><a href="/2014/02/02/2014-02-02-hadoop--hdfs_shell/">hdfs_shell</a></li><li class="list-group-item"><a href="/2014/02/02/2014-02-02-hadoop--hadoop/">hadoop</a></li><li class="list-group-item"><a href="/2014/02/02/2014-02-02-hadoop--Hadoop知识分享文稿byquqi99-技术并艺术着/">Hadoop知识分享文稿 ( by quqi99 ) </a></li><li class="list-group-item"><a href="/2014/02/02/2014-02-02-hadoop--JAVA线程池管理及分布式HADOOP调度框架搭建/">JAVA线程池管理及分布式HADOOP调度框架搭建</a></li><li class="list-group-item"><a href="/2014/02/02/2014-02-02-hadoop--Hadoop版本梳理/">Hadoop版本梳理</a></li></ul></div></section>    
	<div id="comments"><!-- Duoshuo Comment BEGIN -->

<div class="ds-thread"  data-thread-key="2014-02-02-hadoop--CentOS的Hadoop集群配置"  data-url="http://itsolife.com/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/" data-title="CentOS的Hadoop集群配置"></div>

		

<!-- Duoshuo Comment END -->

</div></div><!--wapper-->
       </div><!-- ID main-col END -->
       <aside id="sidebar" class="alignright col-sx-6 col-sm-4 col-md-3 col-lg-3">
<div id="widget_search" class="widget panel panel-primary">
    <form action="//google.com/search" method="get" accept-charset="utf-8">
  <div class="input-group">
    <input class="form-control" id="searchbox" type="search" name="q" results="0" placeholder="search">
    <span class="input-group-btn">
      <button class="btn btn-default" type="submit">Go!</button>
    </span>
    <input type="hidden" name="q" value="site:itsolife.com">
  </div>
</form>
</div>

<div id="widget_category" class="widget panel panel-primary">
  <div class="panel-heading">category</div>  <div data-src='category' class='ajax_widgets'>正在加载...</div>
</div>

<div id="widget_recent_posts" class="widget panel panel-primary">
  <div class="panel-heading">recent posts</div>  <div data-src='recent_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_tagcloud" class="widget panel panel-primary">
  <div class="panel-heading">tagcloud</div>  <div data-src='tagcloud' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_latest_update_posts" class="widget panel panel-primary">
  <div class="panel-heading">最近更新</div>  <div data-src='latest_update_posts' class='ajax_widgets'>正在加载...</div></div>

<div id="widget_recent_comments" class="widget panel panel-primary">
  <div class="panel-heading">recent comments</div>  

<div class="list-group-item ds-recent-comments" data-num-items="6" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="1" data-excerpt-length="50"></div>



</div>

</aside>
       <div class="clearfix"></div>
     </div><!-- row END -->
  </div>
  <footer id="footer" class="container">
  <div class="panel panel-info">
  <section id='footer_widget'></section>  <div class="panel-footer">
  <div id="site-info">
    <span class='author'>
  
  &copy; 2014 RobinChia
  
    &nbsp;&nbsp;</span>
  
  <span id='analytics-51la'></span><span id='analytics-google'>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-48559895-1']);
  _gaq.push(['_trackPageview']);
  _js2load.push({src:('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'});
</script></span><span id='analytics-cnzz'>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_5774006'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s17.cnzz.com/stat.php%3Fid%3D5774006%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</span><span id='analytics-baidu'>
<script>
var _hmt = _hmt || [];
_js2load.push({src:"//hm.baidu.com/hm.js?1442f50724afc42380b51f097c43082c"});
</script>
</span>  </div>
  <div id="copyright">Site powered by <a href='http://zespia.tw/hexo/'><strong>hexo</strong></a>  update time: <em>2014-03-07 09:54:36</em></span></div>
</div>
<div class="clearfix"></div>


  </div>
  </footer>
  
        <script src="http://cdn.bootcss.com/jquery/1.10.2/jquery.min.js"></script>        
        <script src="http://cdn.staticfile.org/twitter-bootstrap/3.1.0/js/bootstrap.min.js"></script>        
                
        <script src="http://cdn.bootcss.com/prettify/r298/prettify.min.js"></script>    <script type="text/javascript">
   var lang=["bsh", "c", "cc", "cpp", "cs", "csh", "cyc", "cv", "htm", "html",
    "java", "js", "m", "mxml", "perl", "pl", "pm", "py", "rb", "sh",
    "xhtml", "xml", "xsl"];
   var pretty_base='';
   $('script').each(function(){
	var c = $(this).attr('src');
	if (!c)
	    return;
	if (c.match(/(\/)?prettify(\.min)?\.js/i))
	{
	    var index = c.lastIndexOf('/');
	    if (index != -1)
		pretty_base = c.substr(0,index + 1);
	    return false;
	}
   })
   $('pre code').each(function(){
	var c = $(this).attr('class')
	if (!c)
	    return;
	c = c.match(/\s?(lang\-\w+)/i);
	if (c && lang.indexOf(c[1]) == -1)
	{
	    lang.push(c[1]);
	    $.getScript(pretty_base + c[1] + '.min.js');
	}
   })

    $(window).load(function(){
       $("pre").addClass("prettyprint");
       prettyPrint();
    })
</script>    
            <script type="text/javascript">
var duoshuoQuery = {short_name:"robinchia"};
_js2load.push({src:'http://static.duoshuo.com/embed.js',charset:'UTF-8'});
</script>
    
            <!--wumii_relatedItems-->

<script type="text/javascript">
    var wumiiPermaLink = "http://itsolife.com/2014/02/02/2014-02-02-hadoop--CentOS的Hadoop集群配置/";
    var wumiiTitle = "CentOS的Hadoop集群配置";
    var wumiiTags = "hadoop";
    var wumiiCategories = ["hadoop"];
    var wumiiSitePrefix = "http://itsolife.com";
    var wumiiParams = "&num=5&mode=3&pf=JAVASCRIPT";
    _js2load.push({src:'http://widget.wumii.cn/ext/relatedItemsWidget'});
</script>
<a href="http://www.wumii.com/widget/relatedItems" style="border:0;">
<img src="http://static.wumii.cn/images/pixel.png" alt="无觅关联推荐，快速提升流量" style="border:0;padding:0;margin:0;" />
</a>
    
        <script src="http://cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js"></script>    <script type="text/javascript">
(function($){
  $('.entry').each(function(i){
    $(this).find('img').each(function(){
      var alt = this.alt;

      if (alt){
        $(this).before('<span class="caption">' + alt + '</span>');
      }

      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox" rel="fancybox' + i + '" />');
    });
  });

  $('.fancybox').fancybox();
})(jQuery);
</script>    
        <script src="http://cdn.bootcss.com/mathjax/2.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>
    
<script type="text/javascript">
$('.ajax_widgets').each(function(){var src=$(this).attr('data-src');if(src)$(this).load('/widgets/'+src+'.html');});
$.each(_js2load,function(index,obj){loadjs(obj.src,obj.charset)});
</script>

<div id="scroll2top">
<img src="/scroll2top/arrow.png"/>
</div>
<script src="/scroll2top/scroll2top.min.js"></script>
<div id="winterland">
  <canvas></canvas>
</div>
<script src="/js/winterland.min.js"></script>

  </body>
</html>
